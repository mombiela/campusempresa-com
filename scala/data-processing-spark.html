<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Procesamiento de Datos con Spark</title>

    <link rel="alternate" href="https://campusempresa.com/scala/data-processing-spark" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/scala/data-processing-spark" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/scala/data-processing-spark" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/scala/data-processing-spark" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/scala/data-processing-spark" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='web-development-play-framework'>&#x25C4;Desarrollo Web con Play Framework</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Procesamiento de Datos con Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='building-rest-apis'>Construcción de APIs REST &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción a Apache Spark</h1>
<div class='content'><p>Apache Spark es un potente motor de análisis unificado de código abierto para el procesamiento de datos a gran escala. Proporciona una interfaz para programar clústeres completos con paralelismo de datos implícito y tolerancia a fallos.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>Resilient Distributed Datasets (RDDs):</strong> Colecciones distribuidas inmutables de objetos que pueden ser procesadas en paralelo.</li>
<li><strong>DataFrames:</strong> Colecciones distribuidas de datos organizadas en columnas con nombre, similar a una tabla en una base de datos relacional.</li>
<li><strong>Spark SQL:</strong> Módulo para trabajar con datos estructurados utilizando consultas SQL.</li>
<li><strong>Spark Streaming:</strong> Permite el procesamiento de flujos de datos en vivo de manera escalable y tolerante a fallos.</li>
<li><strong>MLlib:</strong> Biblioteca de aprendizaje automático para Spark.</li>
<li><strong>GraphX:</strong> API para gráficos y computación paralela de gráficos.</li>
</ul>
</div><h1>Configuración de Spark con Scala</h1>
<div class='content'><p>Para comenzar a usar Spark con Scala, necesitas configurar tu entorno de desarrollo.</p>
</div><h2>Pasos de Instalación</h2>
<div class='content'><ol>
<li><strong>Instalar Java Development Kit (JDK):</strong> Spark requiere Java para ejecutarse.</li>
<li><strong>Descargar e Instalar Apache Spark:</strong> Obtén la última versión desde el sitio web oficial.</li>
<li><strong>Configurar Scala:</strong> Instala Scala en tu máquina.</li>
<li><strong>Instalar un IDE:</strong> IntelliJ IDEA es recomendado para el desarrollo en Scala.</li>
</ol>
</div><h2>Ejemplo: Configuración de una Aplicación Simple de Spark</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgoKb2JqZWN0IFNpbXBsZUFwcCB7CiAgZGVmIG1haW4oYXJnczogQXJyYXlbU3RyaW5nXSk6IFVuaXQgPSB7CiAgICB2YWwgc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlcgogICAgICAuYXBwTmFtZSgiU2ltcGxlIEFwcGxpY2F0aW9uIikKICAgICAgLmNvbmZpZygic3BhcmsubWFzdGVyIiwgImxvY2FsIikKICAgICAgLmdldE9yQ3JlYXRlKCkKCiAgICB2YWwgZGF0YSA9IHNwYXJrLnJlYWQudGV4dEZpbGUoImRhdGEudHh0IikucmRkCiAgICB2YWwgbnVtQXMgPSBkYXRhLmZpbHRlcihsaW5lID0+IGxpbmUuY29udGFpbnMoImEiKSkuY291bnQoKQogICAgdmFsIG51bUJzID0gZGF0YS5maWx0ZXIobGluZSA9PiBsaW5lLmNvbnRhaW5zKCJiIikpLmNvdW50KCkKCiAgICBwcmludGxuKHMiTMOtbmVhcyBjb24gYTogJG51bUFzLCBMw61uZWFzIGNvbiBiOiAkbnVtQnMiKQoKICAgIHNwYXJrLnN0b3AoKQogIH0KfQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession

object SimpleApp {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder
      .appName(&quot;Simple Application&quot;)
      .config(&quot;spark.master&quot;, &quot;local&quot;)
      .getOrCreate()

    val data = spark.read.textFile(&quot;data.txt&quot;).rdd
    val numAs = data.filter(line =&gt; line.contains(&quot;a&quot;)).count()
    val numBs = data.filter(line =&gt; line.contains(&quot;b&quot;)).count()

    println(s&quot;L&iacute;neas con a: $numAs, L&iacute;neas con b: $numBs&quot;)

    spark.stop()
  }
}</pre></div><div class='content'><p>Explicación:</p>
<ul>
<li><strong>SparkSession:</strong> Punto de entrada para programar Spark con la API de Dataset y DataFrame.</li>
<li><strong>read.textFile:</strong> Lee un archivo de texto y devuelve un RDD.</li>
<li><strong>filter:</strong> Filtra el RDD basado en una condición.</li>
<li><strong>count:</strong> Cuenta el número de elementos en el RDD.</li>
</ul>
</div><h1>Trabajando con RDDs</h1>
<div class='content'><p>Los RDDs son la estructura de datos fundamental de Spark. Son colecciones inmutables y distribuidas de objetos.</p>
</div><h2>Creación de RDDs</h2>
<div class='content'><p>Puedes crear RDDs a partir de datos existentes en tu programa o desde conjuntos de datos externos.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIGRhdGEgPSBBcnJheSgxLCAyLCAzLCA0LCA1KQp2YWwgZGlzdERhdGEgPSBzcGFyay5zcGFya0NvbnRleHQucGFyYWxsZWxpemUoZGF0YSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val data = Array(1, 2, 3, 4, 5)
val distData = spark.sparkContext.parallelize(data)</pre></div><div class='content'></div><h2>Transformaciones y Acciones</h2>
<div class='content'><ul>
<li><strong>Transformaciones:</strong> Operaciones en RDDs que devuelven un nuevo RDD (e.g., <code>map</code>, <code>filter</code>).</li>
<li><strong>Acciones:</strong> Operaciones que devuelven un valor al programa controlador o escriben datos en un sistema de almacenamiento externo (e.g., <code>count</code>, <code>collect</code>).</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNwYXJrLnNwYXJrQ29udGV4dC5wYXJhbGxlbGl6ZShTZXEoMSwgMiwgMywgNCwgNSkpCnZhbCBtYXBwZWRSREQgPSByZGQubWFwKHggPT4geCAqIHgpCnZhbCBmaWx0ZXJlZFJERCA9IG1hcHBlZFJERC5maWx0ZXIoeCA9PiB4ID4gMTApCnZhbCByZXN1bHQgPSBmaWx0ZXJlZFJERC5jb2xsZWN0KCkKcmVzdWx0LmZvcmVhY2gocHJpbnRsbik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = spark.sparkContext.parallelize(Seq(1, 2, 3, 4, 5))
val mappedRDD = rdd.map(x =&gt; x * x)
val filteredRDD = mappedRDD.filter(x =&gt; x &gt; 10)
val result = filteredRDD.collect()
result.foreach(println)</pre></div><div class='content'></div><h1>Trabajando con DataFrames</h1>
<div class='content'><p>Los DataFrames son similares a los RDDs pero con optimizaciones adicionales y la capacidad de usar consultas SQL.</p>
</div><h2>Creación de DataFrames</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIGRmID0gc3BhcmsucmVhZC5qc29uKCJwZW9wbGUuanNvbiIpCmRmLnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val df = spark.read.json(&quot;people.json&quot;)
df.show()</pre></div><div class='content'></div><h2>Operaciones con DataFrames</h2>
<div class='content'><ul>
<li><strong>Select:</strong> Selecciona columnas específicas.</li>
<li><strong>Filter:</strong> Filtra filas basadas en una condición.</li>
<li><strong>GroupBy:</strong> Agrupa filas por una columna específica.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYuc2VsZWN0KCJuYW1lIiwgImFnZSIpLnNob3coKQpkZi5maWx0ZXIoJCJhZ2UiID4gMjEpLnNob3coKQpkZi5ncm91cEJ5KCJhZ2UiKS5jb3VudCgpLnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df.select(&quot;name&quot;, &quot;age&quot;).show()
df.filter($&quot;age&quot; &gt; 21).show()
df.groupBy(&quot;age&quot;).count().show()</pre></div><div class='content'></div><h1>Spark SQL</h1>
<div class='content'><p>Spark SQL te permite ejecutar consultas SQL en DataFrames.</p>
</div><h2>Ejemplo: Ejecutando Consultas SQL</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCnZhbCBzcWxERiA9IHNwYXJrLnNxbCgiU0VMRUNUICogRlJPTSBwZW9wbGUgV0hFUkUgYWdlID4gMjEiKQpzcWxERi5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df.createOrReplaceTempView(&quot;people&quot;)
val sqlDF = spark.sql(&quot;SELECT * FROM people WHERE age &gt; 21&quot;)
sqlDF.show()</pre></div><div class='content'></div><h1>Temas Avanzados</h1>
<h2>Spark Streaming</h2>
<div class='content'><p>Spark Streaming permite el procesamiento de datos en tiempo real.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3RyZWFtaW5nLl8KdmFsIHNzYyA9IG5ldyBTdHJlYW1pbmdDb250ZXh0KHNwYXJrLnNwYXJrQ29udGV4dCwgU2Vjb25kcygxKSkKdmFsIGxpbmVzID0gc3NjLnNvY2tldFRleHRTdHJlYW0oImxvY2FsaG9zdCIsIDk5OTkpCnZhbCB3b3JkcyA9IGxpbmVzLmZsYXRNYXAoXy5zcGxpdCgiICIpKQp2YWwgd29yZENvdW50cyA9IHdvcmRzLm1hcCh4ID0+ICh4LCAxKSkucmVkdWNlQnlLZXkoXyArIF8pCndvcmRDb3VudHMucHJpbnQoKQpzc2Muc3RhcnQoKQpzc2MuYXdhaXRUZXJtaW5hdGlvbigp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.streaming._
val ssc = new StreamingContext(spark.sparkContext, Seconds(1))
val lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)
val words = lines.flatMap(_.split(&quot; &quot;))
val wordCounts = words.map(x =&gt; (x, 1)).reduceByKey(_ + _)
wordCounts.print()
ssc.start()
ssc.awaitTermination()</pre></div><div class='content'></div><h2>Aprendizaje Automático con MLlib</h2>
<div class='content'><p>MLlib proporciona varios algoritmos de aprendizaje automático.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3BhcmsubWwuY2xhc3NpZmljYXRpb24uTG9naXN0aWNSZWdyZXNzaW9uCnZhbCB0cmFpbmluZyA9IHNwYXJrLnJlYWQuZm9ybWF0KCJsaWJzdm0iKS5sb2FkKCJkYXRhL21sbGliL3NhbXBsZV9saWJzdm1fZGF0YS50eHQiKQp2YWwgbHIgPSBuZXcgTG9naXN0aWNSZWdyZXNzaW9uKCkKdmFsIG1vZGVsID0gbHIuZml0KHRyYWluaW5nKQp2YWwgcmVzdWx0ID0gbW9kZWwudHJhbnNmb3JtKHRyYWluaW5nKQpyZXN1bHQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.ml.classification.LogisticRegression
val training = spark.read.format(&quot;libsvm&quot;).load(&quot;data/mllib/sample_libsvm_data.txt&quot;)
val lr = new LogisticRegression()
val model = lr.fit(training)
val result = model.transform(training)
result.show()</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En este tema, cubrimos los conceptos básicos del procesamiento de datos con Spark usando Scala, incluyendo la configuración de Spark, el trabajo con RDDs y DataFrames, la ejecución de consultas SQL, y la exploración de temas avanzados como Spark Streaming y MLlib. Las potentes APIs y optimizaciones de Spark lo convierten en una excelente opción para tareas de procesamiento de datos a gran escala.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='web-development-play-framework'>&#x25C4;Desarrollo Web con Play Framework</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Procesamiento de Datos con Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='building-rest-apis'>Construcción de APIs REST &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
