<!DOCTYPE html>
<html lang="es">
<head>
    <title> Proyecto 3: Desarrollo de un Agente con Aprendizaje Automático </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/ia-para-videojuegos/06-03-proyecto-agente" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/ia-per-a-videojocs/06-03-projecte-agent" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/ai-for-video-games/06-03-project-agent" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.188a386f47.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "es";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "ia_videojuegos";
  		var TEMA_NAME = "6-3";
  		var TYPE = "mod";
  		var PATH = "mod/ia_videojuegos/06-03-proyecto-agente";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo_header.png" alt="Logo Campus Empresa"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/courses/ai-for-video-games/06-03-project-agent" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/cursos/ia-per-a-videojocs/06-03-projecte-agent" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/mis-cursos" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Mis cursos</b></i>
</a>
<a href="/cursos-finalizados" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalizados             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="ia_videojuegos">
		<a  href="#" class="text-secondary d-none" data-read-mod="ia_videojuegos" data-read-unit="6-3" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar como leído
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="ia_videojuegos" data-unread-unit="6-3" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar como no leído
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contenido del curso
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-02-proyecto-npc' title="Proyecto 2: Creación de un NPC con Toma de Decisiones" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-02-proyecto-npc' title="Proyecto 2: Creación de un NPC con Toma de Decisiones" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Proyecto 3: Desarrollo de un Agente con Aprendizaje Automático</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='07-01-libros-articulos' title="Libros y Artículos Recomendados" class="py-2 px-3 btn btn-primary"
				data-read-mod="ia_videojuegos" data-read-unit="6-3">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='07-01-libros-articulos' title="Libros y Artículos Recomendados" class="py-2 px-3 btn btn-primary" 
				data-read-mod="ia_videojuegos" data-read-unit="6-3">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>En este proyecto, desarrollaremos un agente que utiliza técnicas de aprendizaje automático para mejorar su comportamiento en un entorno de videojuego. Este proyecto integrará conceptos de los módulos anteriores, especialmente del Módulo 4 sobre Aprendizaje Automático.</p>
</div><h2>Objetivos del Proyecto</h2>
<div class='content'><ol>
<li><strong>Comprender los fundamentos del aprendizaje automático aplicado a videojuegos.</strong></li>
<li><strong>Implementar un agente que aprende y mejora su desempeño a través de la experiencia.</strong></li>
<li><strong>Evaluar y optimizar el rendimiento del agente.</strong></li>
</ol>
</div><h2>Requisitos Previos</h2>
<div class='content'><ul>
<li>Conocimiento básico de programación en Python.</li>
<li>Familiaridad con conceptos de aprendizaje automático.</li>
<li>Comprensión de los algoritmos de navegación y toma de decisiones.</li>
</ul>
</div><h2>Herramientas Necesarias</h2>
<div class='content'><ul>
<li><strong>Python</strong>: Lenguaje de programación principal.</li>
<li><strong>TensorFlow o PyTorch</strong>: Librerías para implementar redes neuronales.</li>
<li><strong>Gym</strong>: Entorno de simulación para entrenar agentes de aprendizaje por refuerzo.</li>
</ul>
</div><h2>Paso 1: Configuración del Entorno</h2>
<div class='content'></div><h3>Instalación de Librerías</h3>
<div class='content'><p>Primero, asegúrate de tener instaladas las librerías necesarias. Puedes instalarlas usando <code>pip</code>:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("cGlwIGluc3RhbGwgbnVtcHkgdGVuc29yZmxvdyBneW0="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>pip install numpy tensorflow gym</pre></div><div class='content'></div><h3>Creación del Entorno de Simulación</h3>
<div class='content'><p>Utilizaremos el entorno <code>CartPole-v1</code> de Gym para este proyecto. Este entorno es sencillo y adecuado para principiantes en aprendizaje por refuerzo.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGd5bQoKZW52ID0gZ3ltLm1ha2UoJ0NhcnRQb2xlLXYxJyk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import gym

env = gym.make('CartPole-v1')</pre></div><div class='content'></div><h2>Paso 2: Implementación del Agente</h2>
<div class='content'></div><h3>Definición del Modelo</h3>
<div class='content'><p>Utilizaremos una red neuronal para que el agente aprenda a tomar decisiones. La red tendrá una capa de entrada, una capa oculta y una capa de salida.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzIGltcG9ydCBsYXllcnMKCmRlZiBjcmVhdGVfbW9kZWwoKToKICAgIG1vZGVsID0gdGYua2VyYXMuU2VxdWVudGlhbChbCiAgICAgICAgbGF5ZXJzLkRlbnNlKDI0LCBhY3RpdmF0aW9uPSdyZWx1JywgaW5wdXRfc2hhcGU9KDQsKSksCiAgICAgICAgbGF5ZXJzLkRlbnNlKDI0LCBhY3RpdmF0aW9uPSdyZWx1JyksCiAgICAgICAgbGF5ZXJzLkRlbnNlKDIsIGFjdGl2YXRpb249J2xpbmVhcicpCiAgICBdKQogICAgbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdtc2UnKQogICAgcmV0dXJuIG1vZGVsCgptb2RlbCA9IGNyZWF0ZV9tb2RlbCgp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import layers

def create_model():
    model = tf.keras.Sequential([
        layers.Dense(24, activation='relu', input_shape=(4,)),
        layers.Dense(24, activation='relu'),
        layers.Dense(2, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

model = create_model()</pre></div><div class='content'></div><h3>Función de Política</h3>
<div class='content'><p>La función de política decide la acción que el agente tomará en cada estado.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgpkZWYgcG9saWN5KHN0YXRlLCBtb2RlbCk6CiAgICBxX3ZhbHVlcyA9IG1vZGVsLnByZWRpY3Qoc3RhdGUpCiAgICByZXR1cm4gbnAuYXJnbWF4KHFfdmFsdWVzWzBdKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

def policy(state, model):
    q_values = model.predict(state)
    return np.argmax(q_values[0])</pre></div><div class='content'></div><h3>Entrenamiento del Agente</h3>
<div class='content'><p>El agente se entrenará utilizando el algoritmo Q-Learning con experiencia de repetición.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from collections import deque
import random

def train_agent(env, model, episodes=1000, gamma=0.99, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01, batch_size=32):
    memory = deque(maxlen=2000)
    for episode in range(episodes):
        state = env.reset()
        state = np.reshape(state, [1, 4])
        total_reward = 0
        done = False
        while not done:
            if np.random.rand() &lt;= epsilon:
                action = env.action_space.sample()
            else:
                action = policy(state, model)
            
            next_state, reward, done, _ = env.step(action)
            next_state = np.reshape(next_state, [1, 4])
            memory.append((state, action, reward, next_state, done))
            state = next_state
            total_reward += reward
            
            if done:
                print(f&quot;Episode: {episode+1}/{episodes}, Score: {total_reward}, Epsilon: {epsilon:.2}&quot;)
                break
            
            if len(memory) &gt; batch_size:
                minibatch = random.sample(memory, batch_size)
                for state, action, reward, next_state, done in minibatch:
                    target = reward
                    if not done:
                        target += gamma * np.amax(model.predict(next_state)[0])
                    target_f = model.predict(state)
                    target_f[0][action] = target
                    model.fit(state, target_f, epochs=1, verbose=0)
        
        if epsilon &gt; epsilon_min:
            epsilon *= epsilon_decay

train_agent(env, model)</pre></div><div class='content'></div><h2>Paso 3: Evaluación del Agente</h2>
<div class='content'></div><h3>Evaluación del Desempeño</h3>
<div class='content'><p>Después del entrenamiento, evaluaremos el desempeño del agente.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGV2YWx1YXRlX2FnZW50KGVudiwgbW9kZWwsIGVwaXNvZGVzPTEwMCk6CiAgICB0b3RhbF9yZXdhcmRzID0gMAogICAgZm9yIGVwaXNvZGUgaW4gcmFuZ2UoZXBpc29kZXMpOgogICAgICAgIHN0YXRlID0gZW52LnJlc2V0KCkKICAgICAgICBzdGF0ZSA9IG5wLnJlc2hhcGUoc3RhdGUsIFsxLCA0XSkKICAgICAgICBkb25lID0gRmFsc2UKICAgICAgICB3aGlsZSBub3QgZG9uZToKICAgICAgICAgICAgYWN0aW9uID0gcG9saWN5KHN0YXRlLCBtb2RlbCkKICAgICAgICAgICAgc3RhdGUsIHJld2FyZCwgZG9uZSwgXyA9IGVudi5zdGVwKGFjdGlvbikKICAgICAgICAgICAgc3RhdGUgPSBucC5yZXNoYXBlKHN0YXRlLCBbMSwgNF0pCiAgICAgICAgICAgIHRvdGFsX3Jld2FyZHMgKz0gcmV3YXJkCiAgICBhdmVyYWdlX3Jld2FyZCA9IHRvdGFsX3Jld2FyZHMgLyBlcGlzb2RlcwogICAgcHJpbnQoZiJBdmVyYWdlIFJld2FyZCBvdmVyIHtlcGlzb2Rlc30gZXBpc29kZXM6IHthdmVyYWdlX3Jld2FyZH0iKQoKZXZhbHVhdGVfYWdlbnQoZW52LCBtb2RlbCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def evaluate_agent(env, model, episodes=100):
    total_rewards = 0
    for episode in range(episodes):
        state = env.reset()
        state = np.reshape(state, [1, 4])
        done = False
        while not done:
            action = policy(state, model)
            state, reward, done, _ = env.step(action)
            state = np.reshape(state, [1, 4])
            total_rewards += reward
    average_reward = total_rewards / episodes
    print(f&quot;Average Reward over {episodes} episodes: {average_reward}&quot;)

evaluate_agent(env, model)</pre></div><div class='content'></div><h2>Paso 4: Optimización del Agente</h2>
<div class='content'></div><h3>Ajuste de Hiperparámetros</h3>
<div class='content'><p>Para mejorar el rendimiento del agente, podemos ajustar los hiperparámetros como la tasa de aprendizaje, el tamaño de la red neuronal y los parámetros de exploración/explotación.</p>
</div><h3>Implementación de Técnicas Avanzadas</h3>
<div class='content'><p>Podemos implementar técnicas avanzadas como Dueling DQN, Double DQN o Prioritized Experience Replay para mejorar aún más el rendimiento del agente.</p>
</div><h2>Conclusión</h2>
<div class='content'><p>En este proyecto, hemos desarrollado un agente que utiliza aprendizaje automático para mejorar su comportamiento en un entorno de videojuego. Hemos cubierto desde la configuración del entorno hasta la implementación y optimización del agente. Este proyecto proporciona una base sólida para explorar técnicas más avanzadas y aplicarlas a entornos de videojuegos más complejos.</p>
<hr />
<p><strong>Resumen del Proyecto:</strong></p>
<ul>
<li><strong>Configuración del entorno:</strong> Instalación de librerías y creación del entorno de simulación.</li>
<li><strong>Implementación del agente:</strong> Definición del modelo, función de política y entrenamiento del agente.</li>
<li><strong>Evaluación del agente:</strong> Evaluación del desempeño del agente después del entrenamiento.</li>
<li><strong>Optimización del agente:</strong> Ajuste de hiperparámetros e implementación de técnicas avanzadas.</li>
</ul>
<p>Con este conocimiento, estás preparado para desarrollar agentes más sofisticados y aplicar técnicas de aprendizaje automático en tus propios proyectos de videojuegos.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-02-proyecto-npc' title="Proyecto 2: Creación de un NPC con Toma de Decisiones" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-02-proyecto-npc' title="Proyecto 2: Creación de un NPC con Toma de Decisiones" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='07-01-libros-articulos' title="Libros y Artículos Recomendados" class="py-2 px-3 btn btn-primary"
				data-read-mod="ia_videojuegos" data-read-unit="6-3">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='07-01-libros-articulos' title="Libros y Artículos Recomendados" class="py-2 px-3 btn btn-primary" 
				data-read-mod="ia_videojuegos" data-read-unit="6-3">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>IA para Videojuegos</h1>
<h2>Módulo 1: Introducción a la IA en Videojuegos</h2>
<ul>
<li><a href="01-01-historia-evolucion">Historia y Evolución de la IA en Videojuegos</a></li>
<li><a href="01-02-conceptos-basicos">Conceptos Básicos de IA</a></li>
<li><a href="01-03-herramientas-lenguajes">Herramientas y Lenguajes de Programación</a></li>
</ul>
<h2>Módulo 2: Navegación en Videojuegos</h2>
<ul>
<li><a href="02-01-algoritmos-busqueda">Algoritmos de Búsqueda de Caminos</a></li>
<li><a href="02-02-implementacion-a-estrella">Implementación de A*</a></li>
<li><a href="02-03-navegacion-navmesh">Navegación con NavMesh</a></li>
<li><a href="02-04-evitacion-obstaculos">Evitación de Obstáculos</a></li>
</ul>
<h2>Módulo 3: Toma de Decisiones</h2>
<ul>
<li><a href="03-01-maquinas-estados-finite">Máquinas de Estados Finite (FSM)</a></li>
<li><a href="03-02-arboles-decision">Árboles de Decisión</a></li>
<li><a href="03-03-behavior-trees">Behavior Trees</a></li>
<li><a href="03-04-sistemas-reglas">Sistemas Basados en Reglas</a></li>
</ul>
<h2>Módulo 4: Aprendizaje Automático</h2>
<ul>
<li><a href="04-01-introduccion-aprendizaje">Introducción al Aprendizaje Automático</a></li>
<li><a href="04-02-redes-neuronales">Redes Neuronales en Videojuegos</a></li>
<li><a href="04-03-aprendizaje-refuerzo">Aprendizaje por Refuerzo</a></li>
<li><a href="04-04-implementacion-agente">Implementación de un Agente de Aprendizaje</a></li>
</ul>
<h2>Módulo 5: Integración y Optimización</h2>
<ul>
<li><a href="05-01-integracion-motores">Integración de IA en Motores de Juego</a></li>
<li><a href="05-02-optimizacion-algoritmos">Optimización de Algoritmos de IA</a></li>
<li><a href="05-03-pruebas-depuracion">Pruebas y Depuración de IA</a></li>
</ul>
<h2>Módulo 6: Proyectos Prácticos</h2>
<ul>
<li><a href="06-01-proyecto-navegacion">Proyecto 1: Implementación de Navegación Básica</a></li>
<li><a href="06-02-proyecto-npc">Proyecto 2: Creación de un NPC con Toma de Decisiones</a></li>
<li><a href="06-03-proyecto-agente">Proyecto 3: Desarrollo de un Agente con Aprendizaje Automático</a></li>
</ul>
<h2>Módulo 7: Recursos Adicionales</h2>
<ul>
<li><a href="07-01-libros-articulos">Libros y Artículos Recomendados</a></li>
<li><a href="07-02-comunidades-foros">Comunidades y Foros</a></li>
<li><a href="07-03-herramientas-librerias">Herramientas y Librerías Útiles</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuario no autenticado</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
