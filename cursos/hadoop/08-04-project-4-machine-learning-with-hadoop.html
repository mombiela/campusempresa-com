<!DOCTYPE html>
<html lang="es">
<head>
    <title> Proyecto 4: Aprendizaje Automático con Hadoop </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/hadoop/08-04-project-4-machine-learning-with-hadoop" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/hadoop/08-04-project-4-machine-learning-with-hadoop" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/hadoop/08-04-project-4-machine-learning-with-hadoop" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.1ab297bfa4.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "es";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "hadoop";
  		var TEMA_NAME = "8-4";
  		var TYPE = "mod";
  		var PATH = "mod/hadoop/08-04-project-4-machine-learning-with-hadoop";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.ae32789132.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo_header.png" alt="Logo Campus Empresa"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/courses/hadoop/08-04-project-4-machine-learning-with-hadoop" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/cursos/hadoop/08-04-project-4-machine-learning-with-hadoop" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/mis-cursos" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Mis cursos</b></i>
</a>
<a href="/cursos-finalizados" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalizados             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="hadoop">
		<a  href="#" class="text-secondary d-none" data-read-mod="hadoop" data-read-unit="8-4" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar como leído
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="hadoop" data-unread-unit="8-4" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar como no leído
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contenido del curso
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='08-03-project-3-real-time-data-processing-with-hadoop' title="Proyecto 3: Procesamiento de Datos en Tiempo Real con Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='08-03-project-3-real-time-data-processing-with-hadoop' title="Proyecto 3: Procesamiento de Datos en Tiempo Real con Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Proyecto 4: Aprendizaje Automático con Hadoop</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href="#" class="py-2 px-3 btn btn-success"
				data-read-mod="hadoop" data-read-unit="8-4">
				<i class="bi bi-flag" data-read-mod="hadoop" data-read-unit="8-4"></i> ¡Fin! 
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href="#" class="py-2 px-3 btn btn-success" 
				data-read-mod="hadoop" data-read-unit="8-4">
				<i class="bi bi-flag" data-read-mod="hadoop" data-read-unit="8-4"></i>
			</a>			
			</div>
</div>
<div class='content'></div><h2>Introducción</h2>
<div class='content'><p>En este proyecto, vamos a explorar cómo utilizar Hadoop para realizar tareas de aprendizaje automático. Hadoop, con su capacidad para manejar grandes volúmenes de datos, es una herramienta poderosa para el procesamiento y análisis de datos a gran escala, lo que es esencial en el campo del aprendizaje automático.</p>
</div><h3>Objetivos del Proyecto</h3>
<div class='content'><ol>
<li><strong>Comprender cómo integrar Hadoop con herramientas de aprendizaje automático.</strong></li>
<li><strong>Implementar un flujo de trabajo de aprendizaje automático utilizando Hadoop.</strong></li>
<li><strong>Evaluar y optimizar modelos de aprendizaje automático en un entorno Hadoop.</strong></li>
</ol>
</div><h2>Paso 1: Configuración del Entorno</h2>
<div class='content'></div><h3>Requisitos Previos</h3>
<div class='content'><ul>
<li>Conocimientos básicos de Hadoop y MapReduce.</li>
<li>Familiaridad con conceptos de aprendizaje automático.</li>
<li>Instalación de Hadoop y herramientas del ecosistema (Pig, Hive, etc.).</li>
</ul>
</div><h3>Instalación de Herramientas Adicionales</h3>
<div class='content'><p>Para este proyecto, utilizaremos Apache Mahout, una biblioteca de aprendizaje automático escalable que se integra bien con Hadoop.</p>
<h4>Instalación de Apache Mahout</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEZXNjYXJnYXIgTWFob3V0CndnZXQgaHR0cDovL2FwYWNoZS5taXJyb3JzLnRkcy5uZXQvbWFob3V0LzAuMTMuMC9hcGFjaGUtbWFob3V0LWRpc3RyaWJ1dGlvbi0wLjEzLjAudGFyLmd6CgojIEV4dHJhZXIgZWwgYXJjaGl2byBkZXNjYXJnYWRvCnRhciAteHpmIGFwYWNoZS1tYWhvdXQtZGlzdHJpYnV0aW9uLTAuMTMuMC50YXIuZ3oKCiMgTW92ZXIgYSB1biBkaXJlY3RvcmlvIGRlIHN1IGVsZWNjacOzbgptdiBhcGFjaGUtbWFob3V0LWRpc3RyaWJ1dGlvbi0wLjEzLjAgL3Vzci9sb2NhbC9tYWhvdXQ="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Descargar Mahout
wget http://apache.mirrors.tds.net/mahout/0.13.0/apache-mahout-distribution-0.13.0.tar.gz

# Extraer el archivo descargado
tar -xzf apache-mahout-distribution-0.13.0.tar.gz

# Mover a un directorio de su elecci&oacute;n
mv apache-mahout-distribution-0.13.0 /usr/local/mahout</pre></div><div class='content'></div><h2>Paso 2: Preparación de los Datos</h2>
<div class='content'></div><h3>Dataset</h3>
<div class='content'><p>Para este proyecto, utilizaremos el conjunto de datos de &quot;MovieLens&quot;, que contiene información sobre las calificaciones de películas por parte de los usuarios.</p>
<h4>Descarga del Dataset</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEZXNjYXJnYXIgZWwgZGF0YXNldAp3Z2V0IGh0dHA6Ly9maWxlcy5ncm91cGxlbnMub3JnL2RhdGFzZXRzL21vdmllbGVucy9tbC1sYXRlc3Qtc21hbGwuemlwCgojIEV4dHJhZXIgZWwgYXJjaGl2byBkZXNjYXJnYWRvCnVuemlwIG1sLWxhdGVzdC1zbWFsbC56aXA="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Descargar el dataset
wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip

# Extraer el archivo descargado
unzip ml-latest-small.zip</pre></div><div class='content'></div><h3>Carga de Datos en HDFS</h3>
<div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhciB1biBkaXJlY3RvcmlvIGVuIEhERlMKaGRmcyBkZnMgLW1rZGlyIC91c2VyL2hhZG9vcC9tb3ZpZWxlbnMKCiMgQ2FyZ2FyIGxvcyBkYXRvcyBlbiBIREZTCmhkZnMgZGZzIC1wdXQgbWwtbGF0ZXN0LXNtYWxsL3JhdGluZ3MuY3N2IC91c2VyL2hhZG9vcC9tb3ZpZWxlbnMv"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Crear un directorio en HDFS
hdfs dfs -mkdir /user/hadoop/movielens

# Cargar los datos en HDFS
hdfs dfs -put ml-latest-small/ratings.csv /user/hadoop/movielens/</pre></div><div class='content'></div><h2>Paso 3: Procesamiento de Datos con MapReduce</h2>
<div class='content'></div><h3>Implementación de un Job MapReduce</h3>
<div class='content'><p>Vamos a escribir un programa MapReduce para preprocesar los datos de calificaciones.</p>
<h4>Código del Mapper</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5Mb25nV3JpdGFibGU7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5UZXh0OwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AubWFwcmVkdWNlLk1hcHBlcjsKCnB1YmxpYyBjbGFzcyBSYXRpbmdzTWFwcGVyIGV4dGVuZHMgTWFwcGVyPExvbmdXcml0YWJsZSwgVGV4dCwgVGV4dCwgVGV4dD4gewogICAgQE92ZXJyaWRlCiAgICBwcm90ZWN0ZWQgdm9pZCBtYXAoTG9uZ1dyaXRhYmxlIGtleSwgVGV4dCB2YWx1ZSwgQ29udGV4dCBjb250ZXh0KSB0aHJvd3MgSU9FeGNlcHRpb24sIEludGVycnVwdGVkRXhjZXB0aW9uIHsKICAgICAgICBTdHJpbmdbXSBmaWVsZHMgPSB2YWx1ZS50b1N0cmluZygpLnNwbGl0KCIsIik7CiAgICAgICAgaWYgKGZpZWxkcy5sZW5ndGggPT0gNCkgewogICAgICAgICAgICBTdHJpbmcgdXNlcklkID0gZmllbGRzWzBdOwogICAgICAgICAgICBTdHJpbmcgbW92aWVJZCA9IGZpZWxkc1sxXTsKICAgICAgICAgICAgU3RyaW5nIHJhdGluZyA9IGZpZWxkc1syXTsKICAgICAgICAgICAgY29udGV4dC53cml0ZShuZXcgVGV4dCh1c2VySWQpLCBuZXcgVGV4dChtb3ZpZUlkICsgIjoiICsgcmF0aW5nKSk7CiAgICAgICAgfQogICAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class RatingsMapper extends Mapper&lt;LongWritable, Text, Text, Text&gt; {
    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String[] fields = value.toString().split(&quot;,&quot;);
        if (fields.length == 4) {
            String userId = fields[0];
            String movieId = fields[1];
            String rating = fields[2];
            context.write(new Text(userId), new Text(movieId + &quot;:&quot; + rating));
        }
    }
}</pre></div><div class='content'><h4>Código del Reducer</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5UZXh0OwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AubWFwcmVkdWNlLlJlZHVjZXI7CgpwdWJsaWMgY2xhc3MgUmF0aW5nc1JlZHVjZXIgZXh0ZW5kcyBSZWR1Y2VyPFRleHQsIFRleHQsIFRleHQsIFRleHQ+IHsKICAgIEBPdmVycmlkZQogICAgcHJvdGVjdGVkIHZvaWQgcmVkdWNlKFRleHQga2V5LCBJdGVyYWJsZTxUZXh0PiB2YWx1ZXMsIENvbnRleHQgY29udGV4dCkgdGhyb3dzIElPRXhjZXB0aW9uLCBJbnRlcnJ1cHRlZEV4Y2VwdGlvbiB7CiAgICAgICAgU3RyaW5nQnVpbGRlciBzYiA9IG5ldyBTdHJpbmdCdWlsZGVyKCk7CiAgICAgICAgZm9yIChUZXh0IHZhbHVlIDogdmFsdWVzKSB7CiAgICAgICAgICAgIHNiLmFwcGVuZCh2YWx1ZS50b1N0cmluZygpKS5hcHBlbmQoIiwiKTsKICAgICAgICB9CiAgICAgICAgY29udGV4dC53cml0ZShrZXksIG5ldyBUZXh0KHNiLnRvU3RyaW5nKCkpKTsKICAgIH0KfQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class RatingsReducer extends Reducer&lt;Text, Text, Text, Text&gt; {
    @Override
    protected void reduce(Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException {
        StringBuilder sb = new StringBuilder();
        for (Text value : values) {
            sb.append(value.toString()).append(&quot;,&quot;);
        }
        context.write(key, new Text(sb.toString()));
    }
}</pre></div><div class='content'><h4>Ejecución del Job MapReduce</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDb21waWxhciBlbCBjw7NkaWdvIEphdmEKamF2YWMgLWNsYXNzcGF0aCBgaGFkb29wIGNsYXNzcGF0aGAgLWQgLiBSYXRpbmdzTWFwcGVyLmphdmEgUmF0aW5nc1JlZHVjZXIuamF2YQoKIyBDcmVhciB1biBhcmNoaXZvIEpBUgpqYXIgLWN2ZiBSYXRpbmdzSm9iLmphciAqLmNsYXNzCgojIEVqZWN1dGFyIGVsIEpvYiBNYXBSZWR1Y2UKaGFkb29wIGphciBSYXRpbmdzSm9iLmphciBSYXRpbmdzTWFwcGVyIFJhdGluZ3NSZWR1Y2VyIC91c2VyL2hhZG9vcC9tb3ZpZWxlbnMvcmF0aW5ncy5jc3YgL3VzZXIvaGFkb29wL21vdmllbGVucy9vdXRwdXQ="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Compilar el c&oacute;digo Java
javac -classpath `hadoop classpath` -d . RatingsMapper.java RatingsReducer.java

# Crear un archivo JAR
jar -cvf RatingsJob.jar *.class

# Ejecutar el Job MapReduce
hadoop jar RatingsJob.jar RatingsMapper RatingsReducer /user/hadoop/movielens/ratings.csv /user/hadoop/movielens/output</pre></div><div class='content'></div><h2>Paso 4: Aplicación de Algoritmos de Aprendizaje Automático</h2>
<div class='content'></div><h3>Uso de Apache Mahout para Recomendaciones</h3>
<div class='content'><p>Vamos a utilizar el algoritmo de filtrado colaborativo de Mahout para generar recomendaciones de películas.</p>
<h4>Preparación de los Datos</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDb252ZXJ0aXIgbG9zIGRhdG9zIHByb2Nlc2Fkb3MgYSBmb3JtYXRvIE1haG91dAptYWhvdXQgc2VxZGlyZWN0b3J5IC1pIC91c2VyL2hhZG9vcC9tb3ZpZWxlbnMvb3V0cHV0IC1vIC91c2VyL2hhZG9vcC9tb3ZpZWxlbnMvc2VxZGF0YQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Convertir los datos procesados a formato Mahout
mahout seqdirectory -i /user/hadoop/movielens/output -o /user/hadoop/movielens/seqdata</pre></div><div class='content'><h4>Ejecución del Algoritmo de Filtrado Colaborativo</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBFamVjdXRhciBlbCBhbGdvcml0bW8gZGUgcmVjb21lbmRhY2nDs24KbWFob3V0IHJlY29tbWVuZGl0ZW1iYXNlZCAtcyBTSU1JTEFSSVRZX0NPU0lORSAtaSAvdXNlci9oYWRvb3AvbW92aWVsZW5zL3NlcWRhdGEgLW8gL3VzZXIvaGFkb29wL21vdmllbGVucy9yZWNvbW1lbmRhdGlvbnM="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Ejecutar el algoritmo de recomendaci&oacute;n
mahout recommenditembased -s SIMILARITY_COSINE -i /user/hadoop/movielens/seqdata -o /user/hadoop/movielens/recommendations</pre></div><div class='content'></div><h2>Paso 5: Evaluación y Optimización</h2>
<div class='content'></div><h3>Evaluación del Modelo</h3>
<div class='content'><p>Para evaluar la precisión de nuestras recomendaciones, podemos dividir nuestro conjunto de datos en entrenamiento y prueba, y calcular métricas como la precisión y el recall.</p>
<h4>Código de Evaluación</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUubWFob3V0LmNmLnRhc3RlLmV2YWwuRGF0YU1vZGVsQnVpbGRlcjsKaW1wb3J0IG9yZy5hcGFjaGUubWFob3V0LmNmLnRhc3RlLmV2YWwuUmVjb21tZW5kZXJCdWlsZGVyOwppbXBvcnQgb3JnLmFwYWNoZS5tYWhvdXQuY2YudGFzdGUuZXZhbC5SZWNvbW1lbmRlckV2YWx1YXRvcjsKaW1wb3J0IG9yZy5hcGFjaGUubWFob3V0LmNmLnRhc3RlLmltcGwuZXZhbC5BdmVyYWdlQWJzb2x1dGVEaWZmZXJlbmNlUmVjb21tZW5kZXJFdmFsdWF0b3I7CmltcG9ydCBvcmcuYXBhY2hlLm1haG91dC5jZi50YXN0ZS5pbXBsLm1vZGVsLmZpbGUuRmlsZURhdGFNb2RlbDsKaW1wb3J0IG9yZy5hcGFjaGUubWFob3V0LmNmLnRhc3RlLmltcGwucmVjb21tZW5kZXIuR2VuZXJpY0l0ZW1CYXNlZFJlY29tbWVuZGVyOwppbXBvcnQgb3JnLmFwYWNoZS5tYWhvdXQuY2YudGFzdGUuaW1wbC5zaW1pbGFyaXR5LlBlYXJzb25Db3JyZWxhdGlvblNpbWlsYXJpdHk7CmltcG9ydCBvcmcuYXBhY2hlLm1haG91dC5jZi50YXN0ZS5tb2RlbC5EYXRhTW9kZWw7CmltcG9ydCBvcmcuYXBhY2hlLm1haG91dC5jZi50YXN0ZS5zaW1pbGFyaXR5Lkl0ZW1TaW1pbGFyaXR5OwoKaW1wb3J0IGphdmEuaW8uRmlsZTsKCnB1YmxpYyBjbGFzcyBSZWNvbW1lbmRlckV2YWx1YXRvckV4YW1wbGUgewogICAgcHVibGljIHN0YXRpYyB2b2lkIG1haW4oU3RyaW5nW10gYXJncykgdGhyb3dzIEV4Y2VwdGlvbiB7CiAgICAgICAgRGF0YU1vZGVsIG1vZGVsID0gbmV3IEZpbGVEYXRhTW9kZWwobmV3IEZpbGUoInBhdGgvdG8vcmF0aW5ncy5jc3YiKSk7CiAgICAgICAgUmVjb21tZW5kZXJFdmFsdWF0b3IgZXZhbHVhdG9yID0gbmV3IEF2ZXJhZ2VBYnNvbHV0ZURpZmZlcmVuY2VSZWNvbW1lbmRlckV2YWx1YXRvcigpOwogICAgICAgIFJlY29tbWVuZGVyQnVpbGRlciBidWlsZGVyID0gbmV3IFJlY29tbWVuZGVyQnVpbGRlcigpIHsKICAgICAgICAgICAgQE92ZXJyaWRlCiAgICAgICAgICAgIHB1YmxpYyBSZWNvbW1lbmRlciBidWlsZFJlY29tbWVuZGVyKERhdGFNb2RlbCBkYXRhTW9kZWwpIHRocm93cyBUYXN0ZUV4Y2VwdGlvbiB7CiAgICAgICAgICAgICAgICBJdGVtU2ltaWxhcml0eSBzaW1pbGFyaXR5ID0gbmV3IFBlYXJzb25Db3JyZWxhdGlvblNpbWlsYXJpdHkoZGF0YU1vZGVsKTsKICAgICAgICAgICAgICAgIHJldHVybiBuZXcgR2VuZXJpY0l0ZW1CYXNlZFJlY29tbWVuZGVyKGRhdGFNb2RlbCwgc2ltaWxhcml0eSk7CiAgICAgICAgICAgIH0KICAgICAgICB9OwogICAgICAgIGRvdWJsZSBzY29yZSA9IGV2YWx1YXRvci5ldmFsdWF0ZShidWlsZGVyLCBudWxsLCBtb2RlbCwgMC43LCAxLjApOwogICAgICAgIFN5c3RlbS5vdXQucHJpbnRsbigiRXZhbHVhdGlvbiBTY29yZTogIiArIHNjb3JlKTsKICAgIH0KfQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.mahout.cf.taste.eval.DataModelBuilder;
import org.apache.mahout.cf.taste.eval.RecommenderBuilder;
import org.apache.mahout.cf.taste.eval.RecommenderEvaluator;
import org.apache.mahout.cf.taste.impl.eval.AverageAbsoluteDifferenceRecommenderEvaluator;
import org.apache.mahout.cf.taste.impl.model.file.FileDataModel;
import org.apache.mahout.cf.taste.impl.recommender.GenericItemBasedRecommender;
import org.apache.mahout.cf.taste.impl.similarity.PearsonCorrelationSimilarity;
import org.apache.mahout.cf.taste.model.DataModel;
import org.apache.mahout.cf.taste.similarity.ItemSimilarity;

import java.io.File;

public class RecommenderEvaluatorExample {
    public static void main(String[] args) throws Exception {
        DataModel model = new FileDataModel(new File(&quot;path/to/ratings.csv&quot;));
        RecommenderEvaluator evaluator = new AverageAbsoluteDifferenceRecommenderEvaluator();
        RecommenderBuilder builder = new RecommenderBuilder() {
            @Override
            public Recommender buildRecommender(DataModel dataModel) throws TasteException {
                ItemSimilarity similarity = new PearsonCorrelationSimilarity(dataModel);
                return new GenericItemBasedRecommender(dataModel, similarity);
            }
        };
        double score = evaluator.evaluate(builder, null, model, 0.7, 1.0);
        System.out.println(&quot;Evaluation Score: &quot; + score);
    }
}</pre></div><div class='content'></div><h3>Optimización del Modelo</h3>
<div class='content'><p>Para mejorar el rendimiento del modelo, podemos ajustar parámetros como el tipo de similitud utilizada (coseno, Pearson, etc.) y la cantidad de datos de entrenamiento.</p>
</div><h2>Conclusión</h2>
<div class='content'><p>En este proyecto, hemos aprendido a integrar Hadoop con herramientas de aprendizaje automático como Apache Mahout. Hemos implementado un flujo de trabajo completo que incluye la preparación de datos, el procesamiento con MapReduce, la aplicación de algoritmos de aprendizaje automático y la evaluación del modelo. Este enfoque nos permite manejar grandes volúmenes de datos y construir modelos de aprendizaje automático escalables y eficientes.</p>
</div><h3>Resumen de Conceptos Clave</h3>
<div class='content'><ul>
<li><strong>Integración de Hadoop con Apache Mahout.</strong></li>
<li><strong>Preprocesamiento de datos con MapReduce.</strong></li>
<li><strong>Aplicación de algoritmos de filtrado colaborativo.</strong></li>
<li><strong>Evaluación y optimización de modelos de aprendizaje automático.</strong></li>
</ul>
</div><h3>Próximos Pasos</h3>
<div class='content'><ul>
<li>Explorar otros algoritmos de aprendizaje automático disponibles en Mahout.</li>
<li>Implementar técnicas avanzadas de optimización y ajuste de hiperparámetros.</li>
<li>Aplicar estos conocimientos a otros conjuntos de datos y casos de uso del mundo real.</li>
</ul>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='08-03-project-3-real-time-data-processing-with-hadoop' title="Proyecto 3: Procesamiento de Datos en Tiempo Real con Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='08-03-project-3-real-time-data-processing-with-hadoop' title="Proyecto 3: Procesamiento de Datos en Tiempo Real con Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href="#" class="py-2 px-3 btn btn-success"
				data-read-mod="hadoop" data-read-unit="8-4">
				<i class="bi bi-flag" data-read-mod="hadoop" data-read-unit="8-4"></i> ¡Fin! 
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href="#" class="py-2 px-3 btn btn-success" 
				data-read-mod="hadoop" data-read-unit="8-4">
				<i class="bi bi-flag" data-read-mod="hadoop" data-read-unit="8-4"></i>
			</a>			
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de Hadoop</h1>
<h2>Módulo 1: Introducción a Hadoop</h2>
<ul>
<li><a href="01-01-what-is-hadoop">¿Qué es Hadoop?</a></li>
<li><a href="01-02-hadoop-ecosystem-overview">Visión General del Ecosistema Hadoop</a></li>
<li><a href="01-03-hadoop-vs-traditional-databases">Hadoop vs Bases de Datos Tradicionales</a></li>
<li><a href="01-04-setting-up-hadoop-environment">Configuración del Entorno Hadoop</a></li>
</ul>
<h2>Módulo 2: Arquitectura de Hadoop</h2>
<ul>
<li><a href="02-01-hadoop-core-components">Componentes Principales de Hadoop</a></li>
<li><a href="02-02-hdfs">HDFS (Sistema de Archivos Distribuido de Hadoop)</a></li>
<li><a href="02-03-mapreduce-framework">Marco de Trabajo MapReduce</a></li>
<li><a href="02-04-yarn">YARN (Yet Another Resource Negotiator)</a></li>
</ul>
<h2>Módulo 3: HDFS (Sistema de Archivos Distribuido de Hadoop)</h2>
<ul>
<li><a href="03-01-hdfs-architecture">Arquitectura de HDFS</a></li>
<li><a href="03-02-hdfs-commands">Comandos de HDFS</a></li>
<li><a href="03-03-data-replication-in-hdfs">Replicación de Datos en HDFS</a></li>
<li><a href="03-04-hdfs-fault-tolerance">Tolerancia a Fallos en HDFS</a></li>
</ul>
<h2>Módulo 4: Programación MapReduce</h2>
<ul>
<li><a href="04-01-introduction-to-mapreduce">Introducción a MapReduce</a></li>
<li><a href="04-02-mapreduce-job-workflow">Flujo de Trabajo de un Job MapReduce</a></li>
<li><a href="04-03-writing-a-mapreduce-program">Escribiendo un Programa MapReduce</a></li>
<li><a href="04-04-mapreduce-optimization-techniques">Técnicas de Optimización de MapReduce</a></li>
</ul>
<h2>Módulo 5: Herramientas del Ecosistema Hadoop</h2>
<ul>
<li><a href="05-01-apache-pig">Apache Pig</a></li>
<li><a href="05-02-apache-hive">Apache Hive</a></li>
<li><a href="05-03-apache-hbase">Apache HBase</a></li>
<li><a href="05-04-apache-sqoop">Apache Sqoop</a></li>
<li><a href="05-05-apache-flume">Apache Flume</a></li>
<li><a href="05-06-apache-oozie">Apache Oozie</a></li>
</ul>
<h2>Módulo 6: Conceptos Avanzados de Hadoop</h2>
<ul>
<li><a href="06-01-hadoop-security">Seguridad en Hadoop</a></li>
<li><a href="06-02-hadoop-cluster-management">Gestión de Clústeres Hadoop</a></li>
<li><a href="06-03-hadoop-performance-tuning">Ajuste de Rendimiento de Hadoop</a></li>
<li><a href="06-04-hadoop-data-serialization">Serialización de Datos en Hadoop</a></li>
</ul>
<h2>Módulo 7: Aplicaciones del Mundo Real y Estudios de Caso</h2>
<ul>
<li><a href="07-01-hadoop-in-data-warehousing">Hadoop en Almacenamiento de Datos</a></li>
<li><a href="07-02-hadoop-in-machine-learning">Hadoop en Aprendizaje Automático</a></li>
<li><a href="07-03-hadoop-in-real-time-data-processing">Hadoop en Procesamiento de Datos en Tiempo Real</a></li>
<li><a href="07-04-case-studies-of-hadoop-implementations">Estudios de Caso de Implementaciones de Hadoop</a></li>
</ul>
<h2>Módulo 8: Proyectos Prácticos</h2>
<ul>
<li><a href="08-01-project-1-analyzing-big-data-with-hadoop">Proyecto 1: Analizando Big Data con Hadoop</a></li>
<li><a href="08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem">Proyecto 2: Construyendo una Canalización de Datos con el Ecosistema Hadoop</a></li>
<li><a href="08-03-project-3-real-time-data-processing-with-hadoop">Proyecto 3: Procesamiento de Datos en Tiempo Real con Hadoop</a></li>
<li><a href="08-04-project-4-machine-learning-with-hadoop">Proyecto 4: Aprendizaje Automático con Hadoop</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuario no autenticado</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
