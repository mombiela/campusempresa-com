<!DOCTYPE html>
<html lang="es">
<head>
    <title> Hadoop en Almacenamiento de Datos </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/hadoop/07-01-hadoop-in-data-warehousing" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/hadoop/07-01-hadoop-in-data-warehousing" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/hadoop/07-01-hadoop-in-data-warehousing" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.1ab297bfa4.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "es";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "hadoop";
  		var TEMA_NAME = "7-1";
  		var TYPE = "mod";
  		var PATH = "mod/hadoop/07-01-hadoop-in-data-warehousing";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.688defeeef.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo_header.png" alt="Logo Campus Empresa"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/courses/hadoop/07-01-hadoop-in-data-warehousing" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/cursos/hadoop/07-01-hadoop-in-data-warehousing" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/mis-cursos" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Mis cursos</b></i>
</a>
<a href="/cursos-finalizados" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalizados             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="hadoop">
		<a  href="#" class="text-secondary d-none" data-read-mod="hadoop" data-read-unit="7-1" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar como leído
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="hadoop" data-unread-unit="7-1" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar como no leído
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contenido del curso
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-04-hadoop-data-serialization' title="Serialización de Datos en Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-04-hadoop-data-serialization' title="Serialización de Datos en Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Hadoop en Almacenamiento de Datos</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='07-02-hadoop-in-machine-learning' title="Hadoop en Aprendizaje Automático" class="py-2 px-3 btn btn-primary"
				data-read-mod="hadoop" data-read-unit="7-1">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='07-02-hadoop-in-machine-learning' title="Hadoop en Aprendizaje Automático" class="py-2 px-3 btn btn-primary" 
				data-read-mod="hadoop" data-read-unit="7-1">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'></div><h2>Introducción</h2>
<div class='content'><p>El almacenamiento de datos es una parte crucial de la gestión de grandes volúmenes de información en las organizaciones modernas. Hadoop, con su capacidad para manejar grandes cantidades de datos distribuidos, se ha convertido en una herramienta esencial para el almacenamiento de datos. En esta sección, exploraremos cómo Hadoop se utiliza en el almacenamiento de datos, sus ventajas y cómo implementarlo.</p>
</div><h2>¿Qué es el Almacenamiento de Datos?</h2>
<div class='content'><p>El almacenamiento de datos (Data Warehousing) es el proceso de recopilar y gestionar datos de diversas fuentes para proporcionar información significativa y útil para la toma de decisiones empresariales. Los almacenes de datos son sistemas diseñados para el análisis y la consulta de datos, en lugar de la transacción de datos.</p>
</div><h3>Características Clave del Almacenamiento de Datos:</h3>
<div class='content'><ul>
<li><strong>Integración de Datos</strong>: Combina datos de múltiples fuentes.</li>
<li><strong>Historización</strong>: Almacena datos históricos para análisis a largo plazo.</li>
<li><strong>Optimización para Consultas</strong>: Diseñado para consultas rápidas y complejas.</li>
<li><strong>Consolidación de Datos</strong>: Proporciona una vista unificada de los datos.</li>
</ul>
</div><h2>Ventajas de Usar Hadoop en el Almacenamiento de Datos</h2>
<div class='content'><p>Hadoop ofrece varias ventajas significativas cuando se utiliza para el almacenamiento de datos:</p>
<ol>
<li><strong>Escalabilidad</strong>: Hadoop puede escalar horizontalmente añadiendo más nodos al clúster, lo que permite manejar grandes volúmenes de datos.</li>
<li><strong>Costo-Efectividad</strong>: Utiliza hardware común y de bajo costo, lo que reduce significativamente los costos en comparación con soluciones tradicionales.</li>
<li><strong>Flexibilidad</strong>: Puede manejar datos estructurados, semiestructurados y no estructurados.</li>
<li><strong>Alta Disponibilidad y Tolerancia a Fallos</strong>: HDFS (Hadoop Distributed File System) replica los datos en múltiples nodos, asegurando la disponibilidad y la tolerancia a fallos.</li>
<li><strong>Procesamiento Distribuido</strong>: MapReduce permite el procesamiento paralelo de grandes conjuntos de datos.</li>
</ol>
</div><h2>Componentes de Hadoop en el Almacenamiento de Datos</h2>
<div class='content'></div><h3>HDFS (Hadoop Distributed File System)</h3>
<div class='content'><p>HDFS es el sistema de archivos distribuido de Hadoop que almacena datos en bloques distribuidos a través de múltiples nodos. Proporciona alta disponibilidad y tolerancia a fallos mediante la replicación de datos.</p>
</div><h3>MapReduce</h3>
<div class='content'><p>MapReduce es el modelo de programación de Hadoop que permite el procesamiento paralelo de grandes conjuntos de datos. Divide las tareas en subtareas más pequeñas que se ejecutan en paralelo en diferentes nodos.</p>
</div><h3>Apache Hive</h3>
<div class='content'><p>Hive es una herramienta de almacenamiento de datos que proporciona una interfaz SQL para consultar y gestionar grandes conjuntos de datos almacenados en Hadoop. Permite a los usuarios escribir consultas en un lenguaje similar a SQL llamado HiveQL.</p>
</div><h3>Apache HBase</h3>
<div class='content'><p>HBase es una base de datos NoSQL distribuida que se ejecuta sobre HDFS. Es adecuada para aplicaciones que requieren acceso en tiempo real a grandes cantidades de datos.</p>
</div><h3>Apache Sqoop</h3>
<div class='content'><p>Sqoop es una herramienta que permite la transferencia eficiente de datos entre Hadoop y bases de datos relacionales. Es útil para importar datos desde bases de datos tradicionales a Hadoop y viceversa.</p>
</div><h3>Apache Flume</h3>
<div class='content'><p>Flume es una herramienta de ingesta de datos que permite la recolección, agregación y movimiento de grandes cantidades de datos de múltiples fuentes a Hadoop.</p>
</div><h2>Implementación de un Almacén de Datos con Hadoop</h2>
<div class='content'></div><h3>Paso 1: Configuración del Entorno Hadoop</h3>
<div class='content'><p>Antes de comenzar, asegúrate de tener un clúster de Hadoop configurado. Puedes seguir las instrucciones del módulo &quot;Configuración del Entorno Hadoop&quot; para configurar tu clúster.</p>
</div><h3>Paso 2: Ingesta de Datos</h3>
<div class='content'><p>Utiliza Apache Sqoop para importar datos desde una base de datos relacional a HDFS. Aquí hay un ejemplo de cómo importar datos desde MySQL a HDFS:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("c3Fvb3AgaW1wb3J0IC0tY29ubmVjdCBqZGJjOm15c3FsOi8vbG9jYWxob3N0L2RibmFtZSAtLXVzZXJuYW1lIHVzZXIgLS1wYXNzd29yZCBwYXNzIC0tdGFibGUgdGFibGVuYW1lIC0tdGFyZ2V0LWRpciAvdXNlci9oYWRvb3AvdGFibGVuYW1l"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>sqoop import --connect jdbc:mysql://localhost/dbname --username user --password pass --table tablename --target-dir /user/hadoop/tablename</pre></div><div class='content'></div><h3>Paso 3: Almacenamiento de Datos en HDFS</h3>
<div class='content'><p>Los datos importados se almacenarán en HDFS. Puedes verificar los datos utilizando comandos de HDFS:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aGRmcyBkZnMgLWxzIC91c2VyL2hhZG9vcC90YWJsZW5hbWU="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>hdfs dfs -ls /user/hadoop/tablename</pre></div><div class='content'></div><h3>Paso 4: Procesamiento de Datos con MapReduce</h3>
<div class='content'><p>Escribe un programa MapReduce para procesar los datos almacenados en HDFS. Aquí hay un ejemplo básico de un programa MapReduce en Java:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

public class WordCount {

    public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt; {
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            String[] tokens = value.toString().split(&quot;\\s+&quot;);
            for (String token : tokens) {
                word.set(token);
                context.write(word, one);
            }
        }
    }

    public static class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
        private IntWritable result = new IntWritable();

        public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            result.set(sum);
            context.write(key, result);
        }
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, &quot;word count&quot;);
        job.setJarByClass(WordCount.class);
        job.setMapperClass(TokenizerMapper.class);
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(IntSumReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}</pre></div><div class='content'></div><h3>Paso 5: Consulta de Datos con Hive</h3>
<div class='content'><p>Utiliza Apache Hive para consultar los datos procesados. Aquí hay un ejemplo de cómo crear una tabla en Hive y ejecutar una consulta:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Q1JFQVRFIFRBQkxFIHdvcmRfY291bnQgKHdvcmQgU1RSSU5HLCBjb3VudCBJTlQpIFJPVyBGT1JNQVQgREVMSU1JVEVEIEZJRUxEUyBURVJNSU5BVEVEIEJZICdcdCcgU1RPUkVEIEFTIFRFWFRGSUxFOwoKTE9BRCBEQVRBIElOUEFUSCAnL3VzZXIvaGFkb29wL291dHB1dCcgSU5UTyBUQUJMRSB3b3JkX2NvdW50OwoKU0VMRUNUICogRlJPTSB3b3JkX2NvdW50IFdIRVJFIGNvdW50ID4gMTA7"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>CREATE TABLE word_count (word STRING, count INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' STORED AS TEXTFILE;

LOAD DATA INPATH '/user/hadoop/output' INTO TABLE word_count;

SELECT * FROM word_count WHERE count &gt; 10;</pre></div><div class='content'></div><h2>Ejercicio Práctico</h2>
<div class='content'></div><h3>Ejercicio 1: Importar y Procesar Datos</h3>
<div class='content'><ol>
<li><strong>Importar Datos</strong>: Utiliza Apache Sqoop para importar datos desde una base de datos relacional a HDFS.</li>
<li><strong>Procesar Datos</strong>: Escribe un programa MapReduce para contar la frecuencia de palabras en los datos importados.</li>
<li><strong>Consultar Datos</strong>: Utiliza Apache Hive para consultar los resultados del programa MapReduce.</li>
</ol>
</div><h3>Solución del Ejercicio</h3>
<div class='content'><ol>
<li>
<p><strong>Importar Datos</strong>:</p>
<pre><code class="language-bash">sqoop import --connect jdbc:mysql://localhost/dbname --username user --password pass --table tablename --target-dir /user/hadoop/tablename
</code></pre>
</li>
<li>
<p><strong>Procesar Datos</strong>: Utiliza el programa MapReduce proporcionado anteriormente.</p>
</li>
<li>
<p><strong>Consultar Datos</strong>:</p>
<pre><code class="language-sql">CREATE TABLE word_count (word STRING, count INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' STORED AS TEXTFILE;

LOAD DATA INPATH '/user/hadoop/output' INTO TABLE word_count;

SELECT * FROM word_count WHERE count &gt; 10;
</code></pre>
</li>
</ol>
</div><h2>Conclusión</h2>
<div class='content'><p>En esta sección, hemos explorado cómo Hadoop se utiliza en el almacenamiento de datos, sus ventajas y cómo implementarlo utilizando componentes clave como HDFS, MapReduce, Hive, HBase, Sqoop y Flume. También hemos proporcionado un ejercicio práctico para reforzar los conceptos aprendidos. En la siguiente sección, profundizaremos en el uso de Hadoop en el aprendizaje automático.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-04-hadoop-data-serialization' title="Serialización de Datos en Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-04-hadoop-data-serialization' title="Serialización de Datos en Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='07-02-hadoop-in-machine-learning' title="Hadoop en Aprendizaje Automático" class="py-2 px-3 btn btn-primary"
				data-read-mod="hadoop" data-read-unit="7-1">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='07-02-hadoop-in-machine-learning' title="Hadoop en Aprendizaje Automático" class="py-2 px-3 btn btn-primary" 
				data-read-mod="hadoop" data-read-unit="7-1">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de Hadoop</h1>
<h2>Módulo 1: Introducción a Hadoop</h2>
<ul>
<li><a href="01-01-what-is-hadoop">¿Qué es Hadoop?</a></li>
<li><a href="01-02-hadoop-ecosystem-overview">Visión General del Ecosistema Hadoop</a></li>
<li><a href="01-03-hadoop-vs-traditional-databases">Hadoop vs Bases de Datos Tradicionales</a></li>
<li><a href="01-04-setting-up-hadoop-environment">Configuración del Entorno Hadoop</a></li>
</ul>
<h2>Módulo 2: Arquitectura de Hadoop</h2>
<ul>
<li><a href="02-01-hadoop-core-components">Componentes Principales de Hadoop</a></li>
<li><a href="02-02-hdfs">HDFS (Sistema de Archivos Distribuido de Hadoop)</a></li>
<li><a href="02-03-mapreduce-framework">Marco de Trabajo MapReduce</a></li>
<li><a href="02-04-yarn">YARN (Yet Another Resource Negotiator)</a></li>
</ul>
<h2>Módulo 3: HDFS (Sistema de Archivos Distribuido de Hadoop)</h2>
<ul>
<li><a href="03-01-hdfs-architecture">Arquitectura de HDFS</a></li>
<li><a href="03-02-hdfs-commands">Comandos de HDFS</a></li>
<li><a href="03-03-data-replication-in-hdfs">Replicación de Datos en HDFS</a></li>
<li><a href="03-04-hdfs-fault-tolerance">Tolerancia a Fallos en HDFS</a></li>
</ul>
<h2>Módulo 4: Programación MapReduce</h2>
<ul>
<li><a href="04-01-introduction-to-mapreduce">Introducción a MapReduce</a></li>
<li><a href="04-02-mapreduce-job-workflow">Flujo de Trabajo de un Job MapReduce</a></li>
<li><a href="04-03-writing-a-mapreduce-program">Escribiendo un Programa MapReduce</a></li>
<li><a href="04-04-mapreduce-optimization-techniques">Técnicas de Optimización de MapReduce</a></li>
</ul>
<h2>Módulo 5: Herramientas del Ecosistema Hadoop</h2>
<ul>
<li><a href="05-01-apache-pig">Apache Pig</a></li>
<li><a href="05-02-apache-hive">Apache Hive</a></li>
<li><a href="05-03-apache-hbase">Apache HBase</a></li>
<li><a href="05-04-apache-sqoop">Apache Sqoop</a></li>
<li><a href="05-05-apache-flume">Apache Flume</a></li>
<li><a href="05-06-apache-oozie">Apache Oozie</a></li>
</ul>
<h2>Módulo 6: Conceptos Avanzados de Hadoop</h2>
<ul>
<li><a href="06-01-hadoop-security">Seguridad en Hadoop</a></li>
<li><a href="06-02-hadoop-cluster-management">Gestión de Clústeres Hadoop</a></li>
<li><a href="06-03-hadoop-performance-tuning">Ajuste de Rendimiento de Hadoop</a></li>
<li><a href="06-04-hadoop-data-serialization">Serialización de Datos en Hadoop</a></li>
</ul>
<h2>Módulo 7: Aplicaciones del Mundo Real y Estudios de Caso</h2>
<ul>
<li><a href="07-01-hadoop-in-data-warehousing">Hadoop en Almacenamiento de Datos</a></li>
<li><a href="07-02-hadoop-in-machine-learning">Hadoop en Aprendizaje Automático</a></li>
<li><a href="07-03-hadoop-in-real-time-data-processing">Hadoop en Procesamiento de Datos en Tiempo Real</a></li>
<li><a href="07-04-case-studies-of-hadoop-implementations">Estudios de Caso de Implementaciones de Hadoop</a></li>
</ul>
<h2>Módulo 8: Proyectos Prácticos</h2>
<ul>
<li><a href="08-01-project-1-analyzing-big-data-with-hadoop">Proyecto 1: Analizando Big Data con Hadoop</a></li>
<li><a href="08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem">Proyecto 2: Construyendo una Canalización de Datos con el Ecosistema Hadoop</a></li>
<li><a href="08-03-project-3-real-time-data-processing-with-hadoop">Proyecto 3: Procesamiento de Datos en Tiempo Real con Hadoop</a></li>
<li><a href="08-04-project-4-machine-learning-with-hadoop">Proyecto 4: Aprendizaje Automático con Hadoop</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuario no autenticado</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
