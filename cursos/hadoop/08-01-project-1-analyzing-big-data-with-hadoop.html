<!DOCTYPE html>
<html lang="es">
<head>
    <title> Proyecto 1: Analizando Big Data con Hadoop </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/hadoop/08-01-project-1-analyzing-big-data-with-hadoop" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/hadoop/08-01-project-1-analyzing-big-data-with-hadoop" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/hadoop/08-01-project-1-analyzing-big-data-with-hadoop" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.1ab297bfa4.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "es";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "hadoop";
  		var TEMA_NAME = "8-1";
  		var TYPE = "mod";
  		var PATH = "mod/hadoop/08-01-project-1-analyzing-big-data-with-hadoop";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.688defeeef.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo_header.png" alt="Logo Campus Empresa"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/courses/hadoop/08-01-project-1-analyzing-big-data-with-hadoop" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/cursos/hadoop/08-01-project-1-analyzing-big-data-with-hadoop" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/mis-cursos" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Mis cursos</b></i>
</a>
<a href="/cursos-finalizados" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalizados             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="hadoop">
		<a  href="#" class="text-secondary d-none" data-read-mod="hadoop" data-read-unit="8-1" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar como leído
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="hadoop" data-unread-unit="8-1" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar como no leído
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contenido del curso
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='07-04-case-studies-of-hadoop-implementations' title="Estudios de Caso de Implementaciones de Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='07-04-case-studies-of-hadoop-implementations' title="Estudios de Caso de Implementaciones de Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Proyecto 1: Analizando Big Data con Hadoop</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem' title="Proyecto 2: Construyendo una Canalización de Datos con el Ecosistema Hadoop" class="py-2 px-3 btn btn-primary"
				data-read-mod="hadoop" data-read-unit="8-1">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem' title="Proyecto 2: Construyendo una Canalización de Datos con el Ecosistema Hadoop" class="py-2 px-3 btn btn-primary" 
				data-read-mod="hadoop" data-read-unit="8-1">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'></div><h2>Introducción</h2>
<div class='content'><p>En este proyecto, aplicaremos los conocimientos adquiridos en los módulos anteriores para analizar un conjunto de datos masivos utilizando Hadoop. Este proyecto te permitirá poner en práctica las habilidades de configuración, manejo de HDFS, y programación MapReduce, así como el uso de herramientas del ecosistema Hadoop.</p>
</div><h2>Objetivos del Proyecto</h2>
<div class='content'><ol>
<li><strong>Configurar un entorno Hadoop funcional.</strong></li>
<li><strong>Cargar y gestionar datos en HDFS.</strong></li>
<li><strong>Desarrollar y ejecutar un programa MapReduce para analizar los datos.</strong></li>
<li><strong>Utilizar herramientas del ecosistema Hadoop para enriquecer el análisis.</strong></li>
</ol>
</div><h2>Requisitos Previos</h2>
<div class='content'><p>Antes de comenzar, asegúrate de tener:</p>
<ul>
<li>Un clúster Hadoop configurado (puede ser un clúster local o en la nube).</li>
<li>Conocimientos básicos de HDFS y MapReduce.</li>
<li>Familiaridad con herramientas del ecosistema Hadoop como Apache Hive y Apache Pig.</li>
</ul>
</div><h2>Paso 1: Configuración del Entorno</h2>
<div class='content'></div><h3>1.1 Instalación de Hadoop</h3>
<div class='content'><p>Si aún no tienes Hadoop instalado, sigue estos pasos para configurarlo en tu máquina local:</p>
<ol>
<li>
<p><strong>Descarga Hadoop:</strong></p>
<pre><code class="language-bash">wget https://downloads.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz
</code></pre>
</li>
<li>
<p><strong>Extrae el archivo descargado:</strong></p>
<pre><code class="language-bash">tar -xzvf hadoop-3.3.1.tar.gz
</code></pre>
</li>
<li>
<p><strong>Configura las variables de entorno:</strong></p>
<pre><code class="language-bash">export HADOOP_HOME=~/hadoop-3.3.1
export PATH=$PATH:$HADOOP_HOME/bin
</code></pre>
</li>
<li>
<p><strong>Configura los archivos de configuración (<code>core-site.xml</code>, <code>hdfs-site.xml</code>, <code>mapred-site.xml</code>, <code>yarn-site.xml</code>):</strong></p>
<ul>
<li>Asegúrate de configurar correctamente los directorios de almacenamiento y los puertos de comunicación.</li>
</ul>
</li>
</ol>
</div><h3>1.2 Iniciar Hadoop</h3>
<div class='content'><ol>
<li>
<p><strong>Formatea el sistema de archivos HDFS:</strong></p>
<pre><code class="language-bash">hdfs namenode -format
</code></pre>
</li>
<li>
<p><strong>Inicia los servicios de Hadoop:</strong></p>
<pre><code class="language-bash">start-dfs.sh
start-yarn.sh
</code></pre>
</li>
</ol>
</div><h2>Paso 2: Cargar Datos en HDFS</h2>
<div class='content'></div><h3>2.1 Descargar el Conjunto de Datos</h3>
<div class='content'><p>Para este proyecto, utilizaremos un conjunto de datos de ejemplo, como el conjunto de datos de registros de acceso web.</p>
<ol>
<li>
<p><strong>Descarga el conjunto de datos:</strong></p>
<pre><code class="language-bash">wget http://example.com/web-logs-dataset.zip
</code></pre>
</li>
<li>
<p><strong>Extrae el archivo descargado:</strong></p>
<pre><code class="language-bash">unzip web-logs-dataset.zip
</code></pre>
</li>
</ol>
</div><h3>2.2 Cargar Datos en HDFS</h3>
<div class='content'><ol>
<li>
<p><strong>Crea un directorio en HDFS para los datos:</strong></p>
<pre><code class="language-bash">hdfs dfs -mkdir /user/hadoop/web-logs
</code></pre>
</li>
<li>
<p><strong>Copia los datos al directorio HDFS:</strong></p>
<pre><code class="language-bash">hdfs dfs -put web-logs/* /user/hadoop/web-logs/
</code></pre>
</li>
</ol>
</div><h2>Paso 3: Desarrollar un Programa MapReduce</h2>
<div class='content'></div><h3>3.1 Escribir el Código MapReduce</h3>
<div class='content'><p>Vamos a escribir un programa MapReduce en Java para analizar los registros de acceso web y contar el número de accesos por cada URL.</p>
<h4>Mapper</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5JbnRXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLkxvbmdXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuTWFwcGVyOwoKcHVibGljIGNsYXNzIFdlYkxvZ01hcHBlciBleHRlbmRzIE1hcHBlcjxMb25nV3JpdGFibGUsIFRleHQsIFRleHQsIEludFdyaXRhYmxlPiB7CiAgICBwcml2YXRlIGZpbmFsIHN0YXRpYyBJbnRXcml0YWJsZSBvbmUgPSBuZXcgSW50V3JpdGFibGUoMSk7CiAgICBwcml2YXRlIFRleHQgdXJsID0gbmV3IFRleHQoKTsKCiAgICBwdWJsaWMgdm9pZCBtYXAoTG9uZ1dyaXRhYmxlIGtleSwgVGV4dCB2YWx1ZSwgQ29udGV4dCBjb250ZXh0KSB0aHJvd3MgSU9FeGNlcHRpb24sIEludGVycnVwdGVkRXhjZXB0aW9uIHsKICAgICAgICBTdHJpbmdbXSBmaWVsZHMgPSB2YWx1ZS50b1N0cmluZygpLnNwbGl0KCIgIik7CiAgICAgICAgaWYgKGZpZWxkcy5sZW5ndGggPiA2KSB7CiAgICAgICAgICAgIHVybC5zZXQoZmllbGRzWzZdKTsKICAgICAgICAgICAgY29udGV4dC53cml0ZSh1cmwsIG9uZSk7CiAgICAgICAgfQogICAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class WebLogMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
    private final static IntWritable one = new IntWritable(1);
    private Text url = new Text();

    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String[] fields = value.toString().split(&quot; &quot;);
        if (fields.length &gt; 6) {
            url.set(fields[6]);
            context.write(url, one);
        }
    }
}</pre></div><div class='content'><h4>Reducer</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5JbnRXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuUmVkdWNlcjsKCnB1YmxpYyBjbGFzcyBXZWJMb2dSZWR1Y2VyIGV4dGVuZHMgUmVkdWNlcjxUZXh0LCBJbnRXcml0YWJsZSwgVGV4dCwgSW50V3JpdGFibGU+IHsKICAgIHB1YmxpYyB2b2lkIHJlZHVjZShUZXh0IGtleSwgSXRlcmFibGU8SW50V3JpdGFibGU+IHZhbHVlcywgQ29udGV4dCBjb250ZXh0KSB0aHJvd3MgSU9FeGNlcHRpb24sIEludGVycnVwdGVkRXhjZXB0aW9uIHsKICAgICAgICBpbnQgc3VtID0gMDsKICAgICAgICBmb3IgKEludFdyaXRhYmxlIHZhbCA6IHZhbHVlcykgewogICAgICAgICAgICBzdW0gKz0gdmFsLmdldCgpOwogICAgICAgIH0KICAgICAgICBjb250ZXh0LndyaXRlKGtleSwgbmV3IEludFdyaXRhYmxlKHN1bSkpOwogICAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class WebLogReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable val : values) {
            sum += val.get();
        }
        context.write(key, new IntWritable(sum));
    }
}</pre></div><div class='content'><h4>Driver</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmNvbmYuQ29uZmlndXJhdGlvbjsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmZzLlBhdGg7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5JbnRXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuSm9iOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AubWFwcmVkdWNlLmxpYi5pbnB1dC5GaWxlSW5wdXRGb3JtYXQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UubGliLm91dHB1dC5GaWxlT3V0cHV0Rm9ybWF0OwoKcHVibGljIGNsYXNzIFdlYkxvZ0FuYWx5c2lzIHsKICAgIHB1YmxpYyBzdGF0aWMgdm9pZCBtYWluKFN0cmluZ1tdIGFyZ3MpIHRocm93cyBFeGNlcHRpb24gewogICAgICAgIENvbmZpZ3VyYXRpb24gY29uZiA9IG5ldyBDb25maWd1cmF0aW9uKCk7CiAgICAgICAgSm9iIGpvYiA9IEpvYi5nZXRJbnN0YW5jZShjb25mLCAid2ViIGxvZyBhbmFseXNpcyIpOwogICAgICAgIGpvYi5zZXRKYXJCeUNsYXNzKFdlYkxvZ0FuYWx5c2lzLmNsYXNzKTsKICAgICAgICBqb2Iuc2V0TWFwcGVyQ2xhc3MoV2ViTG9nTWFwcGVyLmNsYXNzKTsKICAgICAgICBqb2Iuc2V0Q29tYmluZXJDbGFzcyhXZWJMb2dSZWR1Y2VyLmNsYXNzKTsKICAgICAgICBqb2Iuc2V0UmVkdWNlckNsYXNzKFdlYkxvZ1JlZHVjZXIuY2xhc3MpOwogICAgICAgIGpvYi5zZXRPdXRwdXRLZXlDbGFzcyhUZXh0LmNsYXNzKTsKICAgICAgICBqb2Iuc2V0T3V0cHV0VmFsdWVDbGFzcyhJbnRXcml0YWJsZS5jbGFzcyk7CiAgICAgICAgRmlsZUlucHV0Rm9ybWF0LmFkZElucHV0UGF0aChqb2IsIG5ldyBQYXRoKGFyZ3NbMF0pKTsKICAgICAgICBGaWxlT3V0cHV0Rm9ybWF0LnNldE91dHB1dFBhdGgoam9iLCBuZXcgUGF0aChhcmdzWzFdKSk7CiAgICAgICAgU3lzdGVtLmV4aXQoam9iLndhaXRGb3JDb21wbGV0aW9uKHRydWUpID8gMCA6IDEpOwogICAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WebLogAnalysis {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, &quot;web log analysis&quot;);
        job.setJarByClass(WebLogAnalysis.class);
        job.setMapperClass(WebLogMapper.class);
        job.setCombinerClass(WebLogReducer.class);
        job.setReducerClass(WebLogReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}</pre></div><div class='content'></div><h3>3.2 Compilar y Ejecutar el Programa MapReduce</h3>
<div class='content'><ol>
<li>
<p><strong>Compila el código Java:</strong></p>
<pre><code class="language-bash">javac -classpath `hadoop classpath` -d . WebLogMapper.java WebLogReducer.java WebLogAnalysis.java
</code></pre>
</li>
<li>
<p><strong>Empaqueta el código en un archivo JAR:</strong></p>
<pre><code class="language-bash">jar -cvf webloganalysis.jar *.class
</code></pre>
</li>
<li>
<p><strong>Ejecuta el programa MapReduce:</strong></p>
<pre><code class="language-bash">hadoop jar webloganalysis.jar WebLogAnalysis /user/hadoop/web-logs /user/hadoop/output
</code></pre>
</li>
</ol>
</div><h2>Paso 4: Utilizar Herramientas del Ecosistema Hadoop</h2>
<div class='content'></div><h3>4.1 Análisis con Apache Hive</h3>
<div class='content'><p>Hive permite realizar consultas SQL sobre datos almacenados en HDFS.</p>
<ol>
<li>
<p><strong>Crea una tabla en Hive:</strong></p>
<pre><code class="language-sql">CREATE TABLE web_logs (
    ip STRING,
    timestamp STRING,
    request STRING,
    url STRING,
    response_code INT,
    bytes INT
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ' ';
</code></pre>
</li>
<li>
<p><strong>Carga los datos en la tabla Hive:</strong></p>
<pre><code class="language-sql">LOAD DATA INPATH '/user/hadoop/web-logs' INTO TABLE web_logs;
</code></pre>
</li>
<li>
<p><strong>Ejecuta una consulta para contar accesos por URL:</strong></p>
<pre><code class="language-sql">SELECT url, COUNT(*) as access_count
FROM web_logs
GROUP BY url;
</code></pre>
</li>
</ol>
</div><h3>4.2 Análisis con Apache Pig</h3>
<div class='content'><p>Pig permite escribir scripts de análisis de datos en un lenguaje de alto nivel llamado Pig Latin.</p>
<ol>
<li>
<p><strong>Escribe un script Pig para contar accesos por URL:</strong></p>
<pre><code class="language-pig">logs = LOAD '/user/hadoop/web-logs' USING PigStorage(' ') AS (ip:chararray, timestamp:chararray, request:chararray, url:chararray, response_code:int, bytes:int);
grouped_logs = GROUP logs BY url;
url_counts = FOREACH grouped_logs GENERATE group AS url, COUNT(logs) AS access_count;
STORE url_counts INTO '/user/hadoop/output-pig';
</code></pre>
</li>
<li>
<p><strong>Ejecuta el script Pig:</strong></p>
<pre><code class="language-bash">pig -x mapreduce webloganalysis.pig
</code></pre>
</li>
</ol>
</div><h2>Conclusión</h2>
<div class='content'><p>En este proyecto, hemos configurado un entorno Hadoop, cargado datos en HDFS, desarrollado y ejecutado un programa MapReduce, y utilizado herramientas del ecosistema Hadoop como Hive y Pig para analizar un conjunto de datos masivos. Este ejercicio práctico te ha permitido aplicar y consolidar los conocimientos adquiridos en los módulos anteriores, preparándote para enfrentar desafíos reales en el análisis de Big Data con Hadoop.</p>
</div><h2>Ejercicios Adicionales</h2>
<div class='content'><ol>
<li><strong>Modifica el programa MapReduce para contar el número de accesos por dirección IP.</strong></li>
<li><strong>Utiliza Apache HBase para almacenar y consultar los resultados del análisis.</strong></li>
<li><strong>Implementa técnicas de optimización en el programa MapReduce para mejorar su rendimiento.</strong></li>
</ol>
</div><h2>Retroalimentación y Consejos</h2>
<div class='content'><ul>
<li>
<p><strong>Errores Comunes:</strong></p>
<ul>
<li>Asegúrate de que los archivos de configuración de Hadoop estén correctamente configurados.</li>
<li>Verifica que los datos estén correctamente formateados antes de cargarlos en HDFS.</li>
<li>Comprueba los permisos de los directorios en HDFS.</li>
</ul>
</li>
<li>
<p><strong>Consejos Adicionales:</strong></p>
<ul>
<li>Utiliza combinadores en MapReduce para reducir la cantidad de datos transferidos entre el Mapper y el Reducer.</li>
<li>Aprovecha las capacidades de paralelización de Hadoop para procesar grandes volúmenes de datos de manera eficiente.</li>
<li>Familiarízate con las herramientas del ecosistema Hadoop para enriquecer tus análisis y mejorar la productividad.</li>
</ul>
</li>
</ul>
<p>¡Felicidades por completar este proyecto! Ahora estás listo para abordar proyectos más complejos y explorar más a fondo el poder de Hadoop en el análisis de Big Data.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='07-04-case-studies-of-hadoop-implementations' title="Estudios de Caso de Implementaciones de Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='07-04-case-studies-of-hadoop-implementations' title="Estudios de Caso de Implementaciones de Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem' title="Proyecto 2: Construyendo una Canalización de Datos con el Ecosistema Hadoop" class="py-2 px-3 btn btn-primary"
				data-read-mod="hadoop" data-read-unit="8-1">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem' title="Proyecto 2: Construyendo una Canalización de Datos con el Ecosistema Hadoop" class="py-2 px-3 btn btn-primary" 
				data-read-mod="hadoop" data-read-unit="8-1">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de Hadoop</h1>
<h2>Módulo 1: Introducción a Hadoop</h2>
<ul>
<li><a href="01-01-what-is-hadoop">¿Qué es Hadoop?</a></li>
<li><a href="01-02-hadoop-ecosystem-overview">Visión General del Ecosistema Hadoop</a></li>
<li><a href="01-03-hadoop-vs-traditional-databases">Hadoop vs Bases de Datos Tradicionales</a></li>
<li><a href="01-04-setting-up-hadoop-environment">Configuración del Entorno Hadoop</a></li>
</ul>
<h2>Módulo 2: Arquitectura de Hadoop</h2>
<ul>
<li><a href="02-01-hadoop-core-components">Componentes Principales de Hadoop</a></li>
<li><a href="02-02-hdfs">HDFS (Sistema de Archivos Distribuido de Hadoop)</a></li>
<li><a href="02-03-mapreduce-framework">Marco de Trabajo MapReduce</a></li>
<li><a href="02-04-yarn">YARN (Yet Another Resource Negotiator)</a></li>
</ul>
<h2>Módulo 3: HDFS (Sistema de Archivos Distribuido de Hadoop)</h2>
<ul>
<li><a href="03-01-hdfs-architecture">Arquitectura de HDFS</a></li>
<li><a href="03-02-hdfs-commands">Comandos de HDFS</a></li>
<li><a href="03-03-data-replication-in-hdfs">Replicación de Datos en HDFS</a></li>
<li><a href="03-04-hdfs-fault-tolerance">Tolerancia a Fallos en HDFS</a></li>
</ul>
<h2>Módulo 4: Programación MapReduce</h2>
<ul>
<li><a href="04-01-introduction-to-mapreduce">Introducción a MapReduce</a></li>
<li><a href="04-02-mapreduce-job-workflow">Flujo de Trabajo de un Job MapReduce</a></li>
<li><a href="04-03-writing-a-mapreduce-program">Escribiendo un Programa MapReduce</a></li>
<li><a href="04-04-mapreduce-optimization-techniques">Técnicas de Optimización de MapReduce</a></li>
</ul>
<h2>Módulo 5: Herramientas del Ecosistema Hadoop</h2>
<ul>
<li><a href="05-01-apache-pig">Apache Pig</a></li>
<li><a href="05-02-apache-hive">Apache Hive</a></li>
<li><a href="05-03-apache-hbase">Apache HBase</a></li>
<li><a href="05-04-apache-sqoop">Apache Sqoop</a></li>
<li><a href="05-05-apache-flume">Apache Flume</a></li>
<li><a href="05-06-apache-oozie">Apache Oozie</a></li>
</ul>
<h2>Módulo 6: Conceptos Avanzados de Hadoop</h2>
<ul>
<li><a href="06-01-hadoop-security">Seguridad en Hadoop</a></li>
<li><a href="06-02-hadoop-cluster-management">Gestión de Clústeres Hadoop</a></li>
<li><a href="06-03-hadoop-performance-tuning">Ajuste de Rendimiento de Hadoop</a></li>
<li><a href="06-04-hadoop-data-serialization">Serialización de Datos en Hadoop</a></li>
</ul>
<h2>Módulo 7: Aplicaciones del Mundo Real y Estudios de Caso</h2>
<ul>
<li><a href="07-01-hadoop-in-data-warehousing">Hadoop en Almacenamiento de Datos</a></li>
<li><a href="07-02-hadoop-in-machine-learning">Hadoop en Aprendizaje Automático</a></li>
<li><a href="07-03-hadoop-in-real-time-data-processing">Hadoop en Procesamiento de Datos en Tiempo Real</a></li>
<li><a href="07-04-case-studies-of-hadoop-implementations">Estudios de Caso de Implementaciones de Hadoop</a></li>
</ul>
<h2>Módulo 8: Proyectos Prácticos</h2>
<ul>
<li><a href="08-01-project-1-analyzing-big-data-with-hadoop">Proyecto 1: Analizando Big Data con Hadoop</a></li>
<li><a href="08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem">Proyecto 2: Construyendo una Canalización de Datos con el Ecosistema Hadoop</a></li>
<li><a href="08-03-project-3-real-time-data-processing-with-hadoop">Proyecto 3: Procesamiento de Datos en Tiempo Real con Hadoop</a></li>
<li><a href="08-04-project-4-machine-learning-with-hadoop">Proyecto 4: Aprendizaje Automático con Hadoop</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuario no autenticado</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
