<!DOCTYPE html>
<html lang="es">
<head>
    <title> Escribiendo un Programa MapReduce </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/hadoop/04-03-writing-a-mapreduce-program" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/hadoop/04-03-writing-a-mapreduce-program" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/hadoop/04-03-writing-a-mapreduce-program" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.ea63f62b9e.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "es";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "hadoop";
  		var TEMA_NAME = "4-3";
  		var TYPE = "mod";
  		var PATH = "mod/hadoop/04-03-writing-a-mapreduce-program";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/courses/hadoop/04-03-writing-a-mapreduce-program" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/cursos/hadoop/04-03-writing-a-mapreduce-program" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/mis-cursos" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Mis cursos</b></i>
</a>
<a href="/cursos-finalizados" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalizados             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="hadoop">
		<a  href="#" class="text-secondary d-none" data-read-mod="hadoop" data-read-unit="4-3" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar como leído
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="hadoop" data-unread-unit="4-3" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar como no leído
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contenido del curso
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='04-02-mapreduce-job-workflow' title="Flujo de Trabajo de un Job MapReduce" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='04-02-mapreduce-job-workflow' title="Flujo de Trabajo de un Job MapReduce" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h2 style="text-decoration:underline">Escribiendo un Programa MapReduce</h2>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='04-04-mapreduce-optimization-techniques' title="Técnicas de Optimización de MapReduce" class="py-2 px-3 btn btn-primary"
				data-read-mod="hadoop" data-read-unit="4-3">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='04-04-mapreduce-optimization-techniques' title="Técnicas de Optimización de MapReduce" class="py-2 px-3 btn btn-primary" 
				data-read-mod="hadoop" data-read-unit="4-3">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>En este tema, aprenderás a escribir un programa MapReduce desde cero. MapReduce es un modelo de programación que permite el procesamiento de grandes conjuntos de datos de manera distribuida. Este modelo se compone de dos fases principales: Map y Reduce.</p>
</div><h1>Objetivos de Aprendizaje</h1>
<div class='content'><ul>
<li>Comprender la estructura básica de un programa MapReduce.</li>
<li>Escribir un programa MapReduce simple en Java.</li>
<li>Ejecutar y probar el programa en un entorno Hadoop.</li>
</ul>
</div><h1>Estructura de un Programa MapReduce</h1>
<div class='content'><p>Un programa MapReduce típico consta de tres componentes principales:</p>
<ol>
<li><strong>Mapper</strong>: Procesa los datos de entrada y genera pares clave-valor intermedios.</li>
<li><strong>Reducer</strong>: Procesa los pares clave-valor intermedios y genera los resultados finales.</li>
<li><strong>Driver</strong>: Configura y ejecuta el trabajo MapReduce.</li>
</ol>
</div><h2><ol>
<li>Mapper</li>
</ol></h2>
<div class='content'><p>El Mapper toma un conjunto de datos de entrada y los convierte en pares clave-valor intermedios. Aquí está la estructura básica de una clase Mapper en Java:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLkxvbmdXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuTWFwcGVyOwoKaW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CgpwdWJsaWMgY2xhc3MgVG9rZW5pemVyTWFwcGVyIGV4dGVuZHMgTWFwcGVyPExvbmdXcml0YWJsZSwgVGV4dCwgVGV4dCwgTG9uZ1dyaXRhYmxlPiB7CiAgICBwcml2YXRlIGZpbmFsIHN0YXRpYyBMb25nV3JpdGFibGUgb25lID0gbmV3IExvbmdXcml0YWJsZSgxKTsKICAgIHByaXZhdGUgVGV4dCB3b3JkID0gbmV3IFRleHQoKTsKCiAgICBAT3ZlcnJpZGUKICAgIHByb3RlY3RlZCB2b2lkIG1hcChMb25nV3JpdGFibGUga2V5LCBUZXh0IHZhbHVlLCBDb250ZXh0IGNvbnRleHQpIHRocm93cyBJT0V4Y2VwdGlvbiwgSW50ZXJydXB0ZWRFeGNlcHRpb24gewogICAgICAgIFN0cmluZyBsaW5lID0gdmFsdWUudG9TdHJpbmcoKTsKICAgICAgICBTdHJpbmdbXSB0b2tlbnMgPSBsaW5lLnNwbGl0KCJcXHMrIik7CiAgICAgICAgZm9yIChTdHJpbmcgdG9rZW4gOiB0b2tlbnMpIHsKICAgICAgICAgICAgd29yZC5zZXQodG9rZW4pOwogICAgICAgICAgICBjb250ZXh0LndyaXRlKHdvcmQsIG9uZSk7CiAgICAgICAgfQogICAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class TokenizerMapper extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; {
    private final static LongWritable one = new LongWritable(1);
    private Text word = new Text();

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String line = value.toString();
        String[] tokens = line.split(&quot;\\s+&quot;);
        for (String token : tokens) {
            word.set(token);
            context.write(word, one);
        }
    }
}</pre></div><div class='content'></div><h2><ol start="2">
<li>Reducer</li>
</ol></h2>
<div class='content'><p>El Reducer toma los pares clave-valor intermedios generados por el Mapper y los procesa para generar los resultados finales.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLkxvbmdXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuUmVkdWNlcjsKCmltcG9ydCBqYXZhLmlvLklPRXhjZXB0aW9uOwoKcHVibGljIGNsYXNzIEludFN1bVJlZHVjZXIgZXh0ZW5kcyBSZWR1Y2VyPFRleHQsIExvbmdXcml0YWJsZSwgVGV4dCwgTG9uZ1dyaXRhYmxlPiB7CiAgICBwcml2YXRlIExvbmdXcml0YWJsZSByZXN1bHQgPSBuZXcgTG9uZ1dyaXRhYmxlKCk7CgogICAgQE92ZXJyaWRlCiAgICBwcm90ZWN0ZWQgdm9pZCByZWR1Y2UoVGV4dCBrZXksIEl0ZXJhYmxlPExvbmdXcml0YWJsZT4gdmFsdWVzLCBDb250ZXh0IGNvbnRleHQpIHRocm93cyBJT0V4Y2VwdGlvbiwgSW50ZXJydXB0ZWRFeGNlcHRpb24gewogICAgICAgIGxvbmcgc3VtID0gMDsKICAgICAgICBmb3IgKExvbmdXcml0YWJsZSB2YWwgOiB2YWx1ZXMpIHsKICAgICAgICAgICAgc3VtICs9IHZhbC5nZXQoKTsKICAgICAgICB9CiAgICAgICAgcmVzdWx0LnNldChzdW0pOwogICAgICAgIGNvbnRleHQud3JpdGUoa2V5LCByZXN1bHQpOwogICAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class IntSumReducer extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt; {
    private LongWritable result = new LongWritable();

    @Override
    protected void reduce(Text key, Iterable&lt;LongWritable&gt; values, Context context) throws IOException, InterruptedException {
        long sum = 0;
        for (LongWritable val : values) {
            sum += val.get();
        }
        result.set(sum);
        context.write(key, result);
    }
}</pre></div><div class='content'></div><h2><ol start="3">
<li>Driver</li>
</ol></h2>
<div class='content'><p>El Driver configura y ejecuta el trabajo MapReduce. Aquí se especifican las clases Mapper y Reducer, así como los formatos de entrada y salida.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmNvbmYuQ29uZmlndXJhdGlvbjsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmZzLlBhdGg7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5Mb25nV3JpdGFibGU7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5UZXh0OwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AubWFwcmVkdWNlLkpvYjsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLm1hcHJlZHVjZS5saWIuaW5wdXQuRmlsZUlucHV0Rm9ybWF0OwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AubWFwcmVkdWNlLmxpYi5vdXRwdXQuRmlsZU91dHB1dEZvcm1hdDsKCnB1YmxpYyBjbGFzcyBXb3JkQ291bnQgewogICAgcHVibGljIHN0YXRpYyB2b2lkIG1haW4oU3RyaW5nW10gYXJncykgdGhyb3dzIEV4Y2VwdGlvbiB7CiAgICAgICAgQ29uZmlndXJhdGlvbiBjb25mID0gbmV3IENvbmZpZ3VyYXRpb24oKTsKICAgICAgICBKb2Igam9iID0gSm9iLmdldEluc3RhbmNlKGNvbmYsICJ3b3JkIGNvdW50Iik7CiAgICAgICAgam9iLnNldEphckJ5Q2xhc3MoV29yZENvdW50LmNsYXNzKTsKICAgICAgICBqb2Iuc2V0TWFwcGVyQ2xhc3MoVG9rZW5pemVyTWFwcGVyLmNsYXNzKTsKICAgICAgICBqb2Iuc2V0Q29tYmluZXJDbGFzcyhJbnRTdW1SZWR1Y2VyLmNsYXNzKTsKICAgICAgICBqb2Iuc2V0UmVkdWNlckNsYXNzKEludFN1bVJlZHVjZXIuY2xhc3MpOwogICAgICAgIGpvYi5zZXRPdXRwdXRLZXlDbGFzcyhUZXh0LmNsYXNzKTsKICAgICAgICBqb2Iuc2V0T3V0cHV0VmFsdWVDbGFzcyhMb25nV3JpdGFibGUuY2xhc3MpOwogICAgICAgIEZpbGVJbnB1dEZvcm1hdC5hZGRJbnB1dFBhdGgoam9iLCBuZXcgUGF0aChhcmdzWzBdKSk7CiAgICAgICAgRmlsZU91dHB1dEZvcm1hdC5zZXRPdXRwdXRQYXRoKGpvYiwgbmV3IFBhdGgoYXJnc1sxXSkpOwogICAgICAgIFN5c3RlbS5leGl0KGpvYi53YWl0Rm9yQ29tcGxldGlvbih0cnVlKSA/IDAgOiAxKTsKICAgIH0KfQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, &quot;word count&quot;);
        job.setJarByClass(WordCount.class);
        job.setMapperClass(TokenizerMapper.class);
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(IntSumReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(LongWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}</pre></div><div class='content'></div><h1>Ejemplo Completo: Contador de Palabras</h1>
<div class='content'><p>Vamos a combinar los tres componentes anteriores en un programa completo que cuenta la frecuencia de palabras en un conjunto de datos de texto.</p>
</div><h2>Paso 1: Crear el Proyecto</h2>
<div class='content'><ol>
<li>Crea un nuevo proyecto Java en tu IDE favorito.</li>
<li>Añade las dependencias de Hadoop a tu proyecto.</li>
</ol>
</div><h2>Paso 2: Escribir el Código</h2>
<div class='content'><p>Crea tres archivos Java: <code>TokenizerMapper.java</code>, <code>IntSumReducer.java</code>, y <code>WordCount.java</code>, y copia el código proporcionado anteriormente en cada archivo correspondiente.</p>
</div><h2>Paso 3: Compilar y Empaquetar</h2>
<div class='content'><p>Compila y empaqueta tu proyecto en un archivo JAR. Asegúrate de incluir todas las dependencias necesarias.</p>
</div><h2>Paso 4: Ejecutar el Programa en Hadoop</h2>
<div class='content'><ol>
<li>Sube el archivo JAR a tu clúster Hadoop.</li>
<li>Ejecuta el trabajo MapReduce usando el siguiente comando:</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aGFkb29wIGphciBXb3JkQ291bnQuamFyIFdvcmRDb3VudCAvcnV0YS9kZS9lbnRyYWRhIC9ydXRhL2RlL3NhbGlkYQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>hadoop jar WordCount.jar WordCount /ruta/de/entrada /ruta/de/salida</pre></div><div class='content'></div><h1>Ejercicio Práctico</h1>
<div class='content'><p><strong>Ejercicio:</strong> Modifica el programa de contador de palabras para que ignore las palabras comunes (stop words) como &quot;the&quot;, &quot;is&quot;, &quot;in&quot;, etc.</p>
<p><strong>Solución:</strong></p>
<ol>
<li>Crea una lista de palabras comunes.</li>
<li>Modifica el método <code>map</code> en <code>TokenizerMapper</code> para ignorar estas palabras.</li>
</ol>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGphdmEudXRpbC5IYXNoU2V0OwppbXBvcnQgamF2YS51dGlsLlNldDsKCnB1YmxpYyBjbGFzcyBUb2tlbml6ZXJNYXBwZXIgZXh0ZW5kcyBNYXBwZXI8TG9uZ1dyaXRhYmxlLCBUZXh0LCBUZXh0LCBMb25nV3JpdGFibGU+IHsKICAgIHByaXZhdGUgZmluYWwgc3RhdGljIExvbmdXcml0YWJsZSBvbmUgPSBuZXcgTG9uZ1dyaXRhYmxlKDEpOwogICAgcHJpdmF0ZSBUZXh0IHdvcmQgPSBuZXcgVGV4dCgpOwogICAgcHJpdmF0ZSBTZXQ8U3RyaW5nPiBzdG9wV29yZHM7CgogICAgQE92ZXJyaWRlCiAgICBwcm90ZWN0ZWQgdm9pZCBzZXR1cChDb250ZXh0IGNvbnRleHQpIHRocm93cyBJT0V4Y2VwdGlvbiwgSW50ZXJydXB0ZWRFeGNlcHRpb24gewogICAgICAgIHN0b3BXb3JkcyA9IG5ldyBIYXNoU2V0PD4oKTsKICAgICAgICBzdG9wV29yZHMuYWRkKCJ0aGUiKTsKICAgICAgICBzdG9wV29yZHMuYWRkKCJpcyIpOwogICAgICAgIHN0b3BXb3Jkcy5hZGQoImluIik7CiAgICAgICAgLy8gQcOxYWRlIG3DoXMgcGFsYWJyYXMgY29tdW5lcyBzZWfDum4gc2VhIG5lY2VzYXJpbwogICAgfQoKICAgIEBPdmVycmlkZQogICAgcHJvdGVjdGVkIHZvaWQgbWFwKExvbmdXcml0YWJsZSBrZXksIFRleHQgdmFsdWUsIENvbnRleHQgY29udGV4dCkgdGhyb3dzIElPRXhjZXB0aW9uLCBJbnRlcnJ1cHRlZEV4Y2VwdGlvbiB7CiAgICAgICAgU3RyaW5nIGxpbmUgPSB2YWx1ZS50b1N0cmluZygpOwogICAgICAgIFN0cmluZ1tdIHRva2VucyA9IGxpbmUuc3BsaXQoIlxccysiKTsKICAgICAgICBmb3IgKFN0cmluZyB0b2tlbiA6IHRva2VucykgewogICAgICAgICAgICBpZiAoIXN0b3BXb3Jkcy5jb250YWlucyh0b2tlbi50b0xvd2VyQ2FzZSgpKSkgewogICAgICAgICAgICAgICAgd29yZC5zZXQodG9rZW4pOwogICAgICAgICAgICAgICAgY29udGV4dC53cml0ZSh3b3JkLCBvbmUpOwogICAgICAgICAgICB9CiAgICAgICAgfQogICAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.util.HashSet;
import java.util.Set;

public class TokenizerMapper extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; {
    private final static LongWritable one = new LongWritable(1);
    private Text word = new Text();
    private Set&lt;String&gt; stopWords;

    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
        stopWords = new HashSet&lt;&gt;();
        stopWords.add(&quot;the&quot;);
        stopWords.add(&quot;is&quot;);
        stopWords.add(&quot;in&quot;);
        // A&ntilde;ade m&aacute;s palabras comunes seg&uacute;n sea necesario
    }

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String line = value.toString();
        String[] tokens = line.split(&quot;\\s+&quot;);
        for (String token : tokens) {
            if (!stopWords.contains(token.toLowerCase())) {
                word.set(token);
                context.write(word, one);
            }
        }
    }
}</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, has aprendido a escribir un programa MapReduce básico en Java. Has visto cómo estructurar el código en Mapper, Reducer y Driver, y cómo ejecutar el programa en un entorno Hadoop. Además, has practicado modificando el programa para ignorar palabras comunes. En el siguiente módulo, profundizaremos en técnicas de optimización para mejorar el rendimiento de tus trabajos MapReduce.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='04-02-mapreduce-job-workflow' title="Flujo de Trabajo de un Job MapReduce" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='04-02-mapreduce-job-workflow' title="Flujo de Trabajo de un Job MapReduce" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='04-04-mapreduce-optimization-techniques' title="Técnicas de Optimización de MapReduce" class="py-2 px-3 btn btn-primary"
				data-read-mod="hadoop" data-read-unit="4-3">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='04-04-mapreduce-optimization-techniques' title="Técnicas de Optimización de MapReduce" class="py-2 px-3 btn btn-primary" 
				data-read-mod="hadoop" data-read-unit="4-3">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de Hadoop</h1>
<h2>Módulo 1: Introducción a Hadoop</h2>
<ul>
<li><a href="01-01-what-is-hadoop">¿Qué es Hadoop?</a></li>
<li><a href="01-02-hadoop-ecosystem-overview">Visión General del Ecosistema Hadoop</a></li>
<li><a href="01-03-hadoop-vs-traditional-databases">Hadoop vs Bases de Datos Tradicionales</a></li>
<li><a href="01-04-setting-up-hadoop-environment">Configuración del Entorno Hadoop</a></li>
</ul>
<h2>Módulo 2: Arquitectura de Hadoop</h2>
<ul>
<li><a href="02-01-hadoop-core-components">Componentes Principales de Hadoop</a></li>
<li><a href="02-02-hdfs">HDFS (Sistema de Archivos Distribuido de Hadoop)</a></li>
<li><a href="02-03-mapreduce-framework">Marco de Trabajo MapReduce</a></li>
<li><a href="02-04-yarn">YARN (Yet Another Resource Negotiator)</a></li>
</ul>
<h2>Módulo 3: HDFS (Sistema de Archivos Distribuido de Hadoop)</h2>
<ul>
<li><a href="03-01-hdfs-architecture">Arquitectura de HDFS</a></li>
<li><a href="03-02-hdfs-commands">Comandos de HDFS</a></li>
<li><a href="03-03-data-replication-in-hdfs">Replicación de Datos en HDFS</a></li>
<li><a href="03-04-hdfs-fault-tolerance">Tolerancia a Fallos en HDFS</a></li>
</ul>
<h2>Módulo 4: Programación MapReduce</h2>
<ul>
<li><a href="04-01-introduction-to-mapreduce">Introducción a MapReduce</a></li>
<li><a href="04-02-mapreduce-job-workflow">Flujo de Trabajo de un Job MapReduce</a></li>
<li><a href="04-03-writing-a-mapreduce-program">Escribiendo un Programa MapReduce</a></li>
<li><a href="04-04-mapreduce-optimization-techniques">Técnicas de Optimización de MapReduce</a></li>
</ul>
<h2>Módulo 5: Herramientas del Ecosistema Hadoop</h2>
<ul>
<li><a href="05-01-apache-pig">Apache Pig</a></li>
<li><a href="05-02-apache-hive">Apache Hive</a></li>
<li><a href="05-03-apache-hbase">Apache HBase</a></li>
<li><a href="05-04-apache-sqoop">Apache Sqoop</a></li>
<li><a href="05-05-apache-flume">Apache Flume</a></li>
<li><a href="05-06-apache-oozie">Apache Oozie</a></li>
</ul>
<h2>Módulo 6: Conceptos Avanzados de Hadoop</h2>
<ul>
<li><a href="06-01-hadoop-security">Seguridad en Hadoop</a></li>
<li><a href="06-02-hadoop-cluster-management">Gestión de Clústeres Hadoop</a></li>
<li><a href="06-03-hadoop-performance-tuning">Ajuste de Rendimiento de Hadoop</a></li>
<li><a href="06-04-hadoop-data-serialization">Serialización de Datos en Hadoop</a></li>
</ul>
<h2>Módulo 7: Aplicaciones del Mundo Real y Estudios de Caso</h2>
<ul>
<li><a href="07-01-hadoop-in-data-warehousing">Hadoop en Almacenamiento de Datos</a></li>
<li><a href="07-02-hadoop-in-machine-learning">Hadoop en Aprendizaje Automático</a></li>
<li><a href="07-03-hadoop-in-real-time-data-processing">Hadoop en Procesamiento de Datos en Tiempo Real</a></li>
<li><a href="07-04-case-studies-of-hadoop-implementations">Estudios de Caso de Implementaciones de Hadoop</a></li>
</ul>
<h2>Módulo 8: Proyectos Prácticos</h2>
<ul>
<li><a href="08-01-project-1-analyzing-big-data-with-hadoop">Proyecto 1: Analizando Big Data con Hadoop</a></li>
<li><a href="08-02-project-2-building-a-data-pipeline-with-hadoop-ecosystem">Proyecto 2: Construyendo una Canalización de Datos con el Ecosistema Hadoop</a></li>
<li><a href="08-03-project-3-real-time-data-processing-with-hadoop">Proyecto 3: Procesamiento de Datos en Tiempo Real con Hadoop</a></li>
<li><a href="08-04-project-4-machine-learning-with-hadoop">Proyecto 4: Aprendizaje Automático con Hadoop</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuario no autenticado</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
