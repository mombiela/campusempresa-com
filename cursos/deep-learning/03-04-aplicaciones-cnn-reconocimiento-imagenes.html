<!DOCTYPE html>
<html lang="es">
<head>
    <title> Aplicaciones de CNN en Reconocimiento de Imágenes </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/deep-learning/03-04-aplicaciones-cnn-reconocimiento-imagenes" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/deep-learning/03-04-aplicaciones-cnn-reconocimiento-imagenes" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/deep-learning/03-04-cnn-applications-image-recognition" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.188a386f47.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "es";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "deep_learning";
  		var TEMA_NAME = "3-4";
  		var TYPE = "mod";
  		var PATH = "mod/deep_learning/03-04-aplicaciones-cnn-reconocimiento-imagenes";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo_header.png" alt="Logo Campus Empresa"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/courses/deep-learning/03-04-cnn-applications-image-recognition" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/cursos/deep-learning/03-04-aplicaciones-cnn-reconocimiento-imagenes" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/mis-cursos" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Mis cursos</b></i>
</a>
<a href="/cursos-finalizados" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalizados             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="deep_learning">
		<a  href="#" class="text-secondary d-none" data-read-mod="deep_learning" data-read-unit="3-4" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar como leído
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="deep_learning" data-unread-unit="3-4" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar como no leído
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contenido del curso
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='03-03-arquitecturas-populares-cnn' title="Arquitecturas populares de CNN" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='03-03-arquitecturas-populares-cnn' title="Arquitecturas populares de CNN" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Aplicaciones de CNN en Reconocimiento de Imágenes</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='04-01-introduccion-rnn' title="Introducción a las RNN" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="3-4">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='04-01-introduccion-rnn' title="Introducción a las RNN" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="3-4">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'></div><h2>Introducción</h2>
<div class='content'><p>Las Redes Neuronales Convolucionales (CNN) han revolucionado el campo del reconocimiento de imágenes debido a su capacidad para aprender características jerárquicas y complejas directamente a partir de los datos de imagen. En esta sección, exploraremos diversas aplicaciones de las CNN en el reconocimiento de imágenes, desde la clasificación de imágenes hasta la detección de objetos y la segmentación semántica.</p>
</div><h2>Aplicaciones Principales</h2>
<div class='content'></div><h3><ol>
<li>Clasificación de Imágenes</li>
</ol></h3>
<div class='content'><p>La clasificación de imágenes es una de las aplicaciones más comunes de las CNN. En esta tarea, el objetivo es asignar una etiqueta a una imagen de un conjunto predefinido de categorías.</p>
<p><strong>Ejemplo: Clasificación de Imágenes con CNN</strong></p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzIGltcG9ydCBkYXRhc2V0cywgbGF5ZXJzLCBtb2RlbHMKCiMgQ2FyZ2FyIHkgcHJlcHJvY2VzYXIgZWwgY29uanVudG8gZGUgZGF0b3MgQ0lGQVItMTAKKHRyYWluX2ltYWdlcywgdHJhaW5fbGFiZWxzKSwgKHRlc3RfaW1hZ2VzLCB0ZXN0X2xhYmVscykgPSBkYXRhc2V0cy5jaWZhcjEwLmxvYWRfZGF0YSgpCnRyYWluX2ltYWdlcywgdGVzdF9pbWFnZXMgPSB0cmFpbl9pbWFnZXMgLyAyNTUuMCwgdGVzdF9pbWFnZXMgLyAyNTUuMAoKIyBEZWZpbmlyIGxhIGFycXVpdGVjdHVyYSBkZSBsYSBDTk4KbW9kZWwgPSBtb2RlbHMuU2VxdWVudGlhbChbCiAgICBsYXllcnMuQ29udjJEKDMyLCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnLCBpbnB1dF9zaGFwZT0oMzIsIDMyLCAzKSksCiAgICBsYXllcnMuTWF4UG9vbGluZzJEKCgyLCAyKSksCiAgICBsYXllcnMuQ29udjJEKDY0LCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnKSwKICAgIGxheWVycy5NYXhQb29saW5nMkQoKDIsIDIpKSwKICAgIGxheWVycy5Db252MkQoNjQsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpLAogICAgbGF5ZXJzLkZsYXR0ZW4oKSwKICAgIGxheWVycy5EZW5zZSg2NCwgYWN0aXZhdGlvbj0ncmVsdScpLAogICAgbGF5ZXJzLkRlbnNlKDEwKQpdKQoKIyBDb21waWxhciB5IGVudHJlbmFyIGVsIG1vZGVsbwptb2RlbC5jb21waWxlKG9wdGltaXplcj0nYWRhbScsCiAgICAgICAgICAgICAgbG9zcz10Zi5rZXJhcy5sb3NzZXMuU3BhcnNlQ2F0ZWdvcmljYWxDcm9zc2VudHJvcHkoZnJvbV9sb2dpdHM9VHJ1ZSksCiAgICAgICAgICAgICAgbWV0cmljcz1bJ2FjY3VyYWN5J10pCm1vZGVsLmZpdCh0cmFpbl9pbWFnZXMsIHRyYWluX2xhYmVscywgZXBvY2hzPTEwLCAKICAgICAgICAgIHZhbGlkYXRpb25fZGF0YT0odGVzdF9pbWFnZXMsIHRlc3RfbGFiZWxzKSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import datasets, layers, models

# Cargar y preprocesar el conjunto de datos CIFAR-10
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

# Definir la arquitectura de la CNN
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10)
])

# Compilar y entrenar el modelo
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=10, 
          validation_data=(test_images, test_labels))</pre></div><div class='content'></div><h3><ol start="2">
<li>Detección de Objetos</li>
</ol></h3>
<div class='content'><p>La detección de objetos va un paso más allá de la clasificación de imágenes, ya que no solo identifica las categorías de los objetos presentes en una imagen, sino que también localiza sus posiciones mediante cajas delimitadoras (bounding boxes).</p>
<p><strong>Ejemplo: Detección de Objetos con YOLO (You Only Look Once)</strong></p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Este es un ejemplo simplificado y conceptual de c&oacute;mo se podr&iacute;a usar YOLO para la detecci&oacute;n de objetos
# La implementaci&oacute;n completa requiere un entorno configurado con Darknet y el modelo YOLO preentrenado

import cv2
import numpy as np

# Cargar el modelo YOLO preentrenado y las clases
net = cv2.dnn.readNet(&quot;yolov3.weights&quot;, &quot;yolov3.cfg&quot;)
layer_names = net.getLayerNames()
output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]
classes = open(&quot;coco.names&quot;).read().strip().split(&quot;\n&quot;)

# Leer la imagen y preparar la entrada para YOLO
image = cv2.imread(&quot;image.jpg&quot;)
height, width = image.shape[:2]
blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
net.setInput(blob)

# Ejecutar la detecci&oacute;n
outs = net.forward(output_layers)

# Procesar las detecciones
for out in outs:
    for detection in out:
        scores = detection[5:]
        class_id = np.argmax(scores)
        confidence = scores[class_id]
        if confidence &gt; 0.5:
            center_x = int(detection[0] * width)
            center_y = int(detection[1] * height)
            w = int(detection[2] * width)
            h = int(detection[3] * height)
            x = int(center_x - w / 2)
            y = int(center_y - h / 2)
            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(image, classes[class_id], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

cv2.imshow(&quot;Image&quot;, image)
cv2.waitKey(0)
cv2.destroyAllWindows()</pre></div><div class='content'></div><h3><ol start="3">
<li>Segmentación Semántica</li>
</ol></h3>
<div class='content'><p>La segmentación semántica es una tarea más detallada que la detección de objetos, ya que asigna una etiqueta a cada píxel de la imagen, identificando así las regiones específicas de cada objeto.</p>
<p><strong>Ejemplo: Segmentación Semántica con U-Net</strong></p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import layers, models

# Definir la arquitectura U-Net
def unet_model(input_size=(128, 128, 1)):
    inputs = layers.Input(input_size)
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling2D((2, 2))(c1)
    
    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling2D((2, 2))(c2)
    
    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)
    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling2D((2, 2))(c3)
    
    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)
    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)
    p4 = layers.MaxPooling2D((2, 2))(c4)
    
    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)
    
    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = layers.concatenate([u6, c4])
    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)
    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)
    
    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = layers.concatenate([u7, c3])
    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)
    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)
    
    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = layers.concatenate([u8, c2])
    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)
    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)
    
    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = layers.concatenate([u9, c1])
    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)
    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)
    
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)
    
    model = models.Model(inputs=[inputs], outputs=[outputs])
    return model

# Crear y compilar el modelo U-Net
model = unet_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenar el modelo (suponiendo que se tienen los datos de entrenamiento y validaci&oacute;n)
# model.fit(train_images, train_masks, epochs=10, validation_data=(val_images, val_masks))</pre></div><div class='content'></div><h2>Ejercicios Prácticos</h2>
<div class='content'></div><h3>Ejercicio 1: Clasificación de Imágenes</h3>
<div class='content'><p><strong>Tarea:</strong> Implementa una CNN para clasificar el conjunto de datos MNIST (dígitos escritos a mano).</p>
<p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzIGltcG9ydCBkYXRhc2V0cywgbGF5ZXJzLCBtb2RlbHMKCiMgQ2FyZ2FyIHkgcHJlcHJvY2VzYXIgZWwgY29uanVudG8gZGUgZGF0b3MgTU5JU1QKKHRyYWluX2ltYWdlcywgdHJhaW5fbGFiZWxzKSwgKHRlc3RfaW1hZ2VzLCB0ZXN0X2xhYmVscykgPSBkYXRhc2V0cy5tbmlzdC5sb2FkX2RhdGEoKQp0cmFpbl9pbWFnZXMgPSB0cmFpbl9pbWFnZXMucmVzaGFwZSgoNjAwMDAsIDI4LCAyOCwgMSkpLmFzdHlwZSgnZmxvYXQzMicpIC8gMjU1CnRlc3RfaW1hZ2VzID0gdGVzdF9pbWFnZXMucmVzaGFwZSgoMTAwMDAsIDI4LCAyOCwgMSkpLmFzdHlwZSgnZmxvYXQzMicpIC8gMjU1CgojIERlZmluaXIgbGEgYXJxdWl0ZWN0dXJhIGRlIGxhIENOTgptb2RlbCA9IG1vZGVscy5TZXF1ZW50aWFsKFsKICAgIGxheWVycy5Db252MkQoMzIsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScsIGlucHV0X3NoYXBlPSgyOCwgMjgsIDEpKSwKICAgIGxheWVycy5NYXhQb29saW5nMkQoKDIsIDIpKSwKICAgIGxheWVycy5Db252MkQoNjQsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpLAogICAgbGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpLAogICAgbGF5ZXJzLkNvbnYyRCg2NCwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JyksCiAgICBsYXllcnMuRmxhdHRlbigpLAogICAgbGF5ZXJzLkRlbnNlKDY0LCBhY3RpdmF0aW9uPSdyZWx1JyksCiAgICBsYXllcnMuRGVuc2UoMTAsIGFjdGl2YXRpb249J3NvZnRtYXgnKQpdKQoKIyBDb21waWxhciB5IGVudHJlbmFyIGVsIG1vZGVsbwptb2RlbC5jb21waWxlKG9wdGltaXplcj0nYWRhbScsCiAgICAgICAgICAgICAgbG9zcz0nc3BhcnNlX2NhdGVnb3JpY2FsX2Nyb3NzZW50cm9weScsCiAgICAgICAgICAgICAgbWV0cmljcz1bJ2FjY3VyYWN5J10pCm1vZGVsLmZpdCh0cmFpbl9pbWFnZXMsIHRyYWluX2xhYmVscywgZXBvY2hzPTUsIAogICAgICAgICAgdmFsaWRhdGlvbl9kYXRhPSh0ZXN0X2ltYWdlcywgdGVzdF9sYWJlbHMpKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import datasets, layers, models

# Cargar y preprocesar el conjunto de datos MNIST
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()
train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255

# Definir la arquitectura de la CNN
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compilar y entrenar el modelo
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=5, 
          validation_data=(test_images, test_labels))</pre></div><div class='content'></div><h3>Ejercicio 2: Detección de Objetos</h3>
<div class='content'><p><strong>Tarea:</strong> Implementa una detección de objetos simple utilizando un modelo preentrenado como MobileNet SSD.</p>
<p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGN2MgoKIyBDYXJnYXIgZWwgbW9kZWxvIE1vYmlsZU5ldCBTU0QgcHJlZW50cmVuYWRvIHkgbGFzIGNsYXNlcwpuZXQgPSBjdjIuZG5uLnJlYWROZXRGcm9tQ2FmZmUoImRlcGxveS5wcm90b3R4dCIsICJtb2JpbGVuZXRfaXRlcl83MzAwMC5jYWZmZW1vZGVsIikKY2xhc3NlcyA9IG9wZW4oInN5bnNldF93b3Jkcy50eHQiKS5yZWFkKCkuc3RyaXAoKS5zcGxpdCgiXG4iKQoKIyBMZWVyIGxhIGltYWdlbiB5IHByZXBhcmFyIGxhIGVudHJhZGEgcGFyYSBNb2JpbGVOZXQgU1NECmltYWdlID0gY3YyLmltcmVhZCgiaW1hZ2UuanBnIikKKGgsIHcpID0gaW1hZ2Uuc2hhcGVbOjJdCmJsb2IgPSBjdjIuZG5uLmJsb2JGcm9tSW1hZ2UoY3YyLnJlc2l6ZShpbWFnZSwgKDMwMCwgMzAwKSksIDAuMDA3ODQzLCAoMzAwLCAzMDApLCAxMjcuNSkKbmV0LnNldElucHV0KGJsb2IpCgojIEVqZWN1dGFyIGxhIGRldGVjY2nDs24KZGV0ZWN0aW9ucyA9IG5ldC5mb3J3YXJkKCkKCiMgUHJvY2VzYXIgbGFzIGRldGVjY2lvbmVzCmZvciBpIGluIHJhbmdlKGRldGVjdGlvbnMuc2hhcGVbMl0pOgogICAgY29uZmlkZW5jZSA9IGRldGVjdGlvbnNbMCwgMCwgaSwgMl0KICAgIGlmIGNvbmZpZGVuY2UgPiAwLjI6CiAgICAgICAgaWR4ID0gaW50KGRldGVjdGlvbnNbMCwgMCwgaSwgMV0pCiAgICAgICAgYm94ID0gZGV0ZWN0aW9uc1swLCAwLCBpLCAzOjddICogbnAuYXJyYXkoW3csIGgsIHcsIGhdKQogICAgICAgIChzdGFydFgsIHN0YXJ0WSwgZW5kWCwgZW5kWSkgPSBib3guYXN0eXBlKCJpbnQiKQogICAgICAgIGxhYmVsID0gInt9OiB7Oi4yZn0lIi5mb3JtYXQoY2xhc3Nlc1tpZHhdLCBjb25maWRlbmNlICogMTAwKQogICAgICAgIGN2Mi5yZWN0YW5nbGUoaW1hZ2UsIChzdGFydFgsIHN0YXJ0WSksIChlbmRYLCBlbmRZKSwgKDAsIDI1NSwgMCksIDIpCiAgICAgICAgeSA9IHN0YXJ0WSAtIDE1IGlmIHN0YXJ0WSAtIDE1ID4gMTUgZWxzZSBzdGFydFkgKyAxNQogICAgICAgIGN2Mi5wdXRUZXh0KGltYWdlLCBsYWJlbCwgKHN0YXJ0WCwgeSksIGN2Mi5GT05UX0hFUlNIRVlfU0lNUExFWCwgMC41LCAoMCwgMjU1LCAwKSwgMikKCmN2Mi5pbXNob3coIkltYWdlIiwgaW1hZ2UpCmN2Mi53YWl0S2V5KDApCmN2Mi5kZXN0cm95QWxsV2luZG93cygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import cv2

# Cargar el modelo MobileNet SSD preentrenado y las clases
net = cv2.dnn.readNetFromCaffe(&quot;deploy.prototxt&quot;, &quot;mobilenet_iter_73000.caffemodel&quot;)
classes = open(&quot;synset_words.txt&quot;).read().strip().split(&quot;\n&quot;)

# Leer la imagen y preparar la entrada para MobileNet SSD
image = cv2.imread(&quot;image.jpg&quot;)
(h, w) = image.shape[:2]
blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)
net.setInput(blob)

# Ejecutar la detecci&oacute;n
detections = net.forward()

# Procesar las detecciones
for i in range(detections.shape[2]):
    confidence = detections[0, 0, i, 2]
    if confidence &gt; 0.2:
        idx = int(detections[0, 0, i, 1])
        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
        (startX, startY, endX, endY) = box.astype(&quot;int&quot;)
        label = &quot;{}: {:.2f}%&quot;.format(classes[idx], confidence * 100)
        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)
        y = startY - 15 if startY - 15 &gt; 15 else startY + 15
        cv2.putText(image, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

cv2.imshow(&quot;Image&quot;, image)
cv2.waitKey(0)
cv2.destroyAllWindows()</pre></div><div class='content'></div><h2>Conclusión</h2>
<div class='content'><p>Las Redes Neuronales Convolucionales (CNN) han demostrado ser extremadamente efectivas en una variedad de tareas de reconocimiento de imágenes, incluyendo la clasificación de imágenes, la detección de objetos y la segmentación semántica. A través de ejemplos prácticos y ejercicios, hemos explorado cómo implementar estas aplicaciones utilizando diferentes arquitecturas y frameworks. En el próximo módulo, profundizaremos en las Redes Neuronales Recurrentes (RNN) y sus aplicaciones en el procesamiento del lenguaje natural y las series temporales.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='03-03-arquitecturas-populares-cnn' title="Arquitecturas populares de CNN" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='03-03-arquitecturas-populares-cnn' title="Arquitecturas populares de CNN" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='04-01-introduccion-rnn' title="Introducción a las RNN" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="3-4">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='04-01-introduccion-rnn' title="Introducción a las RNN" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="3-4">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de Deep Learning</h1>
<h2>Módulo 1: Introducción a Deep Learning</h2>
<ul>
<li><a href="01-01-que-es-deep-learning">¿Qué es Deep Learning?</a></li>
<li><a href="01-02-historia-evolucion-deep-learning">Historia y evolución del Deep Learning</a></li>
<li><a href="01-03-aplicaciones-deep-learning">Aplicaciones de Deep Learning</a></li>
<li><a href="01-04-conceptos-basicos-redes-neuronales">Conceptos básicos de redes neuronales</a></li>
</ul>
<h2>Módulo 2: Fundamentos de Redes Neuronales</h2>
<ul>
<li><a href="02-01-perceptron-perceptron-multicapa">Perceptrón y Perceptrón Multicapa</a></li>
<li><a href="02-02-funcion-de-activacion">Función de activación</a></li>
<li><a href="02-03-propagacion-hacia-adelante-atras">Propagación hacia adelante y hacia atrás</a></li>
<li><a href="02-04-optimizacion-funcion-de-perdida">Optimización y función de pérdida</a></li>
</ul>
<h2>Módulo 3: Redes Neuronales Convolucionales (CNN)</h2>
<ul>
<li><a href="03-01-introduccion-cnn">Introducción a las CNN</a></li>
<li><a href="03-02-capas-convolucionales-pooling">Capas convolucionales y de pooling</a></li>
<li><a href="03-03-arquitecturas-populares-cnn">Arquitecturas populares de CNN</a></li>
<li><a href="03-04-aplicaciones-cnn-reconocimiento-imagenes">Aplicaciones de CNN en reconocimiento de imágenes</a></li>
</ul>
<h2>Módulo 4: Redes Neuronales Recurrentes (RNN)</h2>
<ul>
<li><a href="04-01-introduccion-rnn">Introducción a las RNN</a></li>
<li><a href="04-02-lstm-gru">LSTM y GRU</a></li>
<li><a href="04-03-aplicaciones-rnn-pln">Aplicaciones de RNN en procesamiento del lenguaje natural</a></li>
<li><a href="04-04-secuencias-series-temporales">Secuencias y series temporales</a></li>
</ul>
<h2>Módulo 5: Técnicas Avanzadas en Deep Learning</h2>
<ul>
<li><a href="05-01-redes-generativas-adversariales">Redes Generativas Adversariales (GAN)</a></li>
<li><a href="05-02-autoencoders">Autoencoders</a></li>
<li><a href="05-03-transfer-learning">Transfer Learning</a></li>
<li><a href="05-04-regularizacion-tecnicas-mejora">Regularización y técnicas de mejora</a></li>
</ul>
<h2>Módulo 6: Herramientas y Frameworks</h2>
<ul>
<li><a href="06-01-introduccion-tensorflow">Introducción a TensorFlow</a></li>
<li><a href="06-02-introduccion-pytorch">Introducción a PyTorch</a></li>
<li><a href="06-03-comparacion-frameworks">Comparación de frameworks</a></li>
<li><a href="06-04-entornos-desarrollo-recursos">Entornos de desarrollo y recursos adicionales</a></li>
</ul>
<h2>Módulo 7: Proyectos Prácticos</h2>
<ul>
<li><a href="07-01-clasificacion-imagenes-cnn">Clasificación de imágenes con CNN</a></li>
<li><a href="07-02-generacion-texto-rnn">Generación de texto con RNN</a></li>
<li><a href="07-03-deteccion-anomalias-autoencoders">Detección de anomalías con Autoencoders</a></li>
<li><a href="07-04-creacion-gan-generacion-imagenes">Creación de una GAN para generación de imágenes</a></li>
</ul>
<h2>Módulo 8: Consideraciones Éticas y Futuro del Deep Learning</h2>
<ul>
<li><a href="08-01-etica-deep-learning">Ética en Deep Learning</a></li>
<li><a href="08-02-impacto-social-economico">Impacto social y económico</a></li>
<li><a href="08-03-tendencias-futuras-deep-learning">Tendencias futuras en Deep Learning</a></li>
<li><a href="08-04-desafios-oportunidades">Desafíos y oportunidades</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuario no autenticado</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
