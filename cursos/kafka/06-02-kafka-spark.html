<!DOCTYPE html>
<html lang="es">
<head>
    <title> Kafka con Spark </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/mod/kafka/06-02-kafka-spark" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/kafka/06-02-kafka-spark" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/kafka/06-02-kafka-spark" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.ea63f62b9e.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "es";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "kafka";
  		var TEMA_NAME = "6-2";
  		var TYPE = "mod";
  		var PATH = "mod/kafka/06-02-kafka-spark";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/mod/kafka/06-02-kafka-spark" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/kafka/06-02-kafka-spark" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/mis-cursos" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Mis cursos</b></i>
</a>
<a href="/cursos-finalizados" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalizados             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="kafka">
		<a  href="#" class="text-secondary d-none" data-read-mod="kafka" data-read-unit="6-2" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar como leído
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="kafka" data-unread-unit="6-2" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar como no leído
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contenido del curso
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-01-kafka-hadoop' title="Kafka con Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-01-kafka-hadoop' title="Kafka con Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h2 style="text-decoration:underline">Kafka con Spark</h2>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='06-03-kafka-flink' title="Kafka con Flink" class="py-2 px-3 btn btn-primary"
				data-read-mod="kafka" data-read-unit="6-2">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='06-03-kafka-flink' title="Kafka con Flink" class="py-2 px-3 btn btn-primary" 
				data-read-mod="kafka" data-read-unit="6-2">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>En este módulo, exploraremos cómo integrar Apache Kafka con Apache Spark para procesar flujos de datos en tiempo real. Esta combinación es poderosa para construir aplicaciones de procesamiento de datos en tiempo real que pueden manejar grandes volúmenes de datos con baja latencia.</p>
</div><h1>Objetivos del Módulo</h1>
<div class='content'><ul>
<li>Comprender la integración entre Kafka y Spark.</li>
<li>Configurar un entorno para trabajar con Kafka y Spark.</li>
<li>Implementar un ejemplo práctico de procesamiento de datos en tiempo real utilizando Kafka y Spark.</li>
<li>Realizar ejercicios prácticos para reforzar los conceptos aprendidos.</li>
</ul>
</div><h1><ol>
<li>Introducción a la Integración Kafka-Spark</li>
</ol></h1>
<div class='content'></div><h2>¿Por qué Integrar Kafka con Spark?</h2>
<div class='content'><ul>
<li><strong>Procesamiento en Tiempo Real</strong>: Spark Streaming permite procesar datos en tiempo real, mientras que Kafka actúa como un sistema de mensajería distribuido que puede manejar grandes volúmenes de datos.</li>
<li><strong>Escalabilidad</strong>: Ambos sistemas están diseñados para escalar horizontalmente, lo que permite manejar grandes cantidades de datos y usuarios.</li>
<li><strong>Tolerancia a Fallos</strong>: Kafka y Spark proporcionan mecanismos para la recuperación de fallos, asegurando la continuidad del procesamiento de datos.</li>
</ul>
</div><h2>Arquitectura de la Integración</h2>
<div class='content'><p>La arquitectura típica de una integración Kafka-Spark incluye:</p>
<ul>
<li><strong>Kafka Producer</strong>: Publica mensajes en un tema de Kafka.</li>
<li><strong>Kafka Broker</strong>: Almacena los mensajes y los distribuye a los consumidores.</li>
<li><strong>Spark Streaming</strong>: Consume los mensajes de Kafka y los procesa en tiempo real.</li>
<li><strong>Spark Processing</strong>: Realiza operaciones de transformación y acción sobre los datos.</li>
</ul>
</div><h1><ol start="2">
<li>Configuración del Entorno</li>
</ol></h1>
<div class='content'></div><h2>Requisitos Previos</h2>
<div class='content'><ul>
<li><strong>Java</strong>: Asegúrate de tener Java instalado en tu sistema.</li>
<li><strong>Kafka</strong>: Debes tener un clúster de Kafka en funcionamiento.</li>
<li><strong>Spark</strong>: Instala Apache Spark en tu sistema.</li>
</ul>
</div><h2>Instalación de Apache Spark</h2>
<div class='content'><ol>
<li><strong>Descargar Spark</strong>:
<pre><code class="language-sh">wget https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz
</code></pre>
</li>
<li><strong>Extraer el archivo</strong>:
<pre><code class="language-sh">tar -xvzf spark-3.1.2-bin-hadoop3.2.tgz
</code></pre>
</li>
<li><strong>Configurar las variables de entorno</strong>:
<pre><code class="language-sh">export SPARK_HOME=~/spark-3.1.2-bin-hadoop3.2
export PATH=$PATH:$SPARK_HOME/bin
</code></pre>
</li>
</ol>
</div><h2>Configuración de Kafka</h2>
<div class='content'><ol>
<li><strong>Descargar Kafka</strong>:
<pre><code class="language-sh">wget https://archive.apache.org/dist/kafka/2.8.0/kafka_2.13-2.8.0.tgz
</code></pre>
</li>
<li><strong>Extraer el archivo</strong>:
<pre><code class="language-sh">tar -xvzf kafka_2.13-2.8.0.tgz
</code></pre>
</li>
<li><strong>Iniciar Zookeeper</strong>:
<pre><code class="language-sh">cd kafka_2.13-2.8.0
bin/zookeeper-server-start.sh config/zookeeper.properties
</code></pre>
</li>
<li><strong>Iniciar Kafka</strong>:
<pre><code class="language-sh">bin/kafka-server-start.sh config/server.properties
</code></pre>
</li>
</ol>
</div><h1><ol start="3">
<li>Ejemplo Práctico: Procesamiento de Datos en Tiempo Real</li>
</ol></h1>
<div class='content'></div><h2>Crear un Productor de Kafka</h2>
<div class='content'><p>Primero, crearemos un productor de Kafka que enviará mensajes a un tema.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBrYWZrYSBpbXBvcnQgS2Fma2FQcm9kdWNlcgppbXBvcnQganNvbgppbXBvcnQgdGltZQoKcHJvZHVjZXIgPSBLYWZrYVByb2R1Y2VyKGJvb3RzdHJhcF9zZXJ2ZXJzPSdsb2NhbGhvc3Q6OTA5MicsCiAgICAgICAgICAgICAgICAgICAgICAgICB2YWx1ZV9zZXJpYWxpemVyPWxhbWJkYSB2OiBqc29uLmR1bXBzKHYpLmVuY29kZSgndXRmLTgnKSkKCmZvciBpIGluIHJhbmdlKDEwMCk6CiAgICBkYXRhID0geydudW1iZXInOiBpfQogICAgcHJvZHVjZXIuc2VuZCgnbnVtYmVycycsIHZhbHVlPWRhdGEpCiAgICB0aW1lLnNsZWVwKDEpCgpwcm9kdWNlci5mbHVzaCgpCnByb2R1Y2VyLmNsb3NlKCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from kafka import KafkaProducer
import json
import time

producer = KafkaProducer(bootstrap_servers='localhost:9092',
                         value_serializer=lambda v: json.dumps(v).encode('utf-8'))

for i in range(100):
    data = {'number': i}
    producer.send('numbers', value=data)
    time.sleep(1)

producer.flush()
producer.close()</pre></div><div class='content'></div><h2>Crear un Consumidor de Spark</h2>
<div class='content'><p>Ahora, crearemos una aplicación de Spark Streaming que consumirá los mensajes de Kafka y los procesará.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCmZyb20gcHlzcGFyay5zcWwuZnVuY3Rpb25zIGltcG9ydCBmcm9tX2pzb24sIGNvbApmcm9tIHB5c3Bhcmsuc3FsLnR5cGVzIGltcG9ydCBTdHJ1Y3RUeXBlLCBTdHJ1Y3RGaWVsZCwgSW50ZWdlclR5cGUKCiMgQ3JlYXIgdW5hIHNlc2nDs24gZGUgU3BhcmsKc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlciBcCiAgICAuYXBwTmFtZSgiS2Fma2FTcGFya0ludGVncmF0aW9uIikgXAogICAgLmdldE9yQ3JlYXRlKCkKCiMgRGVmaW5pciBlbCBlc3F1ZW1hIGRlIGxvcyBkYXRvcwpzY2hlbWEgPSBTdHJ1Y3RUeXBlKFtTdHJ1Y3RGaWVsZCgibnVtYmVyIiwgSW50ZWdlclR5cGUoKSwgVHJ1ZSldKQoKIyBMZWVyIGRhdG9zIGRlIEthZmthCmRmID0gc3BhcmsgXAogICAgLnJlYWRTdHJlYW0gXAogICAgLmZvcm1hdCgia2Fma2EiKSBcCiAgICAub3B0aW9uKCJrYWZrYS5ib290c3RyYXAuc2VydmVycyIsICJsb2NhbGhvc3Q6OTA5MiIpIFwKICAgIC5vcHRpb24oInN1YnNjcmliZSIsICJudW1iZXJzIikgXAogICAgLmxvYWQoKQoKIyBDb252ZXJ0aXIgbG9zIGRhdG9zIGRlIEthZmthIGEgdW4gRGF0YUZyYW1lCmRmID0gZGYuc2VsZWN0RXhwcigiQ0FTVCh2YWx1ZSBBUyBTVFJJTkcpIGFzIGpzb24iKSBcCiAgICAuc2VsZWN0KGZyb21fanNvbihjb2woImpzb24iKSwgc2NoZW1hKS5hbGlhcygiZGF0YSIpKSBcCiAgICAuc2VsZWN0KCJkYXRhLioiKQoKIyBSZWFsaXphciB1bmEgb3BlcmFjacOzbiBkZSBhZ3JlZ2FjacOzbgphZ2dfZGYgPSBkZi5ncm91cEJ5KCJudW1iZXIiKS5jb3VudCgpCgojIEVzY3JpYmlyIGxvcyByZXN1bHRhZG9zIGVuIGxhIGNvbnNvbGEKcXVlcnkgPSBhZ2dfZGYud3JpdGVTdHJlYW0gXAogICAgLm91dHB1dE1vZGUoImNvbXBsZXRlIikgXAogICAgLmZvcm1hdCgiY29uc29sZSIpIFwKICAgIC5zdGFydCgpCgpxdWVyeS5hd2FpdFRlcm1pbmF0aW9uKCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col
from pyspark.sql.types import StructType, StructField, IntegerType

# Crear una sesi&oacute;n de Spark
spark = SparkSession.builder \
    .appName(&quot;KafkaSparkIntegration&quot;) \
    .getOrCreate()

# Definir el esquema de los datos
schema = StructType([StructField(&quot;number&quot;, IntegerType(), True)])

# Leer datos de Kafka
df = spark \
    .readStream \
    .format(&quot;kafka&quot;) \
    .option(&quot;kafka.bootstrap.servers&quot;, &quot;localhost:9092&quot;) \
    .option(&quot;subscribe&quot;, &quot;numbers&quot;) \
    .load()

# Convertir los datos de Kafka a un DataFrame
df = df.selectExpr(&quot;CAST(value AS STRING) as json&quot;) \
    .select(from_json(col(&quot;json&quot;), schema).alias(&quot;data&quot;)) \
    .select(&quot;data.*&quot;)

# Realizar una operaci&oacute;n de agregaci&oacute;n
agg_df = df.groupBy(&quot;number&quot;).count()

# Escribir los resultados en la consola
query = agg_df.writeStream \
    .outputMode(&quot;complete&quot;) \
    .format(&quot;console&quot;) \
    .start()

query.awaitTermination()</pre></div><div class='content'></div><h2>Explicación del Código</h2>
<div class='content'><ol>
<li>
<p><strong>Productor de Kafka</strong>:</p>
<ul>
<li>Utilizamos <code>KafkaProducer</code> para enviar mensajes JSON a un tema llamado <code>numbers</code>.</li>
<li>Los mensajes se envían en un bucle con un retraso de 1 segundo entre cada mensaje.</li>
</ul>
</li>
<li>
<p><strong>Consumidor de Spark</strong>:</p>
<ul>
<li>Creamos una sesión de Spark y definimos el esquema de los datos que esperamos recibir.</li>
<li>Leemos los datos de Kafka utilizando el formato <code>kafka</code> y especificamos el servidor y el tema.</li>
<li>Convertimos los datos de Kafka a un DataFrame de Spark.</li>
<li>Realizamos una operación de agregación para contar la cantidad de veces que aparece cada número.</li>
<li>Escribimos los resultados en la consola en modo de salida <code>complete</code>.</li>
</ul>
</li>
</ol>
</div><h1><ol start="4">
<li>Ejercicios Prácticos</li>
</ol></h1>
<div class='content'></div><h2>Ejercicio 1: Filtrado de Datos</h2>
<div class='content'><p>Modifica el consumidor de Spark para filtrar los números pares y contar solo los números impares.</p>
</div><h2>Ejercicio 2: Almacenamiento en HDFS</h2>
<div class='content'><p>Modifica el consumidor de Spark para almacenar los resultados en HDFS en lugar de la consola.</p>
</div><h2>Ejercicio 3: Integración con una Base de Datos</h2>
<div class='content'><p>Modifica el consumidor de Spark para almacenar los resultados en una base de datos SQL.</p>
</div><h1>Soluciones a los Ejercicios</h1>
<div class='content'></div><h2>Solución al Ejercicio 1</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBGaWx0cmFyIG7Dum1lcm9zIGltcGFyZXMKZmlsdGVyZWRfZGYgPSBkZi5maWx0ZXIoY29sKCJudW1iZXIiKSAlIDIgIT0gMCkKCiMgUmVhbGl6YXIgdW5hIG9wZXJhY2nDs24gZGUgYWdyZWdhY2nDs24KYWdnX2RmID0gZmlsdGVyZWRfZGYuZ3JvdXBCeSgibnVtYmVyIikuY291bnQoKQoKIyBFc2NyaWJpciBsb3MgcmVzdWx0YWRvcyBlbiBsYSBjb25zb2xhCnF1ZXJ5ID0gYWdnX2RmLndyaXRlU3RyZWFtIFwKICAgIC5vdXRwdXRNb2RlKCJjb21wbGV0ZSIpIFwKICAgIC5mb3JtYXQoImNvbnNvbGUiKSBcCiAgICAuc3RhcnQoKQoKcXVlcnkuYXdhaXRUZXJtaW5hdGlvbigp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Filtrar n&uacute;meros impares
filtered_df = df.filter(col(&quot;number&quot;) % 2 != 0)

# Realizar una operaci&oacute;n de agregaci&oacute;n
agg_df = filtered_df.groupBy(&quot;number&quot;).count()

# Escribir los resultados en la consola
query = agg_df.writeStream \
    .outputMode(&quot;complete&quot;) \
    .format(&quot;console&quot;) \
    .start()

query.awaitTermination()</pre></div><div class='content'></div><h2>Solución al Ejercicio 2</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBFc2NyaWJpciBsb3MgcmVzdWx0YWRvcyBlbiBIREZTCnF1ZXJ5ID0gYWdnX2RmLndyaXRlU3RyZWFtIFwKICAgIC5vdXRwdXRNb2RlKCJjb21wbGV0ZSIpIFwKICAgIC5mb3JtYXQoInBhcnF1ZXQiKSBcCiAgICAub3B0aW9uKCJwYXRoIiwgImhkZnM6Ly9sb2NhbGhvc3Q6OTAwMC91c2VyL3NwYXJrL291dHB1dCIpIFwKICAgIC5vcHRpb24oImNoZWNrcG9pbnRMb2NhdGlvbiIsICJoZGZzOi8vbG9jYWxob3N0OjkwMDAvdXNlci9zcGFyay9jaGVja3BvaW50IikgXAogICAgLnN0YXJ0KCkKCnF1ZXJ5LmF3YWl0VGVybWluYXRpb24oKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Escribir los resultados en HDFS
query = agg_df.writeStream \
    .outputMode(&quot;complete&quot;) \
    .format(&quot;parquet&quot;) \
    .option(&quot;path&quot;, &quot;hdfs://localhost:9000/user/spark/output&quot;) \
    .option(&quot;checkpointLocation&quot;, &quot;hdfs://localhost:9000/user/spark/checkpoint&quot;) \
    .start()

query.awaitTermination()</pre></div><div class='content'></div><h2>Solución al Ejercicio 3</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBFc2NyaWJpciBsb3MgcmVzdWx0YWRvcyBlbiB1bmEgYmFzZSBkZSBkYXRvcyBTUUwKcXVlcnkgPSBhZ2dfZGYud3JpdGVTdHJlYW0gXAogICAgLm91dHB1dE1vZGUoImNvbXBsZXRlIikgXAogICAgLmZvcm1hdCgiamRiYyIpIFwKICAgIC5vcHRpb24oInVybCIsICJqZGJjOm15c3FsOi8vbG9jYWxob3N0OjMzMDYvc3BhcmtkYiIpIFwKICAgIC5vcHRpb24oImRidGFibGUiLCAibnVtYmVyc19jb3VudCIpIFwKICAgIC5vcHRpb24oInVzZXIiLCAicm9vdCIpIFwKICAgIC5vcHRpb24oInBhc3N3b3JkIiwgInBhc3N3b3JkIikgXAogICAgLnN0YXJ0KCkKCnF1ZXJ5LmF3YWl0VGVybWluYXRpb24oKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Escribir los resultados en una base de datos SQL
query = agg_df.writeStream \
    .outputMode(&quot;complete&quot;) \
    .format(&quot;jdbc&quot;) \
    .option(&quot;url&quot;, &quot;jdbc:mysql://localhost:3306/sparkdb&quot;) \
    .option(&quot;dbtable&quot;, &quot;numbers_count&quot;) \
    .option(&quot;user&quot;, &quot;root&quot;) \
    .option(&quot;password&quot;, &quot;password&quot;) \
    .start()

query.awaitTermination()</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En este módulo, hemos aprendido cómo integrar Apache Kafka con Apache Spark para procesar flujos de datos en tiempo real. Hemos configurado un entorno de trabajo, implementado un ejemplo práctico y realizado ejercicios para reforzar los conceptos aprendidos. Esta integración es fundamental para construir aplicaciones de procesamiento de datos en tiempo real que pueden manejar grandes volúmenes de datos con baja latencia.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-01-kafka-hadoop' title="Kafka con Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-01-kafka-hadoop' title="Kafka con Hadoop" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='06-03-kafka-flink' title="Kafka con Flink" class="py-2 px-3 btn btn-primary"
				data-read-mod="kafka" data-read-unit="6-2">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='06-03-kafka-flink' title="Kafka con Flink" class="py-2 px-3 btn btn-primary" 
				data-read-mod="kafka" data-read-unit="6-2">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de Kafka</h1>
<h2>Módulo 1: Introducción a Kafka</h2>
<ul>
<li><a href="01-01-what-is-kafka">¿Qué es Kafka?</a></li>
<li><a href="01-02-kafka-use-cases">Casos de Uso de Kafka</a></li>
<li><a href="01-03-kafka-architecture-overview">Visión General de la Arquitectura de Kafka</a></li>
<li><a href="01-04-setting-up-kafka">Configuración de Kafka</a></li>
</ul>
<h2>Módulo 2: Conceptos Básicos de Kafka</h2>
<ul>
<li><a href="02-01-producers-and-consumers">Productores y Consumidores</a></li>
<li><a href="02-02-topics-and-partitions">Temas y Particiones</a></li>
<li><a href="02-03-brokers-and-clusters">Brokers y Clústeres</a></li>
<li><a href="02-04-messages-and-offsets">Mensajes y Desplazamientos</a></li>
</ul>
<h2>Módulo 3: Operaciones de Kafka</h2>
<ul>
<li><a href="03-01-producing-messages">Producción de Mensajes</a></li>
<li><a href="03-02-consuming-messages">Consumo de Mensajes</a></li>
<li><a href="03-03-kafka-connect">Kafka Connect</a></li>
<li><a href="03-04-kafka-streams">Kafka Streams</a></li>
</ul>
<h2>Módulo 4: Configuración y Gestión de Kafka</h2>
<ul>
<li><a href="04-01-configuring-kafka">Configuración de Kafka</a></li>
<li><a href="04-02-managing-kafka-topics">Gestión de Temas de Kafka</a></li>
<li><a href="04-03-monitoring-kafka">Monitoreo de Kafka</a></li>
<li><a href="04-04-kafka-security">Seguridad en Kafka</a></li>
</ul>
<h2>Módulo 5: Temas Avanzados de Kafka</h2>
<ul>
<li><a href="05-01-kafka-performance-tuning">Ajuste de Rendimiento de Kafka</a></li>
<li><a href="05-02-kafka-multi-data-center">Kafka en una Configuración Multi-Centro de Datos</a></li>
<li><a href="05-03-kafka-schema-registry">Kafka con Registro de Esquemas</a></li>
<li><a href="05-04-kafka-streams-advanced">Kafka Streams Avanzado</a></li>
</ul>
<h2>Módulo 6: Ecosistema e Integraciones de Kafka</h2>
<ul>
<li><a href="06-01-kafka-hadoop">Kafka con Hadoop</a></li>
<li><a href="06-02-kafka-spark">Kafka con Spark</a></li>
<li><a href="06-03-kafka-flink">Kafka con Flink</a></li>
<li><a href="06-04-kafka-elasticsearch">Kafka con Elasticsearch</a></li>
</ul>
<h2>Módulo 7: Estudios de Caso y Mejores Prácticas de Kafka</h2>
<ul>
<li><a href="07-01-real-world-kafka-use-cases">Casos de Uso de Kafka en el Mundo Real</a></li>
<li><a href="07-02-kafka-best-practices">Mejores Prácticas de Kafka</a></li>
<li><a href="07-03-common-kafka-pitfalls">Errores Comunes de Kafka</a></li>
<li><a href="07-04-future-of-kafka">Futuro de Kafka</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objetivo" rel="nofollow">El Proyecto</a> | 
<a href="/acerca-de" rel="nofollow">Sobre nosotros</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donaciones</a> | 
<a href="/licencia" rel="nofollow">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuario no autenticado</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
