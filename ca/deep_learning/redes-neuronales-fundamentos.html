<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Xarxes Neuronals: Fonaments</title>

    <link rel="alternate" href="https://campusempresa.com/es/deep_learning/redes-neuronales-fundamentos" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/deep_learning/redes-neuronales-fundamentos" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/deep_learning/redes-neuronales-fundamentos" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/ca/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="/es/deep_learning/redes-neuronales-fundamentos" id="lnk_lang_es" data-lang="es" class="px-2">ES</a></b>
				|
				<b id="lit_lang_ca" class="px-2">CA</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/ca/objective">El Projecte</a>
				<a href="/ca/about">Sobre nosaltres</a>
				<a href="/ca/contribute">Contribuir</a>
				<a href="/ca/donate">Donacions</a>
				<a href="/ca/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='historia-evolucion-deep-learning'>&#x25C4;Història i Evolució del Deep Learning</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Xarxes Neuronals: Fonaments</a>
	</div>
	<div class='col-4 text-end'>
					<a href='aplicaciones-deep-learning'>Aplicacions del Deep Learning &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducció a les Xarxes Neuronals</h1>
<div class='content'><p>Les xarxes neuronals són un component essencial del Deep Learning, inspirades en l'estructura i funcionament del cervell humà. Aquestes xarxes estan compostes per unitats bàsiques anomenades neurones, que s'organitzen en capes i es connecten entre si per processar i aprendre de les dades.</p>
</div><h1>Estructura d'una Xarxa Neuronal</h1>
<div class='content'><p>Una xarxa neuronal típica consta de les següents capes:</p>
<ul>
<li><strong>Capa d'Entrada</strong>: Rep les dades d'entrada.</li>
<li><strong>Capes Ocultes</strong>: Processen la informació rebuda de la capa d'entrada mitjançant neurones interconnectades.</li>
<li><strong>Capa de Sortida</strong>: Produeix el resultat final de la xarxa.</li>
</ul>
</div><h2>Neurona Artificial</h2>
<div class='content'><p>Cada neurona en una xarxa neuronal realitza una operació matemàtica simple. L'estructura bàsica d'una neurona inclou:</p>
<ul>
<li><strong>Pesos (Weights)</strong>: Coeficients que ponderen la importància de cada entrada.</li>
<li><strong>Funció d'Activació</strong>: Introdueix no linealitat en la sortida de la neurona.</li>
<li><strong>Bias</strong>: Un terme addicional que ajuda a ajustar la sortida juntament amb els pesos.</li>
</ul>
</div><h2>Exemple d'una Neurona</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIERlZmluaWNpw7MgZGUgbGEgZnVuY2nDsyBkJ2FjdGl2YWNpw7MgKHNpZ21vaWRlKQpkZWYgc2lnbW9pZCh4KToKICAgIHJldHVybiAxIC8gKDEgKyBucC5leHAoLXgpKQoKIyBFbnRyYWRlcyBpIHBlc29zCmlucHV0cyA9IG5wLmFycmF5KFswLjUsIDAuM10pCndlaWdodHMgPSBucC5hcnJheShbMC40LCAwLjddKQpiaWFzID0gMC4xCgojIEPDoGxjdWwgZGUgbGEgc29ydGlkYSBkZSBsYSBuZXVyb25hCm91dHB1dCA9IHNpZ21vaWQobnAuZG90KGlucHV0cywgd2VpZ2h0cykgKyBiaWFzKQpwcmludChvdXRwdXQp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Definici&oacute; de la funci&oacute; d'activaci&oacute; (sigmoide)
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Entrades i pesos
inputs = np.array([0.5, 0.3])
weights = np.array([0.4, 0.7])
bias = 0.1

# C&agrave;lcul de la sortida de la neurona
output = sigmoid(np.dot(inputs, weights) + bias)
print(output)</pre></div><div class='content'></div><h1>Funcions d'Activació</h1>
<div class='content'><p>Les funcions d'activació són crucials per introduir no linealitat en la xarxa, permetent que la xarxa aprengui i modelitzi dades complexes. Algunes funcions d'activació comunes inclouen:</p>
<ul>
<li><strong>Sigmoide</strong>: <code>σ(x) = 1 / (1 + e^(-x))</code></li>
<li><strong>ReLU (Rectified Linear Unit)</strong>: <code>f(x) = max(0, x)</code></li>
<li><strong>Tanh (Tangente hiperbòlica)</strong>: <code>tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))</code></li>
</ul>
</div><h2>Comparació de Funcions d'Activació</h2>
<div class='content'><p>| Funció d'Activació    | Fórmula                  | Rang de Sortida  | Propietats                              |
|-----------------------|--------------------------|------------------|------------------------------------------|
| Sigmoide              | \( \sigma(x) = \frac{1}{1 + e^{-x}} \) | (0, 1)           | Suau, derivable, però pot saturar-se.  |
| ReLU                  | \( f(x) = \max(0, x) \)  | [0, ∞)           | Simple, eficient, però pot causar &quot;neurona morta&quot;. |
| Tanh                  | \( \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \) | (-1, 1)         | Suau, derivable, centrada en zero.      |</p>
</div><h1>Procés d'Entrenament</h1>
<div class='content'><p>L'entrenament d'una xarxa neuronal implica ajustar els pesos i biases per minimitzar l'error en les prediccions. Aquest procés es realitza mitjançant:</p>
<ul>
<li><strong>Propagació cap endavant (Forward Propagation)</strong>: Calcula la sortida de la xarxa.</li>
<li><strong>Funció de Cost (Cost Function)</strong>: Mesura la diferència entre la sortida predida i la sortida real.</li>
<li><strong>Propagació cap enrere (Backpropagation)</strong>: Ajusta els pesos i biases per reduir l'error.</li>
</ul>
</div><h2>Exemple d'Entrenament Simple</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIERhZGVzIGQnZW50cmFkYSBpIHNvcnRpZGEgZXNwZXJhZGEKaW5wdXRzID0gbnAuYXJyYXkoWzAuNSwgMC4zXSkKZXhwZWN0ZWRfb3V0cHV0ID0gMC43CgojIEluaWNpYWxpdHphY2nDsyBkZSBwZXNvcyBpIGJpYXMKd2VpZ2h0cyA9IG5wLmFycmF5KFswLjQsIDAuN10pCmJpYXMgPSAwLjEKbGVhcm5pbmdfcmF0ZSA9IDAuMDEKCiMgRGVmaW5pY2nDsyBkZSBsYSBmdW5jacOzIGQnYWN0aXZhY2nDsyBpIGxhIHNldmEgZGVyaXZhZGEKZGVmIHNpZ21vaWQoeCk6CiAgICByZXR1cm4gMSAvICgxICsgbnAuZXhwKC14KSkKCmRlZiBzaWdtb2lkX2Rlcml2YXRpdmUoeCk6CiAgICByZXR1cm4geCAqICgxIC0geCkKCiMgUHJvY8OpcyBkJ2VudHJlbmFtZW50CmZvciBlcG9jaCBpbiByYW5nZSgxMDAwMCk6CiAgICAjIFByb3BhZ2FjacOzIGNhcCBlbmRhdmFudAogICAgd2VpZ2h0ZWRfc3VtID0gbnAuZG90KGlucHV0cywgd2VpZ2h0cykgKyBiaWFzCiAgICBvdXRwdXQgPSBzaWdtb2lkKHdlaWdodGVkX3N1bSkKICAgIAogICAgIyBDw6BsY3VsIGRlIGwnZXJyb3IKICAgIGVycm9yID0gZXhwZWN0ZWRfb3V0cHV0IC0gb3V0cHV0CiAgICAKICAgICMgUHJvcGFnYWNpw7MgY2FwIGVucmVyZQogICAgYWRqdXN0bWVudHMgPSBlcnJvciAqIHNpZ21vaWRfZGVyaXZhdGl2ZShvdXRwdXQpCiAgICB3ZWlnaHRzICs9IGxlYXJuaW5nX3JhdGUgKiBhZGp1c3RtZW50cyAqIGlucHV0cwogICAgYmlhcyArPSBsZWFybmluZ19yYXRlICogYWRqdXN0bWVudHMKCnByaW50KCJQZXNvcyBhanVzdGF0czoiLCB3ZWlnaHRzKQpwcmludCgiQmlhcyBhanVzdGF0OiIsIGJpYXMp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Dades d'entrada i sortida esperada
inputs = np.array([0.5, 0.3])
expected_output = 0.7

# Inicialitzaci&oacute; de pesos i bias
weights = np.array([0.4, 0.7])
bias = 0.1
learning_rate = 0.01

# Definici&oacute; de la funci&oacute; d'activaci&oacute; i la seva derivada
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

# Proc&eacute;s d'entrenament
for epoch in range(10000):
    # Propagaci&oacute; cap endavant
    weighted_sum = np.dot(inputs, weights) + bias
    output = sigmoid(weighted_sum)
    
    # C&agrave;lcul de l'error
    error = expected_output - output
    
    # Propagaci&oacute; cap enrere
    adjustments = error * sigmoid_derivative(output)
    weights += learning_rate * adjustments * inputs
    bias += learning_rate * adjustments

print(&quot;Pesos ajustats:&quot;, weights)
print(&quot;Bias ajustat:&quot;, bias)</pre></div><div class='content'></div><h1>Conclusió</h1>
<div class='content'><p>Les xarxes neuronals són una eina poderosa en el camp del Deep Learning, capaces d'aprendre i generalitzar a partir de dades complexes. Comprendre els fonaments de la seva estructura, funcions d'activació i procés d'entrenament és crucial per desenvolupar models efectius. En els següents temes, aprofundirem en arquitectures més avançades i tècniques d'optimització per millorar el rendiment de les xarxes neuronals.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='historia-evolucion-deep-learning'>&#x25C4;Història i Evolució del Deep Learning</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Xarxes Neuronals: Fonaments</a>
	</div>
	<div class='col-4 text-end'>
					<a href='aplicaciones-deep-learning'>Aplicacions del Deep Learning &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/ca/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
