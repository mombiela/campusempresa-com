<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aplicacions de RNN en Processament del Llenguatge Natural</title>

    <link rel="alternate" href="https://campusempresa.com/es/deep_learning/aplicaciones-rnn-pln" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/deep_learning/aplicaciones-rnn-pln" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/deep_learning/aplicaciones-rnn-pln" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/ca/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui<br> i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="/es/deep_learning/aplicaciones-rnn-pln" id="lnk_lang_es" data-lang="es" class="px-2">ES</a></b>
				|
				<b id="lit_lang_ca" class="px-2">CA</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="objective">El Projecte</a>
				<a href="about">Sobre nosaltres</a>
				<a href="contribute">Contribuir</a>
				<a href="donate">Donacions</a>
				<a href="licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introducció a les RNN</h1>
<div class='content'><p>Les Xarxes Neuronals Recurrentes (RNN) són un tipus de xarxa neuronal dissenyada per treballar amb dades seqüencials. A diferència de les xarxes neuronals tradicionals, les RNN tenen connexions recurrents que permeten que la informació persisteixi, cosa que les fa especialment útils per a tasques on el context i la seqüència de les dades són importants.</p>
</div><h1>Conceptes Clau</h1>
<div class='content'><ul>
<li><strong>Seqüencialitat</strong>: Les RNN processen dades en seqüència, cosa que els permet mantenir informació sobre els elements anteriors en la seqüència.</li>
<li><strong>Estats Ocults</strong>: Les RNN tenen estats ocults que actuen com a memòria de curt termini, emmagatzemant informació sobre els passos anteriors.</li>
<li><strong>Backpropagation Through Time (BPTT)</strong>: Un algorisme d'entrenament específic per a RNN que estèn l'algorisme de retropropagació per manejar seqüències.</li>
</ul>
</div><h1>Aplicacions de RNN en Processament del Llenguatge Natural (NLP)</h1>
<div class='content'></div><h2>Modelatge del Llenguatge</h2>
<div class='content'><p>Les RNN s'utilitzen per predir la següent paraula en una seqüència de text, cosa que és fonamental per a tasques com la generació de text i l'autocompletació.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBTaW1wbGVSTk4sIERlbnNlCgojIEV4ZW1wbGUgZCd1biBtb2RlbCBkZSBSTk4gc2ltcGxlIHBlciBhIG1vZGVsYXRnZSBkZWwgbGxlbmd1YXRnZQptb2RlbCA9IFNlcXVlbnRpYWwoKQptb2RlbC5hZGQoU2ltcGxlUk5OKDUwLCBpbnB1dF9zaGFwZT0oTm9uZSwgMSkpKQptb2RlbC5hZGQoRGVuc2UoMSwgYWN0aXZhdGlvbj0nbGluZWFyJykpCgptb2RlbC5jb21waWxlKG9wdGltaXplcj0nYWRhbScsIGxvc3M9J21zZScpCnByaW50KG1vZGVsLnN1bW1hcnkoKSk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense

# Exemple d'un model de RNN simple per a modelatge del llenguatge
model = Sequential()
model.add(SimpleRNN(50, input_shape=(None, 1)))
model.add(Dense(1, activation='linear'))

model.compile(optimizer='adam', loss='mse')
print(model.summary())</pre></div><div class='content'></div><h2>Traducció Automàtica</h2>
<div class='content'><p>Les RNN, especialment les arquitectures de Encoder-Decoder, són utilitzades per traduir text d'un idioma a un altre.</p>
<ul>
<li><strong>Encoder</strong>: Processa la seqüència d'entrada i la converteix en un vector de context.</li>
<li><strong>Decoder</strong>: Pren el vector de context i genera la seqüència de sortida en l'idioma objectiu.</li>
</ul>
</div><h2>Anàlisi de Sentiment</h2>
<div class='content'><p>Les RNN poden classificar el sentiment d'un text (positiu, negatiu, neutral) analitzant la seqüència de paraules.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmRhdGFzZXRzIGltcG9ydCBpbWRiCmZyb20gdGVuc29yZmxvdy5rZXJhcy5wcmVwcm9jZXNzaW5nIGltcG9ydCBzZXF1ZW5jZQoKIyBDYXJyZWdhciBkYWRlcyBkZSBJTURCCm1heF9mZWF0dXJlcyA9IDIwMDAwCm1heGxlbiA9IDgwCmJhdGNoX3NpemUgPSAzMgoKKGlucHV0X3RyYWluLCB5X3RyYWluKSwgKGlucHV0X3Rlc3QsIHlfdGVzdCkgPSBpbWRiLmxvYWRfZGF0YShudW1fd29yZHM9bWF4X2ZlYXR1cmVzKQppbnB1dF90cmFpbiA9IHNlcXVlbmNlLnBhZF9zZXF1ZW5jZXMoaW5wdXRfdHJhaW4sIG1heGxlbj1tYXhsZW4pCmlucHV0X3Rlc3QgPSBzZXF1ZW5jZS5wYWRfc2VxdWVuY2VzKGlucHV0X3Rlc3QsIG1heGxlbj1tYXhsZW4pCgojIENyZWFyIGVsIG1vZGVsCm1vZGVsID0gU2VxdWVudGlhbCgpCm1vZGVsLmFkZChTaW1wbGVSTk4oMzIsIGlucHV0X3NoYXBlPShtYXhsZW4sIG1heF9mZWF0dXJlcykpKQptb2RlbC5hZGQoRGVuc2UoMSwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpKQoKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdiaW5hcnlfY3Jvc3NlbnRyb3B5JywgbWV0cmljcz1bJ2FjY3VyYWN5J10pCm1vZGVsLmZpdChpbnB1dF90cmFpbiwgeV90cmFpbiwgZXBvY2hzPTEwLCBiYXRjaF9zaXplPWJhdGNoX3NpemUsIHZhbGlkYXRpb25fZGF0YT0oaW5wdXRfdGVzdCwgeV90ZXN0KSk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing import sequence

# Carregar dades de IMDB
max_features = 20000
maxlen = 80
batch_size = 32

(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)
input_train = sequence.pad_sequences(input_train, maxlen=maxlen)
input_test = sequence.pad_sequences(input_test, maxlen=maxlen)

# Crear el model
model = Sequential()
model.add(SimpleRNN(32, input_shape=(maxlen, max_features)))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(input_train, y_train, epochs=10, batch_size=batch_size, validation_data=(input_test, y_test))</pre></div><div class='content'></div><h2>Resum de Text</h2>
<div class='content'><p>Les RNN poden generar resums de textos llargs, capturant les idees principals i condensant-les en una forma més curta.</p>
</div><h2>Generació de Text</h2>
<div class='content'><p>Les RNN poden ser entrenades per generar text que imiti l'estil i el contingut d'un corpus d'entrenament.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIEV4ZW1wbGUgZGUgZ2VuZXJhY2nDsyBkZSB0ZXh0CnRleHQgPSAieW91ciB0cmFpbmluZyB0ZXh0IGhlcmUiCmNoYXJzID0gc29ydGVkKGxpc3Qoc2V0KHRleHQpKSkKY2hhcl9pbmRpY2VzID0gZGljdCgoYywgaSkgZm9yIGksIGMgaW4gZW51bWVyYXRlKGNoYXJzKSkKaW5kaWNlc19jaGFyID0gZGljdCgoaSwgYykgZm9yIGksIGMgaW4gZW51bWVyYXRlKGNoYXJzKSkKCiMgVmVjdG9yaXR6YWNpw7MgZGUgdGV4dAptYXhsZW4gPSA0MApzdGVwID0gMwpzZW50ZW5jZXMgPSBbXQpuZXh0X2NoYXJzID0gW10KZm9yIGkgaW4gcmFuZ2UoMCwgbGVuKHRleHQpIC0gbWF4bGVuLCBzdGVwKToKICAgIHNlbnRlbmNlcy5hcHBlbmQodGV4dFtpOiBpICsgbWF4bGVuXSkKICAgIG5leHRfY2hhcnMuYXBwZW5kKHRleHRbaSArIG1heGxlbl0pCnggPSBucC56ZXJvcygobGVuKHNlbnRlbmNlcyksIG1heGxlbiwgbGVuKGNoYXJzKSksIGR0eXBlPW5wLmJvb2wpCnkgPSBucC56ZXJvcygobGVuKHNlbnRlbmNlcyksIGxlbihjaGFycykpLCBkdHlwZT1ucC5ib29sKQpmb3IgaSwgc2VudGVuY2UgaW4gZW51bWVyYXRlKHNlbnRlbmNlcyk6CiAgICBmb3IgdCwgY2hhciBpbiBlbnVtZXJhdGUoc2VudGVuY2UpOgogICAgICAgIHhbaSwgdCwgY2hhcl9pbmRpY2VzW2NoYXJdXSA9IDEKICAgIHlbaSwgY2hhcl9pbmRpY2VzW25leHRfY2hhcnNbaV1dXSA9IDEKCiMgQ3JlYXIgZWwgbW9kZWwKbW9kZWwgPSBTZXF1ZW50aWFsKCkKbW9kZWwuYWRkKFNpbXBsZVJOTigxMjgsIGlucHV0X3NoYXBlPShtYXhsZW4sIGxlbihjaGFycykpKSkKbW9kZWwuYWRkKERlbnNlKGxlbihjaGFycyksIGFjdGl2YXRpb249J3NvZnRtYXgnKSkKCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nY2F0ZWdvcmljYWxfY3Jvc3NlbnRyb3B5JykKbW9kZWwuZml0KHgsIHksIGJhdGNoX3NpemU9MTI4LCBlcG9jaHM9MjAp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Exemple de generaci&oacute; de text
text = &quot;your training text here&quot;
chars = sorted(list(set(text)))
char_indices = dict((c, i) for i, c in enumerate(chars))
indices_char = dict((i, c) for i, c in enumerate(chars))

# Vectoritzaci&oacute; de text
maxlen = 40
step = 3
sentences = []
next_chars = []
for i in range(0, len(text) - maxlen, step):
    sentences.append(text[i: i + maxlen])
    next_chars.append(text[i + maxlen])
x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)
y = np.zeros((len(sentences), len(chars)), dtype=np.bool)
for i, sentence in enumerate(sentences):
    for t, char in enumerate(sentence):
        x[i, t, char_indices[char]] = 1
    y[i, char_indices[next_chars[i]]] = 1

# Crear el model
model = Sequential()
model.add(SimpleRNN(128, input_shape=(maxlen, len(chars))))
model.add(Dense(len(chars), activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy')
model.fit(x, y, batch_size=128, epochs=20)</pre></div><div class='content'></div><h1>Comparació de RNN amb altres arquitectures</h1>
<div class='content'><p>| Característica       | RNN           | LSTM/GRU       | Transformers   |
|----------------------|---------------|----------------|----------------|
| Maneig de seqüències | Bo            | Excel·lent     | Excel·lent     |
| Eficiència           | Alta          | Mitjana        | Baixa          |
| Capacitat de memòria | Limitada      | Alta           | Molt Alta      |
| Paral·lelització     | Difícil       | Difícil        | Fàcil          |</p>
</div><h1>Conclusió</h1>
<div class='content'><p>Les RNN són una eina poderosa en el processament del llenguatge natural, especialment per a tasques que requereixen el maneig de dades seqüencials. Tot i que tenen limitacions, com la dificultat per paral·lelitzar i problemes amb dependències a llarg termini, les variants com LSTM i GRU i les noves arquitectures com Transformers han millorat significativament aquestes àrees. Les aplicacions de RNN en NLP són vastes i continuen expandint-se amb l'avanç de la tecnologia i la investigació.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
