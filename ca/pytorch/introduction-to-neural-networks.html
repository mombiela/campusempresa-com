<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introducció a les Xarxes Neuronals</title>

    <link rel="alternate" href="https://campusempresa.com/es/pytorch/introduction-to-neural-networks" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/pytorch/introduction-to-neural-networks" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/pytorch/introduction-to-neural-networks" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/ca/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="/es/pytorch/introduction-to-neural-networks" id="lnk_lang_es" data-lang="es" class="px-2">ES</a></b>
				|
				<b id="lit_lang_ca" class="px-2">CA</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/ca/objective">El Projecte</a>
				<a href="/ca/about">Sobre nosaltres</a>
				<a href="/ca/contribute">Contribuir</a>
				<a href="/ca/donate">Donacions</a>
				<a href="/ca/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'><div class='col-6'><a href='autograd-automatic-differentiation'>&#x25C4; Autograd: Diferenciació Automàtica</a></div><div class='col-6 text-end'><a href='creating-a-simple-neural-network'>Creació d'una Xarxa Neuronal Simple &#x25BA;</a></div></div><div class='content'></div><h1>Visió General</h1>
<div class='content'><p>Les xarxes neuronals són un concepte fonamental en l'aprenentatge profund i són la columna vertebral de moltes aplicacions modernes d'aprenentatge automàtic. Aquesta secció us introduirà als conceptes bàsics de les xarxes neuronals i com implementar-les utilitzant PyTorch.</p>
</div><h1>Conceptes Clau</h1>
<div class='content'><ul>
<li><strong>Neurones i Capes</strong>: Els blocs bàsics de les xarxes neuronals.</li>
<li><strong>Funcions d'Activació</strong>: Funcions que introdueixen no linealitat a la xarxa.</li>
<li><strong>Funcions de Pèrdua</strong>: Mètriques per avaluar el rendiment de la xarxa.</li>
<li><strong>Algoritmes d'Optimització</strong>: Mètodes per minimitzar la funció de pèrdua.</li>
<li><strong>Propagació Endavant i Enrere</strong>: Mecanismes per entrenar la xarxa.</li>
</ul>
</div><h1>Neurones i Capes</h1>
<div class='content'><p>Una xarxa neuronal consisteix en capes de neurones. Cada neurona rep una entrada, la processa i passa la sortida a la següent capa.</p>
</div><h2>Exemple: Neurona Senzilla</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCgojIERlZmluaXIgdW5hIG5ldXJvbmEgc2VuemlsbGEgYW1iIHVuIHBlcyBpIHVuIGJpYWl4CnBlcyA9IHRvcmNoLnRlbnNvcigwLjUsIHJlcXVpcmVzX2dyYWQ9VHJ1ZSkKYmlhaXggPSB0b3JjaC50ZW5zb3IoMC4xLCByZXF1aXJlc19ncmFkPVRydWUpCgojIFZhbG9yIGQnZW50cmFkYQp4ID0gdG9yY2gudGVuc29yKDEuMCkKCiMgVHJhbnNmb3JtYWNpw7MgbGluZWFsCnkgPSBwZXMgKiB4ICsgYmlhaXgKCnByaW50KHkpICAjIFNvcnRpZGE6IHRlbnNvcigwLjYwMDAsIGdyYWRfZm49PEFkZEJhY2t3YXJkMD4p"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch

# Definir una neurona senzilla amb un pes i un biaix
pes = torch.tensor(0.5, requires_grad=True)
biaix = torch.tensor(0.1, requires_grad=True)

# Valor d'entrada
x = torch.tensor(1.0)

# Transformaci&oacute; lineal
y = pes * x + biaix

print(y)  # Sortida: tensor(0.6000, grad_fn=&lt;AddBackward0&gt;)</pre></div><div class='content'></div><h2>Exemple: Xarxa Neuronal Simple</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm5uIGFzIG5uCgojIERlZmluaXIgdW5hIHhhcnhhIG5ldXJvbmFsIHNpbXBsZSBhbWIgdW5hIGNhcGEgb2N1bHRhCmNsYXNzIFNpbXBsZU5OKG5uLk1vZHVsZSk6CiAgICBkZWYgX19pbml0X18oc2VsZik6CiAgICAgICAgc3VwZXIoU2ltcGxlTk4sIHNlbGYpLl9faW5pdF9fKCkKICAgICAgICBzZWxmLmhpZGRlbiA9IG5uLkxpbmVhcigxLCAxMCkgICMgQ2FwYSBvY3VsdGEgYW1iIDEwIG5ldXJvbmVzCiAgICAgICAgc2VsZi5vdXRwdXQgPSBubi5MaW5lYXIoMTAsIDEpICAjIENhcGEgZGUgc29ydGlkYQoKICAgIGRlZiBmb3J3YXJkKHNlbGYsIHgpOgogICAgICAgIHggPSB0b3JjaC5yZWx1KHNlbGYuaGlkZGVuKHgpKSAgIyBBcGxpY2FyIGZ1bmNpw7MgZCdhY3RpdmFjacOzIFJlTFUKICAgICAgICB4ID0gc2VsZi5vdXRwdXQoeCkKICAgICAgICByZXR1cm4geAoKIyBJbnN0YW5jaWFyIGxhIHhhcnhhCm5ldCA9IFNpbXBsZU5OKCkKcHJpbnQobmV0KQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.nn as nn

# Definir una xarxa neuronal simple amb una capa oculta
class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.hidden = nn.Linear(1, 10)  # Capa oculta amb 10 neurones
        self.output = nn.Linear(10, 1)  # Capa de sortida

    def forward(self, x):
        x = torch.relu(self.hidden(x))  # Aplicar funci&oacute; d'activaci&oacute; ReLU
        x = self.output(x)
        return x

# Instanciar la xarxa
net = SimpleNN()
print(net)</pre></div><div class='content'></div><h1>Funcions d'Activació</h1>
<div class='content'><p>Les funcions d'activació introdueixen no linealitat a la xarxa, permetent-li aprendre patrons complexos.</p>
</div><h2>Funcions d'Activació Comunes</h2>
<div class='content'><ul>
<li><strong>ReLU (Rectified Linear Unit)</strong>: <code>torch.relu</code></li>
<li><strong>Sigmoid</strong>: <code>torch.sigmoid</code></li>
<li><strong>Tanh</strong>: <code>torch.tanh</code></li>
</ul>
</div><h2>Exemple: Aplicar Funcions d'Activació</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCgojIFRlbnNvciBkJ2VudHJhZGEKeCA9IHRvcmNoLnRlbnNvcihbLTEuMCwgMC4wLCAxLjBdKQoKIyBBcGxpY2FyIGZ1bmNpw7MgZCdhY3RpdmFjacOzIFJlTFUKcmVsdV9vdXRwdXQgPSB0b3JjaC5yZWx1KHgpCnByaW50KHJlbHVfb3V0cHV0KSAgIyBTb3J0aWRhOiB0ZW5zb3IoWzAuLCAwLiwgMS5dKQoKIyBBcGxpY2FyIGZ1bmNpw7MgZCdhY3RpdmFjacOzIFNpZ21vaWQKc2lnbW9pZF9vdXRwdXQgPSB0b3JjaC5zaWdtb2lkKHgpCnByaW50KHNpZ21vaWRfb3V0cHV0KSAgIyBTb3J0aWRhOiB0ZW5zb3IoWzAuMjY4OSwgMC41MDAwLCAwLjczMTFdKQoKIyBBcGxpY2FyIGZ1bmNpw7MgZCdhY3RpdmFjacOzIFRhbmgKdGFuaF9vdXRwdXQgPSB0b3JjaC50YW5oKHgpCnByaW50KHRhbmhfb3V0cHV0KSAgIyBTb3J0aWRhOiB0ZW5zb3IoWy0wLjc2MTYsICAwLjAwMDAsICAwLjc2MTZdKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch

# Tensor d'entrada
x = torch.tensor([-1.0, 0.0, 1.0])

# Aplicar funci&oacute; d'activaci&oacute; ReLU
relu_output = torch.relu(x)
print(relu_output)  # Sortida: tensor([0., 0., 1.])

# Aplicar funci&oacute; d'activaci&oacute; Sigmoid
sigmoid_output = torch.sigmoid(x)
print(sigmoid_output)  # Sortida: tensor([0.2689, 0.5000, 0.7311])

# Aplicar funci&oacute; d'activaci&oacute; Tanh
tanh_output = torch.tanh(x)
print(tanh_output)  # Sortida: tensor([-0.7616,  0.0000,  0.7616])</pre></div><div class='content'></div><h1>Funcions de Pèrdua</h1>
<div class='content'><p>Les funcions de pèrdua mesuren com de bé està funcionant la xarxa neuronal. Les funcions de pèrdua comunes inclouen l'Error Quadràtic Mitjà (MSE) i la Pèrdua d'Entropia Creuada.</p>
</div><h2>Exemple: Error Quadràtic Mitjà</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm5uLmZ1bmN0aW9uYWwgYXMgRgoKIyBWYWxvcnMgcHJldmlzdG9zIGkgb2JqZWN0aXVzCnByZWRpY3RlZCA9IHRvcmNoLnRlbnNvcihbMC41LCAwLjgsIDAuM10pCnRhcmdldCA9IHRvcmNoLnRlbnNvcihbMS4wLCAwLjAsIDAuMF0pCgojIENhbGN1bGFyIGwnRXJyb3IgUXVhZHLDoHRpYyBNaXRqw6AKbG9zcyA9IEYubXNlX2xvc3MocHJlZGljdGVkLCB0YXJnZXQpCnByaW50KGxvc3MpICAjIFNvcnRpZGE6IHRlbnNvcigwLjM5MzMp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.nn.functional as F

# Valors previstos i objectius
predicted = torch.tensor([0.5, 0.8, 0.3])
target = torch.tensor([1.0, 0.0, 0.0])

# Calcular l'Error Quadr&agrave;tic Mitj&agrave;
loss = F.mse_loss(predicted, target)
print(loss)  # Sortida: tensor(0.3933)</pre></div><div class='content'></div><h1>Algoritmes d'Optimització</h1>
<div class='content'><p>Els algoritmes d'optimització ajusten els pesos i els biaixos per minimitzar la funció de pèrdua. L'algoritme d'optimització més comú és el Descens de Gradient Estocàstic (SGD).</p>
</div><h2>Exemple: Descens de Gradient Estocàstic</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm9wdGltIGFzIG9wdGltCgojIERlZmluaXIgdW5hIHhhcnhhIG5ldXJvbmFsIHNpbXBsZQpuZXQgPSBTaW1wbGVOTigpCgojIERlZmluaXIgbCdvcHRpbWl0emFkb3IKb3B0aW1pemVyID0gb3B0aW0uU0dEKG5ldC5wYXJhbWV0ZXJzKCksIGxyPTAuMDEpCgojIEVudHJhZGEgaSBvYmplY3RpdSBmaWN0aWNpcwppbnB1dCA9IHRvcmNoLnRlbnNvcihbWzEuMF1dKQp0YXJnZXQgPSB0b3JjaC50ZW5zb3IoW1swLjBdXSkKCiMgUGFzc2FkYSBlbmRhdmFudApvdXRwdXQgPSBuZXQoaW5wdXQpCmxvc3MgPSBGLm1zZV9sb3NzKG91dHB1dCwgdGFyZ2V0KQoKIyBQYXNzYWRhIGVucmVyZSBpIG9wdGltaXR6YWNpw7MKb3B0aW1pemVyLnplcm9fZ3JhZCgpICAjIE5ldGVqYXIgZWxzIGdyYWRpZW50cwpsb3NzLmJhY2t3YXJkKCkgICAgICAgICMgUGFzc2FkYSBlbnJlcmUKb3B0aW1pemVyLnN0ZXAoKSAgICAgICAjIEFjdHVhbGl0emFyIGVscyBwZXNvcwoKcHJpbnQobG9zcykgICMgU29ydGlkYTogdGVuc29yKDAuMjUwMCwgZ3JhZF9mbj08TXNlTG9zc0JhY2t3YXJkPik="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.optim as optim

# Definir una xarxa neuronal simple
net = SimpleNN()

# Definir l'optimitzador
optimizer = optim.SGD(net.parameters(), lr=0.01)

# Entrada i objectiu ficticis
input = torch.tensor([[1.0]])
target = torch.tensor([[0.0]])

# Passada endavant
output = net(input)
loss = F.mse_loss(output, target)

# Passada enrere i optimitzaci&oacute;
optimizer.zero_grad()  # Netejar els gradients
loss.backward()        # Passada enrere
optimizer.step()       # Actualitzar els pesos

print(loss)  # Sortida: tensor(0.2500, grad_fn=&lt;MseLossBackward&gt;)</pre></div><div class='content'></div><h1>Propagació Endavant i Enrere</h1>
<div class='content'><p>La propagació endavant implica passar l'entrada a través de la xarxa per obtenir la sortida. La propagació enrere implica calcular els gradients i actualitzar els pesos.</p>
</div><h2>Exemple: Bucle d'Entrenament Complet</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEZWZpbmlyIGxhIHhhcnhhLCBsYSBmdW5jacOzIGRlIHDDqHJkdWEgaSBsJ29wdGltaXR6YWRvcgpuZXQgPSBTaW1wbGVOTigpCmNyaXRlcmlvbiA9IG5uLk1TRUxvc3MoKQpvcHRpbWl6ZXIgPSBvcHRpbS5TR0QobmV0LnBhcmFtZXRlcnMoKSwgbHI9MC4wMSkKCiMgRGFkZXMgZmljdMOtY2llcwppbnB1dHMgPSB0b3JjaC50ZW5zb3IoW1sxLjBdLCBbMi4wXSwgWzMuMF1dKQp0YXJnZXRzID0gdG9yY2gudGVuc29yKFtbMC4wXSwgWzAuMF0sIFsxLjBdXSkKCiMgQnVjbGUgZCdlbnRyZW5hbWVudApmb3IgZXBvY2ggaW4gcmFuZ2UoMTAwKToKICAgIGZvciBpIGluIHJhbmdlKGxlbihpbnB1dHMpKToKICAgICAgICBpbnB1dCA9IGlucHV0c1tpXQogICAgICAgIHRhcmdldCA9IHRhcmdldHNbaV0KCiAgICAgICAgIyBQYXNzYWRhIGVuZGF2YW50CiAgICAgICAgb3V0cHV0ID0gbmV0KGlucHV0KQogICAgICAgIGxvc3MgPSBjcml0ZXJpb24ob3V0cHV0LCB0YXJnZXQpCgogICAgICAgICMgUGFzc2FkYSBlbnJlcmUgaSBvcHRpbWl0emFjacOzCiAgICAgICAgb3B0aW1pemVyLnplcm9fZ3JhZCgpCiAgICAgICAgbG9zcy5iYWNrd2FyZCgpCiAgICAgICAgb3B0aW1pemVyLnN0ZXAoKQoKICAgIGlmIGVwb2NoICUgMTAgPT0gMDoKICAgICAgICBwcmludChmJ0Vwb2NoIHtlcG9jaH0sIExvc3M6IHtsb3NzLml0ZW0oKX0nKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Definir la xarxa, la funci&oacute; de p&egrave;rdua i l'optimitzador
net = SimpleNN()
criterion = nn.MSELoss()
optimizer = optim.SGD(net.parameters(), lr=0.01)

# Dades fict&iacute;cies
inputs = torch.tensor([[1.0], [2.0], [3.0]])
targets = torch.tensor([[0.0], [0.0], [1.0]])

# Bucle d'entrenament
for epoch in range(100):
    for i in range(len(inputs)):
        input = inputs[i]
        target = targets[i]

        # Passada endavant
        output = net(input)
        loss = criterion(output, target)

        # Passada enrere i optimitzaci&oacute;
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    if epoch % 10 == 0:
        print(f'Epoch {epoch}, Loss: {loss.item()}')</pre></div><div class='content'></div><h1>Conclusió</h1>
<div class='content'><p>En aquesta secció, heu après els conceptes bàsics de les xarxes neuronals, incloent neurones, capes, funcions d'activació, funcions de pèrdua, algoritmes d'optimització i els conceptes de propagació endavant i enrere. Amb aquesta base, ara esteu preparats per construir i entrenar xarxes neuronals més complexes utilitzant PyTorch.</p>
</div><div class='row navigation'><div class='col-6'><a href='autograd-automatic-differentiation'>&#x25C4; Autograd: Diferenciació Automàtica</a></div><div class='col-6 text-end'><a href='creating-a-simple-neural-network'>Creació d'una Xarxa Neuronal Simple &#x25BA;</a></div></div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/ca/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
