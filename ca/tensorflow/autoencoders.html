<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Autoencoders en TensorFlow</title>

    <link rel="alternate" href="https://campusempresa.com/es/tensorflow/autoencoders" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/tensorflow/autoencoders" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/tensorflow/autoencoders" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/ca/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui<br> i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="/es/tensorflow/autoencoders" id="lnk_lang_es" data-lang="es" class="px-2">ES</a></b>
				|
				<b id="lit_lang_ca" class="px-2">CA</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/ca/objective">El Projecte</a>
				<a href="/ca/about">Sobre nosaltres</a>
				<a href="/ca/contribute">Contribuir</a>
				<a href="/ca/donate">Donacions</a>
				<a href="/ca/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'><p>Els autoencoders són un tipus de xarxa neuronal artificial utilitzada per aprendre codificacions eficients de dades no etiquetades. S'utilitzen principalment per a la reducció de dimensionalitat, l'aprenentatge de característiques i la detecció d'anomalies. En aquesta secció, explorarem com implementar autoencoders utilitzant TensorFlow, començant pels conceptes bàsics i progressant cap a conceptes més avançats.</p>
</div><h1>Introducció als Autoencoders</h1>
<div class='content'><p>Els autoencoders consten de dues parts principals:</p>
<ul>
<li><strong>Encoder</strong>: Aquesta part comprimeix l'entrada en una representació de l'espai latent.</li>
<li><strong>Decoder</strong>: Aquesta part reconstrueix l'entrada des de l'espai latent.</li>
</ul>
<p>L'objectiu és fer que la sortida sigui el més propera possible a l'entrada.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ul>
<li><strong>Espai Latent</strong>: La representació comprimida de les dades d'entrada.</li>
<li><strong>Pèrdua de Reconstrucció</strong>: La diferència entre l'entrada i la sortida reconstruïda.</li>
<li><strong>Coll d'Ampolla</strong>: La capa al mig de l'autoencoder que representa l'espai latent.</li>
</ul>
</div><h1>Construint un Autoencoder Bàsic</h1>
<div class='content'><p>Comencem construint un autoencoder simple utilitzant TensorFlow i Keras.</p>
</div><h2>Implementació Pas a Pas</h2>
<div class='content'><ol>
<li>
<p><strong>Importar Llibreries</strong></p>
<pre><code class="language-python">import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
import numpy as np
</code></pre>
</li>
<li>
<p><strong>Preparar Dades</strong>
Per simplicitat, utilitzarem el conjunt de dades MNIST.</p>
<pre><code class="language-python">(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
</code></pre>
</li>
<li>
<p><strong>Definir l'Arquitectura de l'Autoencoder</strong></p>
<pre><code class="language-python">input_dim = x_train.shape[1]
encoding_dim = 32  # Aquesta és la mida de les nostres representacions codificades

# Marcador de posició d'entrada
input_img = Input(shape=(input_dim,))
# Representació codificada de l'entrada
encoded = Dense(encoding_dim, activation='relu')(input_img)
# Representació decodificada de l'entrada
decoded = Dense(input_dim, activation='sigmoid')(encoded)

# Model d'autoencoder
autoencoder = Model(input_img, decoded)
</code></pre>
</li>
<li>
<p><strong>Compilar el Model</strong></p>
<pre><code class="language-python">autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
</code></pre>
</li>
<li>
<p><strong>Entrenar el Model</strong></p>
<pre><code class="language-python">autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))
</code></pre>
</li>
<li>
<p><strong>Avaluar el Model</strong></p>
<pre><code class="language-python">decoded_imgs = autoencoder.predict(x_test)
</code></pre>
</li>
</ol>
</div><h2>Explicació</h2>
<div class='content'><ul>
<li><strong>Capa d'Entrada</strong>: La capa d'entrada pren les imatges aplanades de MNIST.</li>
<li><strong>Capa de Codificació</strong>: Aquesta capa comprimeix l'entrada en un espai de menor dimensió.</li>
<li><strong>Capa de Decodificació</strong>: Aquesta capa reconstrueix l'entrada des de la representació codificada.</li>
<li><strong>Funció de Pèrdua</strong>: S'utilitza l'entropia creuada binària per mesurar la diferència entre l'entrada i la sortida reconstruïda.</li>
</ul>
</div><h1>Autoencoders Avançats</h1>
<div class='content'></div><h2>Autoencoders Variacionals (VAEs)</h2>
<div class='content'><p>Els VAEs són un tipus d'autoencoder que imposa una estructura probabilística a l'espai latent. Això permet interpolacions més significatives i la generació de noves dades.</p>
<h4>Conceptes Clau</h4>
<ul>
<li><strong>Variables Latents</strong>: Variables que capturen l'estructura subjacent de les dades.</li>
<li><strong>Divergència KL</strong>: Una mesura de com una distribució de probabilitat divergeix d'una segona distribució de probabilitat esperada.</li>
</ul>
</div><h2>Implementant un VAE</h2>
<div class='content'><ol>
<li>
<p><strong>Definir l'Arquitectura del VAE</strong></p>
<pre><code class="language-python">from tensorflow.keras.layers import Lambda, Layer
from tensorflow.keras.losses import mse

# Encoder
inputs = Input(shape=(input_dim,))
h = Dense(128, activation='relu')(inputs)
z_mean = Dense(encoding_dim)(h)
z_log_var = Dense(encoding_dim)(h)

def sampling(args):
    z_mean, z_log_var = args
    batch = tf.shape(z_mean)[0]
    dim = tf.shape(z_mean)[1]
    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
    return z_mean + tf.exp(0.5 * z_log_var) * epsilon

z = Lambda(sampling, output_shape=(encoding_dim,))([z_mean, z_log_var])

# Decoder
decoder_h = Dense(128, activation='relu')
decoder_mean = Dense(input_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)

# Model VAE
vae = Model(inputs, x_decoded_mean)

# Funció de Pèrdua
reconstruction_loss = mse(inputs, x_decoded_mean)
reconstruction_loss *= input_dim
kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)
kl_loss = tf.reduce_mean(kl_loss) * -0.5
vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)
vae.add_loss(vae_loss)
</code></pre>
</li>
<li>
<p><strong>Compilar i Entrenar el VAE</strong></p>
<pre><code class="language-python">vae.compile(optimizer='adam')
vae.fit(x_train, epochs=50, batch_size=256, validation_data=(x_test, None))
</code></pre>
</li>
</ol>
</div><h2>Explicació</h2>
<div class='content'><ul>
<li><strong>Variables Latents</strong>: <code>z_mean</code> i <code>z_log_var</code> representen la mitjana i la variància de les variables latents.</li>
<li><strong>Capa de Mostreig</strong>: Aquesta capa fa mostreig de l'espai latent utilitzant el truc de reparametrització.</li>
<li><strong>Divergència KL</strong>: Aquest terme assegura que les variables latents apreses segueixin una distribució normal estàndard.</li>
</ul>
</div><h1>Conclusió</h1>
<div class='content'><p>Els autoencoders són eines poderoses per a l'aprenentatge no supervisat, capaços d'aprendre representacions eficients de les dades. Hem començat amb un autoencoder bàsic i hem progressat cap a conceptes més avançats com els Autoencoders Variacionals. Entenent i implementant aquests models, podeu aplicar-los a diverses tasques com la compressió de dades, la neteja de soroll i la detecció d'anomalies.</p>
<p>En les següents seccions, explorarem altres arquitectures avançades de xarxes neuronals i les seves aplicacions en TensorFlow.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/ca/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
