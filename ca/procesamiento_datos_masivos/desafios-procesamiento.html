<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Desafiaments en el Processament de Dades Massives</title>

    <link rel="alternate" href="https://campusempresa.com/es/procesamiento_datos_masivos/desafios-procesamiento" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/procesamiento_datos_masivos/desafios-procesamiento" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/procesamiento_datos_masivos/desafios-procesamiento" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/ca/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui<br> i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="/es/procesamiento_datos_masivos/desafios-procesamiento" id="lnk_lang_es" data-lang="es" class="px-2">ES</a></b>
				|
				<b id="lit_lang_ca" class="px-2">CA</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="objective">El Projecte</a>
				<a href="about">Sobre nosaltres</a>
				<a href="contribute">Contribuir</a>
				<a href="donate">Donacions</a>
				<a href="licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'><p>El processament de dades massives, també conegut com a Big Data, presenta una sèrie de desafiaments únics a causa de l'escala, velocitat i varietat de les dades involucrades. En aquesta secció, explorarem els principals desafiaments que enfronten els professionals en treballar amb grans volums de dades i com abordar-los.</p>
</div><h1>1. Volum</h1>
<div class='content'><p>El volum es refereix a la quantitat de dades que es generen i emmagatzemen. La magnitud de les dades pot ser aclaparadora i planteja diversos desafiaments:</p>
<ul>
<li><strong>Emmagatzematge</strong>: Gestionar grans volums de dades requereix solucions d'emmagatzematge escalables.</li>
<li><strong>Processament</strong>: Processar grans quantitats de dades en temps raonable pot ser complicat.</li>
<li><strong>Cost</strong>: Els costos associats amb l'emmagatzematge i processament de grans volums de dades poden ser significatius.</li>
</ul>
</div><h2>Exemple de Codi: Ús de Hadoop per al Processament de Dades Massives</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCiMgQ3JlYXIgdW4gY29udGV4dCBkZSBTcGFyawpzYyA9IFNwYXJrQ29udGV4dCgibG9jYWwiLCAiQmlnIERhdGEgUHJvY2Vzc2luZyIpCgojIExsZWdpciB1biBmaXR4ZXIgZGUgdGV4dCBncmFuCmRhdGEgPSBzYy50ZXh0RmlsZSgiaGRmczovL3BhdGgvdG8vbGFyZ2VmaWxlLnR4dCIpCgojIENvbXB0YXIgZWwgbm9tYnJlIGRlIGzDrW5pZXMgZW4gZWwgZml0eGVyCmxpbmVfY291bnQgPSBkYXRhLmNvdW50KCkKCnByaW50KGYiRWwgZml0eGVyIHTDqSB7bGluZV9jb3VudH0gbMOtbmllcy4iKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

# Crear un context de Spark
sc = SparkContext(&quot;local&quot;, &quot;Big Data Processing&quot;)

# Llegir un fitxer de text gran
data = sc.textFile(&quot;hdfs://path/to/largefile.txt&quot;)

# Comptar el nombre de l&iacute;nies en el fitxer
line_count = data.count()

print(f&quot;El fitxer t&eacute; {line_count} l&iacute;nies.&quot;)</pre></div><div class='content'><p>Aquest exemple mostra com usar Apache Spark, una eina popular per al processament de grans volums de dades, per comptar el nombre de línies en un fitxer de text gran.</p>
</div><h1>2. Velocitat</h1>
<div class='content'><p>La velocitat es refereix a la rapidesa amb què es generen i processen les dades. Els desafiaments inclouen:</p>
<ul>
<li><strong>Latència</strong>: Minimitzar el temps de resposta per al processament de dades en temps real.</li>
<li><strong>Flux de dades</strong>: Gestionar el flux continu de dades que es generen a alta velocitat.</li>
</ul>
</div><h2>Exemple de Codi: Processament en Temps Real amb Apache Kafka i Spark Streaming</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnN0cmVhbWluZyBpbXBvcnQgU3RyZWFtaW5nQ29udGV4dApmcm9tIHB5c3BhcmsgaW1wb3J0IFNwYXJrQ29udGV4dAoKIyBDcmVhciB1biBjb250ZXh0IGRlIFNwYXJrCnNjID0gU3BhcmtDb250ZXh0KCJsb2NhbFsyXSIsICJOZXR3b3JrV29yZENvdW50IikKc3NjID0gU3RyZWFtaW5nQ29udGV4dChzYywgMSkKCiMgQ3JlYXIgdW4gRFN0cmVhbSBxdWUgY29ubmVjdGkgYWwgcG9ydCA5OTk5CmxpbmVzID0gc3NjLnNvY2tldFRleHRTdHJlYW0oImxvY2FsaG9zdCIsIDk5OTkpCgojIENvbXB0YXIgbGVzIHBhcmF1bGVzIGVuIGNhZGEgbMOtbmlhCndvcmRzID0gbGluZXMuZmxhdE1hcChsYW1iZGEgbGluZTogbGluZS5zcGxpdCgiICIpKQp3b3JkQ291bnRzID0gd29yZHMubWFwKGxhbWJkYSB3b3JkOiAod29yZCwgMSkpLnJlZHVjZUJ5S2V5KGxhbWJkYSBhLCBiOiBhICsgYikKCiMgSW1wcmltaXIgZWwgcmVzdWx0YXQKd29yZENvdW50cy5wcHJpbnQoKQoKc3NjLnN0YXJ0KCkKc3NjLmF3YWl0VGVybWluYXRpb24oKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.streaming import StreamingContext
from pyspark import SparkContext

# Crear un context de Spark
sc = SparkContext(&quot;local[2]&quot;, &quot;NetworkWordCount&quot;)
ssc = StreamingContext(sc, 1)

# Crear un DStream que connecti al port 9999
lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)

# Comptar les paraules en cada l&iacute;nia
words = lines.flatMap(lambda line: line.split(&quot; &quot;))
wordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)

# Imprimir el resultat
wordCounts.pprint()

ssc.start()
ssc.awaitTermination()</pre></div><div class='content'><p>Aquest exemple mostra com usar Apache Kafka i Spark Streaming per processar dades en temps real.</p>
</div><h1>3. Varietat</h1>
<div class='content'><p>La varietat es refereix als diferents tipus de dades que es generen. Els desafiaments inclouen:</p>
<ul>
<li><strong>Integració</strong>: Integrar dades de diferents fonts i formats.</li>
<li><strong>Transformació</strong>: Convertir dades no estructurades en un format estructurat per a la seva anàlisi.</li>
</ul>
</div><h2>Exemple de Codi: Integració de Dades amb Apache NiFi</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("PHByb2Nlc3Nvcj4KICA8bmFtZT5HZXRGaWxlPC9uYW1lPgogIDxwcm9wZXJ0aWVzPgogICAgPGRpcmVjdG9yeT4vcGF0aC90by9pbnB1dDwvZGlyZWN0b3J5PgogIDwvcHJvcGVydGllcz4KPC9wcm9jZXNzb3I+Cgo8cHJvY2Vzc29yPgogIDxuYW1lPlB1dEhERlM8L25hbWU+CiAgPHByb3BlcnRpZXM+CiAgICA8ZGlyZWN0b3J5Pi9wYXRoL3RvL2hkZnM8L2RpcmVjdG9yeT4KICA8L3Byb3BlcnRpZXM+CjwvcHJvY2Vzc29yPgoKPGNvbm5lY3Rpb24+CiAgPGZyb20+R2V0RmlsZTwvZnJvbT4KICA8dG8+UHV0SERGUzwvdG8+CjwvY29ubmVjdGlvbj4="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>&lt;processor&gt;
  &lt;name&gt;GetFile&lt;/name&gt;
  &lt;properties&gt;
    &lt;directory&gt;/path/to/input&lt;/directory&gt;
  &lt;/properties&gt;
&lt;/processor&gt;

&lt;processor&gt;
  &lt;name&gt;PutHDFS&lt;/name&gt;
  &lt;properties&gt;
    &lt;directory&gt;/path/to/hdfs&lt;/directory&gt;
  &lt;/properties&gt;
&lt;/processor&gt;

&lt;connection&gt;
  &lt;from&gt;GetFile&lt;/from&gt;
  &lt;to&gt;PutHDFS&lt;/to&gt;
&lt;/connection&gt;</pre></div><div class='content'><p>Aquest exemple mostra com usar Apache NiFi per integrar dades de diferents fonts i moure'ls a HDFS.</p>
</div><h1>4. Veracitat</h1>
<div class='content'><p>La veracitat es refereix a la qualitat i precisió de les dades. Els desafiaments inclouen:</p>
<ul>
<li><strong>Qualitat de les dades</strong>: Assegurar que les dades siguin precises i consistents.</li>
<li><strong>Neteja de dades</strong>: Identificar i corregir errors en les dades.</li>
</ul>
</div><h2>Exemple de Codi: Neteja de Dades amb Pandas</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHBhbmRhcyBhcyBwZAoKIyBMbGVnaXIgdW4gZml0eGVyIENTVgpkZiA9IHBkLnJlYWRfY3N2KCJkYXRhLmNzdiIpCgojIEVsaW1pbmFyIGZpbGVzIGFtYiB2YWxvcnMgbnVscwpkZl9jbGVhbmVkID0gZGYuZHJvcG5hKCkKCiMgQ29ycmVnaXIgdmFsb3JzIGVycm9uaXMKZGZfY2xlYW5lZFsnY29sdW1uX25hbWUnXSA9IGRmX2NsZWFuZWRbJ2NvbHVtbl9uYW1lJ10ucmVwbGFjZSgnZXJyb25lb3VzX3ZhbHVlJywgJ2NvcnJlY3RfdmFsdWUnKQoKcHJpbnQoZGZfY2xlYW5lZC5oZWFkKCkp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import pandas as pd

# Llegir un fitxer CSV
df = pd.read_csv(&quot;data.csv&quot;)

# Eliminar files amb valors nuls
df_cleaned = df.dropna()

# Corregir valors erronis
df_cleaned['column_name'] = df_cleaned['column_name'].replace('erroneous_value', 'correct_value')

print(df_cleaned.head())</pre></div><div class='content'><p>Aquest exemple mostra com usar Pandas per netejar un conjunt de dades eliminant files amb valors nuls i corregint valors erronis.</p>
</div><h1>Conclusió</h1>
<div class='content'><p>El processament de dades massives presenta desafiaments significatius en termes de volum, velocitat, varietat i veracitat. No obstant això, amb les eines i tècniques adequades, és possible gestionar i extreure valor de grans volums de dades. En aquest tema, hem explorat alguns d'aquests desafiaments i proporcionat exemples pràctics de com abordar-los utilitzant tecnologies com Hadoop, Spark, Kafka i Pandas.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
