<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>

	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui<br> i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="https://campusempresa.com/apachespark/caching-and-persistence" id="lnk_lang_es" data-lang="es">Castellano</a></b>
				|
				<b id="lit_lang_ca">Catala</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="objective">El Projecte</a>
				<a href="about">Sobre nosaltres</a>
				<a href="contribute">Contribuir</a>
				<a href="donate">Donacions</a>
				<a href="licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introducció</h1>
<div class='content'><p>L'emmagatzematge en memòria cau i la persistència són conceptes crucials a Apache Spark que ajuden a optimitzar el rendiment de les teves aplicacions emmagatzemant resultats intermedis. Aquesta secció cobrirà els conceptes bàsics de l'emmagatzematge en memòria cau i la persistència, la seva importància i com utilitzar-los de manera efectiva a Spark.</p>
</div><h1>Per què emmagatzematge en memòria cau i persistència?</h1>
<div class='content'><ul>
<li><strong>Millora del rendiment</strong>: Redueix el temps necessari per recomputar resultats intermedis.</li>
<li><strong>Optimització de recursos</strong>: Ús eficient de la memòria i els recursos d'emmagatzematge.</li>
<li><strong>Tolerància a fallades</strong>: Proporciona resiliència contra fallades de nodes emmagatzemant dades de manera distribuïda.</li>
</ul>
</div><h1>Emmagatzematge en memòria cau a Spark</h1>
<div class='content'><p>L'emmagatzematge en memòria cau és una operació mandrosa a Spark que emmagatzema les dades en memòria per a un accés més ràpid. És útil quan tens un RDD o DataFrame que es reutilitza diverses vegades a la teva aplicació.</p>
</div><h2>Com emmagatzemar dades en memòria cau</h2>
<div class='content'><p>Pots emmagatzemar un RDD o DataFrame en memòria cau utilitzant el mètode <code>cache()</code>.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNjLnRleHRGaWxlKCJoZGZzOi8vcGF0aC90by9maWxlIikKdmFsIGNhY2hlZFJkZCA9IHJkZC5jYWNoZSgp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = sc.textFile(&quot;hdfs://path/to/file&quot;)
val cachedRdd = rdd.cache()</pre></div><div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYgPSBzcGFyay5yZWFkLnRleHQoImhkZnM6Ly9wYXRoL3RvL2ZpbGUiKQpjYWNoZWREZiA9IGRmLmNhY2hlKCk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df = spark.read.text(&quot;hdfs://path/to/file&quot;)
cachedDf = df.cache()</pre></div><div class='content'></div><h2>Quan utilitzar l'emmagatzematge en memòria cau</h2>
<div class='content'><ul>
<li>Quan un RDD o DataFrame es reutilitza diverses vegades.</li>
<li>Quan el cost de computació de regenerar l'RDD o DataFrame és alt.</li>
</ul>
</div><h1>Persistència a Spark</h1>
<div class='content'><p>La persistència és una versió més flexible de l'emmagatzematge en memòria cau que et permet especificar el nivell d'emmagatzematge. El nivell d'emmagatzematge determina com i on es guarden les dades (per exemple, en memòria, en disc o ambdós).</p>
</div><h2>Nivells d'emmagatzematge</h2>
<div class='content'><ul>
<li><strong>MEMORY_ONLY</strong>: Emmagatzema l'RDD com a objectes Java deserialitzats a la JVM. Si l'RDD no cap en memòria, algunes particions no es guardaran en memòria cau i es recomputaran quan sigui necessari.</li>
<li><strong>MEMORY_AND_DISK</strong>: Emmagatzema l'RDD com a objectes Java deserialitzats a la JVM. Si l'RDD no cap en memòria, les particions que no hi caben es guarden en disc i es llegeixen des d'allà quan sigui necessari.</li>
<li><strong>DISK_ONLY</strong>: Emmagatzema les particions de l'RDD només en disc.</li>
<li><strong>MEMORY_ONLY_SER</strong>: Emmagatzema l'RDD com a objectes Java serialitzats (un array de bytes per partició) a la JVM.</li>
<li><strong>MEMORY_AND_DISK_SER</strong>: Similar a MEMORY_ONLY_SER però aboca les particions que no caben en memòria a disc.</li>
</ul>
</div><h2>Com persistir dades</h2>
<div class='content'><p>Pots persistir un RDD o DataFrame utilitzant el mètode <code>persist()</code> amb un nivell d'emmagatzematge especificat.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3RvcmFnZS5TdG9yYWdlTGV2ZWwKCnZhbCByZGQgPSBzYy50ZXh0RmlsZSgiaGRmczovL3BhdGgvdG8vZmlsZSIpCnZhbCBwZXJzaXN0ZWRSZGQgPSByZGQucGVyc2lzdChTdG9yYWdlTGV2ZWwuTUVNT1JZX0FORF9ESVNLKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.storage.StorageLevel

val rdd = sc.textFile(&quot;hdfs://path/to/file&quot;)
val persistedRdd = rdd.persist(StorageLevel.MEMORY_AND_DISK)</pre></div><div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTdG9yYWdlTGV2ZWwKCmRmID0gc3BhcmsucmVhZC50ZXh0KCJoZGZzOi8vcGF0aC90by9maWxlIikKcGVyc2lzdGVkRGYgPSBkZi5wZXJzaXN0KFN0b3JhZ2VMZXZlbC5NRU1PUllfQU5EX0RJU0sp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import StorageLevel

df = spark.read.text(&quot;hdfs://path/to/file&quot;)
persistedDf = df.persist(StorageLevel.MEMORY_AND_DISK)</pre></div><div class='content'></div><h2>Comparació de nivells d'emmagatzematge</h2>
<div class='content'><p>| Nivell d'emmagatzematge | Ús de memòria | Ús de disc | Ús de CPU | Tolerància a fallades |
|-------------------------|---------------|------------|-----------|-----------------------|
| MEMORY_ONLY             | Alt           | Cap        | Baix      | Baixa                 |
| MEMORY_AND_DISK         | Mitjà         | Mitjà      | Mitjà     | Mitjana               |
| DISK_ONLY               | Cap           | Alt        | Alt       | Alta                  |
| MEMORY_ONLY_SER         | Baix          | Cap        | Alt       | Baixa                 |
| MEMORY_AND_DISK_SER     | Baix          | Mitjà      | Alt       | Mitjana               |</p>
</div><h1>Exemples pràctics</h1>
<h2>Exemple 1: Emmagatzemar un DataFrame en memòria cau</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMbGVnaXIgdW4gZml0eGVyIENTViBlbiB1biBEYXRhRnJhbWUKZGYgPSBzcGFyay5yZWFkLmNzdigiaGRmczovL3BhdGgvdG8vY3N2ZmlsZSIsIGhlYWRlcj1UcnVlLCBpbmZlclNjaGVtYT1UcnVlKQoKIyBSZWFsaXR6YXIgYWxndW5lcyB0cmFuc2Zvcm1hY2lvbnMKZGZfZmlsdGVyZWQgPSBkZi5maWx0ZXIoZGZbJ2FnZSddID4gMzApCgojIEVtbWFnYXR6ZW1hciBlbCBEYXRhRnJhbWUgZW4gbWVtw7JyaWEgY2F1CmRmX2NhY2hlZCA9IGRmX2ZpbHRlcmVkLmNhY2hlKCkKCiMgUmVhbGl0emFyIGFjY2lvbnMgc29icmUgZWwgRGF0YUZyYW1lIGVtbWFnYXR6ZW1hdCBlbiBtZW3DsnJpYSBjYXUKZGZfY2FjaGVkLnNob3coKQpkZl9jYWNoZWQuY291bnQoKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Llegir un fitxer CSV en un DataFrame
df = spark.read.csv(&quot;hdfs://path/to/csvfile&quot;, header=True, inferSchema=True)

# Realitzar algunes transformacions
df_filtered = df.filter(df['age'] &gt; 30)

# Emmagatzemar el DataFrame en mem&ograve;ria cau
df_cached = df_filtered.cache()

# Realitzar accions sobre el DataFrame emmagatzemat en mem&ograve;ria cau
df_cached.show()
df_cached.count()</pre></div><div class='content'></div><h2>Exemple 2: Persistir un RDD</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3RvcmFnZS5TdG9yYWdlTGV2ZWwKCi8vIExsZWdpciB1biBmaXR4ZXIgZGUgdGV4dCBlbiB1biBSREQKdmFsIHJkZCA9IHNjLnRleHRGaWxlKCJoZGZzOi8vcGF0aC90by90ZXh0ZmlsZSIpCgovLyBSZWFsaXR6YXIgYWxndW5lcyB0cmFuc2Zvcm1hY2lvbnMKdmFsIHJkZEZpbHRlcmVkID0gcmRkLmZpbHRlcihsaW5lID0+IGxpbmUuY29udGFpbnMoIlNwYXJrIikpCgovLyBQZXJzaXN0aXIgbCdSREQgYW1iIGVsIG5pdmVsbCBkJ2VtbWFnYXR6ZW1hdGdlIE1FTU9SWV9BTkRfRElTSwp2YWwgcmRkUGVyc2lzdGVkID0gcmRkRmlsdGVyZWQucGVyc2lzdChTdG9yYWdlTGV2ZWwuTUVNT1JZX0FORF9ESVNLKQoKLy8gUmVhbGl0emFyIGFjY2lvbnMgc29icmUgbCdSREQgcGVyc2lzdGl0CnByaW50bG4ocmRkUGVyc2lzdGVkLmNvdW50KCkpCnJkZFBlcnNpc3RlZC5jb2xsZWN0KCkuZm9yZWFjaChwcmludGxuKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.storage.StorageLevel

// Llegir un fitxer de text en un RDD
val rdd = sc.textFile(&quot;hdfs://path/to/textfile&quot;)

// Realitzar algunes transformacions
val rddFiltered = rdd.filter(line =&gt; line.contains(&quot;Spark&quot;))

// Persistir l'RDD amb el nivell d'emmagatzematge MEMORY_AND_DISK
val rddPersisted = rddFiltered.persist(StorageLevel.MEMORY_AND_DISK)

// Realitzar accions sobre l'RDD persistit
println(rddPersisted.count())
rddPersisted.collect().foreach(println)</pre></div><div class='content'></div><h1>Conclusió</h1>
<div class='content'><p>L'emmagatzematge en memòria cau i la persistència són tècniques poderoses a Apache Spark que poden millorar significativament el rendiment i l'eficiència de les teves aplicacions. Entenent quan i com utilitzar aquestes característiques, pots optimitzar l'ús de recursos i millorar la tolerància a fallades dels teus treballs Spark. Recorda triar el nivell d'emmagatzematge adequat segons els requisits de la teva aplicació i els recursos disponibles.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
       <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
       <a href="cookies">Més informació</a>
   </div>	
	</div>    
</body>
</html>
