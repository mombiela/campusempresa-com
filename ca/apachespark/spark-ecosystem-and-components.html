<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>

	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui<br> i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="https://campusempresa.com/apachespark/spark-ecosystem-and-components" id="lnk_lang_es" data-lang="es">Castellano</a></b>
				|
				<b id="lit_lang_ca">Catala</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="objective">El Projecte</a>
				<a href="about">Sobre nosaltres</a>
				<a href="contribute">Contribuir</a>
				<a href="donate">Donacions</a>
				<a href="licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'><p>Apache Spark és un potent motor d'anàlisi unificat de codi obert dissenyat per al processament de dades a gran escala. Proporciona API d'alt nivell en Java, Scala, Python i R, i un motor optimitzat que admet gràfics d'execució generals. En aquest tema, explorarem l'ecosistema de Spark i els seus components clau.</p>
</div><h1>Nucli de Spark</h1>
<div class='content'><p>El nucli de Spark és la base de l'ecosistema d'Apache Spark. Proporciona funcionalitats essencials com la programació de tasques, la gestió de memòria, la recuperació d'errors i la interacció amb sistemes d'emmagatzematge.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ul>
<li><strong>Resilient Distributed Datasets (RDDs)</strong>: L'estructura de dades fonamental de Spark, que és immutable i distribuïda a través del clúster.</li>
<li><strong>Transformacions i Accions</strong>: Operacions sobre RDDs. Les transformacions creen nous RDDs, mentre que les accions calculen un resultat basat en un RDD.</li>
<li><strong>Avaluació Mandrosa</strong>: Les transformacions no s'executen immediatament, sinó que es registren en un gràfic de línia. Les accions desencadenen l'execució.</li>
</ul>
</div><h2>Exemple</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCnNjID0gU3BhcmtDb250ZXh0KCJsb2NhbCIsICJTaW1wbGUgQXBwIikKZGF0YSA9IFsxLCAyLCAzLCA0LCA1XQpyZGQgPSBzYy5wYXJhbGxlbGl6ZShkYXRhKQoKIyBUcmFuc2Zvcm1hY2nDszogbWFwCnNxdWFyZWRfcmRkID0gcmRkLm1hcChsYW1iZGEgeDogeCAqIHgpCgojIEFjY2nDszogY29sbGVjdApyZXN1bHQgPSBzcXVhcmVkX3JkZC5jb2xsZWN0KCkKcHJpbnQocmVzdWx0KSAgIyBPdXRwdXQ6IFsxLCA0LCA5LCAxNiwgMjVd"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

sc = SparkContext(&quot;local&quot;, &quot;Simple App&quot;)
data = [1, 2, 3, 4, 5]
rdd = sc.parallelize(data)

# Transformaci&oacute;: map
squared_rdd = rdd.map(lambda x: x * x)

# Acci&oacute;: collect
result = squared_rdd.collect()
print(result)  # Output: [1, 4, 9, 16, 25]</pre></div><div class='content'></div><h1>Spark SQL</h1>
<div class='content'><p>Spark SQL és un mòdul per al processament de dades estructurades. Permet consultar dades mitjançant SQL així com l'API de DataFrame.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ul>
<li><strong>DataFrames</strong>: Col·leccions distribuïdes de dades organitzades en columnes amb nom, similar a una taula en una base de dades relacional.</li>
<li><strong>Datasets</strong>: Extensió dels DataFrames que proporciona seguretat de tipus i una interfície de programació orientada a objectes.</li>
<li><strong>Catalyst Optimizer</strong>: Un optimitzador de consultes extensible utilitzat per Spark SQL.</li>
</ul>
</div><h2>Exemple</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIlNwYXJrIFNRTCBFeGFtcGxlIikuZ2V0T3JDcmVhdGUoKQpkYXRhID0gWygiQWxpY2UiLCAxKSwgKCJCb2IiLCAyKSwgKCJDYXRoeSIsIDMpXQpjb2x1bW5zID0gWyJOYW1lIiwgIlZhbHVlIl0KCmRmID0gc3BhcmsuY3JlYXRlRGF0YUZyYW1lKGRhdGEsIGNvbHVtbnMpCmRmLnNob3coKQoKIyBDb25zdWx0YSBTUUwKZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCnNxbERGID0gc3Bhcmsuc3FsKCJTRUxFQ1QgKiBGUk9NIHBlb3BsZSBXSEVSRSBWYWx1ZSA+IDEiKQpzcWxERi5zaG93KCk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;Spark SQL Example&quot;).getOrCreate()
data = [(&quot;Alice&quot;, 1), (&quot;Bob&quot;, 2), (&quot;Cathy&quot;, 3)]
columns = [&quot;Name&quot;, &quot;Value&quot;]

df = spark.createDataFrame(data, columns)
df.show()

# Consulta SQL
df.createOrReplaceTempView(&quot;people&quot;)
sqlDF = spark.sql(&quot;SELECT * FROM people WHERE Value &gt; 1&quot;)
sqlDF.show()</pre></div><div class='content'></div><h1>Spark Streaming</h1>
<div class='content'><p>Spark Streaming permet el processament escalable i tolerant a fallades de fluxos de dades en temps real.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ul>
<li><strong>DStreams (Discretized Streams)</strong>: L'abstracció bàsica en Spark Streaming, que representa un flux continu de dades.</li>
<li><strong>Operacions de Finestra</strong>: Operacions sobre una finestra lliscant de dades.</li>
</ul>
</div><h2>Exemple</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKZnJvbSBweXNwYXJrLnN0cmVhbWluZyBpbXBvcnQgU3RyZWFtaW5nQ29udGV4dAoKc2MgPSBTcGFya0NvbnRleHQoImxvY2FsWzJdIiwgIk5ldHdvcmtXb3JkQ291bnQiKQpzc2MgPSBTdHJlYW1pbmdDb250ZXh0KHNjLCAxKQoKbGluZXMgPSBzc2Muc29ja2V0VGV4dFN0cmVhbSgibG9jYWxob3N0IiwgOTk5OSkKd29yZHMgPSBsaW5lcy5mbGF0TWFwKGxhbWJkYSBsaW5lOiBsaW5lLnNwbGl0KCIgIikpCndvcmRDb3VudHMgPSB3b3Jkcy5tYXAobGFtYmRhIHdvcmQ6ICh3b3JkLCAxKSkucmVkdWNlQnlLZXkobGFtYmRhIGEsIGI6IGEgKyBiKQoKd29yZENvdW50cy5wcHJpbnQoKQoKc3NjLnN0YXJ0KCkKc3NjLmF3YWl0VGVybWluYXRpb24oKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext
from pyspark.streaming import StreamingContext

sc = SparkContext(&quot;local[2]&quot;, &quot;NetworkWordCount&quot;)
ssc = StreamingContext(sc, 1)

lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)
words = lines.flatMap(lambda line: line.split(&quot; &quot;))
wordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)

wordCounts.pprint()

ssc.start()
ssc.awaitTermination()</pre></div><div class='content'></div><h1>MLlib (Biblioteca d'Aprenentatge Automàtic)</h1>
<div class='content'><p>MLlib és la biblioteca d'aprenentatge automàtic escalable de Spark, que proporciona diversos algoritmes i utilitats.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ul>
<li><strong>Algoritmes</strong>: Classificació, regressió, agrupament, filtratge col·laboratiu, etc.</li>
<li><strong>Pipelines</strong>: Eines per construir, avaluar i ajustar fluxos de treball d'aprenentatge automàtic.</li>
</ul>
</div><h2>Exemple</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmNsYXNzaWZpY2F0aW9uIGltcG9ydCBMb2dpc3RpY1JlZ3Jlc3Npb24KZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIk1MbGliIEV4YW1wbGUiKS5nZXRPckNyZWF0ZSgpCmRhdGEgPSBzcGFyay5yZWFkLmZvcm1hdCgibGlic3ZtIikubG9hZCgic2FtcGxlX2xpYnN2bV9kYXRhLnR4dCIpCgpsciA9IExvZ2lzdGljUmVncmVzc2lvbihtYXhJdGVyPTEwLCByZWdQYXJhbT0wLjMsIGVsYXN0aWNOZXRQYXJhbT0wLjgpCmxyTW9kZWwgPSBsci5maXQoZGF0YSkKCnByaW50KCJDb2VmZmljaWVudHM6ICIgKyBzdHIobHJNb2RlbC5jb2VmZmljaWVudHMpKQpwcmludCgiSW50ZXJjZXB0OiAiICsgc3RyKGxyTW9kZWwuaW50ZXJjZXB0KSk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.classification import LogisticRegression
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;MLlib Example&quot;).getOrCreate()
data = spark.read.format(&quot;libsvm&quot;).load(&quot;sample_libsvm_data.txt&quot;)

lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)
lrModel = lr.fit(data)

print(&quot;Coefficients: &quot; + str(lrModel.coefficients))
print(&quot;Intercept: &quot; + str(lrModel.intercept))</pre></div><div class='content'></div><h1>GraphX</h1>
<div class='content'><p>GraphX és l'API de Spark per a gràfics i càlcul paral·lel de gràfics.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ul>
<li><strong>Gràfic de Propietats</strong>: Un multigràfic dirigit amb propietats adjuntes a cada vèrtex i aresta.</li>
<li><strong>API Pregel</strong>: Una API per a algoritmes iteratius de gràfics.</li>
</ul>
</div><h2>Exemple</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCmZyb20gcHlzcGFyay5ncmFwaHggaW1wb3J0IEdyYXBoCgpzYyA9IFNwYXJrQ29udGV4dCgibG9jYWwiLCAiR3JhcGhYIEV4YW1wbGUiKQp2ZXJ0aWNlcyA9IHNjLnBhcmFsbGVsaXplKFsoMSwgIkFsaWNlIiksICgyLCAiQm9iIiksICgzLCAiQ2F0aHkiKV0pCmVkZ2VzID0gc2MucGFyYWxsZWxpemUoWygxLCAyLCAiZnJpZW5kIiksICgyLCAzLCAiZm9sbG93IildKQoKZ3JhcGggPSBHcmFwaCh2ZXJ0aWNlcywgZWRnZXMpCnByaW50KGdyYXBoLnZlcnRpY2VzLmNvbGxlY3QoKSkKcHJpbnQoZ3JhcGguZWRnZXMuY29sbGVjdCgpKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext
from pyspark.sql import SparkSession
from pyspark.graphx import Graph

sc = SparkContext(&quot;local&quot;, &quot;GraphX Example&quot;)
vertices = sc.parallelize([(1, &quot;Alice&quot;), (2, &quot;Bob&quot;), (3, &quot;Cathy&quot;)])
edges = sc.parallelize([(1, 2, &quot;friend&quot;), (2, 3, &quot;follow&quot;)])

graph = Graph(vertices, edges)
print(graph.vertices.collect())
print(graph.edges.collect())</pre></div><div class='content'></div><h1>Conclusió</h1>
<div class='content'><p>L'ecosistema d'Apache Spark és vast i potent, proporcionant eines per a diverses necessitats de processament de dades. Des de les funcionalitats bàsiques del nucli de Spark fins als mòduls especialitzats com Spark SQL, Spark Streaming, MLlib i GraphX, Spark ofereix una suite completa per a l'anàlisi de grans dades. Entendre aquests components i les seves interaccions és crucial per aprofitar tot el potencial de Spark en aplicacions del món real.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
       <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
       <a href="cookies">Més informació</a>
   </div>	
	</div>    
</body>
</html>
