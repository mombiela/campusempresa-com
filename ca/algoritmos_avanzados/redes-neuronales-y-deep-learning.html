<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Xarxes Neuronals i Deep Learning</title>

    <link rel="alternate" href="https://campusempresa.com/es/algoritmos_avanzados/redes-neuronales-y-deep-learning" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/algoritmos_avanzados/redes-neuronales-y-deep-learning" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/algoritmos_avanzados/redes-neuronales-y-deep-learning" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/ca/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="/es/algoritmos_avanzados/redes-neuronales-y-deep-learning" id="lnk_lang_es" data-lang="es" class="px-2">ES</a></b>
				|
				<b id="lit_lang_ca" class="px-2">CA</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/ca/objective">El Projecte</a>
				<a href="/ca/about">Sobre nosaltres</a>
				<a href="/ca/contribute">Contribuir</a>
				<a href="/ca/donate">Donacions</a>
				<a href="/ca/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'><div class='col-6'></div><div class='col-6 text-end'></div></div><div class='content'></div><h1>Introducció a les Xarxes Neuronals</h1>
<div class='content'><p>Les xarxes neuronals són un conjunt d'algoritmes dissenyats per reconèixer patrons. S'inspiren en l'estructura i funcionament del cervell humà. Les xarxes neuronals són la base del Deep Learning, una subdisciplina de l'aprenentatge automàtic.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ul>
<li><strong>Neurones Artificials</strong>: Unitats bàsiques d'una xarxa neuronal, també conegudes com perceptrons.</li>
<li><strong>Capes</strong>: Conjunt de neurones. Les xarxes neuronals solen tenir una capa d'entrada, una o més capes ocultes i una capa de sortida.</li>
<li><strong>Pesos i Biasos</strong>: Paràmetres ajustables que determinen la sortida d'una neurona.</li>
<li><strong>Funció d'Activació</strong>: Funció que introdueix no linealitat a la xarxa. Exemples comuns inclouen ReLU, Sigmoid i Tanh.</li>
<li><strong>Propagació cap endavant</strong>: Procés de calcular la sortida de la xarxa neuronal.</li>
<li><strong>Retropropagació</strong>: Algoritme utilitzat per ajustar els pesos i biasos de la xarxa neuronal durant l'entrenament.</li>
</ul>
</div><h2>Exemple de Codi: Neurona Simple</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIEZ1bmNpw7MgZCdhY3RpdmFjacOzIFNpZ21vaWQKZGVmIHNpZ21vaWQoeCk6CiAgICByZXR1cm4gMSAvICgxICsgbnAuZXhwKC14KSkKCiMgRGVyaXZhZGEgZGUgbGEgZnVuY2nDsyBTaWdtb2lkCmRlZiBzaWdtb2lkX2Rlcml2YXRpdmUoeCk6CiAgICByZXR1cm4geCAqICgxIC0geCkKCiMgRW50cmVuYW1lbnQgZCd1bmEgbmV1cm9uYSBzaW1wbGUKaW5wdXRzID0gbnAuYXJyYXkoW1swLCAwXSwgWzAsIDFdLCBbMSwgMF0sIFsxLCAxXV0pCm91dHB1dHMgPSBucC5hcnJheShbWzBdLCBbMV0sIFsxXSwgWzBdXSkKCiMgSW5pY2lhbGl0emFjacOzIGRlIHBlc29zIGkgYmlhc29zCndlaWdodHMgPSBucC5yYW5kb20ucmFuZCgyLCAxKQpiaWFzID0gbnAucmFuZG9tLnJhbmQoMSkKCiMgVGF4YSBkJ2FwcmVuZW50YXRnZQpsZWFybmluZ19yYXRlID0gMC4xCgojIEVudHJlbmFtZW50CmZvciBlcG9jaCBpbiByYW5nZSgxMDAwMCk6CiAgICAjIFByb3BhZ2FjacOzIGNhcCBlbmRhdmFudAogICAgaW5wdXRfbGF5ZXIgPSBpbnB1dHMKICAgIHdlaWdodGVkX3N1bSA9IG5wLmRvdChpbnB1dF9sYXllciwgd2VpZ2h0cykgKyBiaWFzCiAgICBhY3RpdmF0ZWRfb3V0cHV0ID0gc2lnbW9pZCh3ZWlnaHRlZF9zdW0pCiAgICAKICAgICMgQ8OgbGN1bCBkZSBsJ2Vycm9yCiAgICBlcnJvciA9IG91dHB1dHMgLSBhY3RpdmF0ZWRfb3V0cHV0CiAgICAKICAgICMgUmV0cm9wcm9wYWdhY2nDswogICAgYWRqdXN0bWVudHMgPSBlcnJvciAqIHNpZ21vaWRfZGVyaXZhdGl2ZShhY3RpdmF0ZWRfb3V0cHV0KQogICAgd2VpZ2h0cyArPSBucC5kb3QoaW5wdXRfbGF5ZXIuVCwgYWRqdXN0bWVudHMpICogbGVhcm5pbmdfcmF0ZQogICAgYmlhcyArPSBucC5zdW0oYWRqdXN0bWVudHMpICogbGVhcm5pbmdfcmF0ZQoKcHJpbnQoIlBlc29zIGFqdXN0YXRzIGRlc3Byw6lzIGRlIGwnZW50cmVuYW1lbnQ6IikKcHJpbnQod2VpZ2h0cykKcHJpbnQoIkJpYXMgYWp1c3RhdCBkZXNwcsOpcyBkZSBsJ2VudHJlbmFtZW50OiIpCnByaW50KGJpYXMp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Funci&oacute; d'activaci&oacute; Sigmoid
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Derivada de la funci&oacute; Sigmoid
def sigmoid_derivative(x):
    return x * (1 - x)

# Entrenament d'una neurona simple
inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
outputs = np.array([[0], [1], [1], [0]])

# Inicialitzaci&oacute; de pesos i biasos
weights = np.random.rand(2, 1)
bias = np.random.rand(1)

# Taxa d'aprenentatge
learning_rate = 0.1

# Entrenament
for epoch in range(10000):
    # Propagaci&oacute; cap endavant
    input_layer = inputs
    weighted_sum = np.dot(input_layer, weights) + bias
    activated_output = sigmoid(weighted_sum)
    
    # C&agrave;lcul de l'error
    error = outputs - activated_output
    
    # Retropropagaci&oacute;
    adjustments = error * sigmoid_derivative(activated_output)
    weights += np.dot(input_layer.T, adjustments) * learning_rate
    bias += np.sum(adjustments) * learning_rate

print(&quot;Pesos ajustats despr&eacute;s de l'entrenament:&quot;)
print(weights)
print(&quot;Bias ajustat despr&eacute;s de l'entrenament:&quot;)
print(bias)</pre></div><div class='content'></div><h1>Deep Learning</h1>
<div class='content'><p>Deep Learning és una branca de l'aprenentatge automàtic que utilitza xarxes neuronals profundes, és a dir, xarxes amb múltiples capes ocultes. Aquestes xarxes són capaces d'aprendre representacions jeràrquiques de les dades.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ul>
<li><strong>Xarxes Neuronals Convolucionals (CNNs)</strong>: Utilitzades principalment per al processament d'imatges i vídeo.</li>
<li><strong>Xarxes Neuronals Recurrentes (RNNs)</strong>: Adequades per al processament de seqüències, com text i sèries temporals.</li>
<li><strong>Autoencoders</strong>: Xarxes neuronals utilitzades per a la reducció de dimensionalitat i la detecció d'anomalies.</li>
<li><strong>Generative Adversarial Networks (GANs)</strong>: Xarxes utilitzades per generar dades sintètiques que semblen reals.</li>
</ul>
</div><h2>Exemple de Codi: Xarxa Neuronal Convolucional (CNN) amb Keras</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzIGltcG9ydCBsYXllcnMsIG1vZGVscwoKIyBEZWZpbmljacOzIGRlbCBtb2RlbAptb2RlbCA9IG1vZGVscy5TZXF1ZW50aWFsKCkKbW9kZWwuYWRkKGxheWVycy5Db252MkQoMzIsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScsIGlucHV0X3NoYXBlPSgyOCwgMjgsIDEpKSkKbW9kZWwuYWRkKGxheWVycy5NYXhQb29saW5nMkQoKDIsIDIpKSkKbW9kZWwuYWRkKGxheWVycy5Db252MkQoNjQsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScpKQptb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQptb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg2NCwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JykpCgojIEFmZWdpciBjYXBlcyBkZW5zZXMKbW9kZWwuYWRkKGxheWVycy5GbGF0dGVuKCkpCm1vZGVsLmFkZChsYXllcnMuRGVuc2UoNjQsIGFjdGl2YXRpb249J3JlbHUnKSkKbW9kZWwuYWRkKGxheWVycy5EZW5zZSgxMCwgYWN0aXZhdGlvbj0nc29mdG1heCcpKQoKIyBDb21waWxhY2nDsyBkZWwgbW9kZWwKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLAogICAgICAgICAgICAgIGxvc3M9J3NwYXJzZV9jYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLAogICAgICAgICAgICAgIG1ldHJpY3M9WydhY2N1cmFjeSddKQoKIyBSZXN1bSBkZWwgbW9kZWwKbW9kZWwuc3VtbWFyeSgp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import layers, models

# Definici&oacute; del model
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

# Afegir capes denses
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

# Compilaci&oacute; del model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Resum del model
model.summary()</pre></div><div class='content'></div><h1>Comparació de Tipus de Xarxes Neuronals</h1>
<div class='content'><p>| Tipus de Xarxa | Aplicacions Principals | Avantatges | Desavantatges |
|----------------|------------------------|------------|---------------|
| CNN            | Processament d'imatges i vídeo | Eficient en l'extracció de característiques espacials | Requereix gran quantitat de dades etiquetades |
| RNN            | Processament de seqüències, text, sèries temporals | Captura dependències temporals | Problemes de desvaniment de gradients |
| Autoencoders   | Reducció de dimensionalitat, detecció d'anomalies | Eficient en la compressió de dades | No sempre captura totes les característiques importants |
| GANs           | Generació de dades sintètiques | Capacitat de generar dades realistes | Difícil d'entrenar, problemes d'estabilitat |</p>
</div><h1>Conclusió</h1>
<div class='content'><p>Les xarxes neuronals i el Deep Learning han revolucionat el camp de l'aprenentatge automàtic, permetent avenços significatius en àrees com el reconeixement d'imatges, processament de llenguatge natural i generació de dades sintètiques. Comprendre els conceptes bàsics i les diferents arquitectures de xarxes neuronals és fonamental per a qualsevol professional que desitgi especialitzar-se en algoritmes avançats i aprenentatge automàtic.</p>
</div><div class='row navigation'><div class='col-6'></div><div class='col-6 text-end'></div></div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/ca/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
