<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bias i Fairness en Machine Learning</title>

    <link rel="alternate" href="https://campusempresa.com/es/machine_learning/bias-fairness" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/machine_learning/bias-fairness" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/machine_learning/bias-fairness" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/ca/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui<br> i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="/es/machine_learning/bias-fairness" id="lnk_lang_es" data-lang="es" class="px-2">ES</a></b>
				|
				<b id="lit_lang_ca" class="px-2">CA</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/ca/objective">El Projecte</a>
				<a href="/ca/about">Sobre nosaltres</a>
				<a href="/ca/contribute">Contribuir</a>
				<a href="/ca/donate">Donacions</a>
				<a href="/ca/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introducció</h1>
<div class='content'><p>En el context de Machine Learning, els conceptes de bias (biaix) i fairness (justícia) són fonamentals per desenvolupar models que no només siguin precisos, sinó també ètics i equitatius. Aquest tema abordarà les definicions, tipus de biaixos, mètodes per detectar i mitigar biaixos, i com avaluar l'equitat en els models de Machine Learning.</p>
</div><h1>Què és el Bias?</h1>
<div class='content'><p>El bias en Machine Learning es refereix a qualsevol error sistemàtic en el model que condueix a resultats inexactes o injustos. Pot sorgir en diverses etapes del procés de desenvolupament del model, des de la recopilació de dades fins a la implementació del model.</p>
</div><h2>Tipus de Bias</h2>
<div class='content'><ul>
<li><strong>Bias de Selecció</strong>: Ocorre quan les dades d'entrenament no representen adequadament la població objectiu.</li>
<li><strong>Bias de Confirmació</strong>: Sorgeix quan es busquen o interpreten dades de manera que confirmin les creences preexistents.</li>
<li><strong>Bias d'Exclusió</strong>: Es produeix quan certs grups o característiques s'exclouen del conjunt de dades.</li>
<li><strong>Bias de Mesura</strong>: Apareix quan les variables d'entrada no es mesuren amb precisió.</li>
</ul>
</div><h1>Què és Fairness?</h1>
<div class='content'><p>La fairness en Machine Learning es refereix a la creació de models que tractin a tots els individus o grups de manera equitativa. L'equitat pot ser avaluada des de diferents perspectives, com l'equitat demogràfica, l'equitat d'oportunitats i l'equitat de resultats.</p>
</div><h2>Mètodes per Avaluar la Fairness</h2>
<div class='content'><ul>
<li><strong>Equitat Demogràfica</strong>: Assegura que totes les classes o grups demogràfics tinguin una representació equitativa en els resultats del model.</li>
<li><strong>Equitat d'Oportunitats</strong>: Garanteix que tots els individus tinguin les mateixes oportunitats de rebre un resultat positiu.</li>
<li><strong>Equitat de Resultats</strong>: Se centra en que els resultats finals siguin equitatius per a tots els grups.</li>
</ul>
</div><h1>Exemples de Bias i Fairness</h1>
<div class='content'></div><h2>Exemple de Bias de Selecció</h2>
<div class='content'><p>Suposem que estem desenvolupant un model de classificació per predir si un candidat serà contractat. Si el conjunt de dades d'entrenament conté principalment dades de candidats d'una sola universitat, el model podria tenir un bias de selecció.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHBhbmRhcyBhcyBwZApmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0CmZyb20gc2tsZWFybi5saW5lYXJfbW9kZWwgaW1wb3J0IExvZ2lzdGljUmVncmVzc2lvbgoKIyBDYXJyZWdhciBkYWRlcwpkYXRhID0gcGQucmVhZF9jc3YoJ2NhbmRpZGF0ZXMuY3N2JykKCiMgVmVyaWZpY2FyIGxhIGRpc3RyaWJ1Y2nDsyBkZSBsYSB1bml2ZXJzaXRhdApwcmludChkYXRhWyd1bml2ZXJzaXR5J10udmFsdWVfY291bnRzKCkpCgojIERpdmlkaXIgbGVzIGRhZGVzIGVuIGVudHJlbmFtZW50IGkgcHJvdmEKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KGRhdGEuZHJvcCgnaGlyZWQnLCBheGlzPTEpLCBkYXRhWydoaXJlZCddLCB0ZXN0X3NpemU9MC4yLCByYW5kb21fc3RhdGU9NDIpCgojIEVudHJlbmFyIGVsIG1vZGVsCm1vZGVsID0gTG9naXN0aWNSZWdyZXNzaW9uKCkKbW9kZWwuZml0KFhfdHJhaW4sIHlfdHJhaW4pCgojIEF2YWx1YXIgZWwgbW9kZWwKYWNjdXJhY3kgPSBtb2RlbC5zY29yZShYX3Rlc3QsIHlfdGVzdCkKcHJpbnQoZidBY2N1cmFjeToge2FjY3VyYWN5fScp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Carregar dades
data = pd.read_csv('candidates.csv')

# Verificar la distribuci&oacute; de la universitat
print(data['university'].value_counts())

# Dividir les dades en entrenament i prova
X_train, X_test, y_train, y_test = train_test_split(data.drop('hired', axis=1), data['hired'], test_size=0.2, random_state=42)

# Entrenar el model
model = LogisticRegression()
model.fit(X_train, y_train)

# Avaluar el model
accuracy = model.score(X_test, y_test)
print(f'Accuracy: {accuracy}')</pre></div><div class='content'></div><h2>Exemple d'Avaluació de Fairness</h2>
<div class='content'><p>Per avaluar l'equitat demogràfica, podem utilitzar mètriques com la Taxa de Falsos Positius (FPR) i la Taxa de Falsos Negatius (FNR) per a diferents grups demogràfics.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1ldHJpY3MgaW1wb3J0IGNvbmZ1c2lvbl9tYXRyaXgKCiMgUHJlZGljY2lvbnMgZGVsIG1vZGVsCnlfcHJlZCA9IG1vZGVsLnByZWRpY3QoWF90ZXN0KQoKIyBDb25mdXNpb24gbWF0cml4IHBlciBhIGRpZmVyZW50cyBncnVwcwpjb25mX21hdHJpeF9ncm91cDEgPSBjb25mdXNpb25fbWF0cml4KHlfdGVzdFtYX3Rlc3RbJ2dyb3VwJ10gPT0gMV0sIHlfcHJlZFtYX3Rlc3RbJ2dyb3VwJ10gPT0gMV0pCmNvbmZfbWF0cml4X2dyb3VwMiA9IGNvbmZ1c2lvbl9tYXRyaXgoeV90ZXN0W1hfdGVzdFsnZ3JvdXAnXSA9PSAyXSwgeV9wcmVkW1hfdGVzdFsnZ3JvdXAnXSA9PSAyXSkKCiMgQ2FsY3VsYXIgRlBSIGkgRk5SCmRlZiBjYWxjdWxhdGVfZnByX2Zucihjb25mX21hdHJpeCk6CiAgICB0biwgZnAsIGZuLCB0cCA9IGNvbmZfbWF0cml4LnJhdmVsKCkKICAgIGZwciA9IGZwIC8gKGZwICsgdG4pCiAgICBmbnIgPSBmbiAvIChmbiArIHRwKQogICAgcmV0dXJuIGZwciwgZm5yCgpmcHJfZ3JvdXAxLCBmbnJfZ3JvdXAxID0gY2FsY3VsYXRlX2Zwcl9mbnIoY29uZl9tYXRyaXhfZ3JvdXAxKQpmcHJfZ3JvdXAyLCBmbnJfZ3JvdXAyID0gY2FsY3VsYXRlX2Zwcl9mbnIoY29uZl9tYXRyaXhfZ3JvdXAyKQoKcHJpbnQoZidHcm91cCAxIC0gRlBSOiB7ZnByX2dyb3VwMX0sIEZOUjoge2Zucl9ncm91cDF9JykKcHJpbnQoZidHcm91cCAyIC0gRlBSOiB7ZnByX2dyb3VwMn0sIEZOUjoge2Zucl9ncm91cDJ9Jyk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.metrics import confusion_matrix

# Prediccions del model
y_pred = model.predict(X_test)

# Confusion matrix per a diferents grups
conf_matrix_group1 = confusion_matrix(y_test[X_test['group'] == 1], y_pred[X_test['group'] == 1])
conf_matrix_group2 = confusion_matrix(y_test[X_test['group'] == 2], y_pred[X_test['group'] == 2])

# Calcular FPR i FNR
def calculate_fpr_fnr(conf_matrix):
    tn, fp, fn, tp = conf_matrix.ravel()
    fpr = fp / (fp + tn)
    fnr = fn / (fn + tp)
    return fpr, fnr

fpr_group1, fnr_group1 = calculate_fpr_fnr(conf_matrix_group1)
fpr_group2, fnr_group2 = calculate_fpr_fnr(conf_matrix_group2)

print(f'Group 1 - FPR: {fpr_group1}, FNR: {fnr_group1}')
print(f'Group 2 - FPR: {fpr_group2}, FNR: {fnr_group2}')</pre></div><div class='content'></div><h1>Mètodes per Mitigar el Bias</h1>
<div class='content'><ul>
<li><strong>Recollida de Dades Diverses</strong>: Assegurar-se que el conjunt de dades d'entrenament sigui representatiu de la població objectiu.</li>
<li><strong>Preprocessament de Dades</strong>: Aplicar tècniques de balanceig de dades, com sobremostreig o submostreig.</li>
<li><strong>Regularització del Model</strong>: Utilitzar tècniques de regularització per reduir l'overfitting i el bias.</li>
<li><strong>Auditories d'Equitat</strong>: Realitzar auditories periòdiques per avaluar i mitigar el bias en el model.</li>
</ul>
</div><h1>Conclusió</h1>
<div class='content'><p>El bias i la fairness són aspectes crítics en el desenvolupament de models de Machine Learning. Comprendre i abordar aquests conceptes no només millora la precisió del model, sinó que també assegura que els models siguin justos i ètics. En implementar tècniques per detectar i mitigar el bias, i avaluar l'equitat, els professionals poden desenvolupar models més robustos i equitatius.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/ca/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
