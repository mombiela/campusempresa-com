<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Màquines de Suport Vectorial (SVM)</title>

    <link rel="alternate" href="https://campusempresa.com/es/machine_learning/svm" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/machine_learning/svm" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/machine_learning/svm" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/ca/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui<br> i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="/es/machine_learning/svm" id="lnk_lang_es" data-lang="es" class="px-2">ES</a></b>
				|
				<b id="lit_lang_ca" class="px-2">CA</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/ca/objective">El Projecte</a>
				<a href="/ca/about">Sobre nosaltres</a>
				<a href="/ca/contribute">Contribuir</a>
				<a href="/ca/donate">Donacions</a>
				<a href="/ca/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introducció a les Màquines de Suport Vectorial</h1>
<div class='content'><p>Les Màquines de Suport Vectorial (SVM, per les seves sigles en anglès) són un conjunt d'algoritmes d'aprenentatge supervisat utilitzats per a classificació i regressió. No obstant això, són més conegudes per la seva aplicació en problemes de classificació.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ul>
<li><strong>Hiperplà</strong>: En el context de SVM, un hiperplà és una línia (en 2D), un pla (en 3D) o un espai de major dimensió que separa les dades en diferents classes.</li>
<li><strong>Margen</strong>: La distància entre l'hiperplà i els punts més propers de cada classe. SVM busca maximitzar aquest marge.</li>
<li><strong>Vectors de Suport</strong>: Els punts de dades que estan més a prop de l'hiperplà i que són crítics per definir la seva posició i orientació.</li>
<li><strong>Kernel</strong>: Una funció que transforma les dades en un espai de major dimensió per fer-les separables per un hiperplà.</li>
</ul>
</div><h1>Funcionament de SVM</h1>
<div class='content'></div><h2>Classificació Lineal</h2>
<div class='content'><p>En una classificació lineal, SVM intenta trobar l'hiperplà que millor separa les dues classes de dades.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0cwpmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0CmZyb20gc2tsZWFybi5zdm0gaW1wb3J0IFNWQwppbXBvcnQgbWF0cGxvdGxpYi5weXBsb3QgYXMgcGx0CgojIENhcnJlZ2FyIGVsIGRhdGFzZXQgZCdpcmlzCmlyaXMgPSBkYXRhc2V0cy5sb2FkX2lyaXMoKQpYID0gaXJpcy5kYXRhWzosIDoyXSAgIyBGZW0gc2VydmlyIG5vbcOpcyBsZXMgZHVlcyBwcmltZXJlcyBjYXJhY3RlcsOtc3RpcXVlcwp5ID0gaXJpcy50YXJnZXQKCiMgRGl2aWRpciBlbCBkYXRhc2V0IGVuIGNvbmp1bnQgZCdlbnRyZW5hbWVudCBpIHByb3ZhClhfdHJhaW4sIFhfdGVzdCwgeV90cmFpbiwgeV90ZXN0ID0gdHJhaW5fdGVzdF9zcGxpdChYLCB5LCB0ZXN0X3NpemU9MC4zLCByYW5kb21fc3RhdGU9NDIpCgojIENyZWFyIGVsIG1vZGVsIFNWTSBhbWIgdW4ga2VybmVsIGxpbmVhbAptb2RlbCA9IFNWQyhrZXJuZWw9J2xpbmVhcicpCm1vZGVsLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBWaXN1YWxpdHphciBsJ2hpcGVycGzDoApwbHQuc2NhdHRlcihYWzosIDBdLCBYWzosIDFdLCBjPXksIGNtYXA9J3ZpcmlkaXMnKQpheCA9IHBsdC5nY2EoKQp4bGltID0gYXguZ2V0X3hsaW0oKQp5bGltID0gYXguZ2V0X3lsaW0oKQoKIyBDcmVhciB1bmEgbWFsbGEgcGVyIHRyYcOnYXIgbCdoaXBlcnBsw6AKeHgsIHl5ID0gbnAubWVzaGdyaWQobnAubGluc3BhY2UoeGxpbVswXSwgeGxpbVsxXSwgMzApLCBucC5saW5zcGFjZSh5bGltWzBdLCB5bGltWzFdLCAzMCkpCnh5ID0gbnAudnN0YWNrKFt4eC5yYXZlbCgpLCB5eS5yYXZlbCgpXSkuVApaID0gbW9kZWwuZGVjaXNpb25fZnVuY3Rpb24oeHkpLnJlc2hhcGUoeHguc2hhcGUpCgojIFRyYcOnYXIgbCdoaXBlcnBsw6AgaSBlbHMgbWFyZ2VzCmF4LmNvbnRvdXIoeHgsIHl5LCBaLCBjb2xvcnM9J2snLCBsZXZlbHM9Wy0xLCAwLCAxXSwgYWxwaGE9MC41LCBsaW5lc3R5bGVzPVsnLS0nLCAnLScsICctLSddKQpwbHQuc2hvdygp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import matplotlib.pyplot as plt

# Carregar el dataset d'iris
iris = datasets.load_iris()
X = iris.data[:, :2]  # Fem servir nom&eacute;s les dues primeres caracter&iacute;stiques
y = iris.target

# Dividir el dataset en conjunt d'entrenament i prova
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Crear el model SVM amb un kernel lineal
model = SVC(kernel='linear')
model.fit(X_train, y_train)

# Visualitzar l'hiperpl&agrave;
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')
ax = plt.gca()
xlim = ax.get_xlim()
ylim = ax.get_ylim()

# Crear una malla per tra&ccedil;ar l'hiperpl&agrave;
xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 30), np.linspace(ylim[0], ylim[1], 30))
xy = np.vstack([xx.ravel(), yy.ravel()]).T
Z = model.decision_function(xy).reshape(xx.shape)

# Tra&ccedil;ar l'hiperpl&agrave; i els marges
ax.contour(xx, yy, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])
plt.show()</pre></div><div class='content'></div><h2>Classificació No Lineal</h2>
<div class='content'><p>Per a problemes on les dades no són linealment separables, SVM utilitza funcions kernel per projectar les dades en un espai de major dimensió.</p>
<ul>
<li><strong>Kernel Lineal</strong>: <code>kernel='linear'</code></li>
<li><strong>Kernel Polinòmic</strong>: <code>kernel='poly'</code></li>
<li><strong>Kernel Radial (RBF)</strong>: <code>kernel='rbf'</code></li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhciBlbCBtb2RlbCBTVk0gYW1iIHVuIGtlcm5lbCByYWRpYWwKbW9kZWwgPSBTVkMoa2VybmVsPSdyYmYnKQptb2RlbC5maXQoWF90cmFpbiwgeV90cmFpbikKCiMgVmlzdWFsaXR6YXIgbCdoaXBlcnBsw6AgZW4gbCdlc3BhaSB0cmFuc2Zvcm1hdApwbHQuc2NhdHRlcihYWzosIDBdLCBYWzosIDFdLCBjPXksIGNtYXA9J3ZpcmlkaXMnKQpheCA9IHBsdC5nY2EoKQp4bGltID0gYXguZ2V0X3hsaW0oKQp5bGltID0gYXguZ2V0X3lsaW0oKQoKIyBDcmVhciB1bmEgbWFsbGEgcGVyIHRyYcOnYXIgbCdoaXBlcnBsw6AKeHgsIHl5ID0gbnAubWVzaGdyaWQobnAubGluc3BhY2UoeGxpbVswXSwgeGxpbVsxXSwgMzApLCBucC5saW5zcGFjZSh5bGltWzBdLCB5bGltWzFdLCAzMCkpCnh5ID0gbnAudnN0YWNrKFt4eC5yYXZlbCgpLCB5eS5yYXZlbCgpXSkuVApaID0gbW9kZWwuZGVjaXNpb25fZnVuY3Rpb24oeHkpLnJlc2hhcGUoeHguc2hhcGUpCgojIFRyYcOnYXIgbCdoaXBlcnBsw6AgaSBlbHMgbWFyZ2VzCmF4LmNvbnRvdXIoeHgsIHl5LCBaLCBjb2xvcnM9J2snLCBsZXZlbHM9Wy0xLCAwLCAxXSwgYWxwaGE9MC41LCBsaW5lc3R5bGVzPVsnLS0nLCAnLScsICctLSddKQpwbHQuc2hvdygp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Crear el model SVM amb un kernel radial
model = SVC(kernel='rbf')
model.fit(X_train, y_train)

# Visualitzar l'hiperpl&agrave; en l'espai transformat
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')
ax = plt.gca()
xlim = ax.get_xlim()
ylim = ax.get_ylim()

# Crear una malla per tra&ccedil;ar l'hiperpl&agrave;
xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 30), np.linspace(ylim[0], ylim[1], 30))
xy = np.vstack([xx.ravel(), yy.ravel()]).T
Z = model.decision_function(xy).reshape(xx.shape)

# Tra&ccedil;ar l'hiperpl&agrave; i els marges
ax.contour(xx, yy, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])
plt.show()</pre></div><div class='content'></div><h1>Comparació de Kernels</h1>
<div class='content'><p>| Kernel       | Descripció                                                                 | Aplicació                                                                 |
|--------------|-----------------------------------------------------------------------------|----------------------------------------------------------------------------|
| Lineal       | Separa les dades amb un hiperplà lineal.                                  | Quan les dades són linealment separables o gairebé linealment separables. |
| Polinòmic   | Separa les dades amb un hiperplà polinòmic.                              | Quan les dades tenen una relació polinòmica.                           |
| Radial (RBF) | Separa les dades en un espai de major dimensió usant una funció radial.| Quan les dades no són linealment separables.                            |</p>
</div><h1>Exercicis Pràctics</h1>
<div class='content'><ol>
<li><strong>Exercici 1</strong>: Implementar una SVM amb un kernel lineal per a un dataset de dues classes i visualitzar l'hiperplà.</li>
<li><strong>Exercici 2</strong>: Provar diferents kernels (lineal, polinòmic, radial) en un dataset no linealment separable i comparar els resultats.</li>
<li><strong>Exercici 3</strong>: Ajustar els paràmetres de regularització i gamma en una SVM amb kernel radial i observar com afecten la classificació.</li>
</ol>
</div><h1>Conclusió</h1>
<div class='content'><p>Les Màquines de Suport Vectorial són eines poderoses per a la classificació i regressió en Machine Learning. La seva capacitat per trobar l'hiperplà òptim que separa les classes i la seva flexibilitat mitjançant l'ús de diferents kernels les fa molt versàtils. En comprendre els conceptes clau i practicar amb exemples, els professionals poden aplicar SVM de manera efectiva en una varietat de problemes de classificació.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/ca/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
