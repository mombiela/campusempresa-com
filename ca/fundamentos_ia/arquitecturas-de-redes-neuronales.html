<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>

	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui<br> i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="https://campusempresa.com/fundamentos_ia/arquitecturas-de-redes-neuronales" id="lnk_lang_es" data-lang="es">Castellano</a></b>
				|
				<b id="lit_lang_ca">Catala</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="objective">El Projecte</a>
				<a href="about">Sobre nosaltres</a>
				<a href="contribute">Contribuir</a>
				<a href="donate">Donacions</a>
				<a href="licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introducció</h1>
<div class='content'><p>Les arquitectures de xarxes neuronals són fonamentals en el camp de la intel·ligència artificial i l'aprenentatge profund. Aquestes arquitectures determinen com s'estructuren les neurones i les connexions entre elles per processar i aprendre de les dades. En aquesta secció, explorarem les arquitectures més comunes i les seves aplicacions.</p>
</div><h1>Xarxes Neuronals Feedforward (FNN)</h1>
<div class='content'><p>Les Xarxes Neuronals Feedforward són la forma més bàsica de xarxes neuronals. En aquestes xarxes, la informació es mou en una sola direcció, des de les entrades fins a les sortides, passant per capes ocultes.</p>
<ul>
<li>
<p><strong>Estructura</strong>:</p>
<ul>
<li><strong>Capa d'Entrada</strong>: Rep les dades d'entrada.</li>
<li><strong>Capes Ocultes</strong>: Processen la informació a través de múltiples neurones.</li>
<li><strong>Capa de Sortida</strong>: Produeix la sortida final.</li>
</ul>
</li>
<li>
<p><strong>Exemple de Codi</strong>:</p>
<pre><code class="language-python">import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Crear el model
model = Sequential()
# Afegir la capa d'entrada i la primera capa oculta
model.add(Dense(64, input_dim=10, activation='relu'))
# Afegir una segona capa oculta
model.add(Dense(64, activation='relu'))
# Afegir la capa de sortida
model.add(Dense(1, activation='sigmoid'))

# Compilar el model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Resum del model
model.summary()
</code></pre>
</li>
</ul>
</div><h1>Xarxes Neuronals Convolucionals (CNN)</h1>
<div class='content'><p>Les Xarxes Neuronals Convolucionals són especialment efectives per a tasques de processament d'imatges i reconeixement de patrons.</p>
<ul>
<li>
<p><strong>Components Clau</strong>:</p>
<ul>
<li><strong>Capes Convolucionals</strong>: Apliquen filtres per extreure característiques de les imatges.</li>
<li><strong>Capes de Pooling</strong>: Redueixen la dimensionalitat i la quantitat de paràmetres.</li>
<li><strong>Capes Completament Connectades</strong>: Realitzen la classificació final.</li>
</ul>
</li>
<li>
<p><strong>Exemple de Codi</strong>:</p>
<pre><code class="language-python">import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Crear el model
model = Sequential()
# Afegir una capa convolucional
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))
# Afegir una capa de pooling
model.add(MaxPooling2D(pool_size=(2, 2)))
# Afegir una segona capa convolucional
model.add(Conv2D(32, (3, 3), activation='relu'))
# Afegir una segona capa de pooling
model.add(MaxPooling2D(pool_size=(2, 2)))
# Aplanar les capes
model.add(Flatten())
# Afegir una capa completament connectada
model.add(Dense(128, activation='relu'))
# Afegir la capa de sortida
model.add(Dense(1, activation='sigmoid'))

# Compilar el model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Resum del model
model.summary()
</code></pre>
</li>
</ul>
</div><h1>Xarxes Neuronals Recurrentes (RNN)</h1>
<div class='content'><p>Les Xarxes Neuronals Recurrentes són adequades per a seqüències de dades, com sèries temporals i processament de llenguatge natural.</p>
<ul>
<li>
<p><strong>Característiques</strong>:</p>
<ul>
<li><strong>Memòria Interna</strong>: Permet recordar informació de passos anteriors.</li>
<li><strong>Capes Recurrentes</strong>: Processen seqüències de dades.</li>
</ul>
</li>
<li>
<p><strong>Exemple de Codi</strong>:</p>
<pre><code class="language-python">import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense

# Crear el model
model = Sequential()
# Afegir una capa recurrent
model.add(SimpleRNN(50, input_shape=(10, 1)))
# Afegir la capa de sortida
model.add(Dense(1))

# Compilar el model
model.compile(optimizer='adam', loss='mean_squared_error')

# Resum del model
model.summary()
</code></pre>
</li>
</ul>
</div><h1>Xarxes Neuronals de Memòria a Llarg Termini (LSTM)</h1>
<div class='content'><p>Les Xarxes Neuronals de Memòria a Llarg Termini són una variant de les RNN que poden aprendre dependències a llarg termini.</p>
<ul>
<li>
<p><strong>Components Clau</strong>:</p>
<ul>
<li><strong>Cèl·lules LSTM</strong>: Controlen el flux d'informació a través de portes d'entrada, oblit i sortida.</li>
</ul>
</li>
<li>
<p><strong>Exemple de Codi</strong>:</p>
<pre><code class="language-python">import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Crear el model
model = Sequential()
# Afegir una capa LSTM
model.add(LSTM(50, input_shape=(10, 1)))
# Afegir la capa de sortida
model.add(Dense(1))

# Compilar el model
model.compile(optimizer='adam', loss='mean_squared_error')

# Resum del model
model.summary()
</code></pre>
</li>
</ul>
</div><h1>Xarxes Generatives Antagòniques (GAN)</h1>
<div class='content'><p>Les Xarxes Generatives Antagòniques són una classe de xarxes neuronals utilitzades per generar noves dades similars a les dades d'entrenament.</p>
<ul>
<li>
<p><strong>Components Clau</strong>:</p>
<ul>
<li><strong>Generador</strong>: Crea dades falses.</li>
<li><strong>Discriminador</strong>: Distingeix entre dades reals i falses.</li>
</ul>
</li>
<li>
<p><strong>Exemple de Codi</strong>:</p>
<pre><code class="language-python">import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LeakyReLU

# Crear el generador
generator = Sequential()
generator.add(Dense(128, input_dim=100))
generator.add(LeakyReLU(alpha=0.2))
generator.add(Dense(256))
generator.add(LeakyReLU(alpha=0.2))
generator.add(Dense(512))
generator.add(LeakyReLU(alpha=0.2))
generator.add(Dense(784, activation='tanh'))

# Crear el discriminador
discriminator = Sequential()
discriminator.add(Dense(512, input_dim=784))
discriminator.add(LeakyReLU(alpha=0.2))
discriminator.add(Dense(256))
discriminator.add(LeakyReLU(alpha=0.2))
discriminator.add(Dense(1, activation='sigmoid'))

# Compilar el discriminador
discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Resum dels models
generator.summary()
discriminator.summary()
</code></pre>
</li>
</ul>
</div><h1>Conclusió</h1>
<div class='content'><p>Les arquitectures de xarxes neuronals són diverses i cadascuna té els seus propis avantatges i aplicacions específiques. Des de les simples Xarxes Neuronals Feedforward fins a les complexes Xarxes Generatives Antagòniques, cada arquitectura juga un paper crucial en l'avanç de la intel·ligència artificial. Comprendre aquestes arquitectures i les seves aplicacions és essencial per a qualsevol professional que desitgi especialitzar-se en el camp de la IA.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
       <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
       <a href="cookies">Més informació</a>
   </div>	
	</div>    
</body>
</html>
