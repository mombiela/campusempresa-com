<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tipus d'Aprenentatge Automàtic</title>

    <link rel="alternate" href="https://campusempresa.com/es/fundamentos_ia/tipos-de-aprendizaje-automatico" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/fundamentos_ia/tipos-de-aprendizaje-automatico" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/fundamentos_ia/tipos-de-aprendizaje-automatico" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/ca/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui<br> i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="/es/fundamentos_ia/tipos-de-aprendizaje-automatico" id="lnk_lang_es" data-lang="es" class="px-2">ES</a></b>
				|
				<b id="lit_lang_ca" class="px-2">CA</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/ca/objective">El Projecte</a>
				<a href="/ca/about">Sobre nosaltres</a>
				<a href="/ca/contribute">Contribuir</a>
				<a href="/ca/donate">Donacions</a>
				<a href="/ca/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'><p>En aquest tema, explorarem els diferents tipus d'aprenentatge automàtic, una subdisciplina fonamental de la intel·ligència artificial. Comprendre aquests tipus és essencial per seleccionar l'enfocament adequat per resoldre problemes específics.</p>
</div><h1>Aprenentatge Supervisat</h1>
<div class='content'><p>L'aprenentatge supervisat és un dels tipus més comuns d'aprenentatge automàtic. En aquest enfocament, el model s'entrena utilitzant un conjunt de dades etiquetades. Això significa que cada entrada de dades ve amb una etiqueta o resultat esperat.</p>
</div><h2>Característiques Clau</h2>
<div class='content'><ul>
<li><strong>Dades Etiquetades:</strong> Es requereix un conjunt de dades on cada entrada té una etiqueta corresponent.</li>
<li><strong>Entrenament i Prova:</strong> El conjunt de dades es divideix en dades d'entrenament i dades de prova.</li>
<li><strong>Predicció:</strong> L'objectiu és predir l'etiqueta per a noves entrades de dades.</li>
</ul>
</div><h2>Exemples d'Algoritmes</h2>
<div class='content'><ul>
<li><strong>Regressió Lineal:</strong> Utilitzat per a problemes de regressió.</li>
<li><strong>Màquines de Suport Vectorial (SVM):</strong> Utilitzades per a classificació.</li>
<li><strong>Xarxes Neuronals:</strong> Poden ser utilitzades tant per a classificació com per a regressió.</li>
</ul>
</div><h2>Exemple de Codi</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdApmcm9tIHNrbGVhcm4ubGluZWFyX21vZGVsIGltcG9ydCBMaW5lYXJSZWdyZXNzaW9uCmZyb20gc2tsZWFybi5tZXRyaWNzIGltcG9ydCBtZWFuX3NxdWFyZWRfZXJyb3IKCiMgRGFkZXMgZCdleGVtcGxlClggPSBbWzFdLCBbMl0sIFszXSwgWzRdLCBbNV1dCnkgPSBbMSwgNCwgOSwgMTYsIDI1XQoKIyBEaXZpZGlyIGxlcyBkYWRlcyBlbiBjb25qdW50cyBkJ2VudHJlbmFtZW50IGkgcHJvdmEKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjIsIHJhbmRvbV9zdGF0ZT00MikKCiMgQ3JlYXIgaSBlbnRyZW5hciBlbCBtb2RlbAptb2RlbCA9IExpbmVhclJlZ3Jlc3Npb24oKQptb2RlbC5maXQoWF90cmFpbiwgeV90cmFpbikKCiMgRmVyIHByZWRpY2Npb25zCnlfcHJlZCA9IG1vZGVsLnByZWRpY3QoWF90ZXN0KQoKIyBBdmFsdWFyIGVsIG1vZGVsCm1zZSA9IG1lYW5fc3F1YXJlZF9lcnJvcih5X3Rlc3QsIHlfcHJlZCkKcHJpbnQoZidFcnJvciBRdWFkcsOgdGljIE1pdGrDoDoge21zZX0nKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Dades d'exemple
X = [[1], [2], [3], [4], [5]]
y = [1, 4, 9, 16, 25]

# Dividir les dades en conjunts d'entrenament i prova
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear i entrenar el model
model = LinearRegression()
model.fit(X_train, y_train)

# Fer prediccions
y_pred = model.predict(X_test)

# Avaluar el model
mse = mean_squared_error(y_test, y_pred)
print(f'Error Quadr&agrave;tic Mitj&agrave;: {mse}')</pre></div><div class='content'></div><h1>Aprenentatge No Supervisat</h1>
<div class='content'><p>L'aprenentatge no supervisat s'utilitza quan les dades no estan etiquetades. L'objectiu és trobar patrons o estructures ocultes en les dades.</p>
</div><h2>Característiques Clau</h2>
<div class='content'><ul>
<li><strong>Dades No Etiquetades:</strong> No es requereix un conjunt de dades etiquetades.</li>
<li><strong>Agrupament i Reducció de Dimensionalitat:</strong> Els principals objectius són agrupar dades similars i reduir la dimensionalitat de les dades.</li>
</ul>
</div><h2>Exemples d'Algoritmes</h2>
<div class='content'><ul>
<li><strong>K-Means:</strong> Utilitzat per a agrupament.</li>
<li><strong>Anàlisi de Components Principals (PCA):</strong> Utilitzat per a reducció de dimensionalitat.</li>
<li><strong>Xarxes Neuronals Autoencoders:</strong> Utilitzades per a reducció de dimensionalitat i detecció d'anomalies.</li>
</ul>
</div><h2>Exemple de Codi</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmNsdXN0ZXIgaW1wb3J0IEtNZWFucwppbXBvcnQgbnVtcHkgYXMgbnAKCiMgRGFkZXMgZCdleGVtcGxlClggPSBucC5hcnJheShbWzEsIDJdLCBbMSwgNF0sIFsxLCAwXSwKICAgICAgICAgICAgICBbNCwgMl0sIFs0LCA0XSwgWzQsIDBdXSkKCiMgQ3JlYXIgaSBlbnRyZW5hciBlbCBtb2RlbAprbWVhbnMgPSBLTWVhbnMobl9jbHVzdGVycz0yLCByYW5kb21fc3RhdGU9MCkuZml0KFgpCgojIE9idGVuaXIgbGVzIGV0aXF1ZXRlcyBkZWxzIGNsdXN0ZXJzCmxhYmVscyA9IGttZWFucy5sYWJlbHNfCnByaW50KGYnRXRpcXVldGVzIGRlbHMgY2x1c3RlcnM6IHtsYWJlbHN9JykKCiMgT2J0ZW5pciBlbHMgY2VudHJlcyBkZWxzIGNsdXN0ZXJzCmNlbnRlcnMgPSBrbWVhbnMuY2x1c3Rlcl9jZW50ZXJzXwpwcmludChmJ0NlbnRyZXMgZGVscyBjbHVzdGVyczoge2NlbnRlcnN9Jyk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.cluster import KMeans
import numpy as np

# Dades d'exemple
X = np.array([[1, 2], [1, 4], [1, 0],
              [4, 2], [4, 4], [4, 0]])

# Crear i entrenar el model
kmeans = KMeans(n_clusters=2, random_state=0).fit(X)

# Obtenir les etiquetes dels clusters
labels = kmeans.labels_
print(f'Etiquetes dels clusters: {labels}')

# Obtenir els centres dels clusters
centers = kmeans.cluster_centers_
print(f'Centres dels clusters: {centers}')</pre></div><div class='content'></div><h1>Aprenentatge per Reforç</h1>
<div class='content'><p>L'aprenentatge per reforç és un tipus d'aprenentatge automàtic on un agent aprèn a prendre decisions mitjançant la interacció amb un entorn. L'agent rep recompenses o càstigs en funció de les accions que realitza.</p>
</div><h2>Característiques Clau</h2>
<div class='content'><ul>
<li><strong>Agent i Entorn:</strong> L'agent interactua amb l'entorn.</li>
<li><strong>Recompenses i Càstigs:</strong> L'agent rep recompenses o càstigs basats en les seves accions.</li>
<li><strong>Política de Decisió:</strong> L'objectiu és aprendre una política que maximitzi la recompensa acumulada.</li>
</ul>
</div><h2>Exemples d'Algoritmes</h2>
<div class='content'><ul>
<li><strong>Q-Learning:</strong> Un algoritme d'aprenentatge per reforç basat en taules.</li>
<li><strong>Deep Q-Networks (DQN):</strong> Utilitza xarxes neuronals per aproximar la funció Q.</li>
<li><strong>Política Proximal (PPO):</strong> Un algoritme avançat per a problemes de control continu.</li>
</ul>
</div><h2>Exemple de Codi</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIFBhcsOgbWV0cmVzIGRlIGwnZW50b3JuCnN0YXRlcyA9IFswLCAxLCAyLCAzXQphY3Rpb25zID0gWzAsIDFdICAjIDA6IGVzcXVlcnJhLCAxOiBkcmV0YQpyZXdhcmRzID0gWzAsIDAsIDAsIDFdICAjIFJlY29tcGVuc2EgZW4gbCdlc3RhdCBmaW5hbAoKIyBQYXLDoG1ldHJlcyBkZSBsJ2FnZW50CnFfdGFibGUgPSBucC56ZXJvcygobGVuKHN0YXRlcyksIGxlbihhY3Rpb25zKSkpCmFscGhhID0gMC4xICAjIFRheGEgZCdhcHJlbmVudGF0Z2UKZ2FtbWEgPSAwLjkgICMgRmFjdG9yIGRlIGRlc2NvbXB0ZQplcHNpbG9uID0gMC4xICAjIFRheGEgZCdleHBsb3JhY2nDswoKIyBGdW5jacOzIGQnYXByZW5lbnRhdGdlIFEtTGVhcm5pbmcKZGVmIHFfbGVhcm5pbmcoc3RhdGUsIGFjdGlvbiwgcmV3YXJkLCBuZXh0X3N0YXRlKToKICAgIGJlc3RfbmV4dF9hY3Rpb24gPSBucC5hcmdtYXgocV90YWJsZVtuZXh0X3N0YXRlXSkKICAgIHRkX3RhcmdldCA9IHJld2FyZCArIGdhbW1hICogcV90YWJsZVtuZXh0X3N0YXRlLCBiZXN0X25leHRfYWN0aW9uXQogICAgdGRfZXJyb3IgPSB0ZF90YXJnZXQgLSBxX3RhYmxlW3N0YXRlLCBhY3Rpb25dCiAgICBxX3RhYmxlW3N0YXRlLCBhY3Rpb25dICs9IGFscGhhICogdGRfZXJyb3IKCiMgU2ltdWxhY2nDsyBkJ3VuIGVwaXNvZGkKc3RhdGUgPSAwCndoaWxlIHN0YXRlICE9IDM6CiAgICBpZiBucC5yYW5kb20ucmFuZCgpIDwgZXBzaWxvbjoKICAgICAgICBhY3Rpb24gPSBucC5yYW5kb20uY2hvaWNlKGFjdGlvbnMpCiAgICBlbHNlOgogICAgICAgIGFjdGlvbiA9IG5wLmFyZ21heChxX3RhYmxlW3N0YXRlXSkKICAgIAogICAgbmV4dF9zdGF0ZSA9IHN0YXRlICsgKDEgaWYgYWN0aW9uID09IDEgZWxzZSAtMSkKICAgIHJld2FyZCA9IHJld2FyZHNbbmV4dF9zdGF0ZV0KICAgIAogICAgcV9sZWFybmluZyhzdGF0ZSwgYWN0aW9uLCByZXdhcmQsIG5leHRfc3RhdGUpCiAgICAKICAgIHN0YXRlID0gbmV4dF9zdGF0ZQoKcHJpbnQoZidUYXVsYSBRIGFjdHVhbGl0emFkYTpcbntxX3RhYmxlfScp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Par&agrave;metres de l'entorn
states = [0, 1, 2, 3]
actions = [0, 1]  # 0: esquerra, 1: dreta
rewards = [0, 0, 0, 1]  # Recompensa en l'estat final

# Par&agrave;metres de l'agent
q_table = np.zeros((len(states), len(actions)))
alpha = 0.1  # Taxa d'aprenentatge
gamma = 0.9  # Factor de descompte
epsilon = 0.1  # Taxa d'exploraci&oacute;

# Funci&oacute; d'aprenentatge Q-Learning
def q_learning(state, action, reward, next_state):
    best_next_action = np.argmax(q_table[next_state])
    td_target = reward + gamma * q_table[next_state, best_next_action]
    td_error = td_target - q_table[state, action]
    q_table[state, action] += alpha * td_error

# Simulaci&oacute; d'un episodi
state = 0
while state != 3:
    if np.random.rand() &lt; epsilon:
        action = np.random.choice(actions)
    else:
        action = np.argmax(q_table[state])
    
    next_state = state + (1 if action == 1 else -1)
    reward = rewards[next_state]
    
    q_learning(state, action, reward, next_state)
    
    state = next_state

print(f'Taula Q actualitzada:\n{q_table}')</pre></div><div class='content'></div><h1>Conclusió</h1>
<div class='content'><p>En resum, els tres tipus principals d'aprenentatge automàtic són l'aprenentatge supervisat, l'aprenentatge no supervisat i l'aprenentatge per reforç. Cadascun té les seves pròpies característiques, algoritmes i aplicacions. Comprendre aquests tipus i saber quan aplicar-los és fonamental per desenvolupar solucions efectives en el camp de la intel·ligència artificial.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/ca/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
