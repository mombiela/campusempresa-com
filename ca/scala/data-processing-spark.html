<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Processament de Dades amb Spark</title>

    <link rel="alternate" href="https://campusempresa.com/es/scala/data-processing-spark" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/scala/data-processing-spark" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/scala/data-processing-spark" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/ca/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui<br> i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="/es/scala/data-processing-spark" id="lnk_lang_es" data-lang="es" class="px-2">ES</a></b>
				|
				<b id="lit_lang_ca" class="px-2">CA</b>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/ca/objective">El Projecte</a>
				<a href="/ca/about">Sobre nosaltres</a>
				<a href="/ca/contribute">Contribuir</a>
				<a href="/ca/donate">Donacions</a>
				<a href="/ca/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introducció a Apache Spark</h1>
<div class='content'><p>Apache Spark és un potent motor d'analítica unificada de codi obert per al processament de dades a gran escala. Proporciona una interfície per programar clústers sencers amb paral·lelisme de dades implícit i tolerància a fallades.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ul>
<li><strong>Resilient Distributed Datasets (RDDs):</strong> Col·leccions distribuïdes immutables d'objectes que es poden processar en paral·lel.</li>
<li><strong>DataFrames:</strong> Col·leccions distribuïdes de dades organitzades en columnes amb nom, similar a una taula en una base de dades relacional.</li>
<li><strong>Spark SQL:</strong> Mòdul per treballar amb dades estructurades utilitzant consultes SQL.</li>
<li><strong>Spark Streaming:</strong> Permet el processament de fluxos de dades en temps real de manera escalable i tolerant a fallades.</li>
<li><strong>MLlib:</strong> Biblioteca d'aprenentatge automàtic per a Spark.</li>
<li><strong>GraphX:</strong> API per a gràfics i càlcul paral·lel de gràfics.</li>
</ul>
</div><h1>Configuració de Spark amb Scala</h1>
<div class='content'><p>Per començar a utilitzar Spark amb Scala, cal configurar l'entorn de desenvolupament.</p>
</div><h2>Passos d'Instal·lació</h2>
<div class='content'><ol>
<li><strong>Instal·lar Java Development Kit (JDK):</strong> Spark requereix Java per funcionar.</li>
<li><strong>Descarregar i Instal·lar Apache Spark:</strong> Obteniu l'última versió des del lloc web oficial.</li>
<li><strong>Configurar Scala:</strong> Instal·leu Scala a la vostra màquina.</li>
<li><strong>Instal·lar un IDE:</strong> Es recomana IntelliJ IDEA per al desenvolupament amb Scala.</li>
</ol>
</div><h2>Exemple: Configuració d'una Aplicació Simple amb Spark</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgoKb2JqZWN0IFNpbXBsZUFwcCB7CiAgZGVmIG1haW4oYXJnczogQXJyYXlbU3RyaW5nXSk6IFVuaXQgPSB7CiAgICB2YWwgc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlcgogICAgICAuYXBwTmFtZSgiU2ltcGxlIEFwcGxpY2F0aW9uIikKICAgICAgLmNvbmZpZygic3BhcmsubWFzdGVyIiwgImxvY2FsIikKICAgICAgLmdldE9yQ3JlYXRlKCkKCiAgICB2YWwgZGF0YSA9IHNwYXJrLnJlYWQudGV4dEZpbGUoImRhdGEudHh0IikucmRkCiAgICB2YWwgbnVtQXMgPSBkYXRhLmZpbHRlcihsaW5lID0+IGxpbmUuY29udGFpbnMoImEiKSkuY291bnQoKQogICAgdmFsIG51bUJzID0gZGF0YS5maWx0ZXIobGluZSA9PiBsaW5lLmNvbnRhaW5zKCJiIikpLmNvdW50KCkKCiAgICBwcmludGxuKHMiTGluZXMgd2l0aCBhOiAkbnVtQXMsIExpbmVzIHdpdGggYjogJG51bUJzIikKCiAgICBzcGFyay5zdG9wKCkKICB9Cn0="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession

object SimpleApp {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder
      .appName(&quot;Simple Application&quot;)
      .config(&quot;spark.master&quot;, &quot;local&quot;)
      .getOrCreate()

    val data = spark.read.textFile(&quot;data.txt&quot;).rdd
    val numAs = data.filter(line =&gt; line.contains(&quot;a&quot;)).count()
    val numBs = data.filter(line =&gt; line.contains(&quot;b&quot;)).count()

    println(s&quot;Lines with a: $numAs, Lines with b: $numBs&quot;)

    spark.stop()
  }
}</pre></div><div class='content'><p>Explicació:</p>
<ul>
<li><strong>SparkSession:</strong> Punt d'entrada per programar Spark amb l'API de Dataset i DataFrame.</li>
<li><strong>read.textFile:</strong> Llegeix un fitxer de text i retorna un RDD.</li>
<li><strong>filter:</strong> Filtra l'RDD basant-se en una condició.</li>
<li><strong>count:</strong> Compta el nombre d'elements en l'RDD.</li>
</ul>
</div><h1>Treballant amb RDDs</h1>
<div class='content'><p>Els RDDs són l'estructura de dades fonamental de Spark. Són col·leccions distribuïdes immutables d'objectes.</p>
</div><h2>Creació d'RDDs</h2>
<div class='content'><p>Podeu crear RDDs a partir de dades existents en el vostre programa o de conjunts de dades externs.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIGRhdGEgPSBBcnJheSgxLCAyLCAzLCA0LCA1KQp2YWwgZGlzdERhdGEgPSBzcGFyay5zcGFya0NvbnRleHQucGFyYWxsZWxpemUoZGF0YSk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val data = Array(1, 2, 3, 4, 5)
val distData = spark.sparkContext.parallelize(data)</pre></div><div class='content'></div><h2>Transformacions i Accions</h2>
<div class='content'><ul>
<li><strong>Transformacions:</strong> Operacions sobre RDDs que retornen un nou RDD (per exemple, <code>map</code>, <code>filter</code>).</li>
<li><strong>Accions:</strong> Operacions que retornen un valor al programa controlador o escriuen dades a un sistema d'emmagatzematge extern (per exemple, <code>count</code>, <code>collect</code>).</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNwYXJrLnNwYXJrQ29udGV4dC5wYXJhbGxlbGl6ZShTZXEoMSwgMiwgMywgNCwgNSkpCnZhbCBtYXBwZWRSREQgPSByZGQubWFwKHggPT4geCAqIHgpCnZhbCBmaWx0ZXJlZFJERCA9IG1hcHBlZFJERC5maWx0ZXIoeCA9PiB4ID4gMTApCnZhbCByZXN1bHQgPSBmaWx0ZXJlZFJERC5jb2xsZWN0KCkKcmVzdWx0LmZvcmVhY2gocHJpbnRsbik="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = spark.sparkContext.parallelize(Seq(1, 2, 3, 4, 5))
val mappedRDD = rdd.map(x =&gt; x * x)
val filteredRDD = mappedRDD.filter(x =&gt; x &gt; 10)
val result = filteredRDD.collect()
result.foreach(println)</pre></div><div class='content'></div><h1>Treballant amb DataFrames</h1>
<div class='content'><p>Els DataFrames són similars als RDDs però amb optimitzacions addicionals i la capacitat d'utilitzar consultes SQL.</p>
</div><h2>Creació de DataFrames</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIGRmID0gc3BhcmsucmVhZC5qc29uKCJwZW9wbGUuanNvbiIpCmRmLnNob3coKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val df = spark.read.json(&quot;people.json&quot;)
df.show()</pre></div><div class='content'></div><h2>Operacions amb DataFrames</h2>
<div class='content'><ul>
<li><strong>Select:</strong> Selecciona columnes específiques.</li>
<li><strong>Filter:</strong> Filtra files basant-se en una condició.</li>
<li><strong>GroupBy:</strong> Agrupa files per una columna específica.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYuc2VsZWN0KCJuYW1lIiwgImFnZSIpLnNob3coKQpkZi5maWx0ZXIoJCJhZ2UiID4gMjEpLnNob3coKQpkZi5ncm91cEJ5KCJhZ2UiKS5jb3VudCgpLnNob3coKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df.select(&quot;name&quot;, &quot;age&quot;).show()
df.filter($&quot;age&quot; &gt; 21).show()
df.groupBy(&quot;age&quot;).count().show()</pre></div><div class='content'></div><h1>Spark SQL</h1>
<div class='content'><p>Spark SQL permet executar consultes SQL sobre DataFrames.</p>
</div><h2>Exemple: Executant Consultes SQL</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCnZhbCBzcWxERiA9IHNwYXJrLnNxbCgiU0VMRUNUICogRlJPTSBwZW9wbGUgV0hFUkUgYWdlID4gMjEiKQpzcWxERi5zaG93KCk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df.createOrReplaceTempView(&quot;people&quot;)
val sqlDF = spark.sql(&quot;SELECT * FROM people WHERE age &gt; 21&quot;)
sqlDF.show()</pre></div><div class='content'></div><h1>Temes Avançats</h1>
<h2>Spark Streaming</h2>
<div class='content'><p>Spark Streaming permet el processament de dades en temps real.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3RyZWFtaW5nLl8KdmFsIHNzYyA9IG5ldyBTdHJlYW1pbmdDb250ZXh0KHNwYXJrLnNwYXJrQ29udGV4dCwgU2Vjb25kcygxKSkKdmFsIGxpbmVzID0gc3NjLnNvY2tldFRleHRTdHJlYW0oImxvY2FsaG9zdCIsIDk5OTkpCnZhbCB3b3JkcyA9IGxpbmVzLmZsYXRNYXAoXy5zcGxpdCgiICIpKQp2YWwgd29yZENvdW50cyA9IHdvcmRzLm1hcCh4ID0+ICh4LCAxKSkucmVkdWNlQnlLZXkoXyArIF8pCndvcmRDb3VudHMucHJpbnQoKQpzc2Muc3RhcnQoKQpzc2MuYXdhaXRUZXJtaW5hdGlvbigp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.streaming._
val ssc = new StreamingContext(spark.sparkContext, Seconds(1))
val lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)
val words = lines.flatMap(_.split(&quot; &quot;))
val wordCounts = words.map(x =&gt; (x, 1)).reduceByKey(_ + _)
wordCounts.print()
ssc.start()
ssc.awaitTermination()</pre></div><div class='content'></div><h2>Aprenentatge Automàtic amb MLlib</h2>
<div class='content'><p>MLlib proporciona diversos algoritmes d'aprenentatge automàtic.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3BhcmsubWwuY2xhc3NpZmljYXRpb24uTG9naXN0aWNSZWdyZXNzaW9uCnZhbCB0cmFpbmluZyA9IHNwYXJrLnJlYWQuZm9ybWF0KCJsaWJzdm0iKS5sb2FkKCJkYXRhL21sbGliL3NhbXBsZV9saWJzdm1fZGF0YS50eHQiKQp2YWwgbHIgPSBuZXcgTG9naXN0aWNSZWdyZXNzaW9uKCkKdmFsIG1vZGVsID0gbHIuZml0KHRyYWluaW5nKQp2YWwgcmVzdWx0ID0gbW9kZWwudHJhbnNmb3JtKHRyYWluaW5nKQpyZXN1bHQuc2hvdygp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.ml.classification.LogisticRegression
val training = spark.read.format(&quot;libsvm&quot;).load(&quot;data/mllib/sample_libsvm_data.txt&quot;)
val lr = new LogisticRegression()
val model = lr.fit(training)
val result = model.transform(training)
result.show()</pre></div><div class='content'></div><h1>Conclusió</h1>
<div class='content'><p>En aquest tema, hem cobert les bases del processament de dades amb Spark utilitzant Scala, incloent la configuració de Spark, treballant amb RDDs i DataFrames, executant consultes SQL i explorant temes avançats com Spark Streaming i MLlib. Les potents APIs i optimitzacions de Spark el fan una excel·lent opció per a tasques de processament de dades a gran escala.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/ca/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
