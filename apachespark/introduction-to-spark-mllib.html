<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introducción a Spark MLlib</title>

    <link rel="alternate" href="https://campusempresa.com/apachespark/introduction-to-spark-mllib" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/apachespark/introduction-to-spark-mllib" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/apachespark/introduction-to-spark-mllib" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/apachespark/introduction-to-spark-mllib" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/apachespark/introduction-to-spark-mllib" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='structured-streaming'>&#x25C4;Streaming Estructurado</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Introducción a Spark MLlib</a>
	</div>
	<div class='col-4 text-end'>
					<a href='basic-statistics'>Estadísticas Básicas &#x25BA;</a>
			</div>
</div>
<div class='content'><p>Apache Spark MLlib es una biblioteca de aprendizaje automático escalable que proporciona varios algoritmos y utilidades para tareas de aprendizaje automático. Esta sección te introducirá a los conceptos básicos de Spark MLlib, sus componentes clave y cómo usarlo para construir modelos de aprendizaje automático.</p>
</div><h1>¿Qué es Spark MLlib?</h1>
<div class='content'><p>Spark MLlib es una biblioteca dentro de Apache Spark que proporciona:</p>
<ul>
<li><strong>Algoritmos de aprendizaje automático escalables</strong>: Incluyendo clasificación, regresión, clustering y filtrado colaborativo.</li>
<li><strong>Herramientas para extracción, transformación y selección de características</strong>.</li>
<li><strong>Pipelines</strong>: Para construir y ajustar flujos de trabajo de aprendizaje automático.</li>
<li><strong>Utilidades</strong>: Para guardar y cargar modelos, evaluar modelos y trabajar con datos.</li>
</ul>
</div><h1>Conceptos Clave en Spark MLlib</h1>
<div class='content'><ul>
<li><strong>DataFrames</strong>: La estructura de datos principal utilizada en Spark MLlib para manejar datos.</li>
<li><strong>Transformers</strong>: Objetos que transforman DataFrames en otros DataFrames.</li>
<li><strong>Estimators</strong>: Algoritmos que pueden ajustarse en DataFrames para producir Transformers.</li>
<li><strong>Pipelines</strong>: Secuencias de Transformers y Estimators para optimizar el flujo de trabajo de aprendizaje automático.</li>
</ul>
</div><h1>Configuración de Spark MLlib</h1>
<div class='content'><p>Antes de sumergirte en Spark MLlib, asegúrate de tener Apache Spark instalado. Puedes instalarlo usando el siguiente comando:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("cGlwIGluc3RhbGwgcHlzcGFyaw=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>pip install pyspark</pre></div><div class='content'></div><h1>Flujo de Trabajo Básico en Spark MLlib</h1>
<div class='content'><ol>
<li><strong>Cargar y Preparar Datos</strong>: Cargar datos en un DataFrame y prepararlos para el análisis.</li>
<li><strong>Ingeniería de Características</strong>: Transformar datos en bruto en características adecuadas para el aprendizaje automático.</li>
<li><strong>Entrenamiento del Modelo</strong>: Entrenar un modelo de aprendizaje automático usando un Estimator.</li>
<li><strong>Evaluación del Modelo</strong>: Evaluar el rendimiento del modelo.</li>
<li><strong>Ajuste del Modelo</strong>: Optimizar los parámetros del modelo.</li>
<li><strong>Despliegue del Modelo</strong>: Guardar y cargar el modelo para uso futuro.</li>
</ol>
</div><h1>Ejemplo: Regresión Lineal con Spark MLlib</h1>
<div class='content'></div><h2>Paso 1: Cargar y Preparar Datos</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIEluaWNpYWxpemFyIHNlc2nDs24gZGUgU3BhcmsKc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlci5hcHBOYW1lKCJMaW5lYXJSZWdyZXNzaW9uRXhhbXBsZSIpLmdldE9yQ3JlYXRlKCkKCiMgQ2FyZ2FyIGRhdG9zCmRhdGEgPSBzcGFyay5yZWFkLmNzdigiZGF0YS5jc3YiLCBoZWFkZXI9VHJ1ZSwgaW5mZXJTY2hlbWE9VHJ1ZSkKCiMgTW9zdHJhciBsYXMgcHJpbWVyYXMgZmlsYXMgZGVsIERhdGFGcmFtZQpkYXRhLnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Inicializar sesi&oacute;n de Spark
spark = SparkSession.builder.appName(&quot;LinearRegressionExample&quot;).getOrCreate()

# Cargar datos
data = spark.read.csv(&quot;data.csv&quot;, header=True, inferSchema=True)

# Mostrar las primeras filas del DataFrame
data.show()</pre></div><div class='content'></div><h2>Paso 2: Ingeniería de Características</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmZlYXR1cmUgaW1wb3J0IFZlY3RvckFzc2VtYmxlcgoKIyBFbnNhbWJsYXIgY2FyYWN0ZXLDrXN0aWNhcyBlbiB1biBzb2xvIHZlY3Rvcgphc3NlbWJsZXIgPSBWZWN0b3JBc3NlbWJsZXIoaW5wdXRDb2xzPVsiZmVhdHVyZTEiLCAiZmVhdHVyZTIiXSwgb3V0cHV0Q29sPSJmZWF0dXJlcyIpCmRhdGEgPSBhc3NlbWJsZXIudHJhbnNmb3JtKGRhdGEpCgojIE1vc3RyYXIgZWwgRGF0YUZyYW1lIHRyYW5zZm9ybWFkbwpkYXRhLnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.feature import VectorAssembler

# Ensamblar caracter&iacute;sticas en un solo vector
assembler = VectorAssembler(inputCols=[&quot;feature1&quot;, &quot;feature2&quot;], outputCol=&quot;features&quot;)
data = assembler.transform(data)

# Mostrar el DataFrame transformado
data.show()</pre></div><div class='content'></div><h2>Paso 3: Entrenamiento del Modelo</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLnJlZ3Jlc3Npb24gaW1wb3J0IExpbmVhclJlZ3Jlc3Npb24KCiMgSW5pY2lhbGl6YXIgZWwgbW9kZWxvIGRlIFJlZ3Jlc2nDs24gTGluZWFsCmxyID0gTGluZWFyUmVncmVzc2lvbihmZWF0dXJlc0NvbD0iZmVhdHVyZXMiLCBsYWJlbENvbD0ibGFiZWwiKQoKIyBBanVzdGFyIGVsIG1vZGVsbwpscl9tb2RlbCA9IGxyLmZpdChkYXRhKQoKIyBNb3N0cmFyIGNvZWZpY2llbnRlcyBlIGludGVyY2VwdG8gZGVsIG1vZGVsbwpwcmludChmIkNvZWZmaWNpZW50czoge2xyX21vZGVsLmNvZWZmaWNpZW50c30iKQpwcmludChmIkludGVyY2VwdDoge2xyX21vZGVsLmludGVyY2VwdH0iKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.regression import LinearRegression

# Inicializar el modelo de Regresi&oacute;n Lineal
lr = LinearRegression(featuresCol=&quot;features&quot;, labelCol=&quot;label&quot;)

# Ajustar el modelo
lr_model = lr.fit(data)

# Mostrar coeficientes e intercepto del modelo
print(f&quot;Coefficients: {lr_model.coefficients}&quot;)
print(f&quot;Intercept: {lr_model.intercept}&quot;)</pre></div><div class='content'></div><h2>Paso 4: Evaluación del Modelo</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmV2YWx1YXRpb24gaW1wb3J0IFJlZ3Jlc3Npb25FdmFsdWF0b3IKCiMgSGFjZXIgcHJlZGljY2lvbmVzCnByZWRpY3Rpb25zID0gbHJfbW9kZWwudHJhbnNmb3JtKGRhdGEpCgojIEluaWNpYWxpemFyIGV2YWx1YWRvcgpldmFsdWF0b3IgPSBSZWdyZXNzaW9uRXZhbHVhdG9yKHByZWRpY3Rpb25Db2w9InByZWRpY3Rpb24iLCBsYWJlbENvbD0ibGFiZWwiLCBtZXRyaWNOYW1lPSJybXNlIikKCiMgRXZhbHVhciBlbCBtb2RlbG8Kcm1zZSA9IGV2YWx1YXRvci5ldmFsdWF0ZShwcmVkaWN0aW9ucykKcHJpbnQoZiJSb290IE1lYW4gU3F1YXJlZCBFcnJvciAoUk1TRSk6IHtybXNlfSIp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.evaluation import RegressionEvaluator

# Hacer predicciones
predictions = lr_model.transform(data)

# Inicializar evaluador
evaluator = RegressionEvaluator(predictionCol=&quot;prediction&quot;, labelCol=&quot;label&quot;, metricName=&quot;rmse&quot;)

# Evaluar el modelo
rmse = evaluator.evaluate(predictions)
print(f&quot;Root Mean Squared Error (RMSE): {rmse}&quot;)</pre></div><div class='content'></div><h2>Paso 5: Ajuste del Modelo (Opcional)</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLnR1bmluZyBpbXBvcnQgUGFyYW1HcmlkQnVpbGRlciwgQ3Jvc3NWYWxpZGF0b3IKCiMgQ3JlYXIgZ3JpZCBkZSBwYXLDoW1ldHJvcwpwYXJhbUdyaWQgPSBQYXJhbUdyaWRCdWlsZGVyKCkuYWRkR3JpZChsci5yZWdQYXJhbSwgWzAuMSwgMC4wMV0pLmJ1aWxkKCkKCiMgSW5pY2lhbGl6YXIgQ3Jvc3NWYWxpZGF0b3IKY3Jvc3N2YWwgPSBDcm9zc1ZhbGlkYXRvcihlc3RpbWF0b3I9bHIsIGVzdGltYXRvclBhcmFtTWFwcz1wYXJhbUdyaWQsIGV2YWx1YXRvcj1ldmFsdWF0b3IsIG51bUZvbGRzPTMpCgojIEVqZWN1dGFyIHZhbGlkYWNpw7NuIGNydXphZGEKY3ZfbW9kZWwgPSBjcm9zc3ZhbC5maXQoZGF0YSkKCiMgT2J0ZW5lciBlbCBtZWpvciBtb2RlbG8KYmVzdF9tb2RlbCA9IGN2X21vZGVsLmJlc3RNb2RlbApwcmludChmIkJlc3QgTW9kZWwgQ29lZmZpY2llbnRzOiB7YmVzdF9tb2RlbC5jb2VmZmljaWVudHN9IikKcHJpbnQoZiJCZXN0IE1vZGVsIEludGVyY2VwdDoge2Jlc3RfbW9kZWwuaW50ZXJjZXB0fSIp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.tuning import ParamGridBuilder, CrossValidator

# Crear grid de par&aacute;metros
paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.01]).build()

# Inicializar CrossValidator
crossval = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)

# Ejecutar validaci&oacute;n cruzada
cv_model = crossval.fit(data)

# Obtener el mejor modelo
best_model = cv_model.bestModel
print(f&quot;Best Model Coefficients: {best_model.coefficients}&quot;)
print(f&quot;Best Model Intercept: {best_model.intercept}&quot;)</pre></div><div class='content'></div><h2>Paso 6: Despliegue del Modelo</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBHdWFyZGFyIGVsIG1vZGVsbwpiZXN0X21vZGVsLnNhdmUoImxpbmVhcl9yZWdyZXNzaW9uX21vZGVsIikKCiMgQ2FyZ2FyIGVsIG1vZGVsbwpmcm9tIHB5c3BhcmsubWwucmVncmVzc2lvbiBpbXBvcnQgTGluZWFyUmVncmVzc2lvbk1vZGVsCmxvYWRlZF9tb2RlbCA9IExpbmVhclJlZ3Jlc3Npb25Nb2RlbC5sb2FkKCJsaW5lYXJfcmVncmVzc2lvbl9tb2RlbCIp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Guardar el modelo
best_model.save(&quot;linear_regression_model&quot;)

# Cargar el modelo
from pyspark.ml.regression import LinearRegressionModel
loaded_model = LinearRegressionModel.load(&quot;linear_regression_model&quot;)</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, introdujimos Spark MLlib y sus componentes clave. Recorrimos un flujo de trabajo básico para construir un modelo de aprendizaje automático usando Spark MLlib, incluyendo la carga de datos, ingeniería de características, entrenamiento del modelo, evaluación, ajuste y despliegue. Con esta base, puedes comenzar a explorar características y algoritmos más avanzados proporcionados por Spark MLlib para construir aplicaciones de aprendizaje automático escalables.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='structured-streaming'>&#x25C4;Streaming Estructurado</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Introducción a Spark MLlib</a>
	</div>
	<div class='col-4 text-end'>
					<a href='basic-statistics'>Estadísticas Básicas &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
