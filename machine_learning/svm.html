<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Máquinas de Soporte Vectorial (SVM)</title>

    <link rel="alternate" href="https://campusempresa.com/machine_learning/svm" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/machine_learning/svm" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/machine_learning/svm" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/machine_learning/svm" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/machine_learning/svm" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='arboles-decision'>&#x25C4;Árboles de Decisión</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Máquinas de Soporte Vectorial (SVM)</a>
	</div>
	<div class='col-4 text-end'>
					<a href='k-nn'>K-Vecinos Más Cercanos (K-NN) &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción a las Máquinas de Soporte Vectorial</h1>
<div class='content'><p>Las Máquinas de Soporte Vectorial (SVM, por sus siglas en inglés) son un conjunto de algoritmos de aprendizaje supervisado utilizados para clasificación y regresión. Sin embargo, son más conocidas por su aplicación en problemas de clasificación.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>Hiperplano</strong>: En el contexto de SVM, un hiperplano es una línea (en 2D), un plano (en 3D) o un espacio de mayor dimensión que separa los datos en diferentes clases.</li>
<li><strong>Margen</strong>: La distancia entre el hiperplano y los puntos más cercanos de cada clase. SVM busca maximizar este margen.</li>
<li><strong>Vectores de Soporte</strong>: Los puntos de datos que están más cerca del hiperplano y que son críticos para definir su posición y orientación.</li>
<li><strong>Kernel</strong>: Una función que transforma los datos en un espacio de mayor dimensión para hacerlos separables por un hiperplano.</li>
</ul>
</div><h1>Funcionamiento de SVM</h1>
<div class='content'></div><h2>Clasificación Lineal</h2>
<div class='content'><p>En una clasificación lineal, SVM intenta encontrar el hiperplano que mejor separa las dos clases de datos.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0cwpmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0CmZyb20gc2tsZWFybi5zdm0gaW1wb3J0IFNWQwppbXBvcnQgbWF0cGxvdGxpYi5weXBsb3QgYXMgcGx0CgojIENhcmdhciBlbCBkYXRhc2V0IGRlIGlyaXMKaXJpcyA9IGRhdGFzZXRzLmxvYWRfaXJpcygpClggPSBpcmlzLmRhdGFbOiwgOjJdICAjIFVzYW1vcyBzb2xvIGxhcyBkb3MgcHJpbWVyYXMgY2FyYWN0ZXLDrXN0aWNhcwp5ID0gaXJpcy50YXJnZXQKCiMgRGl2aWRpciBlbCBkYXRhc2V0IGVuIGNvbmp1bnRvIGRlIGVudHJlbmFtaWVudG8geSBwcnVlYmEKWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjMsIHJhbmRvbV9zdGF0ZT00MikKCiMgQ3JlYXIgZWwgbW9kZWxvIFNWTSBjb24gdW4ga2VybmVsIGxpbmVhbAptb2RlbCA9IFNWQyhrZXJuZWw9J2xpbmVhcicpCm1vZGVsLmZpdChYX3RyYWluLCB5X3RyYWluKQoKIyBWaXN1YWxpemFyIGVsIGhpcGVycGxhbm8KcGx0LnNjYXR0ZXIoWFs6LCAwXSwgWFs6LCAxXSwgYz15LCBjbWFwPSd2aXJpZGlzJykKYXggPSBwbHQuZ2NhKCkKeGxpbSA9IGF4LmdldF94bGltKCkKeWxpbSA9IGF4LmdldF95bGltKCkKCiMgQ3JlYXIgdW5hIG1hbGxhIHBhcmEgdHJhemFyIGVsIGhpcGVycGxhbm8KeHgsIHl5ID0gbnAubWVzaGdyaWQobnAubGluc3BhY2UoeGxpbVswXSwgeGxpbVsxXSwgMzApLCBucC5saW5zcGFjZSh5bGltWzBdLCB5bGltWzFdLCAzMCkpCnh5ID0gbnAudnN0YWNrKFt4eC5yYXZlbCgpLCB5eS5yYXZlbCgpXSkuVApaID0gbW9kZWwuZGVjaXNpb25fZnVuY3Rpb24oeHkpLnJlc2hhcGUoeHguc2hhcGUpCgojIFRyYXphciBlbCBoaXBlcnBsYW5vIHkgbG9zIG3DoXJnZW5lcwpheC5jb250b3VyKHh4LCB5eSwgWiwgY29sb3JzPSdrJywgbGV2ZWxzPVstMSwgMCwgMV0sIGFscGhhPTAuNSwgbGluZXN0eWxlcz1bJy0tJywgJy0nLCAnLS0nXSkKcGx0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import matplotlib.pyplot as plt

# Cargar el dataset de iris
iris = datasets.load_iris()
X = iris.data[:, :2]  # Usamos solo las dos primeras caracter&iacute;sticas
y = iris.target

# Dividir el dataset en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Crear el modelo SVM con un kernel lineal
model = SVC(kernel='linear')
model.fit(X_train, y_train)

# Visualizar el hiperplano
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')
ax = plt.gca()
xlim = ax.get_xlim()
ylim = ax.get_ylim()

# Crear una malla para trazar el hiperplano
xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 30), np.linspace(ylim[0], ylim[1], 30))
xy = np.vstack([xx.ravel(), yy.ravel()]).T
Z = model.decision_function(xy).reshape(xx.shape)

# Trazar el hiperplano y los m&aacute;rgenes
ax.contour(xx, yy, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])
plt.show()</pre></div><div class='content'></div><h2>Clasificación No Lineal</h2>
<div class='content'><p>Para problemas donde los datos no son linealmente separables, SVM utiliza funciones kernel para proyectar los datos en un espacio de mayor dimensión.</p>
<ul>
<li><strong>Kernel Lineal</strong>: <code>kernel='linear'</code></li>
<li><strong>Kernel Polinómico</strong>: <code>kernel='poly'</code></li>
<li><strong>Kernel Radial (RBF)</strong>: <code>kernel='rbf'</code></li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDcmVhciBlbCBtb2RlbG8gU1ZNIGNvbiB1biBrZXJuZWwgcmFkaWFsCm1vZGVsID0gU1ZDKGtlcm5lbD0ncmJmJykKbW9kZWwuZml0KFhfdHJhaW4sIHlfdHJhaW4pCgojIFZpc3VhbGl6YXIgZWwgaGlwZXJwbGFubyBlbiBlbCBlc3BhY2lvIHRyYW5zZm9ybWFkbwpwbHQuc2NhdHRlcihYWzosIDBdLCBYWzosIDFdLCBjPXksIGNtYXA9J3ZpcmlkaXMnKQpheCA9IHBsdC5nY2EoKQp4bGltID0gYXguZ2V0X3hsaW0oKQp5bGltID0gYXguZ2V0X3lsaW0oKQoKIyBDcmVhciB1bmEgbWFsbGEgcGFyYSB0cmF6YXIgZWwgaGlwZXJwbGFubwp4eCwgeXkgPSBucC5tZXNoZ3JpZChucC5saW5zcGFjZSh4bGltWzBdLCB4bGltWzFdLCAzMCksIG5wLmxpbnNwYWNlKHlsaW1bMF0sIHlsaW1bMV0sIDMwKSkKeHkgPSBucC52c3RhY2soW3h4LnJhdmVsKCksIHl5LnJhdmVsKCldKS5UClogPSBtb2RlbC5kZWNpc2lvbl9mdW5jdGlvbih4eSkucmVzaGFwZSh4eC5zaGFwZSkKCiMgVHJhemFyIGVsIGhpcGVycGxhbm8geSBsb3MgbcOhcmdlbmVzCmF4LmNvbnRvdXIoeHgsIHl5LCBaLCBjb2xvcnM9J2snLCBsZXZlbHM9Wy0xLCAwLCAxXSwgYWxwaGE9MC41LCBsaW5lc3R5bGVzPVsnLS0nLCAnLScsICctLSddKQpwbHQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Crear el modelo SVM con un kernel radial
model = SVC(kernel='rbf')
model.fit(X_train, y_train)

# Visualizar el hiperplano en el espacio transformado
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')
ax = plt.gca()
xlim = ax.get_xlim()
ylim = ax.get_ylim()

# Crear una malla para trazar el hiperplano
xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 30), np.linspace(ylim[0], ylim[1], 30))
xy = np.vstack([xx.ravel(), yy.ravel()]).T
Z = model.decision_function(xy).reshape(xx.shape)

# Trazar el hiperplano y los m&aacute;rgenes
ax.contour(xx, yy, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])
plt.show()</pre></div><div class='content'></div><h1>Comparación de Kernels</h1>
<div class='content'><p>| Kernel       | Descripción                                                                 | Aplicación                                                                 |
|--------------|-----------------------------------------------------------------------------|----------------------------------------------------------------------------|
| Lineal       | Separa los datos con un hiperplano lineal.                                  | Cuando los datos son linealmente separables o casi linealmente separables. |
| Polinómico   | Separa los datos con un hiperplano polinómico.                              | Cuando los datos tienen una relación polinómica.                           |
| Radial (RBF) | Separa los datos en un espacio de mayor dimensión usando una función radial.| Cuando los datos no son linealmente separables.                            |</p>
</div><h1>Ejercicios Prácticos</h1>
<div class='content'><ol>
<li><strong>Ejercicio 1</strong>: Implementar una SVM con un kernel lineal para un dataset de dos clases y visualizar el hiperplano.</li>
<li><strong>Ejercicio 2</strong>: Probar diferentes kernels (lineal, polinómico, radial) en un dataset no linealmente separable y comparar los resultados.</li>
<li><strong>Ejercicio 3</strong>: Ajustar los parámetros de regularización y gamma en una SVM con kernel radial y observar cómo afectan la clasificación.</li>
</ol>
</div><h1>Conclusión</h1>
<div class='content'><p>Las Máquinas de Soporte Vectorial son herramientas poderosas para la clasificación y regresión en Machine Learning. Su capacidad para encontrar el hiperplano óptimo que separa las clases y su flexibilidad mediante el uso de diferentes kernels las hace muy versátiles. Al comprender los conceptos clave y practicar con ejemplos, los profesionales pueden aplicar SVM de manera efectiva en una variedad de problemas de clasificación.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='arboles-decision'>&#x25C4;Árboles de Decisión</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Máquinas de Soporte Vectorial (SVM)</a>
	</div>
	<div class='col-4 text-end'>
					<a href='k-nn'>K-Vecinos Más Cercanos (K-NN) &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
