<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Caché y Persistencia en Apache Spark</title>

    <link rel="alternate" href="https://campusempresa.com/es/apachespark/caching-and-persistence" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/apachespark/caching-and-persistence" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/apachespark/caching-and-persistence" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/es/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy<br> y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<b id="lit_lang_es" class="px-2">ES</b>
				|
				<a href="/ca/apachespark/caching-and-persistence" id="lnk_lang_ca" data-lang="ca" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="objective">El Proyecto</a>
				<a href="about">Sobre nosotros</a>
				<a href="contribute">Contribuir</a>
				<a href="donate">Donaciones</a>
				<a href="licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introducción</h1>
<div class='content'><p>El caché y la persistencia son conceptos cruciales en Apache Spark que ayudan a optimizar el rendimiento de tus aplicaciones al almacenar resultados intermedios. Esta sección cubrirá los conceptos básicos del caché y la persistencia, su importancia y cómo usarlos efectivamente en Spark.</p>
</div><h1>¿Por qué Caché y Persistencia?</h1>
<div class='content'><ul>
<li><strong>Mejora del Rendimiento</strong>: Reduce el tiempo necesario para recomputar resultados intermedios.</li>
<li><strong>Optimización de Recursos</strong>: Uso eficiente de recursos de memoria y almacenamiento.</li>
<li><strong>Tolerancia a Fallos</strong>: Proporciona resiliencia contra fallos de nodos al almacenar datos de manera distribuida.</li>
</ul>
</div><h1>Caché en Spark</h1>
<div class='content'><p>El caché es una operación perezosa en Spark que almacena los datos en memoria para un acceso más rápido. Es útil cuando tienes un RDD o DataFrame que se reutiliza múltiples veces en tu aplicación.</p>
</div><h2>Cómo Cachear Datos</h2>
<div class='content'><p>Puedes cachear un RDD o DataFrame usando el método <code>cache()</code>.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNjLnRleHRGaWxlKCJoZGZzOi8vcGF0aC90by9maWxlIikKdmFsIGNhY2hlZFJkZCA9IHJkZC5jYWNoZSgp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = sc.textFile(&quot;hdfs://path/to/file&quot;)
val cachedRdd = rdd.cache()</pre></div><div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGYgPSBzcGFyay5yZWFkLnRleHQoImhkZnM6Ly9wYXRoL3RvL2ZpbGUiKQpjYWNoZWREZiA9IGRmLmNhY2hlKCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>df = spark.read.text(&quot;hdfs://path/to/file&quot;)
cachedDf = df.cache()</pre></div><div class='content'></div><h2>Cuándo Usar el Caché</h2>
<div class='content'><ul>
<li>Cuando un RDD o DataFrame se reutiliza múltiples veces.</li>
<li>Cuando el costo de computación de regenerar el RDD o DataFrame es alto.</li>
</ul>
</div><h1>Persistencia en Spark</h1>
<div class='content'><p>La persistencia es una versión más flexible del caché que te permite especificar el nivel de almacenamiento. El nivel de almacenamiento determina cómo y dónde se almacenan los datos (por ejemplo, en memoria, en disco o ambos).</p>
</div><h2>Niveles de Almacenamiento</h2>
<div class='content'><ul>
<li><strong>MEMORY_ONLY</strong>: Almacena el RDD como objetos Java deserializados en la JVM. Si el RDD no cabe en memoria, algunas particiones no se cachearán y se recomputarán cuando sea necesario.</li>
<li><strong>MEMORY_AND_DISK</strong>: Almacena el RDD como objetos Java deserializados en la JVM. Si el RDD no cabe en memoria, las particiones que no caben se almacenan en disco y se leen desde allí cuando sea necesario.</li>
<li><strong>DISK_ONLY</strong>: Almacena las particiones del RDD solo en disco.</li>
<li><strong>MEMORY_ONLY_SER</strong>: Almacena el RDD como objetos Java serializados (un array de bytes por partición) en la JVM.</li>
<li><strong>MEMORY_AND_DISK_SER</strong>: Similar a MEMORY_ONLY_SER pero derrama las particiones que no caben en memoria al disco.</li>
</ul>
</div><h2>Cómo Persistir Datos</h2>
<div class='content'><p>Puedes persistir un RDD o DataFrame usando el método <code>persist()</code> con un nivel de almacenamiento especificado.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3RvcmFnZS5TdG9yYWdlTGV2ZWwKCnZhbCByZGQgPSBzYy50ZXh0RmlsZSgiaGRmczovL3BhdGgvdG8vZmlsZSIpCnZhbCBwZXJzaXN0ZWRSZGQgPSByZGQucGVyc2lzdChTdG9yYWdlTGV2ZWwuTUVNT1JZX0FORF9ESVNLKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.storage.StorageLevel

val rdd = sc.textFile(&quot;hdfs://path/to/file&quot;)
val persistedRdd = rdd.persist(StorageLevel.MEMORY_AND_DISK)</pre></div><div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTdG9yYWdlTGV2ZWwKCmRmID0gc3BhcmsucmVhZC50ZXh0KCJoZGZzOi8vcGF0aC90by9maWxlIikKcGVyc2lzdGVkRGYgPSBkZi5wZXJzaXN0KFN0b3JhZ2VMZXZlbC5NRU1PUllfQU5EX0RJU0sp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import StorageLevel

df = spark.read.text(&quot;hdfs://path/to/file&quot;)
persistedDf = df.persist(StorageLevel.MEMORY_AND_DISK)</pre></div><div class='content'></div><h2>Comparación de Niveles de Almacenamiento</h2>
<div class='content'><p>| Nivel de Almacenamiento | Uso de Memoria | Uso de Disco | Uso de CPU | Tolerancia a Fallos |
|-------------------------|----------------|--------------|------------|---------------------|
| MEMORY_ONLY             | Alto           | Ninguno      | Bajo       | Bajo                |
| MEMORY_AND_DISK         | Medio          | Medio        | Medio      | Medio               |
| DISK_ONLY               | Ninguno        | Alto         | Alto       | Alto                |
| MEMORY_ONLY_SER         | Bajo           | Ninguno      | Alto       | Bajo                |
| MEMORY_AND_DISK_SER     | Bajo           | Medio        | Alto       | Medio               |</p>
</div><h1>Ejemplos Prácticos</h1>
<h2>Ejemplo 1: Cachear un DataFrame</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMZXllbmRvIHVuIGFyY2hpdm8gQ1NWIGVuIHVuIERhdGFGcmFtZQpkZiA9IHNwYXJrLnJlYWQuY3N2KCJoZGZzOi8vcGF0aC90by9jc3ZmaWxlIiwgaGVhZGVyPVRydWUsIGluZmVyU2NoZW1hPVRydWUpCgojIFJlYWxpemFuZG8gYWxndW5hcyB0cmFuc2Zvcm1hY2lvbmVzCmRmX2ZpbHRlcmVkID0gZGYuZmlsdGVyKGRmWydhZ2UnXSA+IDMwKQoKIyBDYWNoZWFuZG8gZWwgRGF0YUZyYW1lCmRmX2NhY2hlZCA9IGRmX2ZpbHRlcmVkLmNhY2hlKCkKCiMgUmVhbGl6YW5kbyBhY2Npb25lcyBlbiBlbCBEYXRhRnJhbWUgY2FjaGVhZG8KZGZfY2FjaGVkLnNob3coKQpkZl9jYWNoZWQuY291bnQoKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Leyendo un archivo CSV en un DataFrame
df = spark.read.csv(&quot;hdfs://path/to/csvfile&quot;, header=True, inferSchema=True)

# Realizando algunas transformaciones
df_filtered = df.filter(df['age'] &gt; 30)

# Cacheando el DataFrame
df_cached = df_filtered.cache()

# Realizando acciones en el DataFrame cacheado
df_cached.show()
df_cached.count()</pre></div><div class='content'></div><h2>Ejemplo 2: Persistir un RDD</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3RvcmFnZS5TdG9yYWdlTGV2ZWwKCi8vIExleWVuZG8gdW4gYXJjaGl2byBkZSB0ZXh0byBlbiB1biBSREQKdmFsIHJkZCA9IHNjLnRleHRGaWxlKCJoZGZzOi8vcGF0aC90by90ZXh0ZmlsZSIpCgovLyBSZWFsaXphbmRvIGFsZ3VuYXMgdHJhbnNmb3JtYWNpb25lcwp2YWwgcmRkRmlsdGVyZWQgPSByZGQuZmlsdGVyKGxpbmUgPT4gbGluZS5jb250YWlucygiU3BhcmsiKSkKCi8vIFBlcnNpc3RpZW5kbyBlbCBSREQgY29uIGVsIG5pdmVsIGRlIGFsbWFjZW5hbWllbnRvIE1FTU9SWV9BTkRfRElTSwp2YWwgcmRkUGVyc2lzdGVkID0gcmRkRmlsdGVyZWQucGVyc2lzdChTdG9yYWdlTGV2ZWwuTUVNT1JZX0FORF9ESVNLKQoKLy8gUmVhbGl6YW5kbyBhY2Npb25lcyBlbiBlbCBSREQgcGVyc2lzdGlkbwpwcmludGxuKHJkZFBlcnNpc3RlZC5jb3VudCgpKQpyZGRQZXJzaXN0ZWQuY29sbGVjdCgpLmZvcmVhY2gocHJpbnRsbik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.storage.StorageLevel

// Leyendo un archivo de texto en un RDD
val rdd = sc.textFile(&quot;hdfs://path/to/textfile&quot;)

// Realizando algunas transformaciones
val rddFiltered = rdd.filter(line =&gt; line.contains(&quot;Spark&quot;))

// Persistiendo el RDD con el nivel de almacenamiento MEMORY_AND_DISK
val rddPersisted = rddFiltered.persist(StorageLevel.MEMORY_AND_DISK)

// Realizando acciones en el RDD persistido
println(rddPersisted.count())
rddPersisted.collect().foreach(println)</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>El caché y la persistencia son técnicas poderosas en Apache Spark que pueden mejorar significativamente el rendimiento y la eficiencia de tus aplicaciones. Al entender cuándo y cómo usar estas características, puedes optimizar el uso de recursos y mejorar la tolerancia a fallos de tus trabajos en Spark. Recuerda elegir el nivel de almacenamiento apropiado basado en los requisitos de tu aplicación y los recursos disponibles.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
