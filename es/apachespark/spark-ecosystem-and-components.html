<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ecosistema y Componentes de Spark</title>

    <link rel="alternate" href="https://campusempresa.com/es/apachespark/spark-ecosystem-and-components" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/apachespark/spark-ecosystem-and-components" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/apachespark/spark-ecosystem-and-components" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/es/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy<br> y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<b id="lit_lang_es" class="px-2">ES</b>
				|
				<a href="/ca/apachespark/spark-ecosystem-and-components" id="lnk_lang_ca" data-lang="ca" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="objective">El Proyecto</a>
				<a href="about">Sobre nosotros</a>
				<a href="contribute">Contribuir</a>
				<a href="donate">Donaciones</a>
				<a href="licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'><p>Apache Spark es un potente motor de análisis unificado de código abierto diseñado para el procesamiento de datos a gran escala. Proporciona APIs de alto nivel en Java, Scala, Python y R, y un motor optimizado que soporta gráficos de ejecución general. En este tema, exploraremos el ecosistema de Spark y sus componentes clave.</p>
</div><h1>Núcleo de Spark</h1>
<div class='content'><p>El núcleo de Spark es la base del ecosistema de Apache Spark. Proporciona funcionalidades esenciales como la programación de tareas, la gestión de memoria, la recuperación ante fallos y la interacción con sistemas de almacenamiento.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>Conjuntos de Datos Distribuidos Resilientes (RDDs)</strong>: La estructura de datos fundamental de Spark, que es inmutable y se distribuye a través del clúster.</li>
<li><strong>Transformaciones y Acciones</strong>: Operaciones en RDDs. Las transformaciones crean nuevos RDDs, mientras que las acciones calculan un resultado basado en un RDD.</li>
<li><strong>Evaluación Perezosa</strong>: Las transformaciones no se ejecutan inmediatamente, sino que se registran en un gráfico de linaje. Las acciones desencadenan la ejecución.</li>
</ul>
</div><h2>Ejemplo</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCnNjID0gU3BhcmtDb250ZXh0KCJsb2NhbCIsICJTaW1wbGUgQXBwIikKZGF0YSA9IFsxLCAyLCAzLCA0LCA1XQpyZGQgPSBzYy5wYXJhbGxlbGl6ZShkYXRhKQoKIyBUcmFuc2Zvcm1hY2nDs246IG1hcApzcXVhcmVkX3JkZCA9IHJkZC5tYXAobGFtYmRhIHg6IHggKiB4KQoKIyBBY2Npw7NuOiBjb2xsZWN0CnJlc3VsdCA9IHNxdWFyZWRfcmRkLmNvbGxlY3QoKQpwcmludChyZXN1bHQpICAjIE91dHB1dDogWzEsIDQsIDksIDE2LCAyNV0="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

sc = SparkContext(&quot;local&quot;, &quot;Simple App&quot;)
data = [1, 2, 3, 4, 5]
rdd = sc.parallelize(data)

# Transformaci&oacute;n: map
squared_rdd = rdd.map(lambda x: x * x)

# Acci&oacute;n: collect
result = squared_rdd.collect()
print(result)  # Output: [1, 4, 9, 16, 25]</pre></div><div class='content'></div><h1>Spark SQL</h1>
<div class='content'><p>Spark SQL es un módulo para el procesamiento de datos estructurados. Permite consultar datos a través de SQL así como la API de DataFrame.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>DataFrames</strong>: Colecciones distribuidas de datos organizadas en columnas con nombre, similar a una tabla en una base de datos relacional.</li>
<li><strong>Datasets</strong>: Extensión de DataFrames que proporciona seguridad de tipos y una interfaz de programación orientada a objetos.</li>
<li><strong>Catalyst Optimizer</strong>: Un optimizador de consultas extensible utilizado por Spark SQL.</li>
</ul>
</div><h2>Ejemplo</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIlNwYXJrIFNRTCBFeGFtcGxlIikuZ2V0T3JDcmVhdGUoKQpkYXRhID0gWygiQWxpY2UiLCAxKSwgKCJCb2IiLCAyKSwgKCJDYXRoeSIsIDMpXQpjb2x1bW5zID0gWyJOYW1lIiwgIlZhbHVlIl0KCmRmID0gc3BhcmsuY3JlYXRlRGF0YUZyYW1lKGRhdGEsIGNvbHVtbnMpCmRmLnNob3coKQoKIyBDb25zdWx0YSBTUUwKZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCnNxbERGID0gc3Bhcmsuc3FsKCJTRUxFQ1QgKiBGUk9NIHBlb3BsZSBXSEVSRSBWYWx1ZSA+IDEiKQpzcWxERi5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;Spark SQL Example&quot;).getOrCreate()
data = [(&quot;Alice&quot;, 1), (&quot;Bob&quot;, 2), (&quot;Cathy&quot;, 3)]
columns = [&quot;Name&quot;, &quot;Value&quot;]

df = spark.createDataFrame(data, columns)
df.show()

# Consulta SQL
df.createOrReplaceTempView(&quot;people&quot;)
sqlDF = spark.sql(&quot;SELECT * FROM people WHERE Value &gt; 1&quot;)
sqlDF.show()</pre></div><div class='content'></div><h1>Spark Streaming</h1>
<div class='content'><p>Spark Streaming permite el procesamiento de flujos de datos en vivo de manera escalable y tolerante a fallos.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>DStreams (Flujos Discretizados)</strong>: La abstracción básica en Spark Streaming, que representa un flujo continuo de datos.</li>
<li><strong>Operaciones de Ventana</strong>: Operaciones sobre una ventana deslizante de datos.</li>
</ul>
</div><h2>Ejemplo</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKZnJvbSBweXNwYXJrLnN0cmVhbWluZyBpbXBvcnQgU3RyZWFtaW5nQ29udGV4dAoKc2MgPSBTcGFya0NvbnRleHQoImxvY2FsWzJdIiwgIk5ldHdvcmtXb3JkQ291bnQiKQpzc2MgPSBTdHJlYW1pbmdDb250ZXh0KHNjLCAxKQoKbGluZXMgPSBzc2Muc29ja2V0VGV4dFN0cmVhbSgibG9jYWxob3N0IiwgOTk5OSkKd29yZHMgPSBsaW5lcy5mbGF0TWFwKGxhbWJkYSBsaW5lOiBsaW5lLnNwbGl0KCIgIikpCndvcmRDb3VudHMgPSB3b3Jkcy5tYXAobGFtYmRhIHdvcmQ6ICh3b3JkLCAxKSkucmVkdWNlQnlLZXkobGFtYmRhIGEsIGI6IGEgKyBiKQoKd29yZENvdW50cy5wcHJpbnQoKQoKc3NjLnN0YXJ0KCkKc3NjLmF3YWl0VGVybWluYXRpb24oKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext
from pyspark.streaming import StreamingContext

sc = SparkContext(&quot;local[2]&quot;, &quot;NetworkWordCount&quot;)
ssc = StreamingContext(sc, 1)

lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)
words = lines.flatMap(lambda line: line.split(&quot; &quot;))
wordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)

wordCounts.pprint()

ssc.start()
ssc.awaitTermination()</pre></div><div class='content'></div><h1>MLlib (Biblioteca de Aprendizaje Automático)</h1>
<div class='content'><p>MLlib es la biblioteca de aprendizaje automático escalable de Spark, que proporciona varios algoritmos y utilidades.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>Algoritmos</strong>: Clasificación, regresión, agrupamiento, filtrado colaborativo, etc.</li>
<li><strong>Pipelines</strong>: Herramientas para construir, evaluar y ajustar flujos de trabajo de aprendizaje automático.</li>
</ul>
</div><h2>Ejemplo</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmNsYXNzaWZpY2F0aW9uIGltcG9ydCBMb2dpc3RpY1JlZ3Jlc3Npb24KZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIk1MbGliIEV4YW1wbGUiKS5nZXRPckNyZWF0ZSgpCmRhdGEgPSBzcGFyay5yZWFkLmZvcm1hdCgibGlic3ZtIikubG9hZCgic2FtcGxlX2xpYnN2bV9kYXRhLnR4dCIpCgpsciA9IExvZ2lzdGljUmVncmVzc2lvbihtYXhJdGVyPTEwLCByZWdQYXJhbT0wLjMsIGVsYXN0aWNOZXRQYXJhbT0wLjgpCmxyTW9kZWwgPSBsci5maXQoZGF0YSkKCnByaW50KCJDb2VmZmljaWVudHM6ICIgKyBzdHIobHJNb2RlbC5jb2VmZmljaWVudHMpKQpwcmludCgiSW50ZXJjZXB0OiAiICsgc3RyKGxyTW9kZWwuaW50ZXJjZXB0KSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.classification import LogisticRegression
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;MLlib Example&quot;).getOrCreate()
data = spark.read.format(&quot;libsvm&quot;).load(&quot;sample_libsvm_data.txt&quot;)

lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)
lrModel = lr.fit(data)

print(&quot;Coefficients: &quot; + str(lrModel.coefficients))
print(&quot;Intercept: &quot; + str(lrModel.intercept))</pre></div><div class='content'></div><h1>GraphX</h1>
<div class='content'><p>GraphX es la API de Spark para gráficos y computación paralela de gráficos.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>Grafo de Propiedades</strong>: Un multigrafo dirigido con propiedades adjuntas a cada vértice y arista.</li>
<li><strong>API Pregel</strong>: Una API para algoritmos iterativos de gráficos.</li>
</ul>
</div><h2>Ejemplo</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCmZyb20gcHlzcGFyay5ncmFwaHggaW1wb3J0IEdyYXBoCgpzYyA9IFNwYXJrQ29udGV4dCgibG9jYWwiLCAiR3JhcGhYIEV4YW1wbGUiKQp2ZXJ0aWNlcyA9IHNjLnBhcmFsbGVsaXplKFsoMSwgIkFsaWNlIiksICgyLCAiQm9iIiksICgzLCAiQ2F0aHkiKV0pCmVkZ2VzID0gc2MucGFyYWxsZWxpemUoWygxLCAyLCAiZnJpZW5kIiksICgyLCAzLCAiZm9sbG93IildKQoKZ3JhcGggPSBHcmFwaCh2ZXJ0aWNlcywgZWRnZXMpCnByaW50KGdyYXBoLnZlcnRpY2VzLmNvbGxlY3QoKSkKcHJpbnQoZ3JhcGguZWRnZXMuY29sbGVjdCgpKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext
from pyspark.sql import SparkSession
from pyspark.graphx import Graph

sc = SparkContext(&quot;local&quot;, &quot;GraphX Example&quot;)
vertices = sc.parallelize([(1, &quot;Alice&quot;), (2, &quot;Bob&quot;), (3, &quot;Cathy&quot;)])
edges = sc.parallelize([(1, 2, &quot;friend&quot;), (2, 3, &quot;follow&quot;)])

graph = Graph(vertices, edges)
print(graph.vertices.collect())
print(graph.edges.collect())</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>El ecosistema de Apache Spark es vasto y poderoso, proporcionando herramientas para diversas necesidades de procesamiento de datos. Desde las funcionalidades básicas del núcleo de Spark hasta los módulos especializados como Spark SQL, Spark Streaming, MLlib y GraphX, Spark ofrece una suite completa para el análisis de grandes datos. Entender estos componentes y sus interacciones es crucial para aprovechar todo el potencial de Spark en aplicaciones del mundo real.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
