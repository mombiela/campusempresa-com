<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>

	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy<br> y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<b id="lit_lang_es">Castellano</b>
				|
				<a href="https://campusempresa.cat/ia_videojuegos/aprendizaje-por-refuerzo" id="lnk_lang_ca" data-lang="ca">Català</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="objective">El Proyecto</a>
				<a href="about">Sobre nosotros</a>
				<a href="contribute">Contribuir</a>
				<a href="donate">Donaciones</a>
				<a href="licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introducción al Aprendizaje por Refuerzo</h1>
<div class='content'><p>El Aprendizaje por Refuerzo (Reinforcement Learning, RL) es una técnica de aprendizaje automático donde un agente aprende a tomar decisiones mediante la interacción con un entorno. En el contexto de los videojuegos, el agente puede ser un personaje o una entidad que aprende a jugar o mejorar su desempeño en el juego.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>Agente</strong>: La entidad que toma decisiones en el entorno.</li>
<li><strong>Entorno</strong>: El mundo con el que interactúa el agente.</li>
<li><strong>Estado</strong>: Una representación del entorno en un momento dado.</li>
<li><strong>Acción</strong>: Una decisión o movimiento que el agente puede tomar.</li>
<li><strong>Recompensa</strong>: Retroalimentación recibida por el agente después de realizar una acción.</li>
<li><strong>Política</strong>: Estrategia que el agente sigue para decidir qué acciones tomar.</li>
<li><strong>Función de Valor</strong>: Estima la recompensa futura que se puede obtener desde un estado específico.</li>
<li><strong>Q-Learning</strong>: Un algoritmo de RL que busca aprender la función de valor de acción.</li>
</ul>
</div><h1>Funcionamiento del Aprendizaje por Refuerzo</h1>
<div class='content'><p>El proceso de RL se puede describir en los siguientes pasos:</p>
<ol>
<li><strong>Inicialización</strong>: El agente comienza en un estado inicial del entorno.</li>
<li><strong>Selección de Acción</strong>: El agente selecciona una acción basada en su política actual.</li>
<li><strong>Transición de Estado</strong>: El entorno responde a la acción y transita a un nuevo estado.</li>
<li><strong>Recompensa</strong>: El agente recibe una recompensa basada en la acción tomada.</li>
<li><strong>Actualización</strong>: El agente actualiza su política y función de valor basándose en la recompensa recibida.</li>
</ol>
</div><h1>Algoritmos de Aprendizaje por Refuerzo</h1>
<div class='content'></div><h2>Q-Learning</h2>
<div class='content'><p>Q-Learning es uno de los algoritmos más populares en RL. Se basa en aprender una función de valor de acción \( Q(s, a) \) que estima la recompensa esperada de tomar una acción \( a \) en un estado \( s \).</p>
<h4>Fórmula de Actualización de Q-Learning</h4>
<p>\[ Q(s, a) \leftarrow Q(s, a) + \alpha \left[ r + \gamma \max_{a'} Q(s', a') - Q(s, a) \right] \]</p>
<ul>
<li>\( \alpha \): Tasa de aprendizaje.</li>
<li>\( \gamma \): Factor de descuento.</li>
<li>\( r \): Recompensa recibida.</li>
<li>\( s' \): Nuevo estado después de tomar la acción \( a \).</li>
</ul>
<h4>Ejemplo de Código en Python</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIFBhcsOhbWV0cm9zIGRlbCBlbnRvcm5vCnN0YXRlcyA9IFsiQSIsICJCIiwgIkMiLCAiRCJdCmFjdGlvbnMgPSBbImxlZnQiLCAicmlnaHQiXQpRID0gbnAuemVyb3MoKGxlbihzdGF0ZXMpLCBsZW4oYWN0aW9ucykpKSAgIyBJbmljaWFsaXphY2nDs24gZGUgbGEgdGFibGEgUQphbHBoYSA9IDAuMSAgIyBUYXNhIGRlIGFwcmVuZGl6YWplCmdhbW1hID0gMC45ICAjIEZhY3RvciBkZSBkZXNjdWVudG8KCiMgRnVuY2nDs24gZGUgcmVjb21wZW5zYSAoZWplbXBsbyBzaW1wbGlmaWNhZG8pCmRlZiByZXdhcmQoc3RhdGUsIGFjdGlvbik6CiAgICBpZiBzdGF0ZSA9PSAiQSIgYW5kIGFjdGlvbiA9PSAicmlnaHQiOgogICAgICAgIHJldHVybiAxCiAgICBlbHNlOgogICAgICAgIHJldHVybiAwCgojIFNpbXVsYWNpw7NuIGRlIHVuIHBhc28gZW4gZWwgZW50b3JubwpkZWYgc3RlcChzdGF0ZSwgYWN0aW9uKToKICAgIGlmIHN0YXRlID09ICJBIiBhbmQgYWN0aW9uID09ICJyaWdodCI6CiAgICAgICAgcmV0dXJuICJCIiwgcmV3YXJkKHN0YXRlLCBhY3Rpb24pCiAgICBlbHNlOgogICAgICAgIHJldHVybiBzdGF0ZSwgcmV3YXJkKHN0YXRlLCBhY3Rpb24pCgojIEVudHJlbmFtaWVudG8gZGVsIGFnZW50ZQpmb3IgZXBpc29kZSBpbiByYW5nZSgxMDAwKToKICAgIHN0YXRlID0gIkEiCiAgICB3aGlsZSBzdGF0ZSAhPSAiQiI6CiAgICAgICAgYWN0aW9uID0gbnAucmFuZG9tLmNob2ljZShhY3Rpb25zKQogICAgICAgIG5leHRfc3RhdGUsIHIgPSBzdGVwKHN0YXRlLCBhY3Rpb24pCiAgICAgICAgYWN0aW9uX2luZGV4ID0gYWN0aW9ucy5pbmRleChhY3Rpb24pCiAgICAgICAgc3RhdGVfaW5kZXggPSBzdGF0ZXMuaW5kZXgoc3RhdGUpCiAgICAgICAgbmV4dF9zdGF0ZV9pbmRleCA9IHN0YXRlcy5pbmRleChuZXh0X3N0YXRlKQogICAgICAgIFFbc3RhdGVfaW5kZXgsIGFjdGlvbl9pbmRleF0gKz0gYWxwaGEgKiAociArIGdhbW1hICogbnAubWF4KFFbbmV4dF9zdGF0ZV9pbmRleF0pIC0gUVtzdGF0ZV9pbmRleCwgYWN0aW9uX2luZGV4XSkKICAgICAgICBzdGF0ZSA9IG5leHRfc3RhdGUKCnByaW50KCJUYWJsYSBRIGZpbmFsOiIpCnByaW50KFEp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Par&aacute;metros del entorno
states = [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;]
actions = [&quot;left&quot;, &quot;right&quot;]
Q = np.zeros((len(states), len(actions)))  # Inicializaci&oacute;n de la tabla Q
alpha = 0.1  # Tasa de aprendizaje
gamma = 0.9  # Factor de descuento

# Funci&oacute;n de recompensa (ejemplo simplificado)
def reward(state, action):
    if state == &quot;A&quot; and action == &quot;right&quot;:
        return 1
    else:
        return 0

# Simulaci&oacute;n de un paso en el entorno
def step(state, action):
    if state == &quot;A&quot; and action == &quot;right&quot;:
        return &quot;B&quot;, reward(state, action)
    else:
        return state, reward(state, action)

# Entrenamiento del agente
for episode in range(1000):
    state = &quot;A&quot;
    while state != &quot;B&quot;:
        action = np.random.choice(actions)
        next_state, r = step(state, action)
        action_index = actions.index(action)
        state_index = states.index(state)
        next_state_index = states.index(next_state)
        Q[state_index, action_index] += alpha * (r + gamma * np.max(Q[next_state_index]) - Q[state_index, action_index])
        state = next_state

print(&quot;Tabla Q final:&quot;)
print(Q)</pre></div><div class='content'></div><h1>Aplicaciones en Videojuegos</h1>
<div class='content'><p>El RL se puede aplicar en videojuegos para:</p>
<ul>
<li><strong>Entrenamiento de NPCs (Non-Player Characters)</strong>: Los NPCs pueden aprender a comportarse de manera más realista y adaptativa.</li>
<li><strong>Optimización de Estrategias</strong>: Los agentes pueden aprender estrategias óptimas para juegos de estrategia.</li>
<li><strong>Generación de Contenidos</strong>: Creación de niveles o desafíos adaptativos basados en el desempeño del jugador.</li>
</ul>
</div><h1>Conclusión</h1>
<div class='content'><p>El Aprendizaje por Refuerzo es una técnica poderosa para desarrollar agentes inteligentes en videojuegos. Al comprender y aplicar conceptos como estados, acciones, recompensas y políticas, los desarrolladores pueden crear experiencias de juego más inmersivas y desafiantes. El algoritmo Q-Learning es un buen punto de partida para aquellos que desean implementar RL en sus proyectos de videojuegos.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
       <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
       <a href="cookies">Més informació</a>
   </div>	
	</div>    
</body>
</html>
