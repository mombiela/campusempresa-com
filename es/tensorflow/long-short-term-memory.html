<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Memoria a Largo Corto Plazo (LSTM)</title>

    <link rel="alternate" href="https://campusempresa.com/es/tensorflow/long-short-term-memory" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/tensorflow/long-short-term-memory" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/tensorflow/long-short-term-memory" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/es/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<b id="lit_lang_es" class="px-2">ES</b>
				|
				<a href="/ca/tensorflow/long-short-term-memory" id="lnk_lang_ca" data-lang="ca" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/es/objective">El Proyecto</a>
				<a href="/es/about">Sobre nosotros</a>
				<a href="/es/contribute">Contribuir</a>
				<a href="/es/donate">Donaciones</a>
				<a href="/es/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'><div class='col-6'><a href='building-an-rnn'>&#x25C4; Construyendo una RNN</a></div><div class='col-6 text-end'><a href='gated-recurrent-units'>Unidades Recurrentes con Puerta (GRUs) &#x25BA;</a></div></div><div class='content'></div><h1>Introducción a LSTM</h1>
<div class='content'><p>Las redes de Memoria a Largo Corto Plazo (LSTM) son un tipo de red neuronal recurrente (RNN) capaz de aprender dependencias a largo plazo. Son particularmente útiles para tareas donde el contexto sobre largas secuencias es importante, como la predicción de series temporales, el procesamiento del lenguaje natural y el reconocimiento de voz.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>Redes Neuronales Recurrentes (RNNs):</strong> Redes con bucles que permiten que la información persista.</li>
<li><strong>Dependencias a Largo Plazo:</strong> La capacidad de recordar información durante largos períodos.</li>
<li><strong>Células LSTM:</strong> Unidades especiales en redes LSTM diseñadas para evitar el problema de dependencia a largo plazo.</li>
</ul>
</div><h1>Entendiendo la Arquitectura LSTM</h1>
<div class='content'><p>Las redes LSTM están compuestas por células LSTM, cada una contiene tres componentes principales: la puerta de olvido, la puerta de entrada y la puerta de salida.</p>
</div><h2>Componentes de la Célula LSTM</h2>
<div class='content'><ul>
<li><strong>Puerta de Olvido:</strong> Decide qué información descartar del estado de la célula.</li>
<li><strong>Puerta de Entrada:</strong> Decide qué valores del input actualizarán el estado de la célula.</li>
<li><strong>Puerta de Salida:</strong> Decide qué parte del estado de la célula se va a emitir.</li>
</ul>
</div><h2>Diagrama de la Célula LSTM</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("W0lucHV0XSAtLT4gW0ZvcmdldCBHYXRlXSAtLT4gW0NlbGwgU3RhdGVdIC0tPiBbT3V0cHV0IEdhdGVdIC0tPiBbT3V0cHV0XQogICAgICAgICAgIFtJbnB1dCBHYXRlXSAtLT4gW0NlbGwgU3RhdGVd"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>[Input] --&gt; [Forget Gate] --&gt; [Cell State] --&gt; [Output Gate] --&gt; [Output]
           [Input Gate] --&gt; [Cell State]</pre></div><div class='content'></div><h1>Implementando LSTM en TensorFlow</h1>
<div class='content'><p>Vamos a implementar una red LSTM simple usando TensorFlow para predecir una secuencia.</p>
</div><h2>Implementación Paso a Paso</h2>
<div class='content'><h4>Paso 1: Importar Librerías</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBMU1RNLCBEZW5zZQppbXBvcnQgbnVtcHkgYXMgbnA="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import numpy as np</pre></div><div class='content'><h4>Paso 2: Preparar Datos</h4>
<p>Para simplificar, usaremos una onda sinusoidal como nuestro conjunto de datos.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBHZW5lcmFyIHVuYSBvbmRhIHNpbnVzb2lkYWwKdGltZV9zdGVwcyA9IG5wLmxpbnNwYWNlKDAsIDEwMCwgMTAwMCkKZGF0YSA9IG5wLnNpbih0aW1lX3N0ZXBzKQoKIyBQcmVwYXJhciBlbCBjb25qdW50byBkZSBkYXRvcwpkZWYgY3JlYXRlX2RhdGFzZXQoZGF0YSwgdGltZV9zdGVwPTEwKToKICAgIFgsIHkgPSBbXSwgW10KICAgIGZvciBpIGluIHJhbmdlKGxlbihkYXRhKSAtIHRpbWVfc3RlcCAtIDEpOgogICAgICAgIFguYXBwZW5kKGRhdGFbaTooaSArIHRpbWVfc3RlcCldKQogICAgICAgIHkuYXBwZW5kKGRhdGFbaSArIHRpbWVfc3RlcF0pCiAgICByZXR1cm4gbnAuYXJyYXkoWCksIG5wLmFycmF5KHkpCgp0aW1lX3N0ZXAgPSAxMApYLCB5ID0gY3JlYXRlX2RhdGFzZXQoZGF0YSwgdGltZV9zdGVwKQpYID0gWC5yZXNoYXBlKFguc2hhcGVbMF0sIFguc2hhcGVbMV0sIDEp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Generar una onda sinusoidal
time_steps = np.linspace(0, 100, 1000)
data = np.sin(time_steps)

# Preparar el conjunto de datos
def create_dataset(data, time_step=10):
    X, y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step)])
        y.append(data[i + time_step])
    return np.array(X), np.array(y)

time_step = 10
X, y = create_dataset(data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)</pre></div><div class='content'><h4>Paso 3: Construir el Modelo LSTM</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("bW9kZWwgPSBTZXF1ZW50aWFsKCkKbW9kZWwuYWRkKExTVE0oNTAsIHJldHVybl9zZXF1ZW5jZXM9VHJ1ZSwgaW5wdXRfc2hhcGU9KHRpbWVfc3RlcCwgMSkpKQptb2RlbC5hZGQoTFNUTSg1MCwgcmV0dXJuX3NlcXVlbmNlcz1GYWxzZSkpCm1vZGVsLmFkZChEZW5zZSgxKSkKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdtZWFuX3NxdWFyZWRfZXJyb3InKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')</pre></div><div class='content'><h4>Paso 4: Entrenar el Modelo</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("bW9kZWwuZml0KFgsIHksIGVwb2Nocz0yMCwgYmF0Y2hfc2l6ZT0zMiwgdmVyYm9zZT0xKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>model.fit(X, y, epochs=20, batch_size=32, verbose=1)</pre></div><div class='content'><h4>Paso 5: Hacer Predicciones</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("cHJlZGljdGlvbnMgPSBtb2RlbC5wcmVkaWN0KFgp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>predictions = model.predict(X)</pre></div><div class='content'></div><h2>Explicación del Código</h2>
<div class='content'><ul>
<li><strong>Modelo Secuencial:</strong> Una pila lineal de capas.</li>
<li><strong>Capas LSTM:</strong> Dos capas LSTM con 50 unidades cada una. La primera capa LSTM devuelve secuencias para alimentar a la siguiente capa LSTM.</li>
<li><strong>Capa Densa:</strong> Una capa completamente conectada para producir la salida final.</li>
<li><strong>Compilar:</strong> Usando el optimizador 'adam' y la función de pérdida 'mean_squared_error'.</li>
<li><strong>Fit:</strong> Entrenando el modelo durante 20 épocas con un tamaño de lote de 32.</li>
</ul>
</div><h1>Técnicas Avanzadas de LSTM</h1>
<h2>LSTM Bidireccional</h2>
<div class='content'><p>Las LSTM bidireccionales entrenan dos LSTM en la secuencia de entrada, una en la dirección hacia adelante y otra en la dirección hacia atrás, mejorando el rendimiento en ciertas tareas.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgQmlkaXJlY3Rpb25hbAoKbW9kZWwgPSBTZXF1ZW50aWFsKCkKbW9kZWwuYWRkKEJpZGlyZWN0aW9uYWwoTFNUTSg1MCwgcmV0dXJuX3NlcXVlbmNlcz1UcnVlKSwgaW5wdXRfc2hhcGU9KHRpbWVfc3RlcCwgMSkpKQptb2RlbC5hZGQoQmlkaXJlY3Rpb25hbChMU1RNKDUwLCByZXR1cm5fc2VxdWVuY2VzPUZhbHNlKSkpCm1vZGVsLmFkZChEZW5zZSgxKSkKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdtZWFuX3NxdWFyZWRfZXJyb3InKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Bidirectional

model = Sequential()
model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(time_step, 1)))
model.add(Bidirectional(LSTM(50, return_sequences=False)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')</pre></div><div class='content'></div><h2>LSTM con Dropout</h2>
<div class='content'><p>Dropout es una técnica de regularización para prevenir el sobreajuste.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgRHJvcG91dAoKbW9kZWwgPSBTZXF1ZW50aWFsKCkKbW9kZWwuYWRkKExTVE0oNTAsIHJldHVybl9zZXF1ZW5jZXM9VHJ1ZSwgaW5wdXRfc2hhcGU9KHRpbWVfc3RlcCwgMSkpKQptb2RlbC5hZGQoRHJvcG91dCgwLjIpKQptb2RlbC5hZGQoTFNUTSg1MCwgcmV0dXJuX3NlcXVlbmNlcz1GYWxzZSkpCm1vZGVsLmFkZChEcm9wb3V0KDAuMikpCm1vZGVsLmFkZChEZW5zZSgxKSkKbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdtZWFuX3NxdWFyZWRfZXJyb3InKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Dropout

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(Dropout(0.2))
model.add(LSTM(50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>Las redes LSTM son herramientas poderosas para tareas de predicción de secuencias. Entender su arquitectura y cómo implementarlas en TensorFlow es crucial para aprovechar sus capacidades. Al dominar técnicas básicas y avanzadas, puedes aplicar LSTM a una amplia gama de problemas, desde predicciones simples de series temporales hasta tareas complejas de procesamiento del lenguaje natural.</p>
</div><div class='row navigation'><div class='col-6'><a href='building-an-rnn'>&#x25C4; Construyendo una RNN</a></div><div class='col-6 text-end'><a href='gated-recurrent-units'>Unidades Recurrentes con Puerta (GRUs) &#x25BA;</a></div></div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="/es/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
