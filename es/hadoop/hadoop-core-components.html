<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Componentes Principales de Hadoop</title>

    <link rel="alternate" href="https://campusempresa.com/es/hadoop/hadoop-core-components" hreflang="es" />
    <link rel="alternate" href="https://campusempresa.com/es/hadoop/hadoop-core-components" hreflang="x-default" />
	<link rel="alternate" href="https://campusempresa.com/ca/hadoop/hadoop-core-components" hreflang="ca" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/es/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy<br> y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<b id="lit_lang_es" class="px-2">ES</b>
				|
				<a href="/ca/hadoop/hadoop-core-components" id="lnk_lang_ca" data-lang="ca" class="px-2">CA</a>
					</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="objective">El Proyecto</a>
				<a href="about">Sobre nosotros</a>
				<a href="contribute">Contribuir</a>
				<a href="donate">Donaciones</a>
				<a href="licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='content'></div><h1>Introducción</h1>
<div class='content'><p>Hadoop es un marco de trabajo de código abierto que permite el procesamiento distribuido de grandes conjuntos de datos a través de clústeres de computadoras utilizando modelos de programación simples. Está diseñado para escalar desde servidores individuales hasta miles de máquinas, cada una ofreciendo computación y almacenamiento locales. Esta sección cubrirá los componentes principales de Hadoop, que son esenciales para entender cómo opera Hadoop y cómo usarlo efectivamente.</p>
</div><h1>Componentes Principales de Hadoop</h1>
<div class='content'></div><h2>1. Sistema de Archivos Distribuido de Hadoop (HDFS)</h2>
<div class='content'><p>HDFS es el sistema de almacenamiento primario utilizado por las aplicaciones de Hadoop. Proporciona acceso de alto rendimiento a los datos de la aplicación y está diseñado para ser altamente tolerante a fallos.</p>
<ul>
<li>
<p><strong>Conceptos Clave:</strong></p>
<ul>
<li><strong>Bloques:</strong> HDFS almacena cada archivo como una serie de bloques. Cada bloque es típicamente de 128 MB por defecto.</li>
<li><strong>Namenode:</strong> El servidor maestro que gestiona el espacio de nombres del sistema de archivos y controla el acceso a los archivos por parte de los clientes.</li>
<li><strong>Datanodes:</strong> Estos son los nodos de trabajo que almacenan y recuperan bloques cuando se les indica (por el Namenode).</li>
</ul>
</li>
<li>
<p><strong>Ejemplo:</strong></p>
<pre><code class="language-shell"># Listar archivos en HDFS
hdfs dfs -ls /

# Subir un archivo a HDFS
hdfs dfs -put localfile.txt /hdfs/directory/

# Leer un archivo desde HDFS
hdfs dfs -cat /hdfs/directory/localfile.txt
</code></pre>
</li>
</ul>
</div><h2>2. MapReduce</h2>
<div class='content'><p>MapReduce es un modelo de programación y una implementación asociada para procesar y generar grandes conjuntos de datos con un algoritmo paralelo y distribuido en un clúster.</p>
<ul>
<li>
<p><strong>Conceptos Clave:</strong></p>
<ul>
<li><strong>Función Map:</strong> Procesa pares clave/valor de entrada para generar un conjunto de pares clave/valor intermedios.</li>
<li><strong>Función Reduce:</strong> Fusiona todos los valores intermedios asociados con la misma clave intermedia.</li>
</ul>
</li>
<li>
<p><strong>Ejemplo:</strong></p>
<pre><code class="language-java">public class WordCount {
    public static class TokenizerMapper
         extends Mapper&lt;Object, Text, Text, IntWritable&gt;{
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context
                        ) throws IOException, InterruptedException {
            StringTokenizer itr = new StringTokenizer(value.toString());
            while (itr.hasMoreTokens()) {
                word.set(itr.nextToken());
                context.write(word, one);
            }
        }
    }

    public static class IntSumReducer
         extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {
        private IntWritable result = new IntWritable();

        public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
                           Context context
                           ) throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            result.set(sum);
            context.write(key, result);
        }
    }
}
</code></pre>
</li>
</ul>
</div><h2>3. YARN (Yet Another Resource Negotiator)</h2>
<div class='content'><p>YARN es el sistema de gestión de recursos de clúster de Hadoop. Permite que múltiples motores de procesamiento de datos, como SQL interactivo, transmisión en tiempo real, ciencia de datos y procesamiento por lotes, se ejecuten y procesen datos almacenados en HDFS.</p>
<ul>
<li>
<p><strong>Conceptos Clave:</strong></p>
<ul>
<li><strong>ResourceManager:</strong> El maestro que arbitra todos los recursos disponibles del clúster.</li>
<li><strong>NodeManager:</strong> El agente de marco por máquina responsable de los contenedores, monitoreando su uso de recursos (CPU, memoria, disco, red) y reportando lo mismo al ResourceManager.</li>
<li><strong>ApplicationMaster:</strong> Gestiona el ciclo de vida de las aplicaciones que se ejecutan en YARN.</li>
</ul>
</li>
<li>
<p><strong>Ejemplo:</strong></p>
<pre><code class="language-shell"># Verificar el estado de YARN
yarn application -list

# Matar una aplicación de YARN
yarn application -kill application_1234567890123_0001
</code></pre>
</li>
</ul>
</div><h2>4. Hadoop Common</h2>
<div class='content'><p>Hadoop Common contiene bibliotecas y utilidades necesarias por otros módulos de Hadoop. Estas bibliotecas proporcionan abstracciones de sistema de archivos y nivel de sistema operativo y contienen los archivos Java y scripts necesarios para iniciar Hadoop.</p>
<ul>
<li>
<p><strong>Conceptos Clave:</strong></p>
<ul>
<li><strong>Configuración:</strong> Proporciona una manera de configurar los diversos parámetros de Hadoop.</li>
<li><strong>Serialización:</strong> Mecanismo para convertir estructuras de datos o el estado de un objeto en un formato que puede ser almacenado o transmitido y reconstruido más tarde.</li>
</ul>
</li>
<li>
<p><strong>Ejemplo:</strong></p>
<pre><code class="language-java">Configuration conf = new Configuration();
conf.set(&quot;fs.defaultFS&quot;, &quot;hdfs://namenode:8020&quot;);
FileSystem fs = FileSystem.get(conf);
</code></pre>
</li>
</ul>
</div><h1>Conclusión</h1>
<div class='content'><p>Entender los componentes principales de Hadoop es crucial para utilizar efectivamente el marco de trabajo para el procesamiento de grandes datos. HDFS proporciona la capa de almacenamiento, MapReduce ofrece el modelo de procesamiento, YARN gestiona los recursos, y Hadoop Common incluye utilidades esenciales. Juntos, estos componentes forman la columna vertebral del ecosistema Hadoop, permitiendo un procesamiento de datos escalable y eficiente en entornos distribuidos.</p>
</div></div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Entès!</a>
    <a href="cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
