<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algoritmos de Clustering</title>

    <link rel="alternate" href="https://campusempresa.com/mod/algoritmos_avanzados/05-05-algoritmos-clustering" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/algoritmos_avanzados/05-05-algoritmes-clustering" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/algoritmos_avanzados/05-05-clustering-algorithms" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/algoritmos_avanzados/05-05-algoritmos-clustering" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/algoritmos_avanzados/05-05-algoritmos-clustering" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-04-redes-neuronales' title="Redes Neuronales y Deep Learning">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Algoritmos de Clustering</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='06-01-optimizacion-industria' title="Optimización en la Industria">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción</h1>
<div class='content'><p>El clustering es una técnica de aprendizaje no supervisado que agrupa un conjunto de objetos de tal manera que los objetos en el mismo grupo (o clúster) son más similares entre sí que a los objetos de otros grupos. Esta técnica es ampliamente utilizada en minería de datos, reconocimiento de patrones y análisis de datos.</p>
</div><h2>Objetivos del Tema</h2>
<div class='content'><ul>
<li>Comprender los conceptos básicos del clustering.</li>
<li>Conocer los algoritmos de clustering más comunes.</li>
<li>Aplicar algoritmos de clustering a conjuntos de datos reales.</li>
<li>Evaluar la calidad de los clústeres obtenidos.</li>
</ul>
</div><h1>Conceptos Básicos</h1>
<div class='content'></div><h2>Definiciones Clave</h2>
<div class='content'><ul>
<li><strong>Clúster</strong>: Un grupo de datos que son similares entre sí.</li>
<li><strong>Centroid</strong>: El centro de un clúster.</li>
<li><strong>Distancia</strong>: Una medida de similitud o disimilitud entre dos puntos de datos.</li>
</ul>
</div><h2>Tipos de Clustering</h2>
<div class='content'><ul>
<li><strong>Particional</strong>: Divide los datos en k clústeres no solapados.</li>
<li><strong>Jerárquico</strong>: Crea una jerarquía de clústeres.</li>
<li><strong>Densidad</strong>: Agrupa puntos que están densamente conectados.</li>
<li><strong>Basado en Modelos</strong>: Asume que los datos son generados por una mezcla de distribuciones probabilísticas.</li>
</ul>
</div><h1>Algoritmos de Clustering</h1>
<div class='content'></div><h2>K-means</h2>
<div class='content'><h4>Descripción</h4>
<p>K-means es uno de los algoritmos de clustering más simples y populares. Divide los datos en k clústeres, donde cada clúster está representado por el centroide de los puntos de datos en el clúster.</p>
<h4>Pasos del Algoritmo</h4>
<ol>
<li>Seleccionar k puntos como centroides iniciales.</li>
<li>Asignar cada punto de datos al clúster cuyo centroide esté más cercano.</li>
<li>Recalcular los centroides como el promedio de los puntos de datos en cada clúster.</li>
<li>Repetir los pasos 2 y 3 hasta que los centroides no cambien significativamente.</li>
</ol>
<h4>Ejemplo en Python</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmNsdXN0ZXIgaW1wb3J0IEtNZWFucwppbXBvcnQgbnVtcHkgYXMgbnAKCiMgRGF0b3MgZGUgZWplbXBsbwpYID0gbnAuYXJyYXkoW1sxLCAyXSwgWzEsIDRdLCBbMSwgMF0sCiAgICAgICAgICAgICAgWzEwLCAyXSwgWzEwLCA0XSwgWzEwLCAwXV0pCgojIENyZWFyIGVsIG1vZGVsbyBLLW1lYW5zCmttZWFucyA9IEtNZWFucyhuX2NsdXN0ZXJzPTIsIHJhbmRvbV9zdGF0ZT0wKS5maXQoWCkKCiMgUHJlZGVjaXIgbG9zIGNsw7pzdGVyZXMKbGFiZWxzID0ga21lYW5zLmxhYmVsc18KCiMgT2J0ZW5lciBsb3MgY2VudHJvaWRlcwpjZW50cm9pZHMgPSBrbWVhbnMuY2x1c3Rlcl9jZW50ZXJzXwoKcHJpbnQoIkxhYmVsczoiLCBsYWJlbHMpCnByaW50KCJDZW50cm9pZHM6IiwgY2VudHJvaWRzKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.cluster import KMeans
import numpy as np

# Datos de ejemplo
X = np.array([[1, 2], [1, 4], [1, 0],
              [10, 2], [10, 4], [10, 0]])

# Crear el modelo K-means
kmeans = KMeans(n_clusters=2, random_state=0).fit(X)

# Predecir los cl&uacute;steres
labels = kmeans.labels_

# Obtener los centroides
centroids = kmeans.cluster_centers_

print(&quot;Labels:&quot;, labels)
print(&quot;Centroids:&quot;, centroids)</pre></div><div class='content'><h4>Ejercicio Práctico</h4>
<p><strong>Ejercicio</strong>: Utiliza el algoritmo K-means para agrupar el conjunto de datos <code>iris</code> de sklearn en 3 clústeres. Visualiza los resultados utilizando un gráfico de dispersión.</p>
<p><strong>Solución</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2lyaXMKaW1wb3J0IG1hdHBsb3RsaWIucHlwbG90IGFzIHBsdAoKIyBDYXJnYXIgZWwgY29uanVudG8gZGUgZGF0b3MgaXJpcwppcmlzID0gbG9hZF9pcmlzKCkKWCA9IGlyaXMuZGF0YQoKIyBBcGxpY2FyIEstbWVhbnMKa21lYW5zID0gS01lYW5zKG5fY2x1c3RlcnM9MywgcmFuZG9tX3N0YXRlPTApLmZpdChYKQpsYWJlbHMgPSBrbWVhbnMubGFiZWxzXwoKIyBWaXN1YWxpemFyIGxvcyByZXN1bHRhZG9zCnBsdC5zY2F0dGVyKFhbOiwgMF0sIFhbOiwgMV0sIGM9bGFiZWxzLCBjbWFwPSd2aXJpZGlzJykKcGx0LnhsYWJlbCgnU2VwYWwgbGVuZ3RoJykKcGx0LnlsYWJlbCgnU2VwYWwgd2lkdGgnKQpwbHQudGl0bGUoJ0stbWVhbnMgQ2x1c3RlcmluZyBvbiBJcmlzIERhdGFzZXQnKQpwbHQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.datasets import load_iris
import matplotlib.pyplot as plt

# Cargar el conjunto de datos iris
iris = load_iris()
X = iris.data

# Aplicar K-means
kmeans = KMeans(n_clusters=3, random_state=0).fit(X)
labels = kmeans.labels_

# Visualizar los resultados
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.xlabel('Sepal length')
plt.ylabel('Sepal width')
plt.title('K-means Clustering on Iris Dataset')
plt.show()</pre></div><div class='content'></div><h2>DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</h2>
<div class='content'><h4>Descripción</h4>
<p>DBSCAN es un algoritmo de clustering basado en densidad que puede encontrar clústeres de forma arbitraria y manejar ruido (puntos de datos que no pertenecen a ningún clúster).</p>
<h4>Pasos del Algoritmo</h4>
<ol>
<li>Para cada punto de datos, encontrar los puntos en su vecindad (dentro de un radio ε).</li>
<li>Si un punto tiene al menos <code>min_samples</code> puntos en su vecindad, se considera un punto central y se forma un clúster.</li>
<li>Expandir el clúster a todos los puntos densamente conectados.</li>
<li>Repetir hasta que todos los puntos estén asignados a un clúster o marcados como ruido.</li>
</ol>
<h4>Ejemplo en Python</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmNsdXN0ZXIgaW1wb3J0IERCU0NBTgoKIyBEYXRvcyBkZSBlamVtcGxvClggPSBucC5hcnJheShbWzEsIDJdLCBbMiwgMl0sIFsyLCAzXSwKICAgICAgICAgICAgICBbOCwgN10sIFs4LCA4XSwgWzI1LCA4MF1dKQoKIyBDcmVhciBlbCBtb2RlbG8gREJTQ0FOCmRiID0gREJTQ0FOKGVwcz0zLCBtaW5fc2FtcGxlcz0yKS5maXQoWCkKCiMgUHJlZGVjaXIgbG9zIGNsw7pzdGVyZXMKbGFiZWxzID0gZGIubGFiZWxzXwoKcHJpbnQoIkxhYmVsczoiLCBsYWJlbHMp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.cluster import DBSCAN

# Datos de ejemplo
X = np.array([[1, 2], [2, 2], [2, 3],
              [8, 7], [8, 8], [25, 80]])

# Crear el modelo DBSCAN
db = DBSCAN(eps=3, min_samples=2).fit(X)

# Predecir los cl&uacute;steres
labels = db.labels_

print(&quot;Labels:&quot;, labels)</pre></div><div class='content'><h4>Ejercicio Práctico</h4>
<p><strong>Ejercicio</strong>: Utiliza el algoritmo DBSCAN para agrupar el conjunto de datos <code>make_moons</code> de sklearn. Visualiza los resultados utilizando un gráfico de dispersión.</p>
<p><strong>Solución</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBtYWtlX21vb25zCgojIEdlbmVyYXIgZGF0b3MgZGUgZWplbXBsbwpYLCBfID0gbWFrZV9tb29ucyhuX3NhbXBsZXM9MzAwLCBub2lzZT0wLjA1KQoKIyBBcGxpY2FyIERCU0NBTgpkYiA9IERCU0NBTihlcHM9MC4yLCBtaW5fc2FtcGxlcz01KS5maXQoWCkKbGFiZWxzID0gZGIubGFiZWxzXwoKIyBWaXN1YWxpemFyIGxvcyByZXN1bHRhZG9zCnBsdC5zY2F0dGVyKFhbOiwgMF0sIFhbOiwgMV0sIGM9bGFiZWxzLCBjbWFwPSd2aXJpZGlzJykKcGx0LnhsYWJlbCgnRmVhdHVyZSAxJykKcGx0LnlsYWJlbCgnRmVhdHVyZSAyJykKcGx0LnRpdGxlKCdEQlNDQU4gQ2x1c3RlcmluZyBvbiBtYWtlX21vb25zIERhdGFzZXQnKQpwbHQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.datasets import make_moons

# Generar datos de ejemplo
X, _ = make_moons(n_samples=300, noise=0.05)

# Aplicar DBSCAN
db = DBSCAN(eps=0.2, min_samples=5).fit(X)
labels = db.labels_

# Visualizar los resultados
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('DBSCAN Clustering on make_moons Dataset')
plt.show()</pre></div><div class='content'></div><h2>Evaluación de Clustering</h2>
<div class='content'><h4>Métricas de Evaluación</h4>
<ul>
<li><strong>Índice de Silueta</strong>: Mide la coherencia de los clústeres.</li>
<li><strong>Coeficiente de Dunn</strong>: Mide la compacidad y separación de los clústeres.</li>
<li><strong>Homogeneidad y Completitud</strong>: Miden la pureza de los clústeres.</li>
</ul>
<h4>Ejemplo de Evaluación</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1ldHJpY3MgaW1wb3J0IHNpbGhvdWV0dGVfc2NvcmUKCiMgQ2FsY3VsYXIgZWwgw61uZGljZSBkZSBzaWx1ZXRhIHBhcmEgSy1tZWFucwpzaWxob3VldHRlX2F2ZyA9IHNpbGhvdWV0dGVfc2NvcmUoWCwgbGFiZWxzKQpwcmludCgiU2lsaG91ZXR0ZSBTY29yZSBmb3IgSy1tZWFuczoiLCBzaWxob3VldHRlX2F2Zyk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.metrics import silhouette_score

# Calcular el &iacute;ndice de silueta para K-means
silhouette_avg = silhouette_score(X, labels)
print(&quot;Silhouette Score for K-means:&quot;, silhouette_avg)</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, hemos explorado los conceptos básicos del clustering y algunos de los algoritmos más comunes, como K-means y DBSCAN. También hemos aprendido cómo evaluar la calidad de los clústeres obtenidos. Estos conocimientos son fundamentales para aplicar técnicas de clustering a problemas del mundo real y extraer información valiosa de los datos.</p>
</div><h2>Próximos Pasos</h2>
<div class='content'><p>En el siguiente módulo, profundizaremos en los casos de estudio y aplicaciones prácticas de los algoritmos de clustering en diversos campos, como la industria y las redes sociales.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-04-redes-neuronales' title="Redes Neuronales y Deep Learning">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='06-01-optimizacion-industria' title="Optimización en la Industria">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
