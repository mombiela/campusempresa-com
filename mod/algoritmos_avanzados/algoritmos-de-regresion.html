<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algoritmos de Regresión</title>

    <link rel="alternate" href="https://campusempresa.com/mod/algoritmos_avanzados/algoritmos-de-regresion" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/algoritmos_avanzados/algoritmos-de-regresion" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/algoritmos_avanzados/algoritmos-de-regresion" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/algoritmos_avanzados/algoritmos-de-regresion" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/algoritmos_avanzados/algoritmos-de-regresion" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-4'>
					<a href='algoritmos-de-clasificacion'>&#x25C4;Algoritmos de Clasificación</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Algoritmos de Regresión</a>
	</div>
	<div class='col-4 text-end'>
					<a href='redes-neuronales-y-deep-learning'>Redes Neuronales y Deep Learning &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción a la Regresión</h1>
<div class='content'><p>La regresión es una técnica de aprendizaje supervisado utilizada para predecir valores continuos. A diferencia de la clasificación, que predice categorías, la regresión se enfoca en predecir una variable dependiente basada en una o más variables independientes.</p>
</div><h1>Tipos de Algoritmos de Regresión</h1>
<div class='content'><p>Existen varios tipos de algoritmos de regresión, cada uno con sus propias características y aplicaciones. A continuación, se describen algunos de los más comunes:</p>
</div><h2>Regresión Lineal</h2>
<div class='content'><p>La regresión lineal es uno de los métodos más simples y ampliamente utilizados para modelar la relación entre una variable dependiente y una o más variables independientes.</p>
<ul>
<li><strong>Fórmula</strong>: \( y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n + \epsilon \)</li>
<li><strong>Objetivo</strong>: Minimizar la suma de los errores cuadrados (MSE).</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgTGluZWFyUmVncmVzc2lvbgoKIyBEYXRvcyBkZSBlamVtcGxvClggPSBucC5hcnJheShbWzFdLCBbMl0sIFszXSwgWzRdLCBbNV1dKQp5ID0gbnAuYXJyYXkoWzEsIDMsIDIsIDUsIDRdKQoKIyBDcmVhciBlbCBtb2RlbG8gZGUgcmVncmVzacOzbiBsaW5lYWwKbW9kZWwgPSBMaW5lYXJSZWdyZXNzaW9uKCkKbW9kZWwuZml0KFgsIHkpCgojIFByZWRpY2Npb25lcwp5X3ByZWQgPSBtb2RlbC5wcmVkaWN0KFgpCgojIFZpc3VhbGl6YWNpw7NuCnBsdC5zY2F0dGVyKFgsIHksIGNvbG9yPSdibHVlJykKcGx0LnBsb3QoWCwgeV9wcmVkLCBjb2xvcj0ncmVkJykKcGx0LnhsYWJlbCgnWCcpCnBsdC55bGFiZWwoJ3knKQpwbHQudGl0bGUoJ1JlZ3Jlc2nDs24gTGluZWFsJykKcGx0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Datos de ejemplo
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([1, 3, 2, 5, 4])

# Crear el modelo de regresi&oacute;n lineal
model = LinearRegression()
model.fit(X, y)

# Predicciones
y_pred = model.predict(X)

# Visualizaci&oacute;n
plt.scatter(X, y, color='blue')
plt.plot(X, y_pred, color='red')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Regresi&oacute;n Lineal')
plt.show()</pre></div><div class='content'></div><h2>Regresión Polinómica</h2>
<div class='content'><p>La regresión polinómica es una extensión de la regresión lineal que permite modelar relaciones no lineales entre las variables.</p>
<ul>
<li><strong>Fórmula</strong>: \( y = \beta_0 + \beta_1 x + \beta_2 x^2 + \ldots + \beta_n x^n + \epsilon \)</li>
<li><strong>Objetivo</strong>: Minimizar la suma de los errores cuadrados (MSE).</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFBvbHlub21pYWxGZWF0dXJlcwpmcm9tIHNrbGVhcm4ucGlwZWxpbmUgaW1wb3J0IG1ha2VfcGlwZWxpbmUKCiMgRGF0b3MgZGUgZWplbXBsbwpYID0gbnAuYXJyYXkoW1sxXSwgWzJdLCBbM10sIFs0XSwgWzVdXSkKeSA9IG5wLmFycmF5KFsxLCAzLCAyLCA1LCA0XSkKCiMgQ3JlYXIgZWwgbW9kZWxvIGRlIHJlZ3Jlc2nDs24gcG9saW7Ds21pY2EKcG9seV9tb2RlbCA9IG1ha2VfcGlwZWxpbmUoUG9seW5vbWlhbEZlYXR1cmVzKGRlZ3JlZT0yKSwgTGluZWFyUmVncmVzc2lvbigpKQpwb2x5X21vZGVsLmZpdChYLCB5KQoKIyBQcmVkaWNjaW9uZXMKeV9wb2x5X3ByZWQgPSBwb2x5X21vZGVsLnByZWRpY3QoWCkKCiMgVmlzdWFsaXphY2nDs24KcGx0LnNjYXR0ZXIoWCwgeSwgY29sb3I9J2JsdWUnKQpwbHQucGxvdChYLCB5X3BvbHlfcHJlZCwgY29sb3I9J3JlZCcpCnBsdC54bGFiZWwoJ1gnKQpwbHQueWxhYmVsKCd5JykKcGx0LnRpdGxlKCdSZWdyZXNpw7NuIFBvbGluw7NtaWNhJykKcGx0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Datos de ejemplo
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([1, 3, 2, 5, 4])

# Crear el modelo de regresi&oacute;n polin&oacute;mica
poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())
poly_model.fit(X, y)

# Predicciones
y_poly_pred = poly_model.predict(X)

# Visualizaci&oacute;n
plt.scatter(X, y, color='blue')
plt.plot(X, y_poly_pred, color='red')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Regresi&oacute;n Polin&oacute;mica')
plt.show()</pre></div><div class='content'></div><h2>Regresión Ridge</h2>
<div class='content'><p>La regresión Ridge es una técnica de regularización que introduce una penalización en los coeficientes de la regresión lineal para evitar el sobreajuste.</p>
<ul>
<li><strong>Fórmula</strong>: \( y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n + \epsilon \)</li>
<li><strong>Penalización</strong>: \( \lambda \sum_{i=1}^{n} \beta_i^2 \)</li>
<li><strong>Objetivo</strong>: Minimizar la suma de los errores cuadrados (MSE) más la penalización.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgUmlkZ2UKCiMgRGF0b3MgZGUgZWplbXBsbwpYID0gbnAuYXJyYXkoW1sxXSwgWzJdLCBbM10sIFs0XSwgWzVdXSkKeSA9IG5wLmFycmF5KFsxLCAzLCAyLCA1LCA0XSkKCiMgQ3JlYXIgZWwgbW9kZWxvIGRlIHJlZ3Jlc2nDs24gUmlkZ2UKcmlkZ2VfbW9kZWwgPSBSaWRnZShhbHBoYT0xLjApCnJpZGdlX21vZGVsLmZpdChYLCB5KQoKIyBQcmVkaWNjaW9uZXMKeV9yaWRnZV9wcmVkID0gcmlkZ2VfbW9kZWwucHJlZGljdChYKQoKIyBWaXN1YWxpemFjacOzbgpwbHQuc2NhdHRlcihYLCB5LCBjb2xvcj0nYmx1ZScpCnBsdC5wbG90KFgsIHlfcmlkZ2VfcHJlZCwgY29sb3I9J3JlZCcpCnBsdC54bGFiZWwoJ1gnKQpwbHQueWxhYmVsKCd5JykKcGx0LnRpdGxlKCdSZWdyZXNpw7NuIFJpZGdlJykKcGx0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.linear_model import Ridge

# Datos de ejemplo
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([1, 3, 2, 5, 4])

# Crear el modelo de regresi&oacute;n Ridge
ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X, y)

# Predicciones
y_ridge_pred = ridge_model.predict(X)

# Visualizaci&oacute;n
plt.scatter(X, y, color='blue')
plt.plot(X, y_ridge_pred, color='red')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Regresi&oacute;n Ridge')
plt.show()</pre></div><div class='content'></div><h2>Regresión Lasso</h2>
<div class='content'><p>La regresión Lasso es otra técnica de regularización que introduce una penalización en los coeficientes de la regresión lineal, pero utiliza la norma L1 en lugar de la norma L2.</p>
<ul>
<li><strong>Fórmula</strong>: \( y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n + \epsilon \)</li>
<li><strong>Penalización</strong>: \( \lambda \sum_{i=1}^{n} |\beta_i| \)</li>
<li><strong>Objetivo</strong>: Minimizar la suma de los errores cuadrados (MSE) más la penalización.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgTGFzc28KCiMgRGF0b3MgZGUgZWplbXBsbwpYID0gbnAuYXJyYXkoW1sxXSwgWzJdLCBbM10sIFs0XSwgWzVdXSkKeSA9IG5wLmFycmF5KFsxLCAzLCAyLCA1LCA0XSkKCiMgQ3JlYXIgZWwgbW9kZWxvIGRlIHJlZ3Jlc2nDs24gTGFzc28KbGFzc29fbW9kZWwgPSBMYXNzbyhhbHBoYT0wLjEpCmxhc3NvX21vZGVsLmZpdChYLCB5KQoKIyBQcmVkaWNjaW9uZXMKeV9sYXNzb19wcmVkID0gbGFzc29fbW9kZWwucHJlZGljdChYKQoKIyBWaXN1YWxpemFjacOzbgpwbHQuc2NhdHRlcihYLCB5LCBjb2xvcj0nYmx1ZScpCnBsdC5wbG90KFgsIHlfbGFzc29fcHJlZCwgY29sb3I9J3JlZCcpCnBsdC54bGFiZWwoJ1gnKQpwbHQueWxhYmVsKCd5JykKcGx0LnRpdGxlKCdSZWdyZXNpw7NuIExhc3NvJykKcGx0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.linear_model import Lasso

# Datos de ejemplo
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([1, 3, 2, 5, 4])

# Crear el modelo de regresi&oacute;n Lasso
lasso_model = Lasso(alpha=0.1)
lasso_model.fit(X, y)

# Predicciones
y_lasso_pred = lasso_model.predict(X)

# Visualizaci&oacute;n
plt.scatter(X, y, color='blue')
plt.plot(X, y_lasso_pred, color='red')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Regresi&oacute;n Lasso')
plt.show()</pre></div><div class='content'></div><h1>Comparación de Algoritmos de Regresión</h1>
<div class='content'><p>A continuación, se presenta una tabla comparativa de los diferentes algoritmos de regresión discutidos:</p>
<table>
<thead>
<tr>
<th>Algoritmo</th>
<th>Penalización</th>
<th>Ventajas</th>
<th>Desventajas</th>
</tr>
</thead>
<tbody>
<tr>
<td>Regresión Lineal</td>
<td>Ninguna</td>
<td>Simple, fácil de interpretar</td>
<td>Puede sobreajustar si hay muchas variables</td>
</tr>
<tr>
<td>Regresión Polinómica</td>
<td>Ninguna</td>
<td>Captura relaciones no lineales</td>
<td>Puede sobreajustar fácilmente</td>
</tr>
<tr>
<td>Regresión Ridge</td>
<td>L2</td>
<td>Reduce el sobreajuste, útil para muchas variables</td>
<td>No realiza selección de variables</td>
</tr>
<tr>
<td>Regresión Lasso</td>
<td>L1</td>
<td>Realiza selección de variables, reduce el sobreajuste</td>
<td>Puede eliminar variables importantes</td>
</tr>
</tbody>
</table>
</div><h1>Conclusión</h1>
<div class='content'><p>Los algoritmos de regresión son herramientas poderosas para predecir valores continuos. Cada tipo de regresión tiene sus propias ventajas y desventajas, y la elección del algoritmo adecuado depende del problema específico y de los datos disponibles. La comprensión de estos algoritmos y su correcta aplicación es esencial para cualquier profesional que trabaje en el campo del análisis de datos y el aprendizaje automático.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='algoritmos-de-clasificacion'>&#x25C4;Algoritmos de Clasificación</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Algoritmos de Regresión</a>
	</div>
	<div class='col-4 text-end'>
					<a href='redes-neuronales-y-deep-learning'>Redes Neuronales y Deep Learning &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
