<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algoritmos de Regresión</title>

    <link rel="alternate" href="https://campusempresa.com/mod/algoritmos_avanzados/05-03-algoritmos-regresion" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/algoritmos_avanzados/05-03-algoritmes-regressio" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/algoritmos_avanzados/05-03-regression-algorithms" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/algoritmos_avanzados/05-03-regression-algorithms" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/algoritmos_avanzados/05-03-algoritmes-regressio" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-02-algoritmos-clasificacion' title="Algoritmos de Clasificación">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Algoritmos de Regresión</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='05-04-redes-neuronales' title="Redes Neuronales y Deep Learning">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción</h1>
<div class='content'><p>Los algoritmos de regresión son una clase de algoritmos de aprendizaje supervisado utilizados para predecir un valor continuo. A diferencia de los algoritmos de clasificación, que predicen categorías discretas, los algoritmos de regresión predicen valores numéricos. Estos algoritmos son fundamentales en diversas aplicaciones, como la predicción de precios, la estimación de ventas y la modelización de relaciones entre variables.</p>
</div><h1>Conceptos Clave</h1>
<div class='content'><ol>
<li><strong>Variable Dependiente (Y)</strong>: La variable que se desea predecir.</li>
<li><strong>Variable Independiente (X)</strong>: Las variables que se utilizan para hacer la predicción.</li>
<li><strong>Función de Pérdida</strong>: Una función que mide el error de las predicciones del modelo.</li>
<li><strong>Coeficientes</strong>: Parámetros del modelo que se ajustan durante el entrenamiento.</li>
</ol>
</div><h1>Tipos de Algoritmos de Regresión</h1>
<div class='content'></div><h2>1. Regresión Lineal</h2>
<div class='content'><p>La regresión lineal es uno de los algoritmos de regresión más simples y ampliamente utilizados. Se basa en la suposición de que existe una relación lineal entre la variable dependiente y las variables independientes.</p>
<h4>Fórmula</h4>
<p>\[ Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n + \epsilon \]</p>
<ul>
<li>\( Y \): Variable dependiente.</li>
<li>\( \beta_0 \): Intercepto.</li>
<li>\( \beta_1, \beta_2, ..., \beta_n \): Coeficientes de las variables independientes.</li>
<li>\( X_1, X_2, ..., X_n \): Variables independientes.</li>
<li>\( \epsilon \): Error residual.</li>
</ul>
<h4>Ejemplo en Python</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgTGluZWFyUmVncmVzc2lvbgoKIyBEYXRvcyBkZSBlamVtcGxvClggPSBucC5hcnJheShbWzFdLCBbMl0sIFszXSwgWzRdLCBbNV1dKQpZID0gbnAuYXJyYXkoWzEsIDMsIDIsIDUsIDRdKQoKIyBDcmVhciBlbCBtb2RlbG8gZGUgcmVncmVzacOzbiBsaW5lYWwKbW9kZWwgPSBMaW5lYXJSZWdyZXNzaW9uKCkKbW9kZWwuZml0KFgsIFkpCgojIFByZWRpY2Npb25lcwpZX3ByZWQgPSBtb2RlbC5wcmVkaWN0KFgpCgojIFZpc3VhbGl6YWNpw7NuCnBsdC5zY2F0dGVyKFgsIFksIGNvbG9yPSdibHVlJykKcGx0LnBsb3QoWCwgWV9wcmVkLCBjb2xvcj0ncmVkJykKcGx0LnhsYWJlbCgnWCcpCnBsdC55bGFiZWwoJ1knKQpwbHQudGl0bGUoJ1JlZ3Jlc2nDs24gTGluZWFsJykKcGx0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Datos de ejemplo
X = np.array([[1], [2], [3], [4], [5]])
Y = np.array([1, 3, 2, 5, 4])

# Crear el modelo de regresi&oacute;n lineal
model = LinearRegression()
model.fit(X, Y)

# Predicciones
Y_pred = model.predict(X)

# Visualizaci&oacute;n
plt.scatter(X, Y, color='blue')
plt.plot(X, Y_pred, color='red')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Regresi&oacute;n Lineal')
plt.show()</pre></div><div class='content'><h4>Explicación del Código</h4>
<ol>
<li><strong>Importación de Bibliotecas</strong>: Se importan las bibliotecas necesarias.</li>
<li><strong>Datos de Ejemplo</strong>: Se crean los datos de entrada \(X\) y las etiquetas \(Y\).</li>
<li><strong>Creación del Modelo</strong>: Se crea un objeto <code>LinearRegression</code> y se ajusta a los datos.</li>
<li><strong>Predicciones</strong>: Se realizan predicciones utilizando el modelo ajustado.</li>
<li><strong>Visualización</strong>: Se visualizan los datos originales y la línea de regresión.</li>
</ol>
</div><h2>2. Regresión Polinómica</h2>
<div class='content'><p>La regresión polinómica es una extensión de la regresión lineal que permite modelar relaciones no lineales entre las variables independientes y la variable dependiente.</p>
<h4>Fórmula</h4>
<p>\[ Y = \beta_0 + \beta_1 X + \beta_2 X^2 + ... + \beta_n X^n + \epsilon \]</p>
<h4>Ejemplo en Python</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFBvbHlub21pYWxGZWF0dXJlcwpmcm9tIHNrbGVhcm4ucGlwZWxpbmUgaW1wb3J0IG1ha2VfcGlwZWxpbmUKCiMgRGF0b3MgZGUgZWplbXBsbwpYID0gbnAuYXJyYXkoW1sxXSwgWzJdLCBbM10sIFs0XSwgWzVdXSkKWSA9IG5wLmFycmF5KFsxLCAzLCAyLCA1LCA3XSkKCiMgQ3JlYXIgZWwgbW9kZWxvIGRlIHJlZ3Jlc2nDs24gcG9saW7Ds21pY2EKZGVncmVlID0gMgptb2RlbCA9IG1ha2VfcGlwZWxpbmUoUG9seW5vbWlhbEZlYXR1cmVzKGRlZ3JlZSksIExpbmVhclJlZ3Jlc3Npb24oKSkKbW9kZWwuZml0KFgsIFkpCgojIFByZWRpY2Npb25lcwpZX3ByZWQgPSBtb2RlbC5wcmVkaWN0KFgpCgojIFZpc3VhbGl6YWNpw7NuCnBsdC5zY2F0dGVyKFgsIFksIGNvbG9yPSdibHVlJykKcGx0LnBsb3QoWCwgWV9wcmVkLCBjb2xvcj0ncmVkJykKcGx0LnhsYWJlbCgnWCcpCnBsdC55bGFiZWwoJ1knKQpwbHQudGl0bGUoJ1JlZ3Jlc2nDs24gUG9saW7Ds21pY2EnKQpwbHQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Datos de ejemplo
X = np.array([[1], [2], [3], [4], [5]])
Y = np.array([1, 3, 2, 5, 7])

# Crear el modelo de regresi&oacute;n polin&oacute;mica
degree = 2
model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
model.fit(X, Y)

# Predicciones
Y_pred = model.predict(X)

# Visualizaci&oacute;n
plt.scatter(X, Y, color='blue')
plt.plot(X, Y_pred, color='red')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Regresi&oacute;n Polin&oacute;mica')
plt.show()</pre></div><div class='content'><h4>Explicación del Código</h4>
<ol>
<li><strong>Importación de Bibliotecas</strong>: Se importan las bibliotecas necesarias.</li>
<li><strong>Datos de Ejemplo</strong>: Se crean los datos de entrada \(X\) y las etiquetas \(Y\).</li>
<li><strong>Creación del Modelo</strong>: Se crea un pipeline que incluye la transformación polinómica y la regresión lineal.</li>
<li><strong>Predicciones</strong>: Se realizan predicciones utilizando el modelo ajustado.</li>
<li><strong>Visualización</strong>: Se visualizan los datos originales y la curva de regresión.</li>
</ol>
</div><h2>3. Regresión Ridge</h2>
<div class='content'><p>La regresión Ridge es una variante de la regresión lineal que incluye una penalización para los coeficientes del modelo, lo que ayuda a prevenir el sobreajuste.</p>
<h4>Fórmula</h4>
<p>\[ Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n + \epsilon \]</p>
<p>Con una penalización:</p>
<p>\[ \text{Penalización} = \lambda \sum_{i=1}^{n} \beta_i^2 \]</p>
<h4>Ejemplo en Python</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgUmlkZ2UKCiMgRGF0b3MgZGUgZWplbXBsbwpYID0gbnAuYXJyYXkoW1sxXSwgWzJdLCBbM10sIFs0XSwgWzVdXSkKWSA9IG5wLmFycmF5KFsxLCAzLCAyLCA1LCA0XSkKCiMgQ3JlYXIgZWwgbW9kZWxvIGRlIHJlZ3Jlc2nDs24gUmlkZ2UKbW9kZWwgPSBSaWRnZShhbHBoYT0xLjApCm1vZGVsLmZpdChYLCBZKQoKIyBQcmVkaWNjaW9uZXMKWV9wcmVkID0gbW9kZWwucHJlZGljdChYKQoKIyBWaXN1YWxpemFjacOzbgpwbHQuc2NhdHRlcihYLCBZLCBjb2xvcj0nYmx1ZScpCnBsdC5wbG90KFgsIFlfcHJlZCwgY29sb3I9J3JlZCcpCnBsdC54bGFiZWwoJ1gnKQpwbHQueWxhYmVsKCdZJykKcGx0LnRpdGxlKCdSZWdyZXNpw7NuIFJpZGdlJykKcGx0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.linear_model import Ridge

# Datos de ejemplo
X = np.array([[1], [2], [3], [4], [5]])
Y = np.array([1, 3, 2, 5, 4])

# Crear el modelo de regresi&oacute;n Ridge
model = Ridge(alpha=1.0)
model.fit(X, Y)

# Predicciones
Y_pred = model.predict(X)

# Visualizaci&oacute;n
plt.scatter(X, Y, color='blue')
plt.plot(X, Y_pred, color='red')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Regresi&oacute;n Ridge')
plt.show()</pre></div><div class='content'><h4>Explicación del Código</h4>
<ol>
<li><strong>Importación de Bibliotecas</strong>: Se importan las bibliotecas necesarias.</li>
<li><strong>Datos de Ejemplo</strong>: Se crean los datos de entrada \(X\) y las etiquetas \(Y\).</li>
<li><strong>Creación del Modelo</strong>: Se crea un objeto <code>Ridge</code> con una penalización \(\alpha\) y se ajusta a los datos.</li>
<li><strong>Predicciones</strong>: Se realizan predicciones utilizando el modelo ajustado.</li>
<li><strong>Visualización</strong>: Se visualizan los datos originales y la línea de regresión.</li>
</ol>
</div><h1>Ejercicios Prácticos</h1>
<div class='content'></div><h2>Ejercicio 1: Regresión Lineal</h2>
<div class='content'><p><strong>Instrucciones</strong>: Utiliza el conjunto de datos proporcionado para ajustar un modelo de regresión lineal y realiza predicciones.</p>
<p><strong>Datos</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("WCA9IG5wLmFycmF5KFtbMV0sIFsyXSwgWzNdLCBbNF0sIFs1XSwgWzZdLCBbN10sIFs4XSwgWzldLCBbMTBdXSkKWSA9IG5wLmFycmF5KFsyLCA0LCA1LCA0LCA1LCA3LCA4LCA5LCAxMCwgMTJdKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])
Y = np.array([2, 4, 5, 4, 5, 7, 8, 9, 10, 12])</pre></div><div class='content'><p><strong>Solución</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgTGluZWFyUmVncmVzc2lvbgoKIyBEYXRvcyBkZSBlamVtcGxvClggPSBucC5hcnJheShbWzFdLCBbMl0sIFszXSwgWzRdLCBbNV0sIFs2XSwgWzddLCBbOF0sIFs5XSwgWzEwXV0pClkgPSBucC5hcnJheShbMiwgNCwgNSwgNCwgNSwgNywgOCwgOSwgMTAsIDEyXSkKCiMgQ3JlYXIgZWwgbW9kZWxvIGRlIHJlZ3Jlc2nDs24gbGluZWFsCm1vZGVsID0gTGluZWFyUmVncmVzc2lvbigpCm1vZGVsLmZpdChYLCBZKQoKIyBQcmVkaWNjaW9uZXMKWV9wcmVkID0gbW9kZWwucHJlZGljdChYKQoKIyBWaXN1YWxpemFjacOzbgpwbHQuc2NhdHRlcihYLCBZLCBjb2xvcj0nYmx1ZScpCnBsdC5wbG90KFgsIFlfcHJlZCwgY29sb3I9J3JlZCcpCnBsdC54bGFiZWwoJ1gnKQpwbHQueWxhYmVsKCdZJykKcGx0LnRpdGxlKCdSZWdyZXNpw7NuIExpbmVhbCcpCnBsdC5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Datos de ejemplo
X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])
Y = np.array([2, 4, 5, 4, 5, 7, 8, 9, 10, 12])

# Crear el modelo de regresi&oacute;n lineal
model = LinearRegression()
model.fit(X, Y)

# Predicciones
Y_pred = model.predict(X)

# Visualizaci&oacute;n
plt.scatter(X, Y, color='blue')
plt.plot(X, Y_pred, color='red')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Regresi&oacute;n Lineal')
plt.show()</pre></div><div class='content'></div><h2>Ejercicio 2: Regresión Polinómica</h2>
<div class='content'><p><strong>Instrucciones</strong>: Ajusta un modelo de regresión polinómica de grado 3 a los siguientes datos y realiza predicciones.</p>
<p><strong>Datos</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("WCA9IG5wLmFycmF5KFtbMV0sIFsyXSwgWzNdLCBbNF0sIFs1XSwgWzZdLCBbN10sIFs4XSwgWzldLCBbMTBdXSkKWSA9IG5wLmFycmF5KFsxLCAzLCAyLCA1LCA3LCA4LCA3LCAxMCwgMTIsIDE1XSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])
Y = np.array([1, 3, 2, 5, 7, 8, 7, 10, 12, 15])</pre></div><div class='content'><p><strong>Solución</strong>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFBvbHlub21pYWxGZWF0dXJlcwpmcm9tIHNrbGVhcm4ucGlwZWxpbmUgaW1wb3J0IG1ha2VfcGlwZWxpbmUKCiMgRGF0b3MgZGUgZWplbXBsbwpYID0gbnAuYXJyYXkoW1sxXSwgWzJdLCBbM10sIFs0XSwgWzVdLCBbNl0sIFs3XSwgWzhdLCBbOV0sIFsxMF1dKQpZID0gbnAuYXJyYXkoWzEsIDMsIDIsIDUsIDcsIDgsIDcsIDEwLCAxMiwgMTVdKQoKIyBDcmVhciBlbCBtb2RlbG8gZGUgcmVncmVzacOzbiBwb2xpbsOzbWljYQpkZWdyZWUgPSAzCm1vZGVsID0gbWFrZV9waXBlbGluZShQb2x5bm9taWFsRmVhdHVyZXMoZGVncmVlKSwgTGluZWFyUmVncmVzc2lvbigpKQptb2RlbC5maXQoWCwgWSkKCiMgUHJlZGljY2lvbmVzCllfcHJlZCA9IG1vZGVsLnByZWRpY3QoWCkKCiMgVmlzdWFsaXphY2nDs24KcGx0LnNjYXR0ZXIoWCwgWSwgY29sb3I9J2JsdWUnKQpwbHQucGxvdChYLCBZX3ByZWQsIGNvbG9yPSdyZWQnKQpwbHQueGxhYmVsKCdYJykKcGx0LnlsYWJlbCgnWScpCnBsdC50aXRsZSgnUmVncmVzacOzbiBQb2xpbsOzbWljYScpCnBsdC5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Datos de ejemplo
X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])
Y = np.array([1, 3, 2, 5, 7, 8, 7, 10, 12, 15])

# Crear el modelo de regresi&oacute;n polin&oacute;mica
degree = 3
model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
model.fit(X, Y)

# Predicciones
Y_pred = model.predict(X)

# Visualizaci&oacute;n
plt.scatter(X, Y, color='blue')
plt.plot(X, Y_pred, color='red')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Regresi&oacute;n Polin&oacute;mica')
plt.show()</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, hemos explorado varios tipos de algoritmos de regresión, incluyendo la regresión lineal, la regresión polinómica y la regresión Ridge. Cada uno de estos algoritmos tiene sus propias ventajas y aplicaciones, y es importante seleccionar el algoritmo adecuado según la naturaleza del problema y los datos disponibles. Los ejercicios prácticos proporcionados ayudan a reforzar los conceptos aprendidos y a aplicar estos algoritmos en situaciones reales.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-02-algoritmos-clasificacion' title="Algoritmos de Clasificación">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='05-04-redes-neuronales' title="Redes Neuronales y Deep Learning">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
