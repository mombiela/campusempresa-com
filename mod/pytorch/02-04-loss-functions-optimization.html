<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Funciones de Pérdida y Optimización</title>

    <link rel="alternate" href="https://campusempresa.com/mod/pytorch/02-04-loss-functions-optimization" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/pytorch/02-04-loss-functions-optimization" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/pytorch/02-04-loss-functions-optimization" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/pytorch/02-04-loss-functions-optimization" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/pytorch/02-04-loss-functions-optimization" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='02-03-activation-functions' title="Funciones de Activación">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Funciones de Pérdida y Optimización</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='03-01-data-loading-preprocessing' title="Carga y Preprocesamiento de Datos">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'><p>En este módulo, aprenderemos sobre las funciones de pérdida y los algoritmos de optimización, que son componentes esenciales en el entrenamiento de redes neuronales. Las funciones de pérdida nos permiten cuantificar qué tan bien o mal está funcionando nuestro modelo, mientras que los algoritmos de optimización nos ayudan a ajustar los parámetros del modelo para minimizar la pérdida.</p>
</div><h1>1. Funciones de Pérdida</h1>
<div class='content'></div><h2>¿Qué es una Función de Pérdida?</h2>
<div class='content'><p>Una función de pérdida (o función de costo) mide la discrepancia entre las predicciones del modelo y los valores reales. El objetivo del entrenamiento es minimizar esta pérdida.</p>
</div><h2>Tipos Comunes de Funciones de Pérdida</h2>
<div class='content'><ol>
<li>
<p><strong>Error Cuadrático Medio (MSE)</strong></p>
<ul>
<li>Utilizado principalmente en problemas de regresión.</li>
<li>Fórmula: \( \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \)</li>
<li>Donde \( y_i \) es el valor real y \( \hat{y}_i \) es la predicción del modelo.</li>
</ul>
</li>
<li>
<p><strong>Entropía Cruzada (Cross-Entropy)</strong></p>
<ul>
<li>Utilizado principalmente en problemas de clasificación.</li>
<li>Fórmula: \( \text{Cross-Entropy} = -\frac{1}{n} \sum_{i=1}^{n} [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)] \)</li>
<li>Donde \( y_i \) es la etiqueta real y \( \hat{y}_i \) es la probabilidad predicha.</li>
</ul>
</li>
</ol>
</div><h2>Implementación en PyTorch</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubiBhcyBubgoKIyBFamVtcGxvIGRlIE1TRSBMb3NzCm1zZV9sb3NzID0gbm4uTVNFTG9zcygpCmlucHV0ID0gdG9yY2gudGVuc29yKFswLjUsIDAuOCwgMC4zXSwgcmVxdWlyZXNfZ3JhZD1UcnVlKQp0YXJnZXQgPSB0b3JjaC50ZW5zb3IoWzAuMCwgMS4wLCAwLjBdKQpsb3NzID0gbXNlX2xvc3MoaW5wdXQsIHRhcmdldCkKcHJpbnQoZidNU0UgTG9zczoge2xvc3MuaXRlbSgpfScpCgojIEVqZW1wbG8gZGUgQ3Jvc3MtRW50cm9weSBMb3NzCmNyb3NzX2VudHJvcHlfbG9zcyA9IG5uLkNyb3NzRW50cm9weUxvc3MoKQppbnB1dCA9IHRvcmNoLnRlbnNvcihbWzAuMiwgMC44XSwgWzAuNiwgMC40XV0sIHJlcXVpcmVzX2dyYWQ9VHJ1ZSkKdGFyZ2V0ID0gdG9yY2gudGVuc29yKFsxLCAwXSkKbG9zcyA9IGNyb3NzX2VudHJvcHlfbG9zcyhpbnB1dCwgdGFyZ2V0KQpwcmludChmJ0Nyb3NzLUVudHJvcHkgTG9zczoge2xvc3MuaXRlbSgpfScp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torch.nn as nn

# Ejemplo de MSE Loss
mse_loss = nn.MSELoss()
input = torch.tensor([0.5, 0.8, 0.3], requires_grad=True)
target = torch.tensor([0.0, 1.0, 0.0])
loss = mse_loss(input, target)
print(f'MSE Loss: {loss.item()}')

# Ejemplo de Cross-Entropy Loss
cross_entropy_loss = nn.CrossEntropyLoss()
input = torch.tensor([[0.2, 0.8], [0.6, 0.4]], requires_grad=True)
target = torch.tensor([1, 0])
loss = cross_entropy_loss(input, target)
print(f'Cross-Entropy Loss: {loss.item()}')</pre></div><div class='content'></div><h1>2. Algoritmos de Optimización</h1>
<div class='content'></div><h2>¿Qué es un Algoritmo de Optimización?</h2>
<div class='content'><p>Un algoritmo de optimización ajusta los parámetros del modelo para minimizar la función de pérdida. Los optimizadores actualizan los pesos del modelo basándose en el gradiente de la pérdida con respecto a los pesos.</p>
</div><h2>Tipos Comunes de Algoritmos de Optimización</h2>
<div class='content'><ol>
<li>
<p><strong>Gradiente Descendente Estocástico (SGD)</strong></p>
<ul>
<li>Actualiza los pesos usando un subconjunto aleatorio de datos.</li>
<li>Fórmula de actualización: \( w = w - \eta \nabla L(w) \)</li>
<li>Donde \( \eta \) es la tasa de aprendizaje y \( \nabla L(w) \) es el gradiente de la pérdida.</li>
</ul>
</li>
<li>
<p><strong>Adam (Adaptive Moment Estimation)</strong></p>
<ul>
<li>Combina las ventajas de AdaGrad y RMSProp.</li>
<li>Fórmula de actualización: Utiliza momentos de primer y segundo orden de los gradientes.</li>
</ul>
</li>
</ol>
</div><h2>Implementación en PyTorch</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm9wdGltIGFzIG9wdGltCgojIEVqZW1wbG8gZGUgU0dECm1vZGVsID0gbm4uTGluZWFyKDIsIDEpICAjIE1vZGVsbyBzaW1wbGUgZGUgdW5hIGNhcGEgbGluZWFsCm9wdGltaXplciA9IG9wdGltLlNHRChtb2RlbC5wYXJhbWV0ZXJzKCksIGxyPTAuMDEpCgojIEVqZW1wbG8gZGUgQWRhbQpvcHRpbWl6ZXIgPSBvcHRpbS5BZGFtKG1vZGVsLnBhcmFtZXRlcnMoKSwgbHI9MC4wMDEp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.optim as optim

# Ejemplo de SGD
model = nn.Linear(2, 1)  # Modelo simple de una capa lineal
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Ejemplo de Adam
optimizer = optim.Adam(model.parameters(), lr=0.001)</pre></div><div class='content'></div><h1>3. Ejemplo Práctico: Entrenamiento de una Red Neuronal Simple</h1>
<div class='content'></div><h2>Definición del Modelo</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubiBhcyBubgppbXBvcnQgdG9yY2gub3B0aW0gYXMgb3B0aW0KCiMgRGVmaW5pY2nDs24gZGUgdW4gbW9kZWxvIHNpbXBsZQpjbGFzcyBTaW1wbGVOTihubi5Nb2R1bGUpOgogICAgZGVmIF9faW5pdF9fKHNlbGYpOgogICAgICAgIHN1cGVyKFNpbXBsZU5OLCBzZWxmKS5fX2luaXRfXygpCiAgICAgICAgc2VsZi5mYzEgPSBubi5MaW5lYXIoMiwgMykKICAgICAgICBzZWxmLmZjMiA9IG5uLkxpbmVhcigzLCAxKQoKICAgIGRlZiBmb3J3YXJkKHNlbGYsIHgpOgogICAgICAgIHggPSB0b3JjaC5yZWx1KHNlbGYuZmMxKHgpKQogICAgICAgIHggPSB0b3JjaC5zaWdtb2lkKHNlbGYuZmMyKHgpKQogICAgICAgIHJldHVybiB4Cgptb2RlbCA9IFNpbXBsZU5OKCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torch.nn as nn
import torch.optim as optim

# Definici&oacute;n de un modelo simple
class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(2, 3)
        self.fc2 = nn.Linear(3, 1)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.sigmoid(self.fc2(x))
        return x

model = SimpleNN()</pre></div><div class='content'></div><h2>Definición de la Función de Pérdida y el Optimizador</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y3JpdGVyaW9uID0gbm4uTVNFTG9zcygpCm9wdGltaXplciA9IG9wdGltLlNHRChtb2RlbC5wYXJhbWV0ZXJzKCksIGxyPTAuMDEp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)</pre></div><div class='content'></div><h2>Bucle de Entrenamiento</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEYXRvcyBkZSBlamVtcGxvCmlucHV0cyA9IHRvcmNoLnRlbnNvcihbWzAuNSwgMC44XSwgWzAuMywgMC4yXSwgWzAuOSwgMC43XV0sIHJlcXVpcmVzX2dyYWQ9VHJ1ZSkKdGFyZ2V0cyA9IHRvcmNoLnRlbnNvcihbWzEuMF0sIFswLjBdLCBbMS4wXV0pCgojIEVudHJlbmFtaWVudG8KZm9yIGVwb2NoIGluIHJhbmdlKDEwMCk6CiAgICBvcHRpbWl6ZXIuemVyb19ncmFkKCkgICMgTGltcGlhciBsb3MgZ3JhZGllbnRlcwogICAgb3V0cHV0cyA9IG1vZGVsKGlucHV0cykgICMgRm9yd2FyZCBwYXNzCiAgICBsb3NzID0gY3JpdGVyaW9uKG91dHB1dHMsIHRhcmdldHMpICAjIENhbGN1bGFyIGxhIHDDqXJkaWRhCiAgICBsb3NzLmJhY2t3YXJkKCkgICMgQmFja3dhcmQgcGFzcwogICAgb3B0aW1pemVyLnN0ZXAoKSAgIyBBY3R1YWxpemFyIGxvcyBwZXNvcwoKICAgIGlmIChlcG9jaCsxKSAlIDEwID09IDA6CiAgICAgICAgcHJpbnQoZidFcG9jaCBbe2Vwb2NoKzF9LzEwMF0sIExvc3M6IHtsb3NzLml0ZW0oKTouNGZ9Jyk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Datos de ejemplo
inputs = torch.tensor([[0.5, 0.8], [0.3, 0.2], [0.9, 0.7]], requires_grad=True)
targets = torch.tensor([[1.0], [0.0], [1.0]])

# Entrenamiento
for epoch in range(100):
    optimizer.zero_grad()  # Limpiar los gradientes
    outputs = model(inputs)  # Forward pass
    loss = criterion(outputs, targets)  # Calcular la p&eacute;rdida
    loss.backward()  # Backward pass
    optimizer.step()  # Actualizar los pesos

    if (epoch+1) % 10 == 0:
        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')</pre></div><div class='content'></div><h1>4. Ejercicios Prácticos</h1>
<div class='content'></div><h2>Ejercicio 1: Implementar una Función de Pérdida Personalizada</h2>
<div class='content'><p><strong>Objetivo:</strong> Implementar una función de pérdida personalizada que combine MSE y Cross-Entropy.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgQ3VzdG9tTG9zcyhubi5Nb2R1bGUpOgogICAgZGVmIF9faW5pdF9fKHNlbGYpOgogICAgICAgIHN1cGVyKEN1c3RvbUxvc3MsIHNlbGYpLl9faW5pdF9fKCkKICAgICAgICBzZWxmLm1zZSA9IG5uLk1TRUxvc3MoKQogICAgICAgIHNlbGYuY3Jvc3NfZW50cm9weSA9IG5uLkNyb3NzRW50cm9weUxvc3MoKQoKICAgIGRlZiBmb3J3YXJkKHNlbGYsIG91dHB1dHMsIHRhcmdldHMpOgogICAgICAgIG1zZV9sb3NzID0gc2VsZi5tc2Uob3V0cHV0cywgdGFyZ2V0cykKICAgICAgICBjcm9zc19lbnRyb3B5X2xvc3MgPSBzZWxmLmNyb3NzX2VudHJvcHkob3V0cHV0cywgdGFyZ2V0cykKICAgICAgICByZXR1cm4gbXNlX2xvc3MgKyBjcm9zc19lbnRyb3B5X2xvc3MKCiMgVXNvIGRlIGxhIGZ1bmNpw7NuIGRlIHDDqXJkaWRhIHBlcnNvbmFsaXphZGEKY3JpdGVyaW9uID0gQ3VzdG9tTG9zcygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class CustomLoss(nn.Module):
    def __init__(self):
        super(CustomLoss, self).__init__()
        self.mse = nn.MSELoss()
        self.cross_entropy = nn.CrossEntropyLoss()

    def forward(self, outputs, targets):
        mse_loss = self.mse(outputs, targets)
        cross_entropy_loss = self.cross_entropy(outputs, targets)
        return mse_loss + cross_entropy_loss

# Uso de la funci&oacute;n de p&eacute;rdida personalizada
criterion = CustomLoss()</pre></div><div class='content'></div><h2>Ejercicio 2: Comparar Diferentes Optimizadores</h2>
<div class='content'><p><strong>Objetivo:</strong> Entrenar el mismo modelo con diferentes optimizadores y comparar los resultados.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEZWZpbmlyIGRpZmVyZW50ZXMgb3B0aW1pemFkb3JlcwpvcHRpbWl6ZXJzID0gewogICAgJ1NHRCc6IG9wdGltLlNHRChtb2RlbC5wYXJhbWV0ZXJzKCksIGxyPTAuMDEpLAogICAgJ0FkYW0nOiBvcHRpbS5BZGFtKG1vZGVsLnBhcmFtZXRlcnMoKSwgbHI9MC4wMDEpLAogICAgJ1JNU3Byb3AnOiBvcHRpbS5STVNwcm9wKG1vZGVsLnBhcmFtZXRlcnMoKSwgbHI9MC4wMSkKfQoKIyBFbnRyZW5hciB5IGNvbXBhcmFyCmZvciBvcHRfbmFtZSwgb3B0aW1pemVyIGluIG9wdGltaXplcnMuaXRlbXMoKToKICAgIG1vZGVsID0gU2ltcGxlTk4oKSAgIyBSZWluaWNpYXIgZWwgbW9kZWxvCiAgICBmb3IgZXBvY2ggaW4gcmFuZ2UoMTAwKToKICAgICAgICBvcHRpbWl6ZXIuemVyb19ncmFkKCkKICAgICAgICBvdXRwdXRzID0gbW9kZWwoaW5wdXRzKQogICAgICAgIGxvc3MgPSBjcml0ZXJpb24ob3V0cHV0cywgdGFyZ2V0cykKICAgICAgICBsb3NzLmJhY2t3YXJkKCkKICAgICAgICBvcHRpbWl6ZXIuc3RlcCgpCgogICAgcHJpbnQoZidPcHRpbWl6ZXI6IHtvcHRfbmFtZX0sIEZpbmFsIExvc3M6IHtsb3NzLml0ZW0oKTouNGZ9Jyk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Definir diferentes optimizadores
optimizers = {
    'SGD': optim.SGD(model.parameters(), lr=0.01),
    'Adam': optim.Adam(model.parameters(), lr=0.001),
    'RMSprop': optim.RMSprop(model.parameters(), lr=0.01)
}

# Entrenar y comparar
for opt_name, optimizer in optimizers.items():
    model = SimpleNN()  # Reiniciar el modelo
    for epoch in range(100):
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

    print(f'Optimizer: {opt_name}, Final Loss: {loss.item():.4f}')</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, hemos aprendido sobre las funciones de pérdida y los algoritmos de optimización, dos componentes cruciales en el entrenamiento de redes neuronales. Hemos visto cómo implementar y utilizar estas funciones en PyTorch, y hemos practicado con ejemplos y ejercicios prácticos. Con este conocimiento, estamos preparados para avanzar al siguiente módulo, donde exploraremos el entrenamiento de redes neuronales en mayor profundidad.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='02-03-activation-functions' title="Funciones de Activación">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='03-01-data-loading-preprocessing' title="Carga y Preprocesamiento de Datos">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
