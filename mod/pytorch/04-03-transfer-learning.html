<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aprendizaje por Transferencia con Modelos Preentrenados</title>

    <link rel="alternate" href="https://campusempresa.com/mod/pytorch/04-03-transfer-learning" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/pytorch/04-03-transfer-learning" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/pytorch/04-03-transfer-learning" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/pytorch/04-03-transfer-learning" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/pytorch/04-03-transfer-learning" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='04-02-building-cnn-from-scratch' title="Construcción de una CNN desde Cero">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Aprendizaje por Transferencia con Modelos Preentrenados</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='04-04-fine-tuning-cnns' title="Ajuste Fino de CNNs">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'><p>El aprendizaje por transferencia es una técnica poderosa en el campo del aprendizaje profundo que permite utilizar modelos preentrenados en grandes conjuntos de datos para resolver problemas específicos con menos datos y tiempo de entrenamiento. En este módulo, aprenderemos cómo aplicar el aprendizaje por transferencia utilizando PyTorch.</p>
</div><h1><p>¿Qué es el Aprendizaje por Transferencia?</p>
</h1>
<div class='content'><p>El aprendizaje por transferencia implica tomar un modelo que ha sido preentrenado en una tarea grande y general (como la clasificación de imágenes en el conjunto de datos ImageNet) y adaptarlo a una tarea específica. Los beneficios incluyen:</p>
<ul>
<li><strong>Reducción del tiempo de entrenamiento</strong>: Aprovechamos el conocimiento ya adquirido por el modelo.</li>
<li><strong>Mejora del rendimiento</strong>: Los modelos preentrenados suelen tener una mejor capacidad de generalización.</li>
<li><strong>Menor necesidad de datos</strong>: Podemos obtener buenos resultados con menos datos de entrenamiento.</li>
</ul>
</div><h1><p>Pasos para Implementar el Aprendizaje por Transferencia</p>
</h1>
<div class='content'><ol>
<li><strong>Seleccionar un modelo preentrenado</strong>: PyTorch proporciona varios modelos preentrenados a través de la biblioteca <code>torchvision.models</code>.</li>
<li><strong>Modificar la última capa</strong>: Adaptar la última capa del modelo para que coincida con el número de clases de nuestro problema específico.</li>
<li><strong>Congelar capas</strong>: Opcionalmente, congelar algunas capas del modelo para evitar que se actualicen durante el entrenamiento.</li>
<li><strong>Entrenar el modelo</strong>: Entrenar el modelo en nuestro conjunto de datos específico.</li>
</ol>
</div><h1><p>Ejemplo Práctico: Clasificación de Imágenes con ResNet</p>
</h1>
<div class='content'></div><h2><p>Paso 1: Importar Librerías y Cargar el Modelo Preentrenado</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubiBhcyBubgppbXBvcnQgdG9yY2gub3B0aW0gYXMgb3B0aW0KZnJvbSB0b3JjaHZpc2lvbiBpbXBvcnQgZGF0YXNldHMsIG1vZGVscywgdHJhbnNmb3JtcwoKIyBDb25maWd1cmFjacOzbiBkZWwgZGlzcG9zaXRpdm8KZGV2aWNlID0gdG9yY2guZGV2aWNlKCJjdWRhIiBpZiB0b3JjaC5jdWRhLmlzX2F2YWlsYWJsZSgpIGVsc2UgImNwdSIpCgojIENhcmdhciBlbCBtb2RlbG8gcHJlZW50cmVuYWRvIFJlc05ldDE4Cm1vZGVsID0gbW9kZWxzLnJlc25ldDE4KHByZXRyYWluZWQ9VHJ1ZSkKbW9kZWwgPSBtb2RlbC50byhkZXZpY2Up"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms

# Configuraci&oacute;n del dispositivo
device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)

# Cargar el modelo preentrenado ResNet18
model = models.resnet18(pretrained=True)
model = model.to(device)</pre></div><div class='content'></div><h2><p>Paso 2: Modificar la Última Capa</p>
</h2>
<div class='content'><p>La red ResNet18 tiene una capa totalmente conectada (<code>fc</code>) al final que produce 1000 salidas (para las 1000 clases de ImageNet). Necesitamos modificar esta capa para que coincida con el número de clases de nuestro problema.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("bnVtX2NsYXNzZXMgPSAxMCAgIyBFamVtcGxvOiAxMCBjbGFzZXMKbW9kZWwuZmMgPSBubi5MaW5lYXIobW9kZWwuZmMuaW5fZmVhdHVyZXMsIG51bV9jbGFzc2VzKQptb2RlbCA9IG1vZGVsLnRvKGRldmljZSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>num_classes = 10  # Ejemplo: 10 clases
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)</pre></div><div class='content'></div><h2><p>Paso 3: Congelar Capas (Opcional)</p>
</h2>
<div class='content'><p>Podemos congelar las capas iniciales del modelo para evitar que se actualicen durante el entrenamiento. Esto es útil si queremos aprovechar al máximo el conocimiento preentrenado.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Zm9yIHBhcmFtIGluIG1vZGVsLnBhcmFtZXRlcnMoKToKICAgIHBhcmFtLnJlcXVpcmVzX2dyYWQgPSBGYWxzZQoKIyBTb2xvIGVudHJlbmFyIGxhIMO6bHRpbWEgY2FwYQpmb3IgcGFyYW0gaW4gbW9kZWwuZmMucGFyYW1ldGVycygpOgogICAgcGFyYW0ucmVxdWlyZXNfZ3JhZCA9IFRydWU="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>for param in model.parameters():
    param.requires_grad = False

# Solo entrenar la &uacute;ltima capa
for param in model.fc.parameters():
    param.requires_grad = True</pre></div><div class='content'></div><h2><p>Paso 4: Preparar el Conjunto de Datos y el Bucle de Entrenamiento</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBUcmFuc2Zvcm1hY2lvbmVzIGRlIGRhdG9zCmRhdGFfdHJhbnNmb3JtcyA9IHsKICAgICd0cmFpbic6IHRyYW5zZm9ybXMuQ29tcG9zZShbCiAgICAgICAgdHJhbnNmb3Jtcy5SYW5kb21SZXNpemVkQ3JvcCgyMjQpLAogICAgICAgIHRyYW5zZm9ybXMuUmFuZG9tSG9yaXpvbnRhbEZsaXAoKSwKICAgICAgICB0cmFuc2Zvcm1zLlRvVGVuc29yKCksCiAgICAgICAgdHJhbnNmb3Jtcy5Ob3JtYWxpemUoWzAuNDg1LCAwLjQ1NiwgMC40MDZdLCBbMC4yMjksIDAuMjI0LCAwLjIyNV0pCiAgICBdKSwKICAgICd2YWwnOiB0cmFuc2Zvcm1zLkNvbXBvc2UoWwogICAgICAgIHRyYW5zZm9ybXMuUmVzaXplKDI1NiksCiAgICAgICAgdHJhbnNmb3Jtcy5DZW50ZXJDcm9wKDIyNCksCiAgICAgICAgdHJhbnNmb3Jtcy5Ub1RlbnNvcigpLAogICAgICAgIHRyYW5zZm9ybXMuTm9ybWFsaXplKFswLjQ4NSwgMC40NTYsIDAuNDA2XSwgWzAuMjI5LCAwLjIyNCwgMC4yMjVdKQogICAgXSksCn0KCmRhdGFfZGlyID0gJ2RhdGEvaHltZW5vcHRlcmFfZGF0YScKaW1hZ2VfZGF0YXNldHMgPSB7eDogZGF0YXNldHMuSW1hZ2VGb2xkZXIob3MucGF0aC5qb2luKGRhdGFfZGlyLCB4KSwgZGF0YV90cmFuc2Zvcm1zW3hdKSBmb3IgeCBpbiBbJ3RyYWluJywgJ3ZhbCddfQpkYXRhbG9hZGVycyA9IHt4OiB0b3JjaC51dGlscy5kYXRhLkRhdGFMb2FkZXIoaW1hZ2VfZGF0YXNldHNbeF0sIGJhdGNoX3NpemU9NCwgc2h1ZmZsZT1UcnVlLCBudW1fd29ya2Vycz00KSBmb3IgeCBpbiBbJ3RyYWluJywgJ3ZhbCddfQpkYXRhc2V0X3NpemVzID0ge3g6IGxlbihpbWFnZV9kYXRhc2V0c1t4XSkgZm9yIHggaW4gWyd0cmFpbicsICd2YWwnXX0KY2xhc3NfbmFtZXMgPSBpbWFnZV9kYXRhc2V0c1sndHJhaW4nXS5jbGFzc2VzCgojIERlZmluaXIgbGEgZnVuY2nDs24gZGUgcMOpcmRpZGEgeSBlbCBvcHRpbWl6YWRvcgpjcml0ZXJpb24gPSBubi5Dcm9zc0VudHJvcHlMb3NzKCkKb3B0aW1pemVyID0gb3B0aW0uU0dEKG1vZGVsLmZjLnBhcmFtZXRlcnMoKSwgbHI9MC4wMDEsIG1vbWVudHVtPTAuOSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Transformaciones de datos
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

data_dir = 'data/hymenoptera_data'
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
class_names = image_datasets['train'].classes

# Definir la funci&oacute;n de p&eacute;rdida y el optimizador
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)</pre></div><div class='content'></div><h2><p>Paso 5: Entrenar y Evaluar el Modelo</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIHRyYWluX21vZGVsKG1vZGVsLCBjcml0ZXJpb24sIG9wdGltaXplciwgbnVtX2Vwb2Nocz0yNSk6CiAgICBmb3IgZXBvY2ggaW4gcmFuZ2UobnVtX2Vwb2Nocyk6CiAgICAgICAgcHJpbnQoZidFcG9jaCB7ZXBvY2h9L3tudW1fZXBvY2hzIC0gMX0nKQogICAgICAgIHByaW50KCctJyAqIDEwKQoKICAgICAgICBmb3IgcGhhc2UgaW4gWyd0cmFpbicsICd2YWwnXToKICAgICAgICAgICAgaWYgcGhhc2UgPT0gJ3RyYWluJzoKICAgICAgICAgICAgICAgIG1vZGVsLnRyYWluKCkKICAgICAgICAgICAgZWxzZToKICAgICAgICAgICAgICAgIG1vZGVsLmV2YWwoKQoKICAgICAgICAgICAgcnVubmluZ19sb3NzID0gMC4wCiAgICAgICAgICAgIHJ1bm5pbmdfY29ycmVjdHMgPSAwCgogICAgICAgICAgICBmb3IgaW5wdXRzLCBsYWJlbHMgaW4gZGF0YWxvYWRlcnNbcGhhc2VdOgogICAgICAgICAgICAgICAgaW5wdXRzID0gaW5wdXRzLnRvKGRldmljZSkKICAgICAgICAgICAgICAgIGxhYmVscyA9IGxhYmVscy50byhkZXZpY2UpCgogICAgICAgICAgICAgICAgb3B0aW1pemVyLnplcm9fZ3JhZCgpCgogICAgICAgICAgICAgICAgd2l0aCB0b3JjaC5zZXRfZ3JhZF9lbmFibGVkKHBoYXNlID09ICd0cmFpbicpOgogICAgICAgICAgICAgICAgICAgIG91dHB1dHMgPSBtb2RlbChpbnB1dHMpCiAgICAgICAgICAgICAgICAgICAgXywgcHJlZHMgPSB0b3JjaC5tYXgob3V0cHV0cywgMSkKICAgICAgICAgICAgICAgICAgICBsb3NzID0gY3JpdGVyaW9uKG91dHB1dHMsIGxhYmVscykKCiAgICAgICAgICAgICAgICAgICAgaWYgcGhhc2UgPT0gJ3RyYWluJzoKICAgICAgICAgICAgICAgICAgICAgICAgbG9zcy5iYWNrd2FyZCgpCiAgICAgICAgICAgICAgICAgICAgICAgIG9wdGltaXplci5zdGVwKCkKCiAgICAgICAgICAgICAgICBydW5uaW5nX2xvc3MgKz0gbG9zcy5pdGVtKCkgKiBpbnB1dHMuc2l6ZSgwKQogICAgICAgICAgICAgICAgcnVubmluZ19jb3JyZWN0cyArPSB0b3JjaC5zdW0ocHJlZHMgPT0gbGFiZWxzLmRhdGEpCgogICAgICAgICAgICBlcG9jaF9sb3NzID0gcnVubmluZ19sb3NzIC8gZGF0YXNldF9zaXplc1twaGFzZV0KICAgICAgICAgICAgZXBvY2hfYWNjID0gcnVubmluZ19jb3JyZWN0cy5kb3VibGUoKSAvIGRhdGFzZXRfc2l6ZXNbcGhhc2VdCgogICAgICAgICAgICBwcmludChmJ3twaGFzZX0gTG9zczoge2Vwb2NoX2xvc3M6LjRmfSBBY2M6IHtlcG9jaF9hY2M6LjRmfScpCgogICAgcmV0dXJuIG1vZGVsCgptb2RlbCA9IHRyYWluX21vZGVsKG1vZGVsLCBjcml0ZXJpb24sIG9wdGltaXplciwgbnVtX2Vwb2Nocz0yNSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def train_model(model, criterion, optimizer, num_epochs=25):
    for epoch in range(num_epochs):
        print(f'Epoch {epoch}/{num_epochs - 1}')
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

    return model

model = train_model(model, criterion, optimizer, num_epochs=25)</pre></div><div class='content'></div><h1><p>Ejercicio Práctico</p>
</h1>
<div class='content'></div><h2><p>Ejercicio 1: Aplicar Aprendizaje por Transferencia con VGG16</p>
</h2>
<div class='content'><ol>
<li><strong>Cargar el modelo VGG16 preentrenado</strong>.</li>
<li><strong>Modificar la última capa para un problema de clasificación con 5 clases</strong>.</li>
<li><strong>Congelar todas las capas excepto la última</strong>.</li>
<li><strong>Entrenar el modelo en un conjunto de datos de su elección</strong>.</li>
</ol>
</div><h2><p>Solución</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDYXJnYXIgZWwgbW9kZWxvIHByZWVudHJlbmFkbyBWR0cxNgptb2RlbF92Z2cgPSBtb2RlbHMudmdnMTYocHJldHJhaW5lZD1UcnVlKQptb2RlbF92Z2cgPSBtb2RlbF92Z2cudG8oZGV2aWNlKQoKIyBNb2RpZmljYXIgbGEgw7psdGltYSBjYXBhCm1vZGVsX3ZnZy5jbGFzc2lmaWVyWzZdID0gbm4uTGluZWFyKG1vZGVsX3ZnZy5jbGFzc2lmaWVyWzZdLmluX2ZlYXR1cmVzLCA1KQptb2RlbF92Z2cgPSBtb2RlbF92Z2cudG8oZGV2aWNlKQoKIyBDb25nZWxhciB0b2RhcyBsYXMgY2FwYXMgZXhjZXB0byBsYSDDumx0aW1hCmZvciBwYXJhbSBpbiBtb2RlbF92Z2cuZmVhdHVyZXMucGFyYW1ldGVycygpOgogICAgcGFyYW0ucmVxdWlyZXNfZ3JhZCA9IEZhbHNlCgojIERlZmluaXIgbGEgZnVuY2nDs24gZGUgcMOpcmRpZGEgeSBlbCBvcHRpbWl6YWRvcgpjcml0ZXJpb24gPSBubi5Dcm9zc0VudHJvcHlMb3NzKCkKb3B0aW1pemVyID0gb3B0aW0uU0dEKG1vZGVsX3ZnZy5jbGFzc2lmaWVyWzZdLnBhcmFtZXRlcnMoKSwgbHI9MC4wMDEsIG1vbWVudHVtPTAuOSkKCiMgRW50cmVuYXIgZWwgbW9kZWxvCm1vZGVsX3ZnZyA9IHRyYWluX21vZGVsKG1vZGVsX3ZnZywgY3JpdGVyaW9uLCBvcHRpbWl6ZXIsIG51bV9lcG9jaHM9MjUp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Cargar el modelo preentrenado VGG16
model_vgg = models.vgg16(pretrained=True)
model_vgg = model_vgg.to(device)

# Modificar la &uacute;ltima capa
model_vgg.classifier[6] = nn.Linear(model_vgg.classifier[6].in_features, 5)
model_vgg = model_vgg.to(device)

# Congelar todas las capas excepto la &uacute;ltima
for param in model_vgg.features.parameters():
    param.requires_grad = False

# Definir la funci&oacute;n de p&eacute;rdida y el optimizador
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model_vgg.classifier[6].parameters(), lr=0.001, momentum=0.9)

# Entrenar el modelo
model_vgg = train_model(model_vgg, criterion, optimizer, num_epochs=25)</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En este módulo, hemos aprendido cómo aplicar el aprendizaje por transferencia utilizando modelos preentrenados en PyTorch. Esta técnica nos permite aprovechar modelos robustos y bien entrenados para resolver problemas específicos de manera eficiente. Hemos cubierto los pasos clave, desde la selección y modificación del modelo hasta el entrenamiento y evaluación. Con esta base, puedes explorar y aplicar el aprendizaje por transferencia a una variedad de problemas en el campo del aprendizaje profundo.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='04-02-building-cnn-from-scratch' title="Construcción de una CNN desde Cero">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='04-04-fine-tuning-cnns' title="Ajuste Fino de CNNs">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
