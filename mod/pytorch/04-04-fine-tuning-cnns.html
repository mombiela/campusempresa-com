<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ajuste Fino de CNNs</title>

    <link rel="alternate" href="https://campusempresa.com/mod/pytorch/04-04-fine-tuning-cnns" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/pytorch/04-04-fine-tuning-cnns" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/pytorch/04-04-fine-tuning-cnns" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/pytorch/04-04-fine-tuning-cnns" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/pytorch/04-04-fine-tuning-cnns" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='04-03-transfer-learning' title="Aprendizaje por Transferencia con Modelos Preentrenados">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Ajuste Fino de CNNs</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='05-01-introduction-to-rnns' title="Introducción a las RNNs">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'><p>El ajuste fino (fine-tuning) de redes neuronales convolucionales (CNNs) es una técnica poderosa que permite reutilizar modelos preentrenados en nuevas tareas. En lugar de entrenar una red desde cero, lo cual puede ser costoso en términos de tiempo y recursos, el ajuste fino aprovecha el conocimiento adquirido por una red preentrenada en una tarea similar y lo adapta a una nueva tarea específica.</p>
</div><h1>Conceptos Clave</h1>
<div class='content'><ol>
<li><strong>Modelos Preentrenados</strong>: Modelos que han sido entrenados en grandes conjuntos de datos, como ImageNet.</li>
<li><strong>Transferencia de Aprendizaje</strong>: Técnica que utiliza modelos preentrenados y los adapta a nuevas tareas.</li>
<li><strong>Congelación de Capas</strong>: Proceso de mantener ciertas capas del modelo preentrenado sin cambios durante el entrenamiento.</li>
<li><strong>Descongelación de Capas</strong>: Proceso de permitir que ciertas capas del modelo preentrenado se actualicen durante el entrenamiento.</li>
</ol>
</div><h1>Pasos para el Ajuste Fino de CNNs</h1>
<div class='content'></div><h2>1. Selección del Modelo Preentrenado</h2>
<div class='content'><p>PyTorch proporciona varios modelos preentrenados a través del módulo <code>torchvision.models</code>. Algunos de los modelos más comunes incluyen ResNet, VGG, y AlexNet.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaHZpc2lvbi5tb2RlbHMgYXMgbW9kZWxzCgojIENhcmdhciB1biBtb2RlbG8gcHJlZW50cmVuYWRvCm1vZGVsID0gbW9kZWxzLnJlc25ldDUwKHByZXRyYWluZWQ9VHJ1ZSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torchvision.models as models

# Cargar un modelo preentrenado
model = models.resnet50(pretrained=True)</pre></div><div class='content'></div><h2>2. Congelación de Capas</h2>
<div class='content'><p>Para evitar que las capas preentrenadas se actualicen durante el entrenamiento inicial, se pueden &quot;congelar&quot; estas capas.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Zm9yIHBhcmFtIGluIG1vZGVsLnBhcmFtZXRlcnMoKToKICAgIHBhcmFtLnJlcXVpcmVzX2dyYWQgPSBGYWxzZQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>for param in model.parameters():
    param.requires_grad = False</pre></div><div class='content'></div><h2>3. Modificación de la Capa de Salida</h2>
<div class='content'><p>La capa de salida del modelo debe ser modificada para que coincida con el número de clases de la nueva tarea.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm5uIGFzIG5uCgojIE1vZGlmaWNhciBsYSBjYXBhIGRlIHNhbGlkYSBwYXJhIHVuYSBudWV2YSB0YXJlYSBjb24gMTAgY2xhc2VzCm51bV9mdHJzID0gbW9kZWwuZmMuaW5fZmVhdHVyZXMKbW9kZWwuZmMgPSBubi5MaW5lYXIobnVtX2Z0cnMsIDEwKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.nn as nn

# Modificar la capa de salida para una nueva tarea con 10 clases
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 10)</pre></div><div class='content'></div><h2>4. Definición del Optimizador y la Función de Pérdida</h2>
<div class='content'><p>Definir el optimizador y la función de pérdida para el entrenamiento.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm9wdGltIGFzIG9wdGltCgpjcml0ZXJpb24gPSBubi5Dcm9zc0VudHJvcHlMb3NzKCkKb3B0aW1pemVyID0gb3B0aW0uU0dEKG1vZGVsLmZjLnBhcmFtZXRlcnMoKSwgbHI9MC4wMDEsIG1vbWVudHVtPTAuOSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)</pre></div><div class='content'></div><h2>5. Entrenamiento del Modelo</h2>
<div class='content'><p>Entrenar el modelo con los datos de la nueva tarea.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBFamVtcGxvIGRlIGJ1Y2xlIGRlIGVudHJlbmFtaWVudG8gc2ltcGxpZmljYWRvCmZvciBlcG9jaCBpbiByYW5nZShudW1fZXBvY2hzKToKICAgIGZvciBpbnB1dHMsIGxhYmVscyBpbiBkYXRhbG9hZGVyOgogICAgICAgIG9wdGltaXplci56ZXJvX2dyYWQoKQogICAgICAgIG91dHB1dHMgPSBtb2RlbChpbnB1dHMpCiAgICAgICAgbG9zcyA9IGNyaXRlcmlvbihvdXRwdXRzLCBsYWJlbHMpCiAgICAgICAgbG9zcy5iYWNrd2FyZCgpCiAgICAgICAgb3B0aW1pemVyLnN0ZXAoKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Ejemplo de bucle de entrenamiento simplificado
for epoch in range(num_epochs):
    for inputs, labels in dataloader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()</pre></div><div class='content'></div><h2>6. Descongelación de Capas y Ajuste Fino</h2>
<div class='content'><p>Después de entrenar la capa de salida, se pueden descongelar algunas de las capas preentrenadas para ajustar finamente el modelo.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEZXNjb25nZWxhciB0b2RhcyBsYXMgY2FwYXMKZm9yIHBhcmFtIGluIG1vZGVsLnBhcmFtZXRlcnMoKToKICAgIHBhcmFtLnJlcXVpcmVzX2dyYWQgPSBUcnVlCgojIFJlZGVmaW5pciBlbCBvcHRpbWl6YWRvciBwYXJhIGluY2x1aXIgdG9kb3MgbG9zIHBhcsOhbWV0cm9zCm9wdGltaXplciA9IG9wdGltLlNHRChtb2RlbC5wYXJhbWV0ZXJzKCksIGxyPTAuMDAwMSwgbW9tZW50dW09MC45KQoKIyBDb250aW51YXIgZWwgZW50cmVuYW1pZW50bwpmb3IgZXBvY2ggaW4gcmFuZ2UobnVtX2ZpbmVfdHVuZV9lcG9jaHMpOgogICAgZm9yIGlucHV0cywgbGFiZWxzIGluIGRhdGFsb2FkZXI6CiAgICAgICAgb3B0aW1pemVyLnplcm9fZ3JhZCgpCiAgICAgICAgb3V0cHV0cyA9IG1vZGVsKGlucHV0cykKICAgICAgICBsb3NzID0gY3JpdGVyaW9uKG91dHB1dHMsIGxhYmVscykKICAgICAgICBsb3NzLmJhY2t3YXJkKCkKICAgICAgICBvcHRpbWl6ZXIuc3RlcCgp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Descongelar todas las capas
for param in model.parameters():
    param.requires_grad = True

# Redefinir el optimizador para incluir todos los par&aacute;metros
optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)

# Continuar el entrenamiento
for epoch in range(num_fine_tune_epochs):
    for inputs, labels in dataloader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()</pre></div><div class='content'></div><h1>Ejercicio Práctico</h1>
<div class='content'></div><h2>Ejercicio</h2>
<div class='content'><ol>
<li>Selecciona un modelo preentrenado de <code>torchvision.models</code>.</li>
<li>Congela todas las capas del modelo.</li>
<li>Modifica la capa de salida para una tarea de clasificación con 5 clases.</li>
<li>Entrena el modelo con un conjunto de datos de tu elección.</li>
<li>Descongela las capas y realiza un ajuste fino del modelo.</li>
</ol>
</div><h2>Solución</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torchvision.models as models
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# 1. Selecci&oacute;n del modelo preentrenado
model = models.resnet50(pretrained=True)

# 2. Congelaci&oacute;n de todas las capas
for param in model.parameters():
    param.requires_grad = False

# 3. Modificaci&oacute;n de la capa de salida
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 5)

# 4. Definici&oacute;n del optimizador y la funci&oacute;n de p&eacute;rdida
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)

# 5. Preparaci&oacute;n de los datos
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
])

train_dataset = datasets.FakeData(transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Entrenamiento inicial
num_epochs = 5
for epoch in range(num_epochs):
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

# 6. Descongelaci&oacute;n de capas y ajuste fino
for param in model.parameters():
    param.requires_grad = True

optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)

num_fine_tune_epochs = 5
for epoch in range(num_fine_tune_epochs):
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>El ajuste fino de CNNs es una técnica eficiente para adaptar modelos preentrenados a nuevas tareas, ahorrando tiempo y recursos. Al congelar y descongelar capas estratégicamente, se puede aprovechar el conocimiento previo del modelo y mejorar su rendimiento en la nueva tarea. Esta técnica es especialmente útil en escenarios donde los datos de entrenamiento son limitados.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='04-03-transfer-learning' title="Aprendizaje por Transferencia con Modelos Preentrenados">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='05-01-introduction-to-rnns' title="Introducción a las RNNs">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
