<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introducción a las RNNs</title>

    <link rel="alternate" href="https://campusempresa.com/mod/pytorch/05-01-introduction-to-rnns" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/pytorch/05-01-introduction-to-rnns" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/pytorch/05-01-introduction-to-rnns" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 px-0 py-2 py-md-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 px-0 py-2 py-md-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/pytorch/05-01-introduction-to-rnns" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/pytorch/05-01-introduction-to-rnns" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='04-04-fine-tuning-cnns' title="Ajuste Fino de CNNs">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Introducción a las RNNs</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='05-02-building-rnn-from-scratch' title="Construcción de una RNN desde Cero">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>¿Qué son las Redes Neuronales Recurrentes (RNNs)?</h1>
<div class='content'><p>Las Redes Neuronales Recurrentes (RNNs) son un tipo de red neuronal diseñada para trabajar con datos secuenciales. A diferencia de las redes neuronales tradicionales, las RNNs tienen conexiones recurrentes que permiten que la información persista. Esto las hace especialmente útiles para tareas donde el contexto y el orden de los datos son importantes, como el procesamiento de lenguaje natural (NLP), la traducción automática, y el análisis de series temporales.</p>
</div><h2>Características Clave de las RNNs:</h2>
<div class='content'><ul>
<li><strong>Memoria</strong>: Las RNNs pueden recordar información de entradas anteriores gracias a sus conexiones recurrentes.</li>
<li><strong>Parámetros Compartidos</strong>: Los mismos parámetros (pesos) se aplican a cada paso de la secuencia, lo que reduce la complejidad del modelo.</li>
<li><strong>Capacidad de Modelar Secuencias</strong>: Son ideales para datos secuenciales donde el orden de los datos es crucial.</li>
</ul>
</div><h1>Arquitectura de una RNN</h1>
<div class='content'><p>Una RNN típica consiste en una capa recurrente que procesa una secuencia de entradas. Cada unidad en la capa recurrente tiene una conexión hacia adelante y una conexión recurrente que alimenta su propia salida de vuelta como entrada en el siguiente paso de tiempo.</p>
</div><h2>Diagrama de una RNN Simple:</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("eF90IC0+IFtoX3RdIC0+IHlfdAogICAgICBeICAgfAogICAgICB8ICAgdgogICAgICBoXyh0LTEp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>x_t -&gt; [h_t] -&gt; y_t
      ^   |
      |   v
      h_(t-1)</pre></div><div class='content'><ul>
<li><strong>x_t</strong>: Entrada en el tiempo t.</li>
<li><strong>h_t</strong>: Estado oculto en el tiempo t.</li>
<li><strong>y_t</strong>: Salida en el tiempo t.</li>
<li><strong>h_(t-1)</strong>: Estado oculto en el tiempo t-1.</li>
</ul>
</div><h1>Implementación Básica de una RNN en PyTorch</h1>
<div class='content'><p>Vamos a implementar una RNN simple en PyTorch para entender mejor su funcionamiento.</p>
</div><h2>Paso 1: Importar las Bibliotecas Necesarias</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubiBhcyBubgppbXBvcnQgdG9yY2gub3B0aW0gYXMgb3B0aW0="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torch.nn as nn
import torch.optim as optim</pre></div><div class='content'></div><h2>Paso 2: Definir la Arquitectura de la RNN</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgU2ltcGxlUk5OKG5uLk1vZHVsZSk6CiAgICBkZWYgX19pbml0X18oc2VsZiwgaW5wdXRfc2l6ZSwgaGlkZGVuX3NpemUsIG91dHB1dF9zaXplKToKICAgICAgICBzdXBlcihTaW1wbGVSTk4sIHNlbGYpLl9faW5pdF9fKCkKICAgICAgICBzZWxmLmhpZGRlbl9zaXplID0gaGlkZGVuX3NpemUKICAgICAgICBzZWxmLnJubiA9IG5uLlJOTihpbnB1dF9zaXplLCBoaWRkZW5fc2l6ZSwgYmF0Y2hfZmlyc3Q9VHJ1ZSkKICAgICAgICBzZWxmLmZjID0gbm4uTGluZWFyKGhpZGRlbl9zaXplLCBvdXRwdXRfc2l6ZSkKICAgIAogICAgZGVmIGZvcndhcmQoc2VsZiwgeCk6CiAgICAgICAgaDAgPSB0b3JjaC56ZXJvcygxLCB4LnNpemUoMCksIHNlbGYuaGlkZGVuX3NpemUpLnRvKHguZGV2aWNlKQogICAgICAgIG91dCwgaG4gPSBzZWxmLnJubih4LCBoMCkKICAgICAgICBvdXQgPSBzZWxmLmZjKG91dFs6LCAtMSwgOl0pCiAgICAgICAgcmV0dXJuIG91dA=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class SimpleRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleRNN, self).__init__()
        self.hidden_size = hidden_size
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)
        out, hn = self.rnn(x, h0)
        out = self.fc(out[:, -1, :])
        return out</pre></div><div class='content'><ul>
<li><strong>input_size</strong>: Dimensión de la entrada.</li>
<li><strong>hidden_size</strong>: Dimensión del estado oculto.</li>
<li><strong>output_size</strong>: Dimensión de la salida.</li>
</ul>
</div><h2>Paso 3: Crear una Instancia del Modelo y Definir el Optimizador y la Función de Pérdida</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW5wdXRfc2l6ZSA9IDEwCmhpZGRlbl9zaXplID0gMjAKb3V0cHV0X3NpemUgPSAxCgptb2RlbCA9IFNpbXBsZVJOTihpbnB1dF9zaXplLCBoaWRkZW5fc2l6ZSwgb3V0cHV0X3NpemUpCmNyaXRlcmlvbiA9IG5uLk1TRUxvc3MoKQpvcHRpbWl6ZXIgPSBvcHRpbS5BZGFtKG1vZGVsLnBhcmFtZXRlcnMoKSwgbHI9MC4wMDEp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>input_size = 10
hidden_size = 20
output_size = 1

model = SimpleRNN(input_size, hidden_size, output_size)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)</pre></div><div class='content'></div><h2>Paso 4: Entrenar la RNN</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEYXRvcyBkZSBlamVtcGxvCmlucHV0cyA9IHRvcmNoLnJhbmRuKDEwMCwgNSwgaW5wdXRfc2l6ZSkgICMgKGJhdGNoX3NpemUsIHNlcXVlbmNlX2xlbmd0aCwgaW5wdXRfc2l6ZSkKdGFyZ2V0cyA9IHRvcmNoLnJhbmRuKDEwMCwgb3V0cHV0X3NpemUpICAgIyAoYmF0Y2hfc2l6ZSwgb3V0cHV0X3NpemUpCgpudW1fZXBvY2hzID0gMTAwCmZvciBlcG9jaCBpbiByYW5nZShudW1fZXBvY2hzKToKICAgIG1vZGVsLnRyYWluKCkKICAgIG91dHB1dHMgPSBtb2RlbChpbnB1dHMpCiAgICBsb3NzID0gY3JpdGVyaW9uKG91dHB1dHMsIHRhcmdldHMpCiAgICAKICAgIG9wdGltaXplci56ZXJvX2dyYWQoKQogICAgbG9zcy5iYWNrd2FyZCgpCiAgICBvcHRpbWl6ZXIuc3RlcCgpCiAgICAKICAgIGlmIChlcG9jaCsxKSAlIDEwID09IDA6CiAgICAgICAgcHJpbnQoZidFcG9jaCBbe2Vwb2NoKzF9L3tudW1fZXBvY2hzfV0sIExvc3M6IHtsb3NzLml0ZW0oKTouNGZ9Jyk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Datos de ejemplo
inputs = torch.randn(100, 5, input_size)  # (batch_size, sequence_length, input_size)
targets = torch.randn(100, output_size)   # (batch_size, output_size)

num_epochs = 100
for epoch in range(num_epochs):
    model.train()
    outputs = model(inputs)
    loss = criterion(outputs, targets)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if (epoch+1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')</pre></div><div class='content'></div><h1>Ejercicio Práctico</h1>
<div class='content'></div><h2>Ejercicio 1: Implementar una RNN para Predecir una Serie Temporal</h2>
<div class='content'><ol>
<li><strong>Objetivo</strong>: Implementar una RNN que prediga el siguiente valor en una serie temporal.</li>
<li><strong>Datos</strong>: Generar una serie temporal sintética.</li>
<li><strong>Pasos</strong>:
<ul>
<li>Generar datos de entrenamiento y prueba.</li>
<li>Definir la arquitectura de la RNN.</li>
<li>Entrenar la RNN.</li>
<li>Evaluar el rendimiento del modelo.</li>
</ul>
</li>
</ol>
</div><h2>Solución del Ejercicio 1</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Generar datos sint&eacute;ticos
def generate_data(seq_length, num_samples):
    X = np.array([np.sin(np.linspace(0, 2*np.pi, seq_length)) for _ in range(num_samples)])
    y = np.array([np.sin(np.linspace(0, 2*np.pi, seq_length+1))[1:] for _ in range(num_samples)])
    return X, y

seq_length = 50
num_samples = 1000
X, y = generate_data(seq_length, num_samples)

# Convertir a tensores
X = torch.tensor(X, dtype=torch.float32)
y = torch.tensor(y, dtype=torch.float32)

# Definir la RNN
class TimeSeriesRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(TimeSeriesRNN, self).__init__()
        self.hidden_size = hidden_size
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)
        out, hn = self.rnn(x, h0)
        out = self.fc(out[:, -1, :])
        return out

input_size = 1
hidden_size = 20
output_size = 1

model = TimeSeriesRNN(input_size, hidden_size, output_size)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Entrenar la RNN
num_epochs = 100
for epoch in range(num_epochs):
    model.train()
    outputs = model(X.unsqueeze(-1))
    loss = criterion(outputs, y.unsqueeze(-1))
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if (epoch+1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, hemos introducido las Redes Neuronales Recurrentes (RNNs) y su arquitectura básica. También hemos implementado una RNN simple en PyTorch y un ejercicio práctico para predecir una serie temporal. Las RNNs son poderosas para trabajar con datos secuenciales, pero también tienen limitaciones, como la dificultad para aprender dependencias a largo plazo. En las siguientes secciones, exploraremos variantes de RNNs como LSTM y GRU que abordan algunas de estas limitaciones.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='04-04-fine-tuning-cnns' title="Ajuste Fino de CNNs">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='05-02-building-rnn-from-scratch' title="Construcción de una RNN desde Cero">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
