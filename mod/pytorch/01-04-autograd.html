<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Autograd: Diferenciación Automática</title>

    <link rel="alternate" href="https://campusempresa.com/mod/pytorch/01-04-autograd" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/pytorch/01-04-autograd" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/pytorch/01-04-autograd" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<a href="https://enterprisecampus.net/mod/pytorch/01-04-autograd" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/pytorch/01-04-autograd" class="px-2">CA</a>
<br>
			<cite>Construyendo la sociedad de hoy y del mañana</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Lenguajes de Programación</a>
				 					<a href="/categ/frameworks">Frameworks y Librerías</a>
				 					<a href="/categ/tech-tools">Herramientas Técnicas</a>
				 					<a href="/categ/foundations">Fundamentos Teóricos</a>
				 					<a href="/categ/soft-skills">Habilidades Sociales</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='01-03-basic-tensor-operations' title="Operaciones Básicas con Tensores">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Autograd: Diferenciación Automática</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='02-01-introduction-to-neural-networks' title="Introducción a las Redes Neuronales">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1><p>Introducción</p>
</h1>
<div class='content'><p>En este tema, aprenderemos sobre <code>autograd</code>, una de las características más poderosas de PyTorch. <code>autograd</code> es el motor de diferenciación automática de PyTorch que permite calcular gradientes automáticamente. Esto es esencial para el entrenamiento de redes neuronales, ya que los gradientes son necesarios para actualizar los pesos de la red durante el proceso de optimización.</p>
</div><h1><p>Conceptos Clave</p>
</h1>
<div class='content'><ol>
<li><strong>Tensores con Gradientes</strong>: Tensores que tienen la capacidad de rastrear todas las operaciones que se realizan sobre ellos para calcular gradientes.</li>
<li><strong>Función de Pérdida</strong>: Una función que mide qué tan bien o mal está funcionando el modelo.</li>
<li><strong>Backpropagation</strong>: El proceso de calcular los gradientes de la función de pérdida con respecto a los parámetros del modelo.</li>
</ol>
</div><h1><p>Tensores con Gradientes</p>
</h1>
<div class='content'><p>Para que un tensor rastree las operaciones y calcule gradientes, debemos establecer su atributo <code>requires_grad</code> a <code>True</code>.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCgojIENyZWFyIHVuIHRlbnNvciBjb24gcmVxdWlyZXNfZ3JhZD1UcnVlCnggPSB0b3JjaC50ZW5zb3IoWzEuMCwgMi4wLCAzLjBdLCByZXF1aXJlc19ncmFkPVRydWUpCnByaW50KHgp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch

# Crear un tensor con requires_grad=True
x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
print(x)</pre></div><div class='content'><p>Salida:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dGVuc29yKFsxLiwgMi4sIDMuXSwgcmVxdWlyZXNfZ3JhZD1UcnVlKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>tensor([1., 2., 3.], requires_grad=True)</pre></div><div class='content'></div><h1><p>Operaciones y Gradientes</p>
</h1>
<div class='content'><p>Cuando realizamos operaciones en tensores con <code>requires_grad=True</code>, PyTorch construye un gráfico computacional dinámico. Este gráfico permite calcular los gradientes automáticamente mediante backpropagation.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBSZWFsaXphciBvcGVyYWNpb25lcwp5ID0geCArIDIKeiA9IHkgKiB5ICogMwpvdXQgPSB6Lm1lYW4oKQoKcHJpbnQoeSwgeiwgb3V0KQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Realizar operaciones
y = x + 2
z = y * y * 3
out = z.mean()

print(y, z, out)</pre></div><div class='content'><p>Salida:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dGVuc29yKFszLiwgNC4sIDUuXSwgZ3JhZF9mbj08QWRkQmFja3dhcmQwPikKdGVuc29yKFsyNy4sIDQ4LiwgNzUuXSwgZ3JhZF9mbj08TXVsQmFja3dhcmQwPikKdGVuc29yKDUwLiwgZ3JhZF9mbj08TWVhbkJhY2t3YXJkMD4p"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>tensor([3., 4., 5.], grad_fn=&lt;AddBackward0&gt;)
tensor([27., 48., 75.], grad_fn=&lt;MulBackward0&gt;)
tensor(50., grad_fn=&lt;MeanBackward0&gt;)</pre></div><div class='content'></div><h1><p>Backpropagation</p>
</h1>
<div class='content'><p>Para calcular los gradientes, utilizamos el método <code>backward()</code> en el tensor de salida.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBSZWFsaXphciBiYWNrcHJvcGFnYXRpb24Kb3V0LmJhY2t3YXJkKCkKCiMgeC5ncmFkIGNvbnRpZW5lIGxvcyBncmFkaWVudGVzIGRlIG91dCBjb24gcmVzcGVjdG8gYSB4CnByaW50KHguZ3JhZCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Realizar backpropagation
out.backward()

# x.grad contiene los gradientes de out con respecto a x
print(x.grad)</pre></div><div class='content'><p>Salida:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dGVuc29yKFs0LjUwMDAsIDYuMDAwMCwgNy41MDAwXSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>tensor([4.5000, 6.0000, 7.5000])</pre></div><div class='content'></div><h1><p>Ejemplo Completo</p>
</h1>
<div class='content'><p>A continuación, se muestra un ejemplo completo que ilustra cómo usar <code>autograd</code> para calcular gradientes.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCgojIENyZWFyIHVuIHRlbnNvciBjb24gcmVxdWlyZXNfZ3JhZD1UcnVlCnggPSB0b3JjaC50ZW5zb3IoWzEuMCwgMi4wLCAzLjBdLCByZXF1aXJlc19ncmFkPVRydWUpCgojIFJlYWxpemFyIG9wZXJhY2lvbmVzCnkgPSB4ICsgMgp6ID0geSAqIHkgKiAzCm91dCA9IHoubWVhbigpCgojIFJlYWxpemFyIGJhY2twcm9wYWdhdGlvbgpvdXQuYmFja3dhcmQoKQoKIyBNb3N0cmFyIGxvcyBncmFkaWVudGVzCnByaW50KCJ4OiIsIHgpCnByaW50KCJHcmFkaWVudGVzIGRlIHg6IiwgeC5ncmFkKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch

# Crear un tensor con requires_grad=True
x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)

# Realizar operaciones
y = x + 2
z = y * y * 3
out = z.mean()

# Realizar backpropagation
out.backward()

# Mostrar los gradientes
print(&quot;x:&quot;, x)
print(&quot;Gradientes de x:&quot;, x.grad)</pre></div><div class='content'><p>Salida:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("eDogdGVuc29yKFsxLiwgMi4sIDMuXSwgcmVxdWlyZXNfZ3JhZD1UcnVlKQpHcmFkaWVudGVzIGRlIHg6IHRlbnNvcihbNC41MDAwLCA2LjAwMDAsIDcuNTAwMF0p"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>x: tensor([1., 2., 3.], requires_grad=True)
Gradientes de x: tensor([4.5000, 6.0000, 7.5000])</pre></div><div class='content'></div><h1><p>Ejercicio Práctico</p>
</h1>
<div class='content'></div><h2><p>Ejercicio 1</p>
</h2>
<div class='content'><p>Crea un tensor <code>a</code> con valores <code>[2.0, 3.0, 4.0]</code> y <code>requires_grad=True</code>. Realiza las siguientes operaciones y calcula los gradientes:</p>
<ol>
<li><code>b = a * 2</code></li>
<li><code>c = b ** 2</code></li>
<li><code>d = c.sum()</code></li>
</ol>
<p>Realiza backpropagation y muestra los gradientes de <code>a</code>.</p>
</div><h2><p>Solución</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCgojIENyZWFyIGVsIHRlbnNvcgphID0gdG9yY2gudGVuc29yKFsyLjAsIDMuMCwgNC4wXSwgcmVxdWlyZXNfZ3JhZD1UcnVlKQoKIyBSZWFsaXphciBvcGVyYWNpb25lcwpiID0gYSAqIDIKYyA9IGIgKiogMgpkID0gYy5zdW0oKQoKIyBSZWFsaXphciBiYWNrcHJvcGFnYXRpb24KZC5iYWNrd2FyZCgpCgojIE1vc3RyYXIgbG9zIGdyYWRpZW50ZXMKcHJpbnQoImE6IiwgYSkKcHJpbnQoIkdyYWRpZW50ZXMgZGUgYToiLCBhLmdyYWQp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch

# Crear el tensor
a = torch.tensor([2.0, 3.0, 4.0], requires_grad=True)

# Realizar operaciones
b = a * 2
c = b ** 2
d = c.sum()

# Realizar backpropagation
d.backward()

# Mostrar los gradientes
print(&quot;a:&quot;, a)
print(&quot;Gradientes de a:&quot;, a.grad)</pre></div><div class='content'><p>Salida esperada:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("YTogdGVuc29yKFsyLiwgMy4sIDQuXSwgcmVxdWlyZXNfZ3JhZD1UcnVlKQpHcmFkaWVudGVzIGRlIGE6IHRlbnNvcihbIDguLCAxMi4sIDE2Ll0p"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>a: tensor([2., 3., 4.], requires_grad=True)
Gradientes de a: tensor([ 8., 12., 16.])</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En esta sección, hemos aprendido sobre <code>autograd</code> y cómo PyTorch facilita el cálculo de gradientes automáticamente. Esto es fundamental para el entrenamiento de redes neuronales, ya que permite optimizar los parámetros del modelo de manera eficiente. En el próximo módulo, comenzaremos a construir redes neuronales utilizando estos conceptos básicos.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='01-03-basic-tensor-operations' title="Operaciones Básicas con Tensores">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='02-01-introduction-to-neural-networks' title="Introducción a las Redes Neuronales">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
