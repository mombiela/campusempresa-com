<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Preguntas y Respuestas de Muestra</title>

    <link rel="alternate" href="https://campusempresa.com/mod/hadoop/sample-questions-and-answers" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/hadoop/sample-questions-and-answers" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/hadoop/sample-questions-and-answers" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body  class="test" >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/hadoop/sample-questions-and-answers" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/hadoop/sample-questions-and-answers" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
									<div class="assert">
						<p><b>Atención!</b> Ha habido un error en la generación del curso y puede contener errores de traducción.Estamos trabajando para solucinarlo por lo que se deben usar los contenidos con cuidado.Se puede consultar el contenido correcto en otro idioma en el siguiente enlace:<br>
						<a href="https://enterprisecampus.net/mod/hadoop/sample-questions-and-answers">https://enterprisecampus.net/mod/hadoop/sample-questions-and-answers</a></p>
					</div>
								<div class='row navigation'>
	<div class='col-4'>
					<a href='exam-preparation-tips'>&#x25C4;Consejos para la Preparación del Examen</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Preguntas y Respuestas de Muestra</a>
	</div>
	<div class='col-4 text-end'>
					<a href='mock-exams'>Exámenes de Prueba &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Nivel Principiante</h1>
<div class='content'></div><h2>¿Qué es Hadoop?</h2>
<div class='content'><p>Hadoop es un marco de trabajo de código abierto que permite el procesamiento distribuido de grandes conjuntos de datos a través de clústeres de computadoras utilizando modelos de programación simples. Está diseñado para escalar desde servidores individuales hasta miles de máquinas, cada una ofreciendo computación y almacenamiento local.</p>
</div><h2>¿Cuáles son los componentes principales de Hadoop?</h2>
<div class='content'><ul>
<li><strong>HDFS (Hadoop Distributed File System)</strong>: Un sistema de archivos distribuido que proporciona acceso de alto rendimiento a los datos de las aplicaciones.</li>
<li><strong>YARN (Yet Another Resource Negotiator)</strong>: Una capa de gestión de recursos para la programación y gestión de recursos del clúster.</li>
<li><strong>MapReduce</strong>: Un modelo de programación para procesar grandes conjuntos de datos con un algoritmo distribuido en un clúster de Hadoop.</li>
</ul>
</div><h2>¿Cómo funciona HDFS?</h2>
<div class='content'><p>HDFS divide archivos grandes en bloques más pequeños y los distribuye a través de nodos en un clúster. Cada bloque se replica varias veces para asegurar la tolerancia a fallos.</p>
</div><h2>Código de Muestra: Conteo de Palabras en Hadoop MapReduce</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CmltcG9ydCBqYXZhLnV0aWwuU3RyaW5nVG9rZW5pemVyOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuY29uZi5Db25maWd1cmF0aW9uOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuZnMuUGF0aDsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLkludFdyaXRhYmxlOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuaW8uVGV4dDsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLm1hcHJlZHVjZS5Kb2I7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuTWFwcGVyOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AubWFwcmVkdWNlLlJlZHVjZXI7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UubGliLmlucHV0LkZpbGVJbnB1dEZvcm1hdDsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLm1hcHJlZHVjZS5saWIub3V0cHV0LkZpbGVPdXRwdXRGb3JtYXQ7CgpwdWJsaWMgY2xhc3MgV29yZENvdW50IHsKCiAgcHVibGljIHN0YXRpYyBjbGFzcyBUb2tlbml6ZXJNYXBwZXIgZXh0ZW5kcyBNYXBwZXI8T2JqZWN0LCBUZXh0LCBUZXh0LCBJbnRXcml0YWJsZT57CiAgICBwcml2YXRlIGZpbmFsIHN0YXRpYyBJbnRXcml0YWJsZSBvbmUgPSBuZXcgSW50V3JpdGFibGUoMSk7CiAgICBwcml2YXRlIFRleHQgd29yZCA9IG5ldyBUZXh0KCk7CgogICAgcHVibGljIHZvaWQgbWFwKE9iamVjdCBrZXksIFRleHQgdmFsdWUsIENvbnRleHQgY29udGV4dCkgdGhyb3dzIElPRXhjZXB0aW9uLCBJbnRlcnJ1cHRlZEV4Y2VwdGlvbiB7CiAgICAgIFN0cmluZ1Rva2VuaXplciBpdHIgPSBuZXcgU3RyaW5nVG9rZW5pemVyKHZhbHVlLnRvU3RyaW5nKCkpOwogICAgICB3aGlsZSAoaXRyLmhhc01vcmVUb2tlbnMoKSkgewogICAgICAgIHdvcmQuc2V0KGl0ci5uZXh0VG9rZW4oKSk7CiAgICAgICAgY29udGV4dC53cml0ZSh3b3JkLCBvbmUpOwogICAgICB9CiAgICB9CiAgfQoKICBwdWJsaWMgc3RhdGljIGNsYXNzIEludFN1bVJlZHVjZXIgZXh0ZW5kcyBSZWR1Y2VyPFRleHQsIEludFdyaXRhYmxlLCBUZXh0LCBJbnRXcml0YWJsZT4gewogICAgcHJpdmF0ZSBJbnRXcml0YWJsZSByZXN1bHQgPSBuZXcgSW50V3JpdGFibGUoKTsKCiAgICBwdWJsaWMgdm9pZCByZWR1Y2UoVGV4dCBrZXksIEl0ZXJhYmxlPEludFdyaXRhYmxlPiB2YWx1ZXMsIENvbnRleHQgY29udGV4dCkgdGhyb3dzIElPRXhjZXB0aW9uLCBJbnRlcnJ1cHRlZEV4Y2VwdGlvbiB7CiAgICAgIGludCBzdW0gPSAwOwogICAgICBmb3IgKEludFdyaXRhYmxlIHZhbCA6IHZhbHVlcykgewogICAgICAgIHN1bSArPSB2YWwuZ2V0KCk7CiAgICAgIH0KICAgICAgcmVzdWx0LnNldChzdW0pOwogICAgICBjb250ZXh0LndyaXRlKGtleSwgcmVzdWx0KTsKICAgIH0KICB9CgogIHB1YmxpYyBzdGF0aWMgdm9pZCBtYWluKFN0cmluZ1tdIGFyZ3MpIHRocm93cyBFeGNlcHRpb24gewogICAgQ29uZmlndXJhdGlvbiBjb25mID0gbmV3IENvbmZpZ3VyYXRpb24oKTsKICAgIEpvYiBqb2IgPSBKb2IuZ2V0SW5zdGFuY2UoY29uZiwgIndvcmQgY291bnQiKTsKICAgIGpvYi5zZXRKYXJCeUNsYXNzKFdvcmRDb3VudC5jbGFzcyk7CiAgICBqb2Iuc2V0TWFwcGVyQ2xhc3MoVG9rZW5pemVyTWFwcGVyLmNsYXNzKTsKICAgIGpvYi5zZXRDb21iaW5lckNsYXNzKEludFN1bVJlZHVjZXIuY2xhc3MpOwogICAgam9iLnNldFJlZHVjZXJDbGFzcyhJbnRTdW1SZWR1Y2VyLmNsYXNzKTsKICAgIGpvYi5zZXRPdXRwdXRLZXlDbGFzcyhUZXh0LmNsYXNzKTsKICAgIGpvYi5zZXRPdXRwdXRWYWx1ZUNsYXNzKEludFdyaXRhYmxlLmNsYXNzKTsKICAgIEZpbGVJbnB1dEZvcm1hdC5hZGRJbnB1dFBhdGgoam9iLCBuZXcgUGF0aChhcmdzWzBdKSk7CiAgICBGaWxlT3V0cHV0Rm9ybWF0LnNldE91dHB1dFBhdGgoam9iLCBuZXcgUGF0aChhcmdzWzFdKSk7CiAgICBTeXN0ZW0uZXhpdChqb2Iud2FpdEZvckNvbXBsZXRpb24odHJ1ZSkgPyAwIDogMSk7CiAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import java.util.StringTokenizer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

  public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;{
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer(value.toString());
      while (itr.hasMoreTokens()) {
        word.set(itr.nextToken());
        context.write(word, one);
      }
    }
  }

  public static class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      result.set(sum);
      context.write(key, result);
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf, &quot;word count&quot;);
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}</pre></div><div class='content'></div><h2>Explicación</h2>
<div class='content'><ul>
<li><strong>TokenizerMapper</strong>: Tokeniza el texto de entrada y emite cada palabra con un conteo de 1.</li>
<li><strong>IntSumReducer</strong>: Suma todos los conteos para cada palabra.</li>
<li><strong>Método Principal</strong>: Configura y ejecuta el trabajo de MapReduce.</li>
</ul>
</div><h1>Nivel Intermedio</h1>
<div class='content'></div><h2>¿Cuál es el papel de YARN en Hadoop?</h2>
<div class='content'><p>YARN es responsable de gestionar los recursos en un clúster de Hadoop y programar trabajos. Permite que múltiples motores de procesamiento de datos, como procesamiento por lotes, procesamiento de flujos, procesamiento interactivo y procesamiento de gráficos, se ejecuten y procesen datos almacenados en HDFS.</p>
</div><h2>¿Cómo se configura un clúster de Hadoop?</h2>
<div class='content'><ul>
<li><strong>Core-site.xml</strong>: Contiene configuraciones para el núcleo de Hadoop, incluidas las configuraciones de I/O.</li>
<li><strong>Hdfs-site.xml</strong>: Contiene configuraciones para los demonios de HDFS, el NameNode y los DataNodes.</li>
<li><strong>Mapred-site.xml</strong>: Contiene configuraciones para trabajos de MapReduce.</li>
<li><strong>Yarn-site.xml</strong>: Contiene configuraciones para los demonios de YARN, el ResourceManager y el NodeManager.</li>
</ul>
</div><h2>Código de Muestra: Particionador Personalizado en Hadoop</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLkludFdyaXRhYmxlOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AuaW8uVGV4dDsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLm1hcHJlZHVjZS5QYXJ0aXRpb25lcjsKCnB1YmxpYyBjbGFzcyBDdXN0b21QYXJ0aXRpb25lciBleHRlbmRzIFBhcnRpdGlvbmVyPFRleHQsIEludFdyaXRhYmxlPiB7CgogIEBPdmVycmlkZQogIHB1YmxpYyBpbnQgZ2V0UGFydGl0aW9uKFRleHQga2V5LCBJbnRXcml0YWJsZSB2YWx1ZSwgaW50IG51bVBhcnRpdGlvbnMpIHsKICAgIFN0cmluZyB3b3JkID0ga2V5LnRvU3RyaW5nKCk7CiAgICBpZiAod29yZC5zdGFydHNXaXRoKCJhIikgfHwgd29yZC5zdGFydHNXaXRoKCJBIikpIHsKICAgICAgcmV0dXJuIDA7CiAgICB9IGVsc2UgewogICAgICByZXR1cm4gMSAlIG51bVBhcnRpdGlvbnM7CiAgICB9CiAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Partitioner;

public class CustomPartitioner extends Partitioner&lt;Text, IntWritable&gt; {

  @Override
  public int getPartition(Text key, IntWritable value, int numPartitions) {
    String word = key.toString();
    if (word.startsWith(&quot;a&quot;) || word.startsWith(&quot;A&quot;)) {
      return 0;
    } else {
      return 1 % numPartitions;
    }
  }
}</pre></div><div class='content'></div><h2>Explicación</h2>
<div class='content'><ul>
<li><strong>CustomPartitioner</strong>: Dirige las palabras que comienzan con 'a' o 'A' a una partición y todas las demás palabras a otra partición.</li>
</ul>
</div><h1>Nivel Avanzado</h1>
<div class='content'></div><h2>¿Cómo se optimiza un trabajo de Hadoop?</h2>
<div class='content'><ul>
<li><strong>Combiner</strong>: Utiliza un combiner para reducir la cantidad de datos transferidos entre las fases de map y reduce.</li>
<li><strong>Ejecución Especulativa</strong>: Habilita la ejecución especulativa para manejar tareas que se ejecutan lentamente.</li>
<li><strong>Localidad de Datos</strong>: Asegura la localidad de datos para minimizar la transferencia de datos a través de la red.</li>
<li><strong>Compresión</strong>: Utiliza compresión para reducir el tamaño de los datos intermedios.</li>
</ul>
</div><h2>¿Cuál es la diferencia entre HDFS y otros sistemas de archivos distribuidos?</h2>
<div class='content'><table>
<thead>
<tr>
<th>Característica</th>
<th>HDFS</th>
<th>Otros Sistemas de Archivos Distribuidos</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tolerancia a Fallos</td>
<td>Alta, con múltiples réplicas</td>
<td>Varía, a menudo menos robusta</td>
</tr>
<tr>
<td>Escalabilidad</td>
<td>Altamente escalable</td>
<td>Varía</td>
</tr>
<tr>
<td>Localidad de Datos</td>
<td>Optimizado para localidad de datos</td>
<td>No siempre optimizado</td>
</tr>
<tr>
<td>Escribir Una Vez, Leer Muchas</td>
<td>Sí</td>
<td>Varía</td>
</tr>
</tbody>
</table>
</div><h2>Código de Muestra: Uso de un Combiner en Hadoop</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5JbnRXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuUmVkdWNlcjsKCnB1YmxpYyBjbGFzcyBXb3JkQ291bnRDb21iaW5lciBleHRlbmRzIFJlZHVjZXI8VGV4dCwgSW50V3JpdGFibGUsIFRleHQsIEludFdyaXRhYmxlPiB7CiAgcHJpdmF0ZSBJbnRXcml0YWJsZSByZXN1bHQgPSBuZXcgSW50V3JpdGFibGUoKTsKCiAgcHVibGljIHZvaWQgcmVkdWNlKFRleHQga2V5LCBJdGVyYWJsZTxJbnRXcml0YWJsZT4gdmFsdWVzLCBDb250ZXh0IGNvbnRleHQpIHRocm93cyBJT0V4Y2VwdGlvbiwgSW50ZXJydXB0ZWRFeGNlcHRpb24gewogICAgaW50IHN1bSA9IDA7CiAgICBmb3IgKEludFdyaXRhYmxlIHZhbCA6IHZhbHVlcykgewogICAgICBzdW0gKz0gdmFsLmdldCgpOwogICAgfQogICAgcmVzdWx0LnNldChzdW0pOwogICAgY29udGV4dC53cml0ZShrZXksIHJlc3VsdCk7CiAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class WordCountCombiner extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
  private IntWritable result = new IntWritable();

  public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
    int sum = 0;
    for (IntWritable val : values) {
      sum += val.get();
    }
    result.set(sum);
    context.write(key, result);
  }
}</pre></div><div class='content'></div><h2>Explicación</h2>
<div class='content'><ul>
<li><strong>WordCountCombiner</strong>: Actúa como un mini-reductor para agregar resultados intermedios, reduciendo la cantidad de datos transferidos entre las fases de map y reduce.</li>
</ul>
</div><h1>Conclusión</h1>
<div class='content'><p>Este tema cubrió una gama de preguntas y respuestas de muestra para Hadoop, desde niveles principiantes hasta avanzados. Comenzamos con conceptos y componentes básicos, pasamos a temas intermedios como YARN y la configuración del clúster, y concluimos con técnicas avanzadas de optimización e implementaciones personalizadas. Al comprender estos ejemplos y explicaciones, los estudiantes pueden obtener una visión más profunda de Hadoop y sus aplicaciones prácticas.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='exam-preparation-tips'>&#x25C4;Consejos para la Preparación del Examen</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Preguntas y Respuestas de Muestra</a>
	</div>
	<div class='col-4 text-end'>
					<a href='mock-exams'>Exámenes de Prueba &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
