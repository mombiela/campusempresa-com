<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Procesamiento de Datos con Hadoop</title>

    <link rel="alternate" href="https://campusempresa.com/mod/hadoop/hadoop-data-processing" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/hadoop/hadoop-data-processing" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/hadoop/hadoop-data-processing" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body  class="test" >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/hadoop/hadoop-data-processing" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/hadoop/hadoop-data-processing" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
									<div class="assert">
						<p><b>Atención!</b> Ha habido un error en la generación del curso y puede contener errores de traducción.Estamos trabajando para solucinarlo por lo que se deben usar los contenidos con cuidado.Se puede consultar el contenido correcto en otro idioma en el siguiente enlace:<br>
						<a href="https://enterprisecampus.net/mod/hadoop/hadoop-data-processing">https://enterprisecampus.net/mod/hadoop/hadoop-data-processing</a></p>
					</div>
								<div class='row navigation'>
	<div class='col-4'>
					<a href='hadoop-data-ingestion'>&#x25C4;Ingesta de Datos en Hadoop</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Procesamiento de Datos con Hadoop</a>
	</div>
	<div class='col-4 text-end'>
					<a href='hadoop-data-storage'>Almacenamiento de Datos en Hadoop &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción al Procesamiento de Datos con Hadoop</h1>
<div class='content'><p>Hadoop es un marco de trabajo de código abierto que permite el procesamiento distribuido de grandes conjuntos de datos a través de clústeres de computadoras utilizando modelos de programación simples. Esta sección introducirá los conceptos fundamentales de Hadoop y su ecosistema.</p>
<ul>
<li><strong>Hadoop Distributed File System (HDFS)</strong>: Un sistema de archivos distribuido que proporciona acceso de alto rendimiento a los datos de las aplicaciones.</li>
<li><strong>MapReduce</strong>: Un modelo de programación para procesar grandes conjuntos de datos con un algoritmo distribuido en un clúster de Hadoop.</li>
<li><strong>YARN (Yet Another Resource Negotiator)</strong>: Gestiona los recursos y la programación de trabajos en Hadoop.</li>
</ul>
</div><h1>HDFS: La Fundación de Hadoop</h1>
<div class='content'><p>HDFS está diseñado para almacenar conjuntos de datos muy grandes de manera confiable y para transmitir esos conjuntos de datos a alta velocidad a las aplicaciones de los usuarios.</p>
<ul>
<li><strong>Bloques</strong>: HDFS divide los archivos en grandes bloques (típicamente 128 MB) y los distribuye a través de los nodos en un clúster.</li>
<li><strong>Replicación</strong>: Cada bloque se replica en múltiples nodos para asegurar la tolerancia a fallos.</li>
<li><strong>NameNode y DataNode</strong>: El NameNode gestiona el espacio de nombres del sistema de archivos y regula el acceso a los archivos por parte de los clientes. Los DataNodes gestionan el almacenamiento adjunto a los nodos en los que se ejecutan.</li>
</ul>
</div><h2>Ejemplo: Escribir y Leer Archivos en HDFS</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBTdWJpciB1biBhcmNoaXZvIGEgSERGUwpoZGZzIGRmcyAtcHV0IGxvY2FsZmlsZS50eHQgL3VzZXIvaGFkb29wLwoKIyBMaXN0YXIgYXJjaGl2b3MgZW4gZWwgZGlyZWN0b3JpbyBkZSBIREZTCmhkZnMgZGZzIC1scyAvdXNlci9oYWRvb3AvCgojIExlZXIgdW4gYXJjaGl2byBkZXNkZSBIREZTCmhkZnMgZGZzIC1jYXQgL3VzZXIvaGFkb29wL2xvY2FsZmlsZS50eHQ="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Subir un archivo a HDFS
hdfs dfs -put localfile.txt /user/hadoop/

# Listar archivos en el directorio de HDFS
hdfs dfs -ls /user/hadoop/

# Leer un archivo desde HDFS
hdfs dfs -cat /user/hadoop/localfile.txt</pre></div><div class='content'></div><h1>MapReduce: Procesamiento de Datos en Hadoop</h1>
<div class='content'><p>MapReduce es un modelo de programación y una implementación asociada para procesar y generar grandes conjuntos de datos.</p>
<ul>
<li><strong>Función Map</strong>: Procesa datos de entrada y produce un conjunto de pares clave/valor intermedios.</li>
<li><strong>Función Reduce</strong>: Fusiona todos los valores intermedios asociados con la misma clave intermedia.</li>
</ul>
</div><h2>Ejemplo: Programa de Conteo de Palabras</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import java.util.StringTokenizer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {
    public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;{
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            StringTokenizer itr = new StringTokenizer(value.toString());
            while (itr.hasMoreTokens()) {
                word.set(itr.nextToken());
                context.write(word, one);
            }
        }
    }

    public static class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
        private IntWritable result = new IntWritable();

        public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            result.set(sum);
            context.write(key, result);
        }
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, &quot;word count&quot;);
        job.setJarByClass(WordCount.class);
        job.setMapperClass(TokenizerMapper.class);
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(IntSumReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}</pre></div><div class='content'></div><h1>YARN: Gestión de Recursos en Hadoop</h1>
<div class='content'><p>YARN es la capa de gestión de recursos de Hadoop. Permite que múltiples motores de procesamiento de datos, como el procesamiento por lotes, el procesamiento de flujos, el procesamiento interactivo y el procesamiento de gráficos, se ejecuten y procesen datos almacenados en HDFS.</p>
<ul>
<li><strong>ResourceManager</strong>: Gestiona los recursos y programa aplicaciones.</li>
<li><strong>NodeManager</strong>: Gestiona los recursos en un solo nodo.</li>
<li><strong>ApplicationMaster</strong>: Gestiona el ciclo de vida de las aplicaciones.</li>
</ul>
</div><h1>Procesamiento de Datos Avanzado con el Ecosistema de Hadoop</h1>
<div class='content'><p>El ecosistema de Hadoop incluye varias herramientas y tecnologías que mejoran sus capacidades.</p>
<ul>
<li><strong>Hive</strong>: Infraestructura de almacén de datos construida sobre Hadoop para proporcionar resumen de datos, consulta y análisis.</li>
<li><strong>Pig</strong>: Plataforma de alto nivel para crear programas MapReduce utilizados con Hadoop.</li>
<li><strong>HBase</strong>: Almacén de datos grande, distribuido y escalable, modelado según Bigtable de Google.</li>
<li><strong>Spark</strong>: Motor rápido y general para el procesamiento de datos a gran escala.</li>
</ul>
</div><h2>Ejemplo: Uso de Hive para Consultas de Datos</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("LS0gQ3JlYXIgdW5hIHRhYmxhIGVuIEhpdmUKQ1JFQVRFIFRBQkxFIGVtcGxveWVlIChpZCBJTlQsIG5hbWUgU1RSSU5HLCBzYWxhcnkgRkxPQVQpClJPVyBGT1JNQVQgREVMSU1JVEVECkZJRUxEUyBURVJNSU5BVEVEIEJZICcsJwpMSU5FUyBURVJNSU5BVEVEIEJZICdcbic7CgotLSBDYXJnYXIgZGF0b3MgZW4gbGEgdGFibGEKTE9BRCBEQVRBIExPQ0FMIElOUEFUSCAnL3BhdGgvdG8vZW1wbG95ZWUuY3N2JyBJTlRPIFRBQkxFIGVtcGxveWVlOwoKLS0gQ29uc3VsdGFyIGxhIHRhYmxhClNFTEVDVCBuYW1lLCBzYWxhcnkgRlJPTSBlbXBsb3llZSBXSEVSRSBzYWxhcnkgPiA1MDAwMDs="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>-- Crear una tabla en Hive
CREATE TABLE employee (id INT, name STRING, salary FLOAT)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n';

-- Cargar datos en la tabla
LOAD DATA LOCAL INPATH '/path/to/employee.csv' INTO TABLE employee;

-- Consultar la tabla
SELECT name, salary FROM employee WHERE salary &gt; 50000;</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>Hadoop proporciona un marco robusto para procesar grandes conjuntos de datos en un entorno de computación distribuida. Entender HDFS, MapReduce y YARN es crucial para aprovechar todo el potencial de Hadoop. Además, herramientas como Hive, Pig, HBase y Spark extienden las capacidades de Hadoop, convirtiéndolo en una solución versátil para el procesamiento de grandes datos. Al dominar estos componentes, puedes gestionar y analizar eficientemente grandes cantidades de datos.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='hadoop-data-ingestion'>&#x25C4;Ingesta de Datos en Hadoop</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Procesamiento de Datos con Hadoop</a>
	</div>
	<div class='col-4 text-end'>
					<a href='hadoop-data-storage'>Almacenamiento de Datos en Hadoop &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
