<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Marco de Trabajo MapReduce</title>

    <link rel="alternate" href="https://campusempresa.com/mod/hadoop/02-03-mapreduce-framework" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/hadoop/02-03-mapreduce-framework" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/hadoop/02-03-mapreduce-framework" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<a href="https://enterprisecampus.net/mod/hadoop/02-03-mapreduce-framework" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/hadoop/02-03-mapreduce-framework" class="px-2">CA</a>
<br>
			<cite>Construyendo la sociedad de hoy y del mañana</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
									<a href="./">Contenido del curso</a>
					<span class="sep">|</span>
								<a href="/all/competencias">Competencias técnicas</a>
				<a href="/all/conocimientos">Conocimientos</a>
				<a href="/all/soft_skills">Competencias sociales</a>
			</div>
		</div>
	</div>
</div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='02-02-hdfs' title="HDFS (Sistema de Archivos Distribuido de Hadoop)">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Marco de Trabajo MapReduce</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='02-04-yarn' title="YARN (Yet Another Resource Negotiator)">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1><p>Introducción</p>
</h1>
<div class='content'><p>MapReduce es un modelo de programación y una plataforma de procesamiento de datos que permite el procesamiento de grandes conjuntos de datos de manera distribuida. Fue desarrollado por Google y es una de las piedras angulares del ecosistema Hadoop. Este modelo divide el procesamiento en dos fases principales: <strong>Map</strong> y <strong>Reduce</strong>.</p>
</div><h1><p>Objetivos de Aprendizaje</p>
</h1>
<div class='content'><p>Al final de esta sección, deberías ser capaz de:</p>
<ol>
<li>Comprender el flujo de trabajo de MapReduce.</li>
<li>Identificar las fases de Map y Reduce.</li>
<li>Escribir y ejecutar un programa básico de MapReduce.</li>
<li>Conocer los componentes clave del marco de trabajo MapReduce.</li>
</ol>
</div><h1><p>Conceptos Clave</p>
</h1>
<div class='content'></div><h2><ol>
<li>Fases de MapReduce</li>
</ol>
</h2>
<div class='content'><h4>Fase de Map</h4>
<ul>
<li><strong>Entrada</strong>: La entrada se divide en fragmentos y se asigna a diferentes nodos en el clúster.</li>
<li><strong>Procesamiento</strong>: Cada nodo procesa su fragmento de datos y genera pares clave-valor intermedios.</li>
<li><strong>Salida</strong>: Los pares clave-valor intermedios se agrupan por clave.</li>
</ul>
<h4>Fase de Reduce</h4>
<ul>
<li><strong>Entrada</strong>: Los pares clave-valor intermedios agrupados se pasan a la fase de Reduce.</li>
<li><strong>Procesamiento</strong>: Cada nodo Reduce procesa los pares clave-valor y genera la salida final.</li>
<li><strong>Salida</strong>: La salida final se escribe en el sistema de archivos distribuido.</li>
</ul>
</div><h2><ol start="2">
<li>Componentes Clave</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>JobTracker</strong>: Coordina los trabajos de MapReduce y asigna tareas a los nodos.</li>
<li><strong>TaskTracker</strong>: Ejecuta las tareas asignadas por el JobTracker.</li>
<li><strong>InputFormat</strong>: Define cómo se dividen los datos de entrada.</li>
<li><strong>OutputFormat</strong>: Define cómo se escriben los datos de salida.</li>
</ul>
</div><h1><p>Ejemplo Práctico</p>
</h1>
<div class='content'><p>Vamos a escribir un programa básico de MapReduce en Java que cuenta la frecuencia de palabras en un conjunto de documentos.</p>
</div><h2><p>Código de Ejemplo</p>
</h2>
<div class='content'><h4>Clase Mapper</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5JbnRXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLkxvbmdXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuTWFwcGVyOwoKcHVibGljIGNsYXNzIFdvcmRDb3VudE1hcHBlciBleHRlbmRzIE1hcHBlcjxMb25nV3JpdGFibGUsIFRleHQsIFRleHQsIEludFdyaXRhYmxlPiB7CiAgICBwcml2YXRlIGZpbmFsIHN0YXRpYyBJbnRXcml0YWJsZSBvbmUgPSBuZXcgSW50V3JpdGFibGUoMSk7CiAgICBwcml2YXRlIFRleHQgd29yZCA9IG5ldyBUZXh0KCk7CgogICAgQE92ZXJyaWRlCiAgICBwcm90ZWN0ZWQgdm9pZCBtYXAoTG9uZ1dyaXRhYmxlIGtleSwgVGV4dCB2YWx1ZSwgQ29udGV4dCBjb250ZXh0KSB0aHJvd3MgSU9FeGNlcHRpb24sIEludGVycnVwdGVkRXhjZXB0aW9uIHsKICAgICAgICBTdHJpbmdbXSB3b3JkcyA9IHZhbHVlLnRvU3RyaW5nKCkuc3BsaXQoIlxccysiKTsKICAgICAgICBmb3IgKFN0cmluZyBzdHIgOiB3b3JkcykgewogICAgICAgICAgICB3b3JkLnNldChzdHIpOwogICAgICAgICAgICBjb250ZXh0LndyaXRlKHdvcmQsIG9uZSk7CiAgICAgICAgfQogICAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String[] words = value.toString().split(&quot;\\s+&quot;);
        for (String str : words) {
            word.set(str);
            context.write(word, one);
        }
    }
}</pre></div><div class='content'><h4>Clase Reducer</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5JbnRXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuUmVkdWNlcjsKCnB1YmxpYyBjbGFzcyBXb3JkQ291bnRSZWR1Y2VyIGV4dGVuZHMgUmVkdWNlcjxUZXh0LCBJbnRXcml0YWJsZSwgVGV4dCwgSW50V3JpdGFibGU+IHsKICAgIEBPdmVycmlkZQogICAgcHJvdGVjdGVkIHZvaWQgcmVkdWNlKFRleHQga2V5LCBJdGVyYWJsZTxJbnRXcml0YWJsZT4gdmFsdWVzLCBDb250ZXh0IGNvbnRleHQpIHRocm93cyBJT0V4Y2VwdGlvbiwgSW50ZXJydXB0ZWRFeGNlcHRpb24gewogICAgICAgIGludCBzdW0gPSAwOwogICAgICAgIGZvciAoSW50V3JpdGFibGUgdmFsIDogdmFsdWVzKSB7CiAgICAgICAgICAgIHN1bSArPSB2YWwuZ2V0KCk7CiAgICAgICAgfQogICAgICAgIGNvbnRleHQud3JpdGUoa2V5LCBuZXcgSW50V3JpdGFibGUoc3VtKSk7CiAgICB9Cn0="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    @Override
    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable val : values) {
            sum += val.get();
        }
        context.write(key, new IntWritable(sum));
    }
}</pre></div><div class='content'><h4>Clase Driver</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmNvbmYuQ29uZmlndXJhdGlvbjsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmZzLlBhdGg7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5JbnRXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuSm9iOwppbXBvcnQgb3JnLmFwYWNoZS5oYWRvb3AubWFwcmVkdWNlLmxpYi5pbnB1dC5GaWxlSW5wdXRGb3JtYXQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UubGliLm91dHB1dC5GaWxlT3V0cHV0Rm9ybWF0OwoKcHVibGljIGNsYXNzIFdvcmRDb3VudCB7CiAgICBwdWJsaWMgc3RhdGljIHZvaWQgbWFpbihTdHJpbmdbXSBhcmdzKSB0aHJvd3MgRXhjZXB0aW9uIHsKICAgICAgICBDb25maWd1cmF0aW9uIGNvbmYgPSBuZXcgQ29uZmlndXJhdGlvbigpOwogICAgICAgIEpvYiBqb2IgPSBKb2IuZ2V0SW5zdGFuY2UoY29uZiwgIndvcmQgY291bnQiKTsKICAgICAgICBqb2Iuc2V0SmFyQnlDbGFzcyhXb3JkQ291bnQuY2xhc3MpOwogICAgICAgIGpvYi5zZXRNYXBwZXJDbGFzcyhXb3JkQ291bnRNYXBwZXIuY2xhc3MpOwogICAgICAgIGpvYi5zZXRDb21iaW5lckNsYXNzKFdvcmRDb3VudFJlZHVjZXIuY2xhc3MpOwogICAgICAgIGpvYi5zZXRSZWR1Y2VyQ2xhc3MoV29yZENvdW50UmVkdWNlci5jbGFzcyk7CiAgICAgICAgam9iLnNldE91dHB1dEtleUNsYXNzKFRleHQuY2xhc3MpOwogICAgICAgIGpvYi5zZXRPdXRwdXRWYWx1ZUNsYXNzKEludFdyaXRhYmxlLmNsYXNzKTsKICAgICAgICBGaWxlSW5wdXRGb3JtYXQuYWRkSW5wdXRQYXRoKGpvYiwgbmV3IFBhdGgoYXJnc1swXSkpOwogICAgICAgIEZpbGVPdXRwdXRGb3JtYXQuc2V0T3V0cHV0UGF0aChqb2IsIG5ldyBQYXRoKGFyZ3NbMV0pKTsKICAgICAgICBTeXN0ZW0uZXhpdChqb2Iud2FpdEZvckNvbXBsZXRpb24odHJ1ZSkgPyAwIDogMSk7CiAgICB9Cn0="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, &quot;word count&quot;);
        job.setJarByClass(WordCount.class);
        job.setMapperClass(WordCountMapper.class);
        job.setCombinerClass(WordCountReducer.class);
        job.setReducerClass(WordCountReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}</pre></div><div class='content'></div><h2><p>Explicación del Código</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>WordCountMapper</strong>: Esta clase extiende <code>Mapper</code> y sobrescribe el método <code>map</code>. Divide cada línea de texto en palabras y emite cada palabra con un valor de <code>1</code>.</p>
</li>
<li>
<p><strong>WordCountReducer</strong>: Esta clase extiende <code>Reducer</code> y sobrescribe el método <code>reduce</code>. Suma los valores para cada palabra y emite la palabra con su frecuencia total.</p>
</li>
<li>
<p><strong>WordCount</strong>: Esta es la clase principal que configura el trabajo de MapReduce. Define las clases Mapper y Reducer, y especifica los formatos de entrada y salida.</p>
</li>
</ol>
</div><h1><p>Ejercicio Práctico</p>
</h1>
<div class='content'></div><h2><p>Ejercicio 1: Contar la Frecuencia de Palabras</p>
</h2>
<div class='content'><p><strong>Objetivo</strong>: Modificar el programa de ejemplo para que ignore las palabras comunes (stop words) como &quot;the&quot;, &quot;is&quot;, &quot;in&quot;, etc.</p>
<p><strong>Pistas</strong>:</p>
<ul>
<li>Usa un conjunto (<code>Set</code>) para almacenar las palabras comunes.</li>
<li>Filtra estas palabras en el método <code>map</code> antes de emitir los pares clave-valor.</li>
</ul>
</div><h2><p>Solución</p>
</h2>
<div class='content'><h4>Clase Mapper Modificada</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGphdmEuaW8uSU9FeGNlcHRpb247CmltcG9ydCBqYXZhLnV0aWwuSGFzaFNldDsKaW1wb3J0IGphdmEudXRpbC5TZXQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5pby5JbnRXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLkxvbmdXcml0YWJsZTsKaW1wb3J0IG9yZy5hcGFjaGUuaGFkb29wLmlvLlRleHQ7CmltcG9ydCBvcmcuYXBhY2hlLmhhZG9vcC5tYXByZWR1Y2UuTWFwcGVyOwoKcHVibGljIGNsYXNzIFdvcmRDb3VudE1hcHBlciBleHRlbmRzIE1hcHBlcjxMb25nV3JpdGFibGUsIFRleHQsIFRleHQsIEludFdyaXRhYmxlPiB7CiAgICBwcml2YXRlIGZpbmFsIHN0YXRpYyBJbnRXcml0YWJsZSBvbmUgPSBuZXcgSW50V3JpdGFibGUoMSk7CiAgICBwcml2YXRlIFRleHQgd29yZCA9IG5ldyBUZXh0KCk7CiAgICBwcml2YXRlIFNldDxTdHJpbmc+IHN0b3BXb3JkczsKCiAgICBAT3ZlcnJpZGUKICAgIHByb3RlY3RlZCB2b2lkIHNldHVwKENvbnRleHQgY29udGV4dCkgdGhyb3dzIElPRXhjZXB0aW9uLCBJbnRlcnJ1cHRlZEV4Y2VwdGlvbiB7CiAgICAgICAgc3RvcFdvcmRzID0gbmV3IEhhc2hTZXQ8PigpOwogICAgICAgIHN0b3BXb3Jkcy5hZGQoInRoZSIpOwogICAgICAgIHN0b3BXb3Jkcy5hZGQoImlzIik7CiAgICAgICAgc3RvcFdvcmRzLmFkZCgiaW4iKTsKICAgICAgICAvLyBBw7FhZGlyIG3DoXMgcGFsYWJyYXMgY29tdW5lcyBzZWfDum4gc2VhIG5lY2VzYXJpbwogICAgfQoKICAgIEBPdmVycmlkZQogICAgcHJvdGVjdGVkIHZvaWQgbWFwKExvbmdXcml0YWJsZSBrZXksIFRleHQgdmFsdWUsIENvbnRleHQgY29udGV4dCkgdGhyb3dzIElPRXhjZXB0aW9uLCBJbnRlcnJ1cHRlZEV4Y2VwdGlvbiB7CiAgICAgICAgU3RyaW5nW10gd29yZHMgPSB2YWx1ZS50b1N0cmluZygpLnNwbGl0KCJcXHMrIik7CiAgICAgICAgZm9yIChTdHJpbmcgc3RyIDogd29yZHMpIHsKICAgICAgICAgICAgaWYgKCFzdG9wV29yZHMuY29udGFpbnMoc3RyLnRvTG93ZXJDYXNlKCkpKSB7CiAgICAgICAgICAgICAgICB3b3JkLnNldChzdHIpOwogICAgICAgICAgICAgICAgY29udGV4dC53cml0ZSh3b3JkLCBvbmUpOwogICAgICAgICAgICB9CiAgICAgICAgfQogICAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import java.io.IOException;
import java.util.HashSet;
import java.util.Set;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();
    private Set&lt;String&gt; stopWords;

    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
        stopWords = new HashSet&lt;&gt;();
        stopWords.add(&quot;the&quot;);
        stopWords.add(&quot;is&quot;);
        stopWords.add(&quot;in&quot;);
        // A&ntilde;adir m&aacute;s palabras comunes seg&uacute;n sea necesario
    }

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String[] words = value.toString().split(&quot;\\s+&quot;);
        for (String str : words) {
            if (!stopWords.contains(str.toLowerCase())) {
                word.set(str);
                context.write(word, one);
            }
        }
    }
}</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En esta sección, hemos cubierto los conceptos básicos del marco de trabajo MapReduce, incluyendo sus fases y componentes clave. También hemos escrito y ejecutado un programa básico de MapReduce para contar la frecuencia de palabras en un conjunto de documentos. A través de un ejercicio práctico, hemos aprendido a modificar el programa para ignorar palabras comunes.</p>
<p>En el próximo módulo, profundizaremos en las técnicas de optimización de MapReduce para mejorar el rendimiento y la eficiencia de nuestros trabajos de procesamiento de datos.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='02-02-hdfs' title="HDFS (Sistema de Archivos Distribuido de Hadoop)">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='02-04-yarn' title="YARN (Yet Another Resource Negotiator)">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
