<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Caso de Estudio 2: Uso de Data Lakes para Big Data</title>

    <link rel="alternate" href="https://campusempresa.com/mod/arquitecturas_datos/caso-de-estudio-2-uso-de-data-lakes-para-big-data" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/arquitecturas_datos/caso-de-estudio-2-uso-de-data-lakes-para-big-data" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/arquitecturas_datos/caso-de-estudio-2-uso-de-data-lakes-para-big-data" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/arquitecturas_datos/caso-de-estudio-2-uso-de-data-lakes-para-big-data" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/arquitecturas_datos/caso-de-estudio-2-uso-de-data-lakes-para-big-data" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-4'>
					<a href='caso-de-estudio-1-implementacion-de-un-data-warehouse'>&#x25C4;Caso de Estudio 1: Implementación de un Data Warehouse</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Caso de Estudio 2: Uso de Data Lakes para Big Data</a>
	</div>
	<div class='col-4 text-end'>
					<a href='mejores-practicas-en-el-diseno-de-arquitecturas-de-datos'>Mejores Prácticas en el Diseño de Arquitecturas de Datos &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción</h1>
<div class='content'><p>En este caso de estudio, exploraremos el uso de Data Lakes en el contexto de Big Data. Los Data Lakes son repositorios centralizados que permiten almacenar grandes cantidades de datos en su formato original, sin necesidad de estructurarlos previamente. Este enfoque es especialmente útil para manejar datos no estructurados y semiestructurados provenientes de diversas fuentes.</p>
</div><h1>Conceptos Clave</h1>
<div class='content'><ul>
<li><strong>Data Lake</strong>: Un repositorio centralizado que permite almacenar datos en su formato original.</li>
<li><strong>Big Data</strong>: Conjunto de datos que es tan grande y complejo que las aplicaciones de procesamiento de datos tradicionales no son suficientes para manejarlos.</li>
<li><strong>ETL (Extract, Transform, Load)</strong>: Proceso de extracción, transformación y carga de datos.</li>
<li><strong>ELT (Extract, Load, Transform)</strong>: Variante del proceso ETL donde los datos se cargan primero y luego se transforman.</li>
<li><strong>Schema-on-read</strong>: Enfoque donde el esquema se aplica a los datos solo cuando se leen, no cuando se almacenan.</li>
</ul>
</div><h1>Ventajas de los Data Lakes</h1>
<div class='content'><ul>
<li><strong>Flexibilidad</strong>: Permiten almacenar datos en cualquier formato.</li>
<li><strong>Escalabilidad</strong>: Pueden manejar grandes volúmenes de datos.</li>
<li><strong>Economía</strong>: Reducen costos al eliminar la necesidad de transformar datos antes de almacenarlos.</li>
<li><strong>Acceso Rápido</strong>: Facilitan el acceso a datos sin necesidad de procesamiento previo.</li>
</ul>
</div><h1>Arquitectura de un Data Lake</h1>
<div class='content'><p>Un Data Lake típico incluye los siguientes componentes:</p>
<ol>
<li><strong>Ingesta de Datos</strong>: Herramientas y procesos para capturar datos de diversas fuentes.</li>
<li><strong>Almacenamiento</strong>: Infraestructura para almacenar datos en su formato original.</li>
<li><strong>Procesamiento</strong>: Herramientas para procesar y analizar datos.</li>
<li><strong>Seguridad y Gobernanza</strong>: Mecanismos para asegurar y gestionar el acceso a los datos.</li>
</ol>
</div><h2>Ejemplo de Arquitectura</h2>
<div class='content'><p>| Componente        | Descripción                                                                 |
|-------------------|-----------------------------------------------------------------------------|
| Ingesta de Datos  | Apache Kafka, AWS Kinesis                                                   |
| Almacenamiento    | Amazon S3, Hadoop HDFS                                                      |
| Procesamiento     | Apache Spark, AWS Glue                                                      |
| Seguridad         | AWS IAM, Apache Ranger                                                      |
| Gobernanza        | Apache Atlas, AWS Lake Formation                                            |</p>
</div><h1>Ejemplo Práctico</h1>
<div class='content'><p>Supongamos que una empresa de comercio electrónico quiere analizar los datos de sus transacciones, logs de servidores y datos de redes sociales para mejorar su estrategia de marketing.</p>
</div><h2>Paso 1: Ingesta de Datos</h2>
<div class='content'><p>Utilizamos Apache Kafka para capturar datos en tiempo real desde diversas fuentes.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBrYWZrYSBpbXBvcnQgS2Fma2FQcm9kdWNlcgoKcHJvZHVjZXIgPSBLYWZrYVByb2R1Y2VyKGJvb3RzdHJhcF9zZXJ2ZXJzPSdsb2NhbGhvc3Q6OTA5MicpCnByb2R1Y2VyLnNlbmQoJ3RyYW5zYWN0aW9ucycsIGIneyJ1c2VyX2lkIjogMTIzLCAiYW1vdW50IjogNTAuNX0nKQpwcm9kdWNlci5zZW5kKCdsb2dzJywgYid7InRpbWVzdGFtcCI6ICIyMDIzLTEwLTAxVDEyOjAwOjAwWiIsICJzdGF0dXMiOiAyMDB9JykKcHJvZHVjZXIuc2VuZCgnc29jaWFsX21lZGlhJywgYid7InBvc3RfaWQiOiA0NTYsICJsaWtlcyI6IDEwMH0nKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from kafka import KafkaProducer

producer = KafkaProducer(bootstrap_servers='localhost:9092')
producer.send('transactions', b'{&quot;user_id&quot;: 123, &quot;amount&quot;: 50.5}')
producer.send('logs', b'{&quot;timestamp&quot;: &quot;2023-10-01T12:00:00Z&quot;, &quot;status&quot;: 200}')
producer.send('social_media', b'{&quot;post_id&quot;: 456, &quot;likes&quot;: 100}')</pre></div><div class='content'></div><h2>Paso 2: Almacenamiento</h2>
<div class='content'><p>Los datos capturados se almacenan en Amazon S3.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("YXdzIHMzIGNwIHRyYW5zYWN0aW9ucy5qc29uIHMzOi8vZGF0YS1sYWtlL3RyYW5zYWN0aW9ucy8KYXdzIHMzIGNwIGxvZ3MuanNvbiBzMzovL2RhdGEtbGFrZS9sb2dzLwphd3MgczMgY3Agc29jaWFsX21lZGlhLmpzb24gczM6Ly9kYXRhLWxha2Uvc29jaWFsX21lZGlhLw=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>aws s3 cp transactions.json s3://data-lake/transactions/
aws s3 cp logs.json s3://data-lake/logs/
aws s3 cp social_media.json s3://data-lake/social_media/</pre></div><div class='content'></div><h2>Paso 3: Procesamiento</h2>
<div class='content'><p>Utilizamos Apache Spark para procesar y analizar los datos almacenados.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIkRhdGFMYWtlRXhhbXBsZSIpLmdldE9yQ3JlYXRlKCkKCnRyYW5zYWN0aW9uc19kZiA9IHNwYXJrLnJlYWQuanNvbigiczM6Ly9kYXRhLWxha2UvdHJhbnNhY3Rpb25zLyIpCmxvZ3NfZGYgPSBzcGFyay5yZWFkLmpzb24oInMzOi8vZGF0YS1sYWtlL2xvZ3MvIikKc29jaWFsX21lZGlhX2RmID0gc3BhcmsucmVhZC5qc29uKCJzMzovL2RhdGEtbGFrZS9zb2NpYWxfbWVkaWEvIikKCiMgRWplbXBsbyBkZSBhbsOhbGlzaXM6IGNhbGN1bGFyIGVsIHRvdGFsIGRlIHRyYW5zYWNjaW9uZXMKdG90YWxfYW1vdW50ID0gdHJhbnNhY3Rpb25zX2RmLmdyb3VwQnkoKS5zdW0oImFtb3VudCIpLmNvbGxlY3QoKVswXVswXQpwcmludChmIlRvdGFsIEFtb3VudDoge3RvdGFsX2Ftb3VudH0iKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName(&quot;DataLakeExample&quot;).getOrCreate()

transactions_df = spark.read.json(&quot;s3://data-lake/transactions/&quot;)
logs_df = spark.read.json(&quot;s3://data-lake/logs/&quot;)
social_media_df = spark.read.json(&quot;s3://data-lake/social_media/&quot;)

# Ejemplo de an&aacute;lisis: calcular el total de transacciones
total_amount = transactions_df.groupBy().sum(&quot;amount&quot;).collect()[0][0]
print(f&quot;Total Amount: {total_amount}&quot;)</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>Los Data Lakes ofrecen una solución flexible y escalable para manejar grandes volúmenes de datos en su formato original. Al permitir el almacenamiento de datos sin necesidad de estructurarlos previamente, facilitan el acceso y análisis de datos diversos, lo que es crucial en el contexto de Big Data. En este caso de estudio, hemos visto cómo una empresa puede utilizar un Data Lake para capturar, almacenar y analizar datos de múltiples fuentes, mejorando así su capacidad para tomar decisiones informadas.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='caso-de-estudio-1-implementacion-de-un-data-warehouse'>&#x25C4;Caso de Estudio 1: Implementación de un Data Warehouse</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Caso de Estudio 2: Uso de Data Lakes para Big Data</a>
	</div>
	<div class='col-4 text-end'>
					<a href='mejores-practicas-en-el-diseno-de-arquitecturas-de-datos'>Mejores Prácticas en el Diseño de Arquitecturas de Datos &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
