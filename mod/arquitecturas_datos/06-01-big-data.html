<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Big Data</title>

    <link rel="alternate" href="https://campusempresa.com/mod/arquitecturas_datos/06-01-big-data" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/arquitecturas_datos/06-01-big-data" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/arquitecturas_datos/06-01-big-data" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/arquitecturas_datos/06-01-big-data" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/arquitecturas_datos/06-01-big-data" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-04-casos-uso' title="Casos de Uso de Análisis de Datos">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Big Data</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='06-02-data-lakes' title="Data Lakes">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1><p>Introducción</p>
</h1>
<div class='content'><p>El término &quot;Big Data&quot; se refiere a conjuntos de datos que son tan grandes o complejos que las aplicaciones tradicionales de procesamiento de datos no son adecuadas para manejarlos. El Big Data se caracteriza por las &quot;3 Vs&quot;: Volumen, Velocidad y Variedad. En esta sección, exploraremos estos conceptos en detalle, así como las tecnologías y herramientas utilizadas para gestionar y analizar Big Data.</p>
</div><h1><p>Características del Big Data</p>
</h1>
<div class='content'></div><h2><ol>
<li>Volumen</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Definición:</strong> Se refiere a la cantidad de datos generados y almacenados. El volumen de datos puede ser tan grande que requiere soluciones de almacenamiento y procesamiento especializadas.</li>
<li><strong>Ejemplo:</strong> Empresas como Facebook y Google manejan petabytes de datos diariamente.</li>
</ul>
</div><h2><ol start="2">
<li>Velocidad</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Definición:</strong> Se refiere a la velocidad a la que se generan y procesan los datos. En muchos casos, los datos deben ser procesados en tiempo real o casi en tiempo real.</li>
<li><strong>Ejemplo:</strong> Las transacciones financieras y las redes sociales generan datos a una velocidad extremadamente alta.</li>
</ul>
</div><h2><ol start="3">
<li>Variedad</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Definición:</strong> Se refiere a los diferentes tipos de datos que se generan. Estos pueden incluir datos estructurados, semi-estructurados y no estructurados.</li>
<li><strong>Ejemplo:</strong> Correos electrónicos, videos, fotos, datos de sensores y registros de transacciones.</li>
</ul>
</div><h2><ol start="4">
<li>Veracidad (Opcional)</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Definición:</strong> Se refiere a la calidad y precisión de los datos.</li>
<li><strong>Ejemplo:</strong> Datos de sensores que pueden tener errores o datos de redes sociales que pueden ser falsos.</li>
</ul>
</div><h2><ol start="5">
<li>Valor (Opcional)</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Definición:</strong> Se refiere al valor que se puede extraer de los datos.</li>
<li><strong>Ejemplo:</strong> Análisis de datos de clientes para mejorar las estrategias de marketing.</li>
</ul>
</div><h1><p>Tecnologías de Big Data</p>
</h1>
<div class='content'></div><h2><ol>
<li>Hadoop</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Descripción:</strong> Un marco de software de código abierto que permite el procesamiento distribuido de grandes conjuntos de datos a través de clusters de computadoras.</li>
<li><strong>Componentes Clave:</strong>
<ul>
<li><strong>HDFS (Hadoop Distributed File System):</strong> Sistema de archivos distribuido que almacena datos en múltiples máquinas.</li>
<li><strong>MapReduce:</strong> Modelo de programación para el procesamiento de datos a gran escala.</li>
</ul>
</li>
</ul>
</div><h2><ol start="2">
<li>Apache Spark</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Descripción:</strong> Un motor de análisis de datos de código abierto que es rápido y generalizado para el procesamiento de datos a gran escala.</li>
<li><strong>Características Clave:</strong>
<ul>
<li><strong>Velocidad:</strong> Procesa datos en memoria, lo que lo hace mucho más rápido que Hadoop MapReduce.</li>
<li><strong>Compatibilidad:</strong> Compatible con Hadoop y puede trabajar con HDFS.</li>
</ul>
</li>
</ul>
</div><h2><ol start="3">
<li>NoSQL Databases</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Descripción:</strong> Bases de datos que no utilizan el modelo relacional tradicional. Son adecuadas para manejar grandes volúmenes de datos no estructurados.</li>
<li><strong>Tipos:</strong>
<ul>
<li><strong>Document Stores (e.g., MongoDB):</strong> Almacenan datos en documentos JSON.</li>
<li><strong>Column Stores (e.g., Cassandra):</strong> Almacenan datos en columnas en lugar de filas.</li>
<li><strong>Key-Value Stores (e.g., Redis):</strong> Almacenan datos como pares clave-valor.</li>
</ul>
</li>
</ul>
</div><h2><ol start="4">
<li>Data Lakes</li>
</ol>
</h2>
<div class='content'><ul>
<li><strong>Descripción:</strong> Repositorios de almacenamiento que pueden contener grandes cantidades de datos en su formato nativo, ya sean estructurados, semi-estructurados o no estructurados.</li>
<li><strong>Ventajas:</strong>
<ul>
<li><strong>Flexibilidad:</strong> Permiten almacenar datos en su forma original sin necesidad de estructurarlos previamente.</li>
<li><strong>Escalabilidad:</strong> Pueden escalar fácilmente para manejar grandes volúmenes de datos.</li>
</ul>
</li>
</ul>
</div><h1><p>Ejemplo Práctico: Análisis de Logs de Servidor Web con Apache Spark</p>
</h1>
<div class='content'></div><h2><p>Paso 1: Configuración del Entorno</p>
</h2>
<div class='content'><p>Primero, asegúrate de tener Apache Spark instalado en tu máquina. Puedes seguir las instrucciones en la <a href="https://spark.apache.org/docs/latest/">documentación oficial de Apache Spark</a>.</p>
</div><h2><p>Paso 2: Cargar los Datos</p>
</h2>
<div class='content'><p>Supongamos que tienes un archivo de logs de servidor web llamado <code>access_logs.txt</code>. Aquí hay un ejemplo de cómo cargar estos datos en Spark:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIENyZWFyIHVuYSBzZXNpw7NuIGRlIFNwYXJrCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIgXAogICAgLmFwcE5hbWUoIldlYiBTZXJ2ZXIgTG9nIEFuYWx5c2lzIikgXAogICAgLmdldE9yQ3JlYXRlKCkKCiMgQ2FyZ2FyIGxvcyBkYXRvcwpsb2dzX2RmID0gc3BhcmsucmVhZC50ZXh0KCJhY2Nlc3NfbG9ncy50eHQiKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Crear una sesi&oacute;n de Spark
spark = SparkSession.builder \
    .appName(&quot;Web Server Log Analysis&quot;) \
    .getOrCreate()

# Cargar los datos
logs_df = spark.read.text(&quot;access_logs.txt&quot;)</pre></div><div class='content'></div><h2><p>Paso 3: Procesar los Datos</p>
</h2>
<div class='content'><p>A continuación, procesaremos los datos para extraer información útil, como el número de solicitudes por cada dirección IP.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IHNwbGl0LCBjb2wKCiMgRGl2aWRpciBjYWRhIGzDrW5lYSBlbiBjb2x1bW5hcwpsb2dzX2RmID0gbG9nc19kZi53aXRoQ29sdW1uKCdpcCcsIHNwbGl0KGNvbCgndmFsdWUnKSwgJyAnKVswXSkKCiMgQ29udGFyIGVsIG7Dum1lcm8gZGUgc29saWNpdHVkZXMgcG9yIElQCmlwX2NvdW50cyA9IGxvZ3NfZGYuZ3JvdXBCeSgnaXAnKS5jb3VudCgpCgojIE1vc3RyYXIgbG9zIHJlc3VsdGFkb3MKaXBfY291bnRzLnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql.functions import split, col

# Dividir cada l&iacute;nea en columnas
logs_df = logs_df.withColumn('ip', split(col('value'), ' ')[0])

# Contar el n&uacute;mero de solicitudes por IP
ip_counts = logs_df.groupBy('ip').count()

# Mostrar los resultados
ip_counts.show()</pre></div><div class='content'></div><h2><p>Paso 4: Guardar los Resultados</p>
</h2>
<div class='content'><p>Finalmente, guardamos los resultados en un archivo CSV.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBHdWFyZGFyIGxvcyByZXN1bHRhZG9zIGVuIHVuIGFyY2hpdm8gQ1NWCmlwX2NvdW50cy53cml0ZS5jc3YoImlwX2NvdW50cy5jc3YiKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Guardar los resultados en un archivo CSV
ip_counts.write.csv(&quot;ip_counts.csv&quot;)</pre></div><div class='content'></div><h1><p>Ejercicio Práctico</p>
</h1>
<div class='content'></div><h2><p>Ejercicio 1: Análisis de Sentimientos en Redes Sociales</p>
</h2>
<div class='content'><p><strong>Descripción:</strong> Utiliza Apache Spark para analizar un conjunto de datos de tweets y determinar el sentimiento general (positivo, negativo, neutral).</p>
<p><strong>Pasos:</strong></p>
<ol>
<li>Cargar los datos de tweets en un DataFrame de Spark.</li>
<li>Utilizar una librería de procesamiento de lenguaje natural (NLP) para analizar el sentimiento de cada tweet.</li>
<li>Contar el número de tweets positivos, negativos y neutrales.</li>
<li>Guardar los resultados en un archivo CSV.</li>
</ol>
<p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCmZyb20gdGV4dGJsb2IgaW1wb3J0IFRleHRCbG9iCmZyb20gcHlzcGFyay5zcWwuZnVuY3Rpb25zIGltcG9ydCB1ZGYKZnJvbSBweXNwYXJrLnNxbC50eXBlcyBpbXBvcnQgU3RyaW5nVHlwZQoKIyBDcmVhciB1bmEgc2VzacOzbiBkZSBTcGFyawpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyIFwKICAgIC5hcHBOYW1lKCJUd2l0dGVyIFNlbnRpbWVudCBBbmFseXNpcyIpIFwKICAgIC5nZXRPckNyZWF0ZSgpCgojIENhcmdhciBsb3MgZGF0b3MgZGUgdHdlZXRzCnR3ZWV0c19kZiA9IHNwYXJrLnJlYWQuanNvbigidHdlZXRzLmpzb24iKQoKIyBEZWZpbmlyIHVuYSBmdW5jacOzbiBVREYgcGFyYSBhbmFsaXphciBlbCBzZW50aW1pZW50bwpkZWYgZ2V0X3NlbnRpbWVudCh0ZXh0KToKICAgIGFuYWx5c2lzID0gVGV4dEJsb2IodGV4dCkKICAgIGlmIGFuYWx5c2lzLnNlbnRpbWVudC5wb2xhcml0eSA+IDA6CiAgICAgICAgcmV0dXJuICdwb3NpdGl2ZScKICAgIGVsaWYgYW5hbHlzaXMuc2VudGltZW50LnBvbGFyaXR5IDwgMDoKICAgICAgICByZXR1cm4gJ25lZ2F0aXZlJwogICAgZWxzZToKICAgICAgICByZXR1cm4gJ25ldXRyYWwnCgojIFJlZ2lzdHJhciBsYSBVREYKc2VudGltZW50X3VkZiA9IHVkZihnZXRfc2VudGltZW50LCBTdHJpbmdUeXBlKCkpCgojIEFwbGljYXIgbGEgVURGIGEgbG9zIGRhdG9zIGRlIHR3ZWV0cwp0d2VldHNfZGYgPSB0d2VldHNfZGYud2l0aENvbHVtbignc2VudGltZW50Jywgc2VudGltZW50X3VkZih0d2VldHNfZGZbJ3RleHQnXSkpCgojIENvbnRhciBlbCBuw7ptZXJvIGRlIHR3ZWV0cyBwb3Igc2VudGltaWVudG8Kc2VudGltZW50X2NvdW50cyA9IHR3ZWV0c19kZi5ncm91cEJ5KCdzZW50aW1lbnQnKS5jb3VudCgpCgojIE1vc3RyYXIgbG9zIHJlc3VsdGFkb3MKc2VudGltZW50X2NvdW50cy5zaG93KCkKCiMgR3VhcmRhciBsb3MgcmVzdWx0YWRvcyBlbiB1biBhcmNoaXZvIENTVgpzZW50aW1lbnRfY291bnRzLndyaXRlLmNzdigic2VudGltZW50X2NvdW50cy5jc3YiKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession
from textblob import TextBlob
from pyspark.sql.functions import udf
from pyspark.sql.types import StringType

# Crear una sesi&oacute;n de Spark
spark = SparkSession.builder \
    .appName(&quot;Twitter Sentiment Analysis&quot;) \
    .getOrCreate()

# Cargar los datos de tweets
tweets_df = spark.read.json(&quot;tweets.json&quot;)

# Definir una funci&oacute;n UDF para analizar el sentimiento
def get_sentiment(text):
    analysis = TextBlob(text)
    if analysis.sentiment.polarity &gt; 0:
        return 'positive'
    elif analysis.sentiment.polarity &lt; 0:
        return 'negative'
    else:
        return 'neutral'

# Registrar la UDF
sentiment_udf = udf(get_sentiment, StringType())

# Aplicar la UDF a los datos de tweets
tweets_df = tweets_df.withColumn('sentiment', sentiment_udf(tweets_df['text']))

# Contar el n&uacute;mero de tweets por sentimiento
sentiment_counts = tweets_df.groupBy('sentiment').count()

# Mostrar los resultados
sentiment_counts.show()

# Guardar los resultados en un archivo CSV
sentiment_counts.write.csv(&quot;sentiment_counts.csv&quot;)</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En esta sección, hemos explorado los conceptos fundamentales del Big Data, incluidas sus características clave y las tecnologías utilizadas para gestionarlo. También hemos visto un ejemplo práctico de cómo utilizar Apache Spark para analizar grandes conjuntos de datos. Con esta base, estás preparado para profundizar en otras áreas de las arquitecturas de datos modernas.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-04-casos-uso' title="Casos de Uso de Análisis de Datos">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='06-02-data-lakes' title="Data Lakes">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
