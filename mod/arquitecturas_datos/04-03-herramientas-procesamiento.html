<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Herramientas de Procesamiento de Datos</title>

    <link rel="alternate" href="https://campusempresa.com/mod/arquitecturas_datos/04-03-herramientas-procesamiento" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/arquitecturas_datos/04-03-eines-processament" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/arquitecturas_datos/04-03-processing-tools" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/arquitecturas_datos/04-03-herramientas-procesamiento" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/arquitecturas_datos/04-03-herramientas-procesamiento" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='04-02-tiempo-real-vs-batch' title="Procesamiento en Tiempo Real vs Batch">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Herramientas de Procesamiento de Datos</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='04-04-optimizacion-rendimiento' title="Optimización del Rendimiento">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'><p>En este tema, exploraremos las herramientas más utilizadas para el procesamiento de datos. Estas herramientas son fundamentales para transformar, limpiar y analizar grandes volúmenes de datos de manera eficiente. A lo largo de esta sección, cubriremos las siguientes áreas:</p>
<ol>
<li><strong>Introducción a las Herramientas de Procesamiento de Datos</strong></li>
<li><strong>Herramientas de Procesamiento por Lotes (Batch Processing)</strong></li>
<li><strong>Herramientas de Procesamiento en Tiempo Real (Real-Time Processing)</strong></li>
<li><strong>Comparación de Herramientas de Procesamiento de Datos</strong></li>
<li><strong>Ejercicios Prácticos</strong></li>
</ol>
</div><h1>1. Introducción a las Herramientas de Procesamiento de Datos</h1>
<div class='content'><p>Las herramientas de procesamiento de datos son software y plataformas que permiten manipular, transformar y analizar datos. Estas herramientas son esenciales para convertir datos brutos en información útil y accionable. Las herramientas de procesamiento de datos se pueden clasificar en dos categorías principales:</p>
<ul>
<li><strong>Procesamiento por Lotes (Batch Processing):</strong> Procesa grandes volúmenes de datos en intervalos específicos.</li>
<li><strong>Procesamiento en Tiempo Real (Real-Time Processing):</strong> Procesa datos de manera continua y en tiempo real.</li>
</ul>
</div><h1>2. Herramientas de Procesamiento por Lotes (Batch Processing)</h1>
<div class='content'></div><h2>Apache Hadoop</h2>
<div class='content'><p>Apache Hadoop es una plataforma de código abierto que permite el procesamiento distribuido de grandes conjuntos de datos a través de clústeres de computadoras. Sus componentes principales incluyen:</p>
<ul>
<li><strong>HDFS (Hadoop Distributed File System):</strong> Sistema de archivos distribuido que almacena datos en múltiples nodos.</li>
<li><strong>MapReduce:</strong> Modelo de programación que permite el procesamiento paralelo de grandes volúmenes de datos.</li>
</ul>
<p><strong>Ejemplo de Código:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

public class WordCount {

    public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt; {
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            String[] tokens = value.toString().split(&quot;\\s+&quot;);
            for (String token : tokens) {
                word.set(token);
                context.write(word, one);
            }
        }
    }

    public static class IntSumReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
        private IntWritable result = new IntWritable();

        public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            result.set(sum);
            context.write(key, result);
        }
    }

    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, &quot;word count&quot;);
        job.setJarByClass(WordCount.class);
        job.setMapperClass(TokenizerMapper.class);
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(IntSumReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}</pre></div><div class='content'></div><h2>Apache Spark</h2>
<div class='content'><p>Apache Spark es una plataforma de procesamiento de datos en clústeres que proporciona una interfaz para la programación de todo el clúster con implicaciones de tolerancia a fallos y paralelismo de datos.</p>
<p><strong>Ejemplo de Código:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQsIFNwYXJrQ29uZgoKY29uZiA9IFNwYXJrQ29uZigpLnNldEFwcE5hbWUoIldvcmRDb3VudCIpCnNjID0gU3BhcmtDb250ZXh0KGNvbmY9Y29uZikKCnRleHRfZmlsZSA9IHNjLnRleHRGaWxlKCJoZGZzOi8vcGF0aC90by9pbnB1dC50eHQiKQpjb3VudHMgPSB0ZXh0X2ZpbGUuZmxhdE1hcChsYW1iZGEgbGluZTogbGluZS5zcGxpdCgiICIpKSBcCiAgICAgICAgICAgICAgICAgIC5tYXAobGFtYmRhIHdvcmQ6ICh3b3JkLCAxKSkgXAogICAgICAgICAgICAgICAgICAucmVkdWNlQnlLZXkobGFtYmRhIGEsIGI6IGEgKyBiKQpjb3VudHMuc2F2ZUFzVGV4dEZpbGUoImhkZnM6Ly9wYXRoL3RvL291dHB1dCIp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext, SparkConf

conf = SparkConf().setAppName(&quot;WordCount&quot;)
sc = SparkContext(conf=conf)

text_file = sc.textFile(&quot;hdfs://path/to/input.txt&quot;)
counts = text_file.flatMap(lambda line: line.split(&quot; &quot;)) \
                  .map(lambda word: (word, 1)) \
                  .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile(&quot;hdfs://path/to/output&quot;)</pre></div><div class='content'></div><h1>3. Herramientas de Procesamiento en Tiempo Real (Real-Time Processing)</h1>
<div class='content'></div><h2>Apache Kafka</h2>
<div class='content'><p>Apache Kafka es una plataforma de transmisión de datos distribuida que permite la publicación, suscripción, almacenamiento y procesamiento de flujos de registros en tiempo real.</p>
<p><strong>Ejemplo de Código:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUua2Fma2EuY2xpZW50cy5wcm9kdWNlci5LYWZrYVByb2R1Y2VyOwppbXBvcnQgb3JnLmFwYWNoZS5rYWZrYS5jbGllbnRzLnByb2R1Y2VyLlByb2R1Y2VyUmVjb3JkOwoKaW1wb3J0IGphdmEudXRpbC5Qcm9wZXJ0aWVzOwoKcHVibGljIGNsYXNzIFNpbXBsZVByb2R1Y2VyIHsKICAgIHB1YmxpYyBzdGF0aWMgdm9pZCBtYWluKFN0cmluZ1tdIGFyZ3MpIHsKICAgICAgICBQcm9wZXJ0aWVzIHByb3BzID0gbmV3IFByb3BlcnRpZXMoKTsKICAgICAgICBwcm9wcy5wdXQoImJvb3RzdHJhcC5zZXJ2ZXJzIiwgImxvY2FsaG9zdDo5MDkyIik7CiAgICAgICAgcHJvcHMucHV0KCJrZXkuc2VyaWFsaXplciIsICJvcmcuYXBhY2hlLmthZmthLmNvbW1vbi5zZXJpYWxpemF0aW9uLlN0cmluZ1NlcmlhbGl6ZXIiKTsKICAgICAgICBwcm9wcy5wdXQoInZhbHVlLnNlcmlhbGl6ZXIiLCAib3JnLmFwYWNoZS5rYWZrYS5jb21tb24uc2VyaWFsaXphdGlvbi5TdHJpbmdTZXJpYWxpemVyIik7CgogICAgICAgIEthZmthUHJvZHVjZXI8U3RyaW5nLCBTdHJpbmc+IHByb2R1Y2VyID0gbmV3IEthZmthUHJvZHVjZXI8Pihwcm9wcyk7CiAgICAgICAgZm9yIChpbnQgaSA9IDA7IGkgPCAxMDA7IGkrKykgewogICAgICAgICAgICBwcm9kdWNlci5zZW5kKG5ldyBQcm9kdWNlclJlY29yZDw+KCJteS10b3BpYyIsIEludGVnZXIudG9TdHJpbmcoaSksIEludGVnZXIudG9TdHJpbmcoaSkpKTsKICAgICAgICB9CiAgICAgICAgcHJvZHVjZXIuY2xvc2UoKTsKICAgIH0KfQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

        KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);
        for (int i = 0; i &lt; 100; i++) {
            producer.send(new ProducerRecord&lt;&gt;(&quot;my-topic&quot;, Integer.toString(i), Integer.toString(i)));
        }
        producer.close();
    }
}</pre></div><div class='content'></div><h2>Apache Flink</h2>
<div class='content'><p>Apache Flink es una plataforma de procesamiento de flujos y lotes que permite el procesamiento de datos en tiempo real con baja latencia y alta capacidad de procesamiento.</p>
<p><strong>Ejemplo de Código:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuZmxpbmsuYXBpLmphdmEuRXhlY3V0aW9uRW52aXJvbm1lbnQ7CmltcG9ydCBvcmcuYXBhY2hlLmZsaW5rLmFwaS5qYXZhLkRhdGFTZXQ7CmltcG9ydCBvcmcuYXBhY2hlLmZsaW5rLmFwaS5qYXZhLnR1cGxlLlR1cGxlMjsKCnB1YmxpYyBjbGFzcyBCYXRjaEpvYiB7CiAgICBwdWJsaWMgc3RhdGljIHZvaWQgbWFpbihTdHJpbmdbXSBhcmdzKSB0aHJvd3MgRXhjZXB0aW9uIHsKICAgICAgICBmaW5hbCBFeGVjdXRpb25FbnZpcm9ubWVudCBlbnYgPSBFeGVjdXRpb25FbnZpcm9ubWVudC5nZXRFeGVjdXRpb25FbnZpcm9ubWVudCgpOwoKICAgICAgICBEYXRhU2V0PFN0cmluZz4gdGV4dCA9IGVudi5yZWFkVGV4dEZpbGUoImhkZnM6Ly9wYXRoL3RvL2lucHV0LnR4dCIpOwoKICAgICAgICBEYXRhU2V0PFR1cGxlMjxTdHJpbmcsIEludGVnZXI+PiB3b3JkQ291bnRzID0gdGV4dAogICAgICAgICAgICAuZmxhdE1hcCgoU3RyaW5nIGxpbmUsIENvbGxlY3RvcjxUdXBsZTI8U3RyaW5nLCBJbnRlZ2VyPj4gb3V0KSAtPiB7CiAgICAgICAgICAgICAgICBmb3IgKFN0cmluZyB3b3JkIDogbGluZS5zcGxpdCgiICIpKSB7CiAgICAgICAgICAgICAgICAgICAgb3V0LmNvbGxlY3QobmV3IFR1cGxlMjw+KHdvcmQsIDEpKTsKICAgICAgICAgICAgICAgIH0KICAgICAgICAgICAgfSkKICAgICAgICAgICAgLmdyb3VwQnkoMCkKICAgICAgICAgICAgLnN1bSgxKTsKCiAgICAgICAgd29yZENvdW50cy53cml0ZUFzQ3N2KCJoZGZzOi8vcGF0aC90by9vdXRwdXQiKTsKICAgICAgICBlbnYuZXhlY3V0ZSgiV29yZCBDb3VudCBFeGFtcGxlIik7CiAgICB9Cn0="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.flink.api.java.ExecutionEnvironment;
import org.apache.flink.api.java.DataSet;
import org.apache.flink.api.java.tuple.Tuple2;

public class BatchJob {
    public static void main(String[] args) throws Exception {
        final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();

        DataSet&lt;String&gt; text = env.readTextFile(&quot;hdfs://path/to/input.txt&quot;);

        DataSet&lt;Tuple2&lt;String, Integer&gt;&gt; wordCounts = text
            .flatMap((String line, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out) -&gt; {
                for (String word : line.split(&quot; &quot;)) {
                    out.collect(new Tuple2&lt;&gt;(word, 1));
                }
            })
            .groupBy(0)
            .sum(1);

        wordCounts.writeAsCsv(&quot;hdfs://path/to/output&quot;);
        env.execute(&quot;Word Count Example&quot;);
    }
}</pre></div><div class='content'></div><h1>4. Comparación de Herramientas de Procesamiento de Datos</h1>
<div class='content'><table>
<thead>
<tr>
<th>Herramienta</th>
<th>Tipo de Procesamiento</th>
<th>Ventajas</th>
<th>Desventajas</th>
</tr>
</thead>
<tbody>
<tr>
<td>Apache Hadoop</td>
<td>Batch</td>
<td>Escalabilidad, manejo de grandes volúmenes</td>
<td>Alta latencia, complejidad de configuración</td>
</tr>
<tr>
<td>Apache Spark</td>
<td>Batch/Real-Time</td>
<td>Velocidad, facilidad de uso</td>
<td>Consumo de memoria</td>
</tr>
<tr>
<td>Apache Kafka</td>
<td>Real-Time</td>
<td>Alta capacidad de procesamiento, escalabilidad</td>
<td>Complejidad de configuración</td>
</tr>
<tr>
<td>Apache Flink</td>
<td>Real-Time/Batch</td>
<td>Baja latencia, procesamiento de flujos</td>
<td>Curva de aprendizaje</td>
</tr>
</tbody>
</table>
</div><h1>5. Ejercicios Prácticos</h1>
<div class='content'></div><h2>Ejercicio 1: Procesamiento por Lotes con Apache Spark</h2>
<div class='content'><p><strong>Objetivo:</strong> Contar la frecuencia de palabras en un archivo de texto utilizando Apache Spark.</p>
<p><strong>Instrucciones:</strong></p>
<ol>
<li>Configura un entorno de Apache Spark.</li>
<li>Crea un script en Python para contar la frecuencia de palabras en un archivo de texto.</li>
<li>Ejecuta el script y verifica los resultados.</li>
</ol>
<p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQsIFNwYXJrQ29uZgoKY29uZiA9IFNwYXJrQ29uZigpLnNldEFwcE5hbWUoIldvcmRDb3VudCIpCnNjID0gU3BhcmtDb250ZXh0KGNvbmY9Y29uZikKCnRleHRfZmlsZSA9IHNjLnRleHRGaWxlKCJoZGZzOi8vcGF0aC90by9pbnB1dC50eHQiKQpjb3VudHMgPSB0ZXh0X2ZpbGUuZmxhdE1hcChsYW1iZGEgbGluZTogbGluZS5zcGxpdCgiICIpKSBcCiAgICAgICAgICAgICAgICAgIC5tYXAobGFtYmRhIHdvcmQ6ICh3b3JkLCAxKSkgXAogICAgICAgICAgICAgICAgICAucmVkdWNlQnlLZXkobGFtYmRhIGEsIGI6IGEgKyBiKQpjb3VudHMuc2F2ZUFzVGV4dEZpbGUoImhkZnM6Ly9wYXRoL3RvL291dHB1dCIp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext, SparkConf

conf = SparkConf().setAppName(&quot;WordCount&quot;)
sc = SparkContext(conf=conf)

text_file = sc.textFile(&quot;hdfs://path/to/input.txt&quot;)
counts = text_file.flatMap(lambda line: line.split(&quot; &quot;)) \
                  .map(lambda word: (word, 1)) \
                  .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile(&quot;hdfs://path/to/output&quot;)</pre></div><div class='content'></div><h2>Ejercicio 2: Procesamiento en Tiempo Real con Apache Kafka</h2>
<div class='content'><p><strong>Objetivo:</strong> Enviar mensajes a un tópico de Kafka y consumirlos en tiempo real.</p>
<p><strong>Instrucciones:</strong></p>
<ol>
<li>Configura un entorno de Apache Kafka.</li>
<li>Crea un productor en Java que envíe mensajes a un tópico de Kafka.</li>
<li>Crea un consumidor en Java que lea mensajes del tópico de Kafka.</li>
</ol>
<p><strong>Solución:</strong></p>
<p><strong>Productor:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUua2Fma2EuY2xpZW50cy5wcm9kdWNlci5LYWZrYVByb2R1Y2VyOwppbXBvcnQgb3JnLmFwYWNoZS5rYWZrYS5jbGllbnRzLnByb2R1Y2VyLlByb2R1Y2VyUmVjb3JkOwoKaW1wb3J0IGphdmEudXRpbC5Qcm9wZXJ0aWVzOwoKcHVibGljIGNsYXNzIFNpbXBsZVByb2R1Y2VyIHsKICAgIHB1YmxpYyBzdGF0aWMgdm9pZCBtYWluKFN0cmluZ1tdIGFyZ3MpIHsKICAgICAgICBQcm9wZXJ0aWVzIHByb3BzID0gbmV3IFByb3BlcnRpZXMoKTsKICAgICAgICBwcm9wcy5wdXQoImJvb3RzdHJhcC5zZXJ2ZXJzIiwgImxvY2FsaG9zdDo5MDkyIik7CiAgICAgICAgcHJvcHMucHV0KCJrZXkuc2VyaWFsaXplciIsICJvcmcuYXBhY2hlLmthZmthLmNvbW1vbi5zZXJpYWxpemF0aW9uLlN0cmluZ1NlcmlhbGl6ZXIiKTsKICAgICAgICBwcm9wcy5wdXQoInZhbHVlLnNlcmlhbGl6ZXIiLCAib3JnLmFwYWNoZS5rYWZrYS5jb21tb24uc2VyaWFsaXphdGlvbi5TdHJpbmdTZXJpYWxpemVyIik7CgogICAgICAgIEthZmthUHJvZHVjZXI8U3RyaW5nLCBTdHJpbmc+IHByb2R1Y2VyID0gbmV3IEthZmthUHJvZHVjZXI8Pihwcm9wcyk7CiAgICAgICAgZm9yIChpbnQgaSA9IDA7IGkgPCAxMDA7IGkrKykgewogICAgICAgICAgICBwcm9kdWNlci5zZW5kKG5ldyBQcm9kdWNlclJlY29yZDw+KCJteS10b3BpYyIsIEludGVnZXIudG9TdHJpbmcoaSksIEludGVnZXIudG9TdHJpbmcoaSkpKTsKICAgICAgICB9CiAgICAgICAgcHJvZHVjZXIuY2xvc2UoKTsKICAgIH0KfQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

        KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);
        for (int i = 0; i &lt; 100; i++) {
            producer.send(new ProducerRecord&lt;&gt;(&quot;my-topic&quot;, Integer.toString(i), Integer.toString(i)));
        }
        producer.close();
    }
}</pre></div><div class='content'><p><strong>Consumidor:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUua2Fma2EuY2xpZW50cy5jb25zdW1lci5Db25zdW1lclJlY29yZDsKaW1wb3J0IG9yZy5hcGFjaGUua2Fma2EuY2xpZW50cy5jb25zdW1lci5Db25zdW1lclJlY29yZHM7CmltcG9ydCBvcmcuYXBhY2hlLmthZmthLmNsaWVudHMuY29uc3VtZXIuS2Fma2FDb25zdW1lcjsKCmltcG9ydCBqYXZhLnV0aWwuQ29sbGVjdGlvbnM7CmltcG9ydCBqYXZhLnV0aWwuUHJvcGVydGllczsKCnB1YmxpYyBjbGFzcyBTaW1wbGVDb25zdW1lciB7CiAgICBwdWJsaWMgc3RhdGljIHZvaWQgbWFpbihTdHJpbmdbXSBhcmdzKSB7CiAgICAgICAgUHJvcGVydGllcyBwcm9wcyA9IG5ldyBQcm9wZXJ0aWVzKCk7CiAgICAgICAgcHJvcHMucHV0KCJib290c3RyYXAuc2VydmVycyIsICJsb2NhbGhvc3Q6OTA5MiIpOwogICAgICAgIHByb3BzLnB1dCgiZ3JvdXAuaWQiLCAidGVzdCIpOwogICAgICAgIHByb3BzLnB1dCgiZW5hYmxlLmF1dG8uY29tbWl0IiwgInRydWUiKTsKICAgICAgICBwcm9wcy5wdXQoImtleS5kZXNlcmlhbGl6ZXIiLCAib3JnLmFwYWNoZS5rYWZrYS5jb21tb24uc2VyaWFsaXphdGlvbi5TdHJpbmdEZXNlcmlhbGl6ZXIiKTsKICAgICAgICBwcm9wcy5wdXQoInZhbHVlLmRlc2VyaWFsaXplciIsICJvcmcuYXBhY2hlLmthZmthLmNvbW1vbi5zZXJpYWxpemF0aW9uLlN0cmluZ0Rlc2VyaWFsaXplciIpOwoKICAgICAgICBLYWZrYUNvbnN1bWVyPFN0cmluZywgU3RyaW5nPiBjb25zdW1lciA9IG5ldyBLYWZrYUNvbnN1bWVyPD4ocHJvcHMpOwogICAgICAgIGNvbnN1bWVyLnN1YnNjcmliZShDb2xsZWN0aW9ucy5zaW5nbGV0b25MaXN0KCJteS10b3BpYyIpKTsKCiAgICAgICAgd2hpbGUgKHRydWUpIHsKICAgICAgICAgICAgQ29uc3VtZXJSZWNvcmRzPFN0cmluZywgU3RyaW5nPiByZWNvcmRzID0gY29uc3VtZXIucG9sbCgxMDApOwogICAgICAgICAgICBmb3IgKENvbnN1bWVyUmVjb3JkPFN0cmluZywgU3RyaW5nPiByZWNvcmQgOiByZWNvcmRzKSB7CiAgICAgICAgICAgICAgICBTeXN0ZW0ub3V0LnByaW50Zigib2Zmc2V0ID0gJWQsIGtleSA9ICVzLCB2YWx1ZSA9ICVzJW4iLCByZWNvcmQub2Zmc2V0KCksIHJlY29yZC5rZXkoKSwgcmVjb3JkLnZhbHVlKCkpOwogICAgICAgICAgICB9CiAgICAgICAgfQogICAgfQp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

import java.util.Collections;
import java.util.Properties;

public class SimpleConsumer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);
        props.put(&quot;group.id&quot;, &quot;test&quot;);
        props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);
        props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);

        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
        consumer.subscribe(Collections.singletonList(&quot;my-topic&quot;));

        while (true) {
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);
            for (ConsumerRecord&lt;String, String&gt; record : records) {
                System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());
            }
        }
    }
}</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, hemos explorado diversas herramientas de procesamiento de datos, tanto para procesamiento por lotes como en tiempo real. Hemos visto ejemplos prácticos de cómo utilizar Apache Hadoop, Apache Spark, Apache Kafka y Apache Flink. Además, hemos comparado estas herramientas para entender mejor sus ventajas y desventajas. Los ejercicios prácticos proporcionados te ayudarán a aplicar los conceptos aprendidos y a familiarizarte con estas herramientas en un entorno real.</p>
<p>En el siguiente tema, profundizaremos en la <strong>Optimización del Rendimiento</strong> en el procesamiento de datos, donde aprenderemos técnicas y estrategias para mejorar la eficiencia y velocidad de nuestras operaciones de procesamiento de datos.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='04-02-tiempo-real-vs-batch' title="Procesamiento en Tiempo Real vs Batch">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='04-04-optimizacion-rendimiento' title="Optimización del Rendimiento">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
