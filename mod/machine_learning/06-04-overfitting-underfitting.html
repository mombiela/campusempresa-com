<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Overfitting y Underfitting</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/06-04-overfitting-underfitting" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/06-04-overfitting-underfitting" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/06-04-overfitting-underfitting" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/machine_learning/06-04-overfitting-underfitting" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/machine_learning/06-04-overfitting-underfitting" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='06-03-curva-roc-auc' title="Curva ROC y AUC">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Overfitting y Underfitting</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='07-01-ensemble-learning' title="Ensemble Learning">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'><p>En el contexto del Machine Learning, el overfitting y el underfitting son dos problemas comunes que pueden afectar el rendimiento de los modelos. Entender estos conceptos es crucial para desarrollar modelos que generalicen bien en datos no vistos.</p>
</div><h1><p>¿Qué es el Overfitting?</p>
</h1>
<div class='content'><p>El overfitting ocurre cuando un modelo se ajusta demasiado bien a los datos de entrenamiento, capturando tanto las tendencias generales como el ruido y las peculiaridades específicas de esos datos. Como resultado, el modelo tiene un rendimiento excelente en el conjunto de entrenamiento pero falla en generalizar a nuevos datos.</p>
</div><h2><p>Características del Overfitting:</p>
</h2>
<div class='content'><ul>
<li><strong>Alta precisión en datos de entrenamiento</strong>: El modelo tiene un rendimiento muy alto en el conjunto de entrenamiento.</li>
<li><strong>Baja precisión en datos de validación/prueba</strong>: El modelo no generaliza bien y tiene un rendimiento significativamente peor en datos no vistos.</li>
<li><strong>Modelo complejo</strong>: El modelo puede tener demasiados parámetros o ser demasiado flexible.</li>
</ul>
</div><h2><p>Ejemplo de Overfitting:</p>
</h2>
<div class='content'><p>Consideremos un conjunto de datos de puntos en un plano. Un modelo de regresión polinómica de grado muy alto puede ajustarse perfectamente a todos los puntos del conjunto de entrenamiento, pero fallará en predecir correctamente nuevos puntos.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFBvbHlub21pYWxGZWF0dXJlcwpmcm9tIHNrbGVhcm4ubGluZWFyX21vZGVsIGltcG9ydCBMaW5lYXJSZWdyZXNzaW9uCmZyb20gc2tsZWFybi5tZXRyaWNzIGltcG9ydCBtZWFuX3NxdWFyZWRfZXJyb3IKCiMgR2VuZXJhciBkYXRvcyBkZSBlamVtcGxvCm5wLnJhbmRvbS5zZWVkKDApClggPSBucC5zb3J0KG5wLnJhbmRvbS5yYW5kKDIwLCAxKSAqIDEwLCBheGlzPTApCnkgPSBucC5zaW4oWCkucmF2ZWwoKSArIG5wLnJhbmRvbS5yYW5kbigyMCkgKiAwLjUKCiMgQWp1c3RhciB1biBtb2RlbG8gcG9saW7Ds21pY28gZGUgZ3JhZG8gMTUgKG92ZXJmaXR0aW5nKQpwb2x5X2ZlYXR1cmVzID0gUG9seW5vbWlhbEZlYXR1cmVzKGRlZ3JlZT0xNSkKWF9wb2x5ID0gcG9seV9mZWF0dXJlcy5maXRfdHJhbnNmb3JtKFgpCm1vZGVsID0gTGluZWFyUmVncmVzc2lvbigpCm1vZGVsLmZpdChYX3BvbHksIHkpCgojIFByZWRpY2Npb25lcwpYX3Rlc3QgPSBucC5saW5zcGFjZSgwLCAxMCwgMTAwKS5yZXNoYXBlKC0xLCAxKQpYX3Rlc3RfcG9seSA9IHBvbHlfZmVhdHVyZXMudHJhbnNmb3JtKFhfdGVzdCkKeV9wcmVkID0gbW9kZWwucHJlZGljdChYX3Rlc3RfcG9seSkKCiMgVmlzdWFsaXphY2nDs24KcGx0LnNjYXR0ZXIoWCwgeSwgY29sb3I9J2JsdWUnLCBsYWJlbD0nRGF0b3MgZGUgZW50cmVuYW1pZW50bycpCnBsdC5wbG90KFhfdGVzdCwgeV9wcmVkLCBjb2xvcj0ncmVkJywgbGFiZWw9J01vZGVsbyBwb2xpbsOzbWljbyBncmFkbyAxNScpCnBsdC5sZWdlbmQoKQpwbHQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Generar datos de ejemplo
np.random.seed(0)
X = np.sort(np.random.rand(20, 1) * 10, axis=0)
y = np.sin(X).ravel() + np.random.randn(20) * 0.5

# Ajustar un modelo polin&oacute;mico de grado 15 (overfitting)
poly_features = PolynomialFeatures(degree=15)
X_poly = poly_features.fit_transform(X)
model = LinearRegression()
model.fit(X_poly, y)

# Predicciones
X_test = np.linspace(0, 10, 100).reshape(-1, 1)
X_test_poly = poly_features.transform(X_test)
y_pred = model.predict(X_test_poly)

# Visualizaci&oacute;n
plt.scatter(X, y, color='blue', label='Datos de entrenamiento')
plt.plot(X_test, y_pred, color='red', label='Modelo polin&oacute;mico grado 15')
plt.legend()
plt.show()</pre></div><div class='content'></div><h1><p>¿Qué es el Underfitting?</p>
</h1>
<div class='content'><p>El underfitting ocurre cuando un modelo es demasiado simple para capturar las tendencias subyacentes en los datos. Como resultado, el modelo tiene un rendimiento pobre tanto en el conjunto de entrenamiento como en el conjunto de validación/prueba.</p>
</div><h2><p>Características del Underfitting:</p>
</h2>
<div class='content'><ul>
<li><strong>Baja precisión en datos de entrenamiento</strong>: El modelo no se ajusta bien a los datos de entrenamiento.</li>
<li><strong>Baja precisión en datos de validación/prueba</strong>: El modelo tampoco generaliza bien a nuevos datos.</li>
<li><strong>Modelo simple</strong>: El modelo tiene muy pocos parámetros o es demasiado rígido.</li>
</ul>
</div><h2><p>Ejemplo de Underfitting:</p>
</h2>
<div class='content'><p>Consideremos el mismo conjunto de datos de puntos en un plano. Un modelo de regresión lineal puede ser demasiado simple para capturar la relación no lineal entre las variables.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBBanVzdGFyIHVuIG1vZGVsbyBsaW5lYWwgKHVuZGVyZml0dGluZykKbW9kZWxfbGluZWFyID0gTGluZWFyUmVncmVzc2lvbigpCm1vZGVsX2xpbmVhci5maXQoWCwgeSkKCiMgUHJlZGljY2lvbmVzCnlfcHJlZF9saW5lYXIgPSBtb2RlbF9saW5lYXIucHJlZGljdChYX3Rlc3QpCgojIFZpc3VhbGl6YWNpw7NuCnBsdC5zY2F0dGVyKFgsIHksIGNvbG9yPSdibHVlJywgbGFiZWw9J0RhdG9zIGRlIGVudHJlbmFtaWVudG8nKQpwbHQucGxvdChYX3Rlc3QsIHlfcHJlZF9saW5lYXIsIGNvbG9yPSdncmVlbicsIGxhYmVsPSdNb2RlbG8gbGluZWFsJykKcGx0LmxlZ2VuZCgpCnBsdC5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Ajustar un modelo lineal (underfitting)
model_linear = LinearRegression()
model_linear.fit(X, y)

# Predicciones
y_pred_linear = model_linear.predict(X_test)

# Visualizaci&oacute;n
plt.scatter(X, y, color='blue', label='Datos de entrenamiento')
plt.plot(X_test, y_pred_linear, color='green', label='Modelo lineal')
plt.legend()
plt.show()</pre></div><div class='content'></div><h1><p>Cómo Evitar el Overfitting y el Underfitting</p>
</h1>
<div class='content'></div><h2><p>Técnicas para Evitar el Overfitting:</p>
</h2>
<div class='content'><ol>
<li><strong>Regularización</strong>: Añadir términos de penalización a la función de costo (L1, L2).</li>
<li><strong>Cross-validation</strong>: Utilizar validación cruzada para evaluar el rendimiento del modelo.</li>
<li><strong>Reducción de la complejidad del modelo</strong>: Simplificar el modelo reduciendo el número de parámetros.</li>
<li><strong>Aumentar el tamaño del conjunto de datos</strong>: Obtener más datos de entrenamiento para que el modelo tenga más ejemplos de los que aprender.</li>
</ol>
</div><h2><p>Técnicas para Evitar el Underfitting:</p>
</h2>
<div class='content'><ol>
<li><strong>Aumentar la complejidad del modelo</strong>: Utilizar modelos más complejos que puedan capturar mejor las tendencias en los datos.</li>
<li><strong>Feature Engineering</strong>: Crear nuevas características que puedan ayudar al modelo a capturar mejor las relaciones en los datos.</li>
<li><strong>Reducir el ruido en los datos</strong>: Limpiar los datos para eliminar el ruido que pueda estar afectando el rendimiento del modelo.</li>
</ol>
</div><h1><p>Ejercicio Práctico</p>
</h1>
<div class='content'></div><h2><p>Ejercicio:</p>
</h2>
<div class='content'><ol>
<li>Utiliza el conjunto de datos <code>Boston Housing</code> de <code>sklearn.datasets</code>.</li>
<li>Ajusta un modelo de regresión lineal y un modelo de regresión polinómica de grado 3.</li>
<li>Compara el rendimiento de ambos modelos utilizando validación cruzada.</li>
</ol>
</div><h2><p>Solución:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2Jvc3Rvbgpmcm9tIHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uIGltcG9ydCBjcm9zc192YWxfc2NvcmUKZnJvbSBza2xlYXJuLnBpcGVsaW5lIGltcG9ydCBtYWtlX3BpcGVsaW5lCgojIENhcmdhciBkYXRvcwpib3N0b24gPSBsb2FkX2Jvc3RvbigpClgsIHkgPSBib3N0b24uZGF0YSwgYm9zdG9uLnRhcmdldAoKIyBNb2RlbG8gZGUgcmVncmVzacOzbiBsaW5lYWwKbW9kZWxfbGluZWFyID0gTGluZWFyUmVncmVzc2lvbigpCnNjb3Jlc19saW5lYXIgPSBjcm9zc192YWxfc2NvcmUobW9kZWxfbGluZWFyLCBYLCB5LCBjdj01LCBzY29yaW5nPSduZWdfbWVhbl9zcXVhcmVkX2Vycm9yJykKcHJpbnQoIk1TRSBSZWdyZXNpw7NuIExpbmVhbDoiLCAtc2NvcmVzX2xpbmVhci5tZWFuKCkpCgojIE1vZGVsbyBkZSByZWdyZXNpw7NuIHBvbGluw7NtaWNhIGRlIGdyYWRvIDMKbW9kZWxfcG9seSA9IG1ha2VfcGlwZWxpbmUoUG9seW5vbWlhbEZlYXR1cmVzKGRlZ3JlZT0zKSwgTGluZWFyUmVncmVzc2lvbigpKQpzY29yZXNfcG9seSA9IGNyb3NzX3ZhbF9zY29yZShtb2RlbF9wb2x5LCBYLCB5LCBjdj01LCBzY29yaW5nPSduZWdfbWVhbl9zcXVhcmVkX2Vycm9yJykKcHJpbnQoIk1TRSBSZWdyZXNpw7NuIFBvbGluw7NtaWNhIEdyYWRvIDM6IiwgLXNjb3Jlc19wb2x5Lm1lYW4oKSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.datasets import load_boston
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import make_pipeline

# Cargar datos
boston = load_boston()
X, y = boston.data, boston.target

# Modelo de regresi&oacute;n lineal
model_linear = LinearRegression()
scores_linear = cross_val_score(model_linear, X, y, cv=5, scoring='neg_mean_squared_error')
print(&quot;MSE Regresi&oacute;n Lineal:&quot;, -scores_linear.mean())

# Modelo de regresi&oacute;n polin&oacute;mica de grado 3
model_poly = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())
scores_poly = cross_val_score(model_poly, X, y, cv=5, scoring='neg_mean_squared_error')
print(&quot;MSE Regresi&oacute;n Polin&oacute;mica Grado 3:&quot;, -scores_poly.mean())</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>El overfitting y el underfitting son problemas críticos en el desarrollo de modelos de Machine Learning. El equilibrio entre la complejidad del modelo y su capacidad para generalizar a nuevos datos es esencial para construir modelos efectivos. Utilizando técnicas como la regularización, la validación cruzada y el ajuste adecuado de la complejidad del modelo, podemos mitigar estos problemas y mejorar el rendimiento de nuestros modelos.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='06-03-curva-roc-auc' title="Curva ROC y AUC">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='07-01-ensemble-learning' title="Ensemble Learning">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
