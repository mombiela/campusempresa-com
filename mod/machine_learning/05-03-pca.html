<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    <title>Análisis de Componentes Principales (PCA)</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/05-03-pca" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/05-03-pca" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/05-03-pca" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>var DEVELOP = window.location.href.indexOf("localhost")!=-1 && true;</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/mod/machine_learning/05-03-pca" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/machine_learning/05-03-pca" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col" id="left_menu">
					<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Contenido del curso
	</a>

			</div>
		</div>
	</div>
</div>

<!--  
<div class="top-bar container-fluid">
	<div class="container-xxl">
		<nav class="navbar navbar-expand-md p-0">
			<div class="container-fluid">
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				
				<div class="collapse navbar-collapse" id="navbarNav">
					<div class="navbar-nav me-auto">
							<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Contenido del curso
	</a>

					</div>
				</div>			
							</div>
		</nav>
	</div>
</div>
 -->				<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-02-clustering-jerarquico' title="Clustering jerárquico">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<h2 style="text-decoration:underline">Análisis de Componentes Principales (PCA)</h2>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-04-dbscan' title="Análisis de agrupamiento DBSCAN">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>El Análisis de Componentes Principales (PCA, por sus siglas en inglés) es una técnica de reducción de dimensionalidad que se utiliza para transformar un conjunto de variables posiblemente correlacionadas en un conjunto de variables no correlacionadas llamadas componentes principales. PCA es ampliamente utilizado en Machine Learning y análisis de datos para simplificar modelos, visualizar datos y eliminar ruido.</p>
</div><h1>Objetivos del PCA</h1>
<div class='content'><ul>
<li><strong>Reducción de dimensionalidad:</strong> Reducir el número de variables en un conjunto de datos mientras se retiene la mayor cantidad posible de variabilidad.</li>
<li><strong>Eliminación de ruido:</strong> Filtrar el ruido de los datos para mejorar la calidad del análisis.</li>
<li><strong>Visualización:</strong> Facilitar la visualización de datos en espacios de menor dimensión.</li>
<li><strong>Descorrelación:</strong> Transformar variables correlacionadas en variables no correlacionadas.</li>
</ul>
</div><h1>Conceptos Clave</h1>
<div class='content'><ol>
<li><strong>Varianza:</strong> Medida de la dispersión de los datos. PCA busca maximizar la varianza en los componentes principales.</li>
<li><strong>Componentes Principales:</strong> Nuevas variables no correlacionadas que son combinaciones lineales de las variables originales.</li>
<li><strong>Autovalores y Autovectores:</strong> Los autovalores representan la cantidad de varianza explicada por cada componente principal, y los autovectores son las direcciones de los componentes principales.</li>
</ol>
</div><h1>Pasos para Realizar PCA</h1>
<div class='content'><ol>
<li>
<p><strong>Estandarización de Datos:</strong></p>
<ul>
<li>Normalizar los datos para que cada variable tenga media cero y varianza uno.</li>
</ul>
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)
</code></pre>
</li>
<li>
<p><strong>Cálculo de la Matriz de Covarianza:</strong></p>
<ul>
<li>Calcular la matriz de covarianza para entender cómo las variables varían juntas.</li>
</ul>
<pre><code class="language-python">import numpy as np
covariance_matrix = np.cov(data_scaled.T)
</code></pre>
</li>
<li>
<p><strong>Cálculo de Autovalores y Autovectores:</strong></p>
<ul>
<li>Descomponer la matriz de covarianza en autovalores y autovectores.</li>
</ul>
<pre><code class="language-python">eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)
</code></pre>
</li>
<li>
<p><strong>Selección de Componentes Principales:</strong></p>
<ul>
<li>Ordenar los autovalores en orden descendente y seleccionar los autovectores correspondientes.</li>
</ul>
<pre><code class="language-python">sorted_index = np.argsort(eigenvalues)[::-1]
sorted_eigenvalues = eigenvalues[sorted_index]
sorted_eigenvectors = eigenvectors[:, sorted_index]
</code></pre>
</li>
<li>
<p><strong>Transformación de Datos:</strong></p>
<ul>
<li>Proyectar los datos originales en el nuevo espacio de componentes principales.</li>
</ul>
<pre><code class="language-python">n_components = 2  # Número de componentes principales a retener
eigenvector_subset = sorted_eigenvectors[:, :n_components]
data_reduced = np.dot(data_scaled, eigenvector_subset)
</code></pre>
</li>
</ol>
</div><h1>Ejemplo Práctico</h1>
<div class='content'><p>Supongamos que tenemos un conjunto de datos con varias características y queremos reducir la dimensionalidad a dos componentes principales.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBwYW5kYXMgYXMgcGQKZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFN0YW5kYXJkU2NhbGVyCmZyb20gc2tsZWFybi5kZWNvbXBvc2l0aW9uIGltcG9ydCBQQ0EKaW1wb3J0IG1hdHBsb3RsaWIucHlwbG90IGFzIHBsdAoKIyBHZW5lcmFyIGRhdG9zIGRlIGVqZW1wbG8KbnAucmFuZG9tLnNlZWQoMCkKZGF0YSA9IG5wLnJhbmRvbS5yYW5kKDEwMCwgNSkgICMgMTAwIG11ZXN0cmFzLCA1IGNhcmFjdGVyw61zdGljYXMKCiMgRXN0YW5kYXJpemFyIGxvcyBkYXRvcwpzY2FsZXIgPSBTdGFuZGFyZFNjYWxlcigpCmRhdGFfc2NhbGVkID0gc2NhbGVyLmZpdF90cmFuc2Zvcm0oZGF0YSkKCiMgQXBsaWNhciBQQ0EKcGNhID0gUENBKG5fY29tcG9uZW50cz0yKQpkYXRhX3BjYSA9IHBjYS5maXRfdHJhbnNmb3JtKGRhdGFfc2NhbGVkKQoKIyBWaXN1YWxpemFyIGxvcyByZXN1bHRhZG9zCnBsdC5zY2F0dGVyKGRhdGFfcGNhWzosIDBdLCBkYXRhX3BjYVs6LCAxXSkKcGx0LnhsYWJlbCgnQ29tcG9uZW50ZSBQcmluY2lwYWwgMScpCnBsdC55bGFiZWwoJ0NvbXBvbmVudGUgUHJpbmNpcGFsIDInKQpwbHQudGl0bGUoJ1Byb3llY2Npw7NuIFBDQScpCnBsdC5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Generar datos de ejemplo
np.random.seed(0)
data = np.random.rand(100, 5)  # 100 muestras, 5 caracter&iacute;sticas

# Estandarizar los datos
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# Aplicar PCA
pca = PCA(n_components=2)
data_pca = pca.fit_transform(data_scaled)

# Visualizar los resultados
plt.scatter(data_pca[:, 0], data_pca[:, 1])
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.title('Proyecci&oacute;n PCA')
plt.show()</pre></div><div class='content'></div><h1>Ejercicio Práctico</h1>
<h2>Ejercicio 1: Aplicar PCA a un Conjunto de Datos Real</h2>
<div class='content'><ol>
<li>Cargar el conjunto de datos <code>Iris</code> desde <code>sklearn.datasets</code>.</li>
<li>Estandarizar los datos.</li>
<li>Aplicar PCA para reducir las dimensiones a 2 componentes principales.</li>
<li>Visualizar los resultados en un gráfico de dispersión.</li>
</ol>
</div><h2>Solución</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2lyaXMKZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFN0YW5kYXJkU2NhbGVyCmZyb20gc2tsZWFybi5kZWNvbXBvc2l0aW9uIGltcG9ydCBQQ0EKaW1wb3J0IG1hdHBsb3RsaWIucHlwbG90IGFzIHBsdAoKIyBDYXJnYXIgZWwgY29uanVudG8gZGUgZGF0b3MgSXJpcwppcmlzID0gbG9hZF9pcmlzKCkKZGF0YSA9IGlyaXMuZGF0YQp0YXJnZXQgPSBpcmlzLnRhcmdldAoKIyBFc3RhbmRhcml6YXIgbG9zIGRhdG9zCnNjYWxlciA9IFN0YW5kYXJkU2NhbGVyKCkKZGF0YV9zY2FsZWQgPSBzY2FsZXIuZml0X3RyYW5zZm9ybShkYXRhKQoKIyBBcGxpY2FyIFBDQQpwY2EgPSBQQ0Eobl9jb21wb25lbnRzPTIpCmRhdGFfcGNhID0gcGNhLmZpdF90cmFuc2Zvcm0oZGF0YV9zY2FsZWQpCgojIFZpc3VhbGl6YXIgbG9zIHJlc3VsdGFkb3MKcGx0LnNjYXR0ZXIoZGF0YV9wY2FbOiwgMF0sIGRhdGFfcGNhWzosIDFdLCBjPXRhcmdldCwgY21hcD0ndmlyaWRpcycpCnBsdC54bGFiZWwoJ0NvbXBvbmVudGUgUHJpbmNpcGFsIDEnKQpwbHQueWxhYmVsKCdDb21wb25lbnRlIFByaW5jaXBhbCAyJykKcGx0LnRpdGxlKCdQcm95ZWNjacOzbiBQQ0EgZGVsIENvbmp1bnRvIGRlIERhdG9zIElyaXMnKQpwbHQuY29sb3JiYXIoKQpwbHQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Cargar el conjunto de datos Iris
iris = load_iris()
data = iris.data
target = iris.target

# Estandarizar los datos
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# Aplicar PCA
pca = PCA(n_components=2)
data_pca = pca.fit_transform(data_scaled)

# Visualizar los resultados
plt.scatter(data_pca[:, 0], data_pca[:, 1], c=target, cmap='viridis')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.title('Proyecci&oacute;n PCA del Conjunto de Datos Iris')
plt.colorbar()
plt.show()</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>El Análisis de Componentes Principales (PCA) es una herramienta poderosa para la reducción de dimensionalidad y la visualización de datos. Al transformar las variables originales en componentes principales no correlacionadas, PCA permite simplificar modelos y mejorar la interpretabilidad de los datos. En el siguiente módulo, exploraremos otras técnicas de clustering no supervisado que también son esenciales en el análisis de datos y Machine Learning.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-02-clustering-jerarquico' title="Clustering jerárquico">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-04-dbscan' title="Análisis de agrupamiento DBSCAN">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
	     crossorigin="anonymous"></script>
	<!-- enterprise_campus -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-0611338592562725"
	     data-ad-slot="6914733106"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
	     (adsbygoogle = window.adsbygoogle || []).push({});
	</script>
			
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de Machine Learning</h1>
<h2>Módulo 1: Introducción al Machine Learning</h2>
<ul>
<li><a href="01-01-que-es-machine-learning">¿Qué es el Machine Learning?</a></li>
<li><a href="01-02-historia-evolucion-machine-learning">Historia y evolución del Machine Learning</a></li>
<li><a href="01-03-tipos-machine-learning">Tipos de Machine Learning</a></li>
<li><a href="01-04-aplicaciones-machine-learning">Aplicaciones del Machine Learning</a></li>
</ul>
<h2>Módulo 2: Fundamentos de Estadística y Probabilidad</h2>
<ul>
<li><a href="02-01-conceptos-basicos-estadistica">Conceptos básicos de estadística</a></li>
<li><a href="02-02-distribuciones-probabilidad">Distribuciones de probabilidad</a></li>
<li><a href="02-03-inferencia-estadistica">Inferencia estadística</a></li>
<li><a href="02-04-teorema-bayes">Teorema de Bayes</a></li>
</ul>
<h2>Módulo 3: Preprocesamiento de Datos</h2>
<ul>
<li><a href="03-01-limpieza-datos">Limpieza de datos</a></li>
<li><a href="03-02-transformacion-datos">Transformación de datos</a></li>
<li><a href="03-03-normalizacion-estandarizacion">Normalización y estandarización</a></li>
<li><a href="03-04-manejo-datos-faltantes">Manejo de datos faltantes</a></li>
</ul>
<h2>Módulo 4: Algoritmos de Machine Learning Supervisado</h2>
<ul>
<li><a href="04-01-regresion-lineal">Regresión lineal</a></li>
<li><a href="04-02-regresion-logistica">Regresión logística</a></li>
<li><a href="04-03-arboles-decision">Árboles de decisión</a></li>
<li><a href="04-04-svm">Máquinas de soporte vectorial (SVM)</a></li>
<li><a href="04-05-knn">K-Vecinos más cercanos (K-NN)</a></li>
<li><a href="04-06-redes-neuronales">Redes neuronales</a></li>
</ul>
<h2>Módulo 5: Algoritmos de Machine Learning No Supervisado</h2>
<ul>
<li><a href="05-01-clustering-k-means">Clustering: K-means</a></li>
<li><a href="05-02-clustering-jerarquico">Clustering jerárquico</a></li>
<li><a href="05-03-pca">Análisis de componentes principales (PCA)</a></li>
<li><a href="05-04-dbscan">Análisis de agrupamiento DBSCAN</a></li>
</ul>
<h2>Módulo 6: Evaluación y Validación de Modelos</h2>
<ul>
<li><a href="06-01-metricas-evaluacion">Métricas de evaluación</a></li>
<li><a href="06-02-validacion-cruzada">Validación cruzada</a></li>
<li><a href="06-03-curva-roc-auc">Curva ROC y AUC</a></li>
<li><a href="06-04-overfitting-underfitting">Overfitting y underfitting</a></li>
</ul>
<h2>Módulo 7: Técnicas Avanzadas y Optimización</h2>
<ul>
<li><a href="07-01-ensemble-learning">Ensemble Learning</a></li>
<li><a href="07-02-gradient-boosting">Gradient Boosting</a></li>
<li><a href="07-03-deep-learning">Redes neuronales profundas (Deep Learning)</a></li>
<li><a href="07-04-optimizacion-hiperparametros">Optimización de hiperparámetros</a></li>
</ul>
<h2>Módulo 8: Implementación y Despliegue de Modelos</h2>
<ul>
<li><a href="08-01-frameworks-bibliotecas">Frameworks y bibliotecas populares</a></li>
<li><a href="08-02-implementacion-produccion">Implementación de modelos en producción</a></li>
<li><a href="08-03-mantenimiento-monitoreo">Mantenimiento y monitoreo de modelos</a></li>
<li><a href="08-04-etica-privacidad">Consideraciones éticas y de privacidad</a></li>
</ul>
<h2>Módulo 9: Proyectos Prácticos</h2>
<ul>
<li><a href="09-01-proyecto-prediccion-precios-viviendas">Proyecto 1: Predicción de precios de viviendas</a></li>
<li><a href="09-02-proyecto-clasificacion-imagenes">Proyecto 2: Clasificación de imágenes</a></li>
<li><a href="09-03-proyecto-analisis-sentimientos">Proyecto 3: Análisis de sentimientos en redes sociales</a></li>
<li><a href="09-04-proyecto-deteccion-fraudes">Proyecto 4: Detección de fraudes</a></li>
</ul>
<h2>Módulo 10: Recursos Adicionales</h2>
<ul>
<li><a href="10-01-libros-recomendados">Libros recomendados</a></li>
<li><a href="10-02-cursos-en-linea">Cursos en línea</a></li>
<li><a href="10-03-comunidades-foros">Comunidades y foros</a></li>
<li><a href="10-04-herramientas-software">Herramientas y software</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
