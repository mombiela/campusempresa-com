<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Validación Cruzada</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/validacion-cruzada" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/validacion-cruzada" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/validacion-cruzada" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/machine_learning/validacion-cruzada" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/machine_learning/validacion-cruzada" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-4'>
					<a href='metricas-evaluacion'>&#x25C4;Métricas de Evaluación</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Validación Cruzada</a>
	</div>
	<div class='col-4 text-end'>
					<a href='curvas-roc-auc'>Curvas ROC y AUC &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción</h1>
<div class='content'><p>La validación cruzada es una técnica fundamental en Machine Learning para evaluar la capacidad de generalización de un modelo. En lugar de depender de una única partición de datos para entrenamiento y prueba, la validación cruzada permite utilizar múltiples particiones para obtener una estimación más robusta del rendimiento del modelo.</p>
</div><h1>Conceptos Clave</h1>
<div class='content'><ul>
<li><strong>Sobreajuste (Overfitting):</strong> Ocurre cuando un modelo se ajusta demasiado a los datos de entrenamiento, capturando ruido y patrones irrelevantes, lo que resulta en un mal desempeño en datos no vistos.</li>
<li><strong>Subajuste (Underfitting):</strong> Ocurre cuando un modelo es demasiado simple para capturar la estructura subyacente de los datos, resultando en un mal desempeño tanto en los datos de entrenamiento como en los de prueba.</li>
<li><strong>Partición de Datos:</strong> Dividir el conjunto de datos en subconjuntos de entrenamiento y prueba para evaluar el rendimiento del modelo.</li>
<li><strong>K-Fold Cross-Validation:</strong> Técnica de validación cruzada donde los datos se dividen en 'k' subconjuntos (folds) y el modelo se entrena y evalúa 'k' veces, cada vez utilizando un fold diferente como conjunto de prueba y los restantes como conjunto de entrenamiento.</li>
</ul>
</div><h1>Tipos de Validación Cruzada</h1>
<div class='content'></div><h2>K-Fold Cross-Validation</h2>
<div class='content'><p>En K-Fold Cross-Validation, el conjunto de datos se divide en 'k' partes iguales. El modelo se entrena 'k' veces, cada vez utilizando un fold diferente como conjunto de prueba y los restantes como conjunto de entrenamiento.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgS0ZvbGQKZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgTGluZWFyUmVncmVzc2lvbgpmcm9tIHNrbGVhcm4ubWV0cmljcyBpbXBvcnQgbWVhbl9zcXVhcmVkX2Vycm9yCmltcG9ydCBudW1weSBhcyBucAoKIyBEYXRvcyBkZSBlamVtcGxvClggPSBucC5hcnJheShbWzEsIDJdLCBbMywgNF0sIFs1LCA2XSwgWzcsIDhdLCBbOSwgMTBdXSkKeSA9IG5wLmFycmF5KFsxLCAyLCAzLCA0LCA1XSkKCiMgQ29uZmlndXJhY2nDs24gZGUgSy1Gb2xkCmtmID0gS0ZvbGQobl9zcGxpdHM9NSkKCiMgSW5pY2lhbGl6YWNpw7NuIGRlbCBtb2RlbG8KbW9kZWwgPSBMaW5lYXJSZWdyZXNzaW9uKCkKCiMgTGlzdGEgcGFyYSBhbG1hY2VuYXIgbG9zIGVycm9yZXMKZXJyb3JzID0gW10KCiMgVmFsaWRhY2nDs24gY3J1emFkYQpmb3IgdHJhaW5faW5kZXgsIHRlc3RfaW5kZXggaW4ga2Yuc3BsaXQoWCk6CiAgICBYX3RyYWluLCBYX3Rlc3QgPSBYW3RyYWluX2luZGV4XSwgWFt0ZXN0X2luZGV4XQogICAgeV90cmFpbiwgeV90ZXN0ID0geVt0cmFpbl9pbmRleF0sIHlbdGVzdF9pbmRleF0KICAgIAogICAgbW9kZWwuZml0KFhfdHJhaW4sIHlfdHJhaW4pCiAgICBwcmVkaWN0aW9ucyA9IG1vZGVsLnByZWRpY3QoWF90ZXN0KQogICAgZXJyb3IgPSBtZWFuX3NxdWFyZWRfZXJyb3IoeV90ZXN0LCBwcmVkaWN0aW9ucykKICAgIGVycm9ycy5hcHBlbmQoZXJyb3IpCgpwcmludCgiRXJyb3JlcyBlbiBjYWRhIGZvbGQ6IiwgZXJyb3JzKQpwcmludCgiRXJyb3IgcHJvbWVkaW86IiwgbnAubWVhbihlcnJvcnMpKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np

# Datos de ejemplo
X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])
y = np.array([1, 2, 3, 4, 5])

# Configuraci&oacute;n de K-Fold
kf = KFold(n_splits=5)

# Inicializaci&oacute;n del modelo
model = LinearRegression()

# Lista para almacenar los errores
errors = []

# Validaci&oacute;n cruzada
for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    error = mean_squared_error(y_test, predictions)
    errors.append(error)

print(&quot;Errores en cada fold:&quot;, errors)
print(&quot;Error promedio:&quot;, np.mean(errors))</pre></div><div class='content'></div><h2>Leave-One-Out Cross-Validation (LOOCV)</h2>
<div class='content'><p>En LOOCV, cada observación en el conjunto de datos se utiliza una vez como conjunto de prueba, mientras que el resto se utiliza como conjunto de entrenamiento. Esto resulta en 'n' iteraciones, donde 'n' es el número de observaciones.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgTGVhdmVPbmVPdXQKCiMgQ29uZmlndXJhY2nDs24gZGUgTE9PQ1YKbG9vID0gTGVhdmVPbmVPdXQoKQoKIyBMaXN0YSBwYXJhIGFsbWFjZW5hciBsb3MgZXJyb3JlcwplcnJvcnMgPSBbXQoKIyBWYWxpZGFjacOzbiBjcnV6YWRhCmZvciB0cmFpbl9pbmRleCwgdGVzdF9pbmRleCBpbiBsb28uc3BsaXQoWCk6CiAgICBYX3RyYWluLCBYX3Rlc3QgPSBYW3RyYWluX2luZGV4XSwgWFt0ZXN0X2luZGV4XQogICAgeV90cmFpbiwgeV90ZXN0ID0geVt0cmFpbl9pbmRleF0sIHlbdGVzdF9pbmRleF0KICAgIAogICAgbW9kZWwuZml0KFhfdHJhaW4sIHlfdHJhaW4pCiAgICBwcmVkaWN0aW9ucyA9IG1vZGVsLnByZWRpY3QoWF90ZXN0KQogICAgZXJyb3IgPSBtZWFuX3NxdWFyZWRfZXJyb3IoeV90ZXN0LCBwcmVkaWN0aW9ucykKICAgIGVycm9ycy5hcHBlbmQoZXJyb3IpCgpwcmludCgiRXJyb3JlcyBlbiBjYWRhIGl0ZXJhY2nDs246IiwgZXJyb3JzKQpwcmludCgiRXJyb3IgcHJvbWVkaW86IiwgbnAubWVhbihlcnJvcnMpKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import LeaveOneOut

# Configuraci&oacute;n de LOOCV
loo = LeaveOneOut()

# Lista para almacenar los errores
errors = []

# Validaci&oacute;n cruzada
for train_index, test_index in loo.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    error = mean_squared_error(y_test, predictions)
    errors.append(error)

print(&quot;Errores en cada iteraci&oacute;n:&quot;, errors)
print(&quot;Error promedio:&quot;, np.mean(errors))</pre></div><div class='content'></div><h2>Stratified K-Fold Cross-Validation</h2>
<div class='content'><p>En problemas de clasificación, es importante que cada fold tenga una proporción similar de clases. Stratified K-Fold asegura que cada fold sea representativo de la distribución de clases en el conjunto de datos completo.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgU3RyYXRpZmllZEtGb2xkCgojIERhdG9zIGRlIGVqZW1wbG8gcGFyYSBjbGFzaWZpY2FjacOzbgpYID0gbnAuYXJyYXkoW1sxLCAyXSwgWzMsIDRdLCBbNSwgNl0sIFs3LCA4XSwgWzksIDEwXV0pCnkgPSBucC5hcnJheShbMCwgMSwgMCwgMSwgMF0pCgojIENvbmZpZ3VyYWNpw7NuIGRlIFN0cmF0aWZpZWQgSy1Gb2xkCnNrZiA9IFN0cmF0aWZpZWRLRm9sZChuX3NwbGl0cz0zKQoKIyBMaXN0YSBwYXJhIGFsbWFjZW5hciBsb3MgZXJyb3JlcwplcnJvcnMgPSBbXQoKIyBWYWxpZGFjacOzbiBjcnV6YWRhCmZvciB0cmFpbl9pbmRleCwgdGVzdF9pbmRleCBpbiBza2Yuc3BsaXQoWCwgeSk6CiAgICBYX3RyYWluLCBYX3Rlc3QgPSBYW3RyYWluX2luZGV4XSwgWFt0ZXN0X2luZGV4XQogICAgeV90cmFpbiwgeV90ZXN0ID0geVt0cmFpbl9pbmRleF0sIHlbdGVzdF9pbmRleF0KICAgIAogICAgbW9kZWwuZml0KFhfdHJhaW4sIHlfdHJhaW4pCiAgICBwcmVkaWN0aW9ucyA9IG1vZGVsLnByZWRpY3QoWF90ZXN0KQogICAgZXJyb3IgPSBtZWFuX3NxdWFyZWRfZXJyb3IoeV90ZXN0LCBwcmVkaWN0aW9ucykKICAgIGVycm9ycy5hcHBlbmQoZXJyb3IpCgpwcmludCgiRXJyb3JlcyBlbiBjYWRhIGZvbGQ6IiwgZXJyb3JzKQpwcmludCgiRXJyb3IgcHJvbWVkaW86IiwgbnAubWVhbihlcnJvcnMpKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import StratifiedKFold

# Datos de ejemplo para clasificaci&oacute;n
X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])
y = np.array([0, 1, 0, 1, 0])

# Configuraci&oacute;n de Stratified K-Fold
skf = StratifiedKFold(n_splits=3)

# Lista para almacenar los errores
errors = []

# Validaci&oacute;n cruzada
for train_index, test_index in skf.split(X, y):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    error = mean_squared_error(y_test, predictions)
    errors.append(error)

print(&quot;Errores en cada fold:&quot;, errors)
print(&quot;Error promedio:&quot;, np.mean(errors))</pre></div><div class='content'></div><h1>Comparación de Métodos</h1>
<div class='content'><p>| Método                  | Ventajas                                                                 | Desventajas                                                              |
|-------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|
| K-Fold Cross-Validation | - Balance entre bias y varianza<br>- Menor costo computacional que LOOCV | - Puede ser menos preciso que LOOCV en pequeños conjuntos de datos       |
| LOOCV                   | - Utiliza toda la información disponible<br>- Menor bias                 | - Alto costo computacional<br>- Mayor varianza en la estimación del error|
| Stratified K-Fold       | - Mejor representación de la distribución de clases                      | - Similar costo computacional a K-Fold                                   |</p>
</div><h1>Conclusión</h1>
<div class='content'><p>La validación cruzada es una herramienta esencial para evaluar el rendimiento de los modelos de Machine Learning. Al utilizar técnicas como K-Fold, LOOCV y Stratified K-Fold, los profesionales pueden obtener estimaciones más precisas y robustas del desempeño del modelo, ayudando a prevenir problemas de sobreajuste y subajuste. La elección del método de validación cruzada dependerá del tamaño del conjunto de datos y del problema específico que se esté abordando.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='metricas-evaluacion'>&#x25C4;Métricas de Evaluación</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Validación Cruzada</a>
	</div>
	<div class='col-4 text-end'>
					<a href='curvas-roc-auc'>Curvas ROC y AUC &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
