<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ajuste y Optimización de Modelos</title>

    <link rel="alternate" href="https://campusempresa.com/mod/analisis_datos/05-03-ajuste-optimizacion" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/analisis_datos/05-03-ajust-optimitzacio" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/analisis_datos/05-03-tuning-optimization" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/analisis_datos/05-03-tuning-optimization" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/analisis_datos/05-03-ajust-optimitzacio" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-02-validacion-cruzada' title="Validación Cruzada y Técnicas de Validación">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Ajuste y Optimización de Modelos</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='06-01-implementacion-produccion' title="Implementación de Modelos en Producción">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'><p>En este tema, aprenderemos sobre las técnicas y métodos utilizados para ajustar y optimizar modelos de análisis de datos. El objetivo es mejorar la precisión y la eficiencia de los modelos para que puedan proporcionar resultados más fiables y útiles.</p>
</div><h1>Conceptos Clave</h1>
<div class='content'><ol>
<li><strong>Ajuste de Modelos</strong>: Proceso de modificar los parámetros de un modelo para mejorar su rendimiento.</li>
<li><strong>Optimización de Hiperparámetros</strong>: Selección de los mejores hiperparámetros para un modelo.</li>
<li><strong>Regularización</strong>: Técnica para prevenir el sobreajuste añadiendo una penalización a la complejidad del modelo.</li>
<li><strong>Grid Search</strong>: Método exhaustivo para encontrar la mejor combinación de hiperparámetros.</li>
<li><strong>Random Search</strong>: Método aleatorio para encontrar una buena combinación de hiperparámetros.</li>
<li><strong>Bayesian Optimization</strong>: Método probabilístico para optimizar hiperparámetros.</li>
</ol>
</div><h1>Ajuste de Modelos</h1>
<div class='content'><p>El ajuste de modelos implica modificar los parámetros internos del modelo para mejorar su rendimiento. Esto se puede hacer mediante técnicas como:</p>
<ul>
<li><strong>Gradient Descent</strong>: Algoritmo de optimización que ajusta los parámetros del modelo minimizando una función de pérdida.</li>
<li><strong>Stochastic Gradient Descent (SGD)</strong>: Variante del Gradient Descent que utiliza una muestra aleatoria de datos en cada iteración.</li>
</ul>
</div><h2>Ejemplo de Gradient Descent en Python</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIEZ1bmNpw7NuIGRlIHDDqXJkaWRhIChNU0UpCmRlZiBsb3NzX2Z1bmN0aW9uKHlfdHJ1ZSwgeV9wcmVkKToKICAgIHJldHVybiBucC5tZWFuKCh5X3RydWUgLSB5X3ByZWQpICoqIDIpCgojIERlcml2YWRhIGRlIGxhIGZ1bmNpw7NuIGRlIHDDqXJkaWRhCmRlZiBncmFkaWVudChYLCB5X3RydWUsIHlfcHJlZCk6CiAgICByZXR1cm4gLTIgKiBucC5kb3QoWC5ULCAoeV90cnVlIC0geV9wcmVkKSkgLyBsZW4oeV90cnVlKQoKIyBHcmFkaWVudCBEZXNjZW50CmRlZiBncmFkaWVudF9kZXNjZW50KFgsIHksIGxlYXJuaW5nX3JhdGU9MC4wMSwgZXBvY2hzPTEwMDApOgogICAgbSwgbiA9IFguc2hhcGUKICAgIHRoZXRhID0gbnAuemVyb3MobikKICAgIGZvciBlcG9jaCBpbiByYW5nZShlcG9jaHMpOgogICAgICAgIHlfcHJlZCA9IG5wLmRvdChYLCB0aGV0YSkKICAgICAgICBncmFkID0gZ3JhZGllbnQoWCwgeSwgeV9wcmVkKQogICAgICAgIHRoZXRhIC09IGxlYXJuaW5nX3JhdGUgKiBncmFkCiAgICAgICAgaWYgZXBvY2ggJSAxMDAgPT0gMDoKICAgICAgICAgICAgcHJpbnQoZidFcG9jaCB7ZXBvY2h9LCBMb3NzOiB7bG9zc19mdW5jdGlvbih5LCB5X3ByZWQpfScpCiAgICByZXR1cm4gdGhldGEKCiMgRGF0b3MgZGUgZWplbXBsbwpYID0gbnAuYXJyYXkoW1sxLCAxXSwgWzEsIDJdLCBbMiwgMl0sIFsyLCAzXV0pCnkgPSBucC5kb3QoWCwgbnAuYXJyYXkoWzEsIDJdKSkgKyAzCgojIEFqdXN0ZSBkZWwgbW9kZWxvCnRoZXRhID0gZ3JhZGllbnRfZGVzY2VudChYLCB5KQpwcmludChmJ0NvZWZpY2llbnRlcyBhanVzdGFkb3M6IHt0aGV0YX0nKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Funci&oacute;n de p&eacute;rdida (MSE)
def loss_function(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

# Derivada de la funci&oacute;n de p&eacute;rdida
def gradient(X, y_true, y_pred):
    return -2 * np.dot(X.T, (y_true - y_pred)) / len(y_true)

# Gradient Descent
def gradient_descent(X, y, learning_rate=0.01, epochs=1000):
    m, n = X.shape
    theta = np.zeros(n)
    for epoch in range(epochs):
        y_pred = np.dot(X, theta)
        grad = gradient(X, y, y_pred)
        theta -= learning_rate * grad
        if epoch % 100 == 0:
            print(f'Epoch {epoch}, Loss: {loss_function(y, y_pred)}')
    return theta

# Datos de ejemplo
X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
y = np.dot(X, np.array([1, 2])) + 3

# Ajuste del modelo
theta = gradient_descent(X, y)
print(f'Coeficientes ajustados: {theta}')</pre></div><div class='content'></div><h1>Optimización de Hiperparámetros</h1>
<div class='content'><p>Los hiperparámetros son parámetros que no se ajustan durante el entrenamiento del modelo, sino que se establecen antes del proceso de entrenamiento. La optimización de hiperparámetros busca encontrar la mejor combinación de estos para mejorar el rendimiento del modelo.</p>
</div><h2>Grid Search</h2>
<div class='content'><p>Grid Search es una técnica exhaustiva que prueba todas las combinaciones posibles de hiperparámetros en un espacio definido.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgR3JpZFNlYXJjaENWCmZyb20gc2tsZWFybi5lbnNlbWJsZSBpbXBvcnQgUmFuZG9tRm9yZXN0Q2xhc3NpZmllcgoKIyBEZWZpbmljacOzbiBkZWwgbW9kZWxvCm1vZGVsID0gUmFuZG9tRm9yZXN0Q2xhc3NpZmllcigpCgojIERlZmluaWNpw7NuIGRlbCBlc3BhY2lvIGRlIGhpcGVycGFyw6FtZXRyb3MKcGFyYW1fZ3JpZCA9IHsKICAgICduX2VzdGltYXRvcnMnOiBbMTAsIDUwLCAxMDBdLAogICAgJ21heF9kZXB0aCc6IFtOb25lLCAxMCwgMjAsIDMwXSwKICAgICdtaW5fc2FtcGxlc19zcGxpdCc6IFsyLCA1LCAxMF0KfQoKIyBHcmlkIFNlYXJjaApncmlkX3NlYXJjaCA9IEdyaWRTZWFyY2hDVihlc3RpbWF0b3I9bW9kZWwsIHBhcmFtX2dyaWQ9cGFyYW1fZ3JpZCwgY3Y9NSkKZ3JpZF9zZWFyY2guZml0KFgsIHkpCgpwcmludChmJ01lam9yZXMgaGlwZXJwYXLDoW1ldHJvczoge2dyaWRfc2VhcmNoLmJlc3RfcGFyYW1zX30nKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Definici&oacute;n del modelo
model = RandomForestClassifier()

# Definici&oacute;n del espacio de hiperpar&aacute;metros
param_grid = {
    'n_estimators': [10, 50, 100],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# Grid Search
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)
grid_search.fit(X, y)

print(f'Mejores hiperpar&aacute;metros: {grid_search.best_params_}')</pre></div><div class='content'></div><h2>Random Search</h2>
<div class='content'><p>Random Search es una técnica que selecciona combinaciones aleatorias de hiperparámetros dentro de un espacio definido.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgUmFuZG9taXplZFNlYXJjaENWCgojIFJhbmRvbSBTZWFyY2gKcmFuZG9tX3NlYXJjaCA9IFJhbmRvbWl6ZWRTZWFyY2hDVihlc3RpbWF0b3I9bW9kZWwsIHBhcmFtX2Rpc3RyaWJ1dGlvbnM9cGFyYW1fZ3JpZCwgbl9pdGVyPTEwLCBjdj01LCByYW5kb21fc3RhdGU9NDIpCnJhbmRvbV9zZWFyY2guZml0KFgsIHkpCgpwcmludChmJ01lam9yZXMgaGlwZXJwYXLDoW1ldHJvczoge3JhbmRvbV9zZWFyY2guYmVzdF9wYXJhbXNffScp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.model_selection import RandomizedSearchCV

# Random Search
random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=5, random_state=42)
random_search.fit(X, y)

print(f'Mejores hiperpar&aacute;metros: {random_search.best_params_}')</pre></div><div class='content'></div><h2>Regularización</h2>
<div class='content'><p>La regularización es una técnica que añade una penalización a la función de pérdida para evitar el sobreajuste. Las técnicas comunes de regularización incluyen:</p>
<ul>
<li><strong>L1 Regularization (Lasso)</strong>: Añade una penalización proporcional al valor absoluto de los coeficientes.</li>
<li><strong>L2 Regularization (Ridge)</strong>: Añade una penalización proporcional al cuadrado de los coeficientes.</li>
<li><strong>Elastic Net</strong>: Combina L1 y L2 regularización.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmxpbmVhcl9tb2RlbCBpbXBvcnQgUmlkZ2UsIExhc3NvLCBFbGFzdGljTmV0CgojIFJpZGdlIFJlZ3Jlc3Npb24KcmlkZ2UgPSBSaWRnZShhbHBoYT0xLjApCnJpZGdlLmZpdChYLCB5KQoKIyBMYXNzbyBSZWdyZXNzaW9uCmxhc3NvID0gTGFzc28oYWxwaGE9MC4xKQpsYXNzby5maXQoWCwgeSkKCiMgRWxhc3RpYyBOZXQKZWxhc3RpY19uZXQgPSBFbGFzdGljTmV0KGFscGhhPTAuMSwgbDFfcmF0aW89MC41KQplbGFzdGljX25ldC5maXQoWCwgeSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.linear_model import Ridge, Lasso, ElasticNet

# Ridge Regression
ridge = Ridge(alpha=1.0)
ridge.fit(X, y)

# Lasso Regression
lasso = Lasso(alpha=0.1)
lasso.fit(X, y)

# Elastic Net
elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)
elastic_net.fit(X, y)</pre></div><div class='content'></div><h1>Ejercicios Prácticos</h1>
<div class='content'></div><h2>Ejercicio 1: Ajuste de un Modelo Lineal</h2>
<div class='content'><ol>
<li>Utiliza el conjunto de datos <code>diabetes</code> de <code>sklearn.datasets</code>.</li>
<li>Ajusta un modelo de regresión lineal utilizando Gradient Descent.</li>
<li>Imprime los coeficientes ajustados y la función de pérdida final.</li>
</ol>
</div><h2>Ejercicio 2: Optimización de Hiperparámetros con Grid Search</h2>
<div class='content'><ol>
<li>Utiliza el conjunto de datos <code>iris</code> de <code>sklearn.datasets</code>.</li>
<li>Ajusta un modelo de clasificación utilizando <code>RandomForestClassifier</code>.</li>
<li>Utiliza Grid Search para encontrar los mejores hiperparámetros.</li>
<li>Imprime los mejores hiperparámetros y el rendimiento del modelo.</li>
</ol>
</div><h2>Ejercicio 3: Regularización</h2>
<div class='content'><ol>
<li>Utiliza el conjunto de datos <code>boston</code> de <code>sklearn.datasets</code>.</li>
<li>Ajusta un modelo de regresión utilizando Ridge, Lasso y Elastic Net.</li>
<li>Compara los coeficientes y el rendimiento de los tres modelos.</li>
</ol>
</div><h1>Soluciones</h1>
<div class='content'></div><h2>Solución Ejercicio 1</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2RpYWJldGVzCmZyb20gc2tsZWFybi5tb2RlbF9zZWxlY3Rpb24gaW1wb3J0IHRyYWluX3Rlc3Rfc3BsaXQKCiMgQ2FyZ2FyIGRhdG9zCmRpYWJldGVzID0gbG9hZF9kaWFiZXRlcygpClgsIHkgPSBkaWFiZXRlcy5kYXRhLCBkaWFiZXRlcy50YXJnZXQKCiMgRGl2aWRpciBkYXRvcwpYX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoWCwgeSwgdGVzdF9zaXplPTAuMiwgcmFuZG9tX3N0YXRlPTQyKQoKIyBBanVzdGFyIG1vZGVsbwp0aGV0YSA9IGdyYWRpZW50X2Rlc2NlbnQoWF90cmFpbiwgeV90cmFpbikKcHJpbnQoZidDb2VmaWNpZW50ZXMgYWp1c3RhZG9zOiB7dGhldGF9Jyk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split

# Cargar datos
diabetes = load_diabetes()
X, y = diabetes.data, diabetes.target

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Ajustar modelo
theta = gradient_descent(X_train, y_train)
print(f'Coeficientes ajustados: {theta}')</pre></div><div class='content'></div><h2>Solución Ejercicio 2</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2lyaXMKZnJvbSBza2xlYXJuLmVuc2VtYmxlIGltcG9ydCBSYW5kb21Gb3Jlc3RDbGFzc2lmaWVyCmZyb20gc2tsZWFybi5tb2RlbF9zZWxlY3Rpb24gaW1wb3J0IEdyaWRTZWFyY2hDVgoKIyBDYXJnYXIgZGF0b3MKaXJpcyA9IGxvYWRfaXJpcygpClgsIHkgPSBpcmlzLmRhdGEsIGlyaXMudGFyZ2V0CgojIERlZmluaXIgbW9kZWxvCm1vZGVsID0gUmFuZG9tRm9yZXN0Q2xhc3NpZmllcigpCgojIERlZmluaXIgZXNwYWNpbyBkZSBoaXBlcnBhcsOhbWV0cm9zCnBhcmFtX2dyaWQgPSB7CiAgICAnbl9lc3RpbWF0b3JzJzogWzEwLCA1MCwgMTAwXSwKICAgICdtYXhfZGVwdGgnOiBbTm9uZSwgMTAsIDIwLCAzMF0sCiAgICAnbWluX3NhbXBsZXNfc3BsaXQnOiBbMiwgNSwgMTBdCn0KCiMgR3JpZCBTZWFyY2gKZ3JpZF9zZWFyY2ggPSBHcmlkU2VhcmNoQ1YoZXN0aW1hdG9yPW1vZGVsLCBwYXJhbV9ncmlkPXBhcmFtX2dyaWQsIGN2PTUpCmdyaWRfc2VhcmNoLmZpdChYLCB5KQoKcHJpbnQoZidNZWpvcmVzIGhpcGVycGFyw6FtZXRyb3M6IHtncmlkX3NlYXJjaC5iZXN0X3BhcmFtc199Jyk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# Cargar datos
iris = load_iris()
X, y = iris.data, iris.target

# Definir modelo
model = RandomForestClassifier()

# Definir espacio de hiperpar&aacute;metros
param_grid = {
    'n_estimators': [10, 50, 100],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# Grid Search
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)
grid_search.fit(X, y)

print(f'Mejores hiperpar&aacute;metros: {grid_search.best_params_}')</pre></div><div class='content'></div><h2>Solución Ejercicio 3</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBsb2FkX2Jvc3Rvbgpmcm9tIHNrbGVhcm4ubGluZWFyX21vZGVsIGltcG9ydCBSaWRnZSwgTGFzc28sIEVsYXN0aWNOZXQKZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdAoKIyBDYXJnYXIgZGF0b3MKYm9zdG9uID0gbG9hZF9ib3N0b24oKQpYLCB5ID0gYm9zdG9uLmRhdGEsIGJvc3Rvbi50YXJnZXQKCiMgRGl2aWRpciBkYXRvcwpYX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoWCwgeSwgdGVzdF9zaXplPTAuMiwgcmFuZG9tX3N0YXRlPTQyKQoKIyBSaWRnZSBSZWdyZXNzaW9uCnJpZGdlID0gUmlkZ2UoYWxwaGE9MS4wKQpyaWRnZS5maXQoWF90cmFpbiwgeV90cmFpbikKcHJpbnQoZidDb2VmaWNpZW50ZXMgUmlkZ2U6IHtyaWRnZS5jb2VmX30nKQoKIyBMYXNzbyBSZWdyZXNzaW9uCmxhc3NvID0gTGFzc28oYWxwaGE9MC4xKQpsYXNzby5maXQoWF90cmFpbiwgeV90cmFpbikKcHJpbnQoZidDb2VmaWNpZW50ZXMgTGFzc286IHtsYXNzby5jb2VmX30nKQoKIyBFbGFzdGljIE5ldAplbGFzdGljX25ldCA9IEVsYXN0aWNOZXQoYWxwaGE9MC4xLCBsMV9yYXRpbz0wLjUpCmVsYXN0aWNfbmV0LmZpdChYX3RyYWluLCB5X3RyYWluKQpwcmludChmJ0NvZWZpY2llbnRlcyBFbGFzdGljIE5ldDoge2VsYXN0aWNfbmV0LmNvZWZffScp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from sklearn.datasets import load_boston
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.model_selection import train_test_split

# Cargar datos
boston = load_boston()
X, y = boston.data, boston.target

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Ridge Regression
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)
print(f'Coeficientes Ridge: {ridge.coef_}')

# Lasso Regression
lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)
print(f'Coeficientes Lasso: {lasso.coef_}')

# Elastic Net
elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)
elastic_net.fit(X_train, y_train)
print(f'Coeficientes Elastic Net: {elastic_net.coef_}')</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, hemos aprendido sobre el ajuste y la optimización de modelos, incluyendo técnicas como Gradient Descent, Grid Search, Random Search y Regularización. Estas técnicas son esenciales para mejorar el rendimiento de los modelos y asegurar que proporcionen resultados precisos y útiles. En el próximo módulo, nos enfocaremos en la implementación y comunicación de los resultados obtenidos de nuestros modelos optimizados.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-02-validacion-cruzada' title="Validación Cruzada y Técnicas de Validación">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='06-01-implementacion-produccion' title="Implementación de Modelos en Producción">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
