<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Uso de BigQuery con Dataflow</title>

    <link rel="alternate" href="https://campusempresa.com/mod/bigquery/08-02-using-dataflow" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/bigquery/08-02-using-dataflow" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/bigquery/08-02-using-dataflow" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=3" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<span>	<a href="https://enterprisecampus.net/mod/bigquery/08-02-using-dataflow" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/bigquery/08-02-using-dataflow" class="px-2">CA</a>
</span>
			<span class="d-none d-md-inline"><br><cite>Construyendo la sociedad de hoy y del mañana</cite></span>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Lenguajes</a>
				 					<a href="/categ/frameworks">Frameworks</a>
				 					<a href="/categ/tech-tools">Herramientas</a>
				 					<a href="/categ/foundations">Fundamentos</a>
				 					<a href="/categ/soft-skills">Competencias</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='08-01-integrating-google-cloud' title="Integración con Servicios de Google Cloud">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Uso de BigQuery con Dataflow</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='08-03-automating-workflows' title="Automatización de Flujos de Trabajo con Cloud Functions">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1><p>Introducción</p>
</h1>
<div class='content'><p>Google Cloud Dataflow es un servicio de procesamiento de datos en tiempo real y por lotes que permite a los usuarios desarrollar y ejecutar pipelines de procesamiento de datos. Integrar BigQuery con Dataflow permite realizar transformaciones complejas y análisis avanzados de datos almacenados en BigQuery. En esta sección, aprenderás cómo utilizar Dataflow para procesar datos de BigQuery y escribir los resultados de vuelta a BigQuery.</p>
</div><h1><p>Objetivos</p>
</h1>
<div class='content'><ul>
<li>Comprender qué es Google Cloud Dataflow y sus beneficios.</li>
<li>Aprender a configurar un pipeline de Dataflow que lea datos de BigQuery.</li>
<li>Realizar transformaciones de datos utilizando Dataflow.</li>
<li>Escribir los resultados procesados de vuelta a BigQuery.</li>
</ul>
</div><h1><p>Requisitos Previos</p>
</h1>
<div class='content'><ul>
<li>Conocimientos básicos de BigQuery y SQL.</li>
<li>Familiaridad con Google Cloud Platform (GCP).</li>
<li>Experiencia básica en programación, preferiblemente en Python o Java.</li>
</ul>
</div><h1><p>Conceptos Clave</p>
</h1>
<div class='content'></div><h2><p>¿Qué es Google Cloud Dataflow?</p>
</h2>
<div class='content'><p>Google Cloud Dataflow es un servicio de procesamiento de datos que permite:</p>
<ul>
<li>Procesamiento en tiempo real y por lotes.</li>
<li>Escalabilidad automática.</li>
<li>Integración con otros servicios de Google Cloud, como BigQuery, Cloud Storage y Pub/Sub.</li>
</ul>
</div><h2><p>Beneficios de Usar Dataflow con BigQuery</p>
</h2>
<div class='content'><ul>
<li><strong>Escalabilidad</strong>: Dataflow puede manejar grandes volúmenes de datos sin problemas.</li>
<li><strong>Flexibilidad</strong>: Permite realizar transformaciones complejas y personalizadas.</li>
<li><strong>Integración</strong>: Se integra fácilmente con BigQuery, permitiendo leer y escribir datos de manera eficiente.</li>
</ul>
</div><h1><p>Configuración del Entorno</p>
</h1>
<div class='content'></div><h2><p>Paso 1: Configurar el Proyecto de GCP</p>
</h2>
<div class='content'><ol>
<li><strong>Crear un Proyecto de GCP</strong>: Si no tienes un proyecto de GCP, crea uno en la consola de Google Cloud.</li>
<li><strong>Habilitar APIs</strong>: Asegúrate de habilitar las APIs de BigQuery y Dataflow.</li>
</ol>
</div><h2><p>Paso 2: Configurar el Entorno de Desarrollo</p>
</h2>
<div class='content'><ol>
<li><strong>Instalar el SDK de Google Cloud</strong>: Si no lo tienes instalado, sigue las instrucciones en la <a href="https://cloud.google.com/sdk/docs/install">documentación oficial</a>.</li>
<li><strong>Instalar Apache Beam</strong>: Dataflow utiliza Apache Beam para definir pipelines. Instala Apache Beam con el siguiente comando:
<pre><code class="language-bash">pip install apache-beam[gcp]
</code></pre>
</li>
</ol>
</div><h1><p>Creación de un Pipeline de Dataflow</p>
</h1>
<div class='content'></div><h2><p>Paso 1: Leer Datos de BigQuery</p>
</h2>
<div class='content'><p>A continuación, se muestra un ejemplo de cómo leer datos de una tabla de BigQuery utilizando Apache Beam en Python:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGFwYWNoZV9iZWFtIGFzIGJlYW0KZnJvbSBhcGFjaGVfYmVhbS5vcHRpb25zLnBpcGVsaW5lX29wdGlvbnMgaW1wb3J0IFBpcGVsaW5lT3B0aW9ucwoKIyBEZWZpbmlyIGxhcyBvcGNpb25lcyBkZWwgcGlwZWxpbmUKb3B0aW9ucyA9IFBpcGVsaW5lT3B0aW9ucygKICAgIHByb2plY3Q9J3R1LXByb3llY3RvLWlkJywKICAgIHJlZ2lvbj0ndHUtcmVnaW9uJywKICAgIHJ1bm5lcj0nRGF0YWZsb3dSdW5uZXInLAogICAgdGVtcF9sb2NhdGlvbj0nZ3M6Ly90dS1idWNrZXQvdGVtcCcsCiAgICBzdGFnaW5nX2xvY2F0aW9uPSdnczovL3R1LWJ1Y2tldC9zdGFnaW5nJwopCgojIERlZmluaXIgbGEgY29uc3VsdGEgU1FMIHBhcmEgbGVlciBkYXRvcyBkZSBCaWdRdWVyeQpxdWVyeSA9ICIiIgpTRUxFQ1QKICBub21icmUsCiAgZWRhZCwKICBjaXVkYWQKRlJPTQogIGB0dS1wcm95ZWN0by1pZC50dS1kYXRhc2V0LnR1LXRhYmxhYAoiIiIKCiMgQ3JlYXIgZWwgcGlwZWxpbmUKd2l0aCBiZWFtLlBpcGVsaW5lKG9wdGlvbnM9b3B0aW9ucykgYXMgcDoKICAgICMgTGVlciBkYXRvcyBkZSBCaWdRdWVyeQogICAgcm93cyA9IHAgfCAnTGVlciBkZSBCaWdRdWVyeScgPj4gYmVhbS5pby5SZWFkRnJvbUJpZ1F1ZXJ5KHF1ZXJ5PXF1ZXJ5KQoKICAgICMgVHJhbnNmb3JtYWNpb25lcyBhZGljaW9uYWxlcyBwdWVkZW4gaXIgYXF1w60KCiAgICAjIEVzY3JpYmlyIGxvcyByZXN1bHRhZG9zIGRlIHZ1ZWx0YSBhIEJpZ1F1ZXJ5CiAgICByb3dzIHwgJ0VzY3JpYmlyIGEgQmlnUXVlcnknID4+IGJlYW0uaW8uV3JpdGVUb0JpZ1F1ZXJ5KAogICAgICAgICd0dS1wcm95ZWN0by1pZDp0dS1kYXRhc2V0LnR1LXRhYmxhLXJlc3VsdGFkb3MnLAogICAgICAgIHNjaGVtYT0nbm9tYnJlOlNUUklORywgZWRhZDpJTlRFR0VSLCBjaXVkYWQ6U1RSSU5HJywKICAgICAgICB3cml0ZV9kaXNwb3NpdGlvbj1iZWFtLmlvLkJpZ1F1ZXJ5RGlzcG9zaXRpb24uV1JJVEVfVFJVTkNBVEUKICAgICk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions

# Definir las opciones del pipeline
options = PipelineOptions(
    project='tu-proyecto-id',
    region='tu-region',
    runner='DataflowRunner',
    temp_location='gs://tu-bucket/temp',
    staging_location='gs://tu-bucket/staging'
)

# Definir la consulta SQL para leer datos de BigQuery
query = &quot;&quot;&quot;
SELECT
  nombre,
  edad,
  ciudad
FROM
  `tu-proyecto-id.tu-dataset.tu-tabla`
&quot;&quot;&quot;

# Crear el pipeline
with beam.Pipeline(options=options) as p:
    # Leer datos de BigQuery
    rows = p | 'Leer de BigQuery' &gt;&gt; beam.io.ReadFromBigQuery(query=query)

    # Transformaciones adicionales pueden ir aqu&iacute;

    # Escribir los resultados de vuelta a BigQuery
    rows | 'Escribir a BigQuery' &gt;&gt; beam.io.WriteToBigQuery(
        'tu-proyecto-id:tu-dataset.tu-tabla-resultados',
        schema='nombre:STRING, edad:INTEGER, ciudad:STRING',
        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE
    )</pre></div><div class='content'></div><h2><p>Paso 2: Transformar Datos</p>
</h2>
<div class='content'><p>Puedes realizar varias transformaciones en los datos antes de escribirlos de vuelta a BigQuery. Aquí hay un ejemplo de cómo filtrar y transformar los datos:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGZpbHRyYXJfbWF5b3Jlc19kZV9lZGFkKGVsZW1lbnRvKToKICAgIHJldHVybiBlbGVtZW50b1snZWRhZCddID49IDE4CgpkZWYgdHJhbnNmb3JtYXJfY2l1ZGFkKGVsZW1lbnRvKToKICAgIGVsZW1lbnRvWydjaXVkYWQnXSA9IGVsZW1lbnRvWydjaXVkYWQnXS51cHBlcigpCiAgICByZXR1cm4gZWxlbWVudG8KCndpdGggYmVhbS5QaXBlbGluZShvcHRpb25zPW9wdGlvbnMpIGFzIHA6CiAgICByb3dzID0gcCB8ICdMZWVyIGRlIEJpZ1F1ZXJ5JyA+PiBiZWFtLmlvLlJlYWRGcm9tQmlnUXVlcnkocXVlcnk9cXVlcnkpCgogICAgIyBGaWx0cmFyIHkgdHJhbnNmb3JtYXIgZGF0b3MKICAgIHRyYW5zZm9ybWFkb3MgPSAoCiAgICAgICAgcm93cwogICAgICAgIHwgJ0ZpbHRyYXIgbWF5b3JlcyBkZSBlZGFkJyA+PiBiZWFtLkZpbHRlcihmaWx0cmFyX21heW9yZXNfZGVfZWRhZCkKICAgICAgICB8ICdUcmFuc2Zvcm1hciBjaXVkYWQnID4+IGJlYW0uTWFwKHRyYW5zZm9ybWFyX2NpdWRhZCkKICAgICkKCiAgICB0cmFuc2Zvcm1hZG9zIHwgJ0VzY3JpYmlyIGEgQmlnUXVlcnknID4+IGJlYW0uaW8uV3JpdGVUb0JpZ1F1ZXJ5KAogICAgICAgICd0dS1wcm95ZWN0by1pZDp0dS1kYXRhc2V0LnR1LXRhYmxhLXJlc3VsdGFkb3MnLAogICAgICAgIHNjaGVtYT0nbm9tYnJlOlNUUklORywgZWRhZDpJTlRFR0VSLCBjaXVkYWQ6U1RSSU5HJywKICAgICAgICB3cml0ZV9kaXNwb3NpdGlvbj1iZWFtLmlvLkJpZ1F1ZXJ5RGlzcG9zaXRpb24uV1JJVEVfVFJVTkNBVEUKICAgICk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def filtrar_mayores_de_edad(elemento):
    return elemento['edad'] &gt;= 18

def transformar_ciudad(elemento):
    elemento['ciudad'] = elemento['ciudad'].upper()
    return elemento

with beam.Pipeline(options=options) as p:
    rows = p | 'Leer de BigQuery' &gt;&gt; beam.io.ReadFromBigQuery(query=query)

    # Filtrar y transformar datos
    transformados = (
        rows
        | 'Filtrar mayores de edad' &gt;&gt; beam.Filter(filtrar_mayores_de_edad)
        | 'Transformar ciudad' &gt;&gt; beam.Map(transformar_ciudad)
    )

    transformados | 'Escribir a BigQuery' &gt;&gt; beam.io.WriteToBigQuery(
        'tu-proyecto-id:tu-dataset.tu-tabla-resultados',
        schema='nombre:STRING, edad:INTEGER, ciudad:STRING',
        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE
    )</pre></div><div class='content'></div><h1><p>Ejercicio Práctico</p>
</h1>
<div class='content'></div><h2><p>Ejercicio 1: Crear un Pipeline de Dataflow</p>
</h2>
<div class='content'><ol>
<li><strong>Objetivo</strong>: Crear un pipeline de Dataflow que lea datos de una tabla de BigQuery, filtre los registros donde la edad sea mayor o igual a 18, transforme la ciudad a mayúsculas y escriba los resultados en una nueva tabla de BigQuery.</li>
<li><strong>Instrucciones</strong>:
<ul>
<li>Configura tu entorno de desarrollo.</li>
<li>Define una consulta SQL para leer datos de BigQuery.</li>
<li>Implementa las funciones de filtrado y transformación.</li>
<li>Escribe los resultados en una nueva tabla de BigQuery.</li>
</ul>
</li>
</ol>
</div><h2><p>Solución</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGFwYWNoZV9iZWFtIGFzIGJlYW0KZnJvbSBhcGFjaGVfYmVhbS5vcHRpb25zLnBpcGVsaW5lX29wdGlvbnMgaW1wb3J0IFBpcGVsaW5lT3B0aW9ucwoKIyBEZWZpbmlyIGxhcyBvcGNpb25lcyBkZWwgcGlwZWxpbmUKb3B0aW9ucyA9IFBpcGVsaW5lT3B0aW9ucygKICAgIHByb2plY3Q9J3R1LXByb3llY3RvLWlkJywKICAgIHJlZ2lvbj0ndHUtcmVnaW9uJywKICAgIHJ1bm5lcj0nRGF0YWZsb3dSdW5uZXInLAogICAgdGVtcF9sb2NhdGlvbj0nZ3M6Ly90dS1idWNrZXQvdGVtcCcsCiAgICBzdGFnaW5nX2xvY2F0aW9uPSdnczovL3R1LWJ1Y2tldC9zdGFnaW5nJwopCgojIERlZmluaXIgbGEgY29uc3VsdGEgU1FMIHBhcmEgbGVlciBkYXRvcyBkZSBCaWdRdWVyeQpxdWVyeSA9ICIiIgpTRUxFQ1QKICBub21icmUsCiAgZWRhZCwKICBjaXVkYWQKRlJPTQogIGB0dS1wcm95ZWN0by1pZC50dS1kYXRhc2V0LnR1LXRhYmxhYAoiIiIKCmRlZiBmaWx0cmFyX21heW9yZXNfZGVfZWRhZChlbGVtZW50byk6CiAgICByZXR1cm4gZWxlbWVudG9bJ2VkYWQnXSA+PSAxOAoKZGVmIHRyYW5zZm9ybWFyX2NpdWRhZChlbGVtZW50byk6CiAgICBlbGVtZW50b1snY2l1ZGFkJ10gPSBlbGVtZW50b1snY2l1ZGFkJ10udXBwZXIoKQogICAgcmV0dXJuIGVsZW1lbnRvCgojIENyZWFyIGVsIHBpcGVsaW5lCndpdGggYmVhbS5QaXBlbGluZShvcHRpb25zPW9wdGlvbnMpIGFzIHA6CiAgICByb3dzID0gcCB8ICdMZWVyIGRlIEJpZ1F1ZXJ5JyA+PiBiZWFtLmlvLlJlYWRGcm9tQmlnUXVlcnkocXVlcnk9cXVlcnkpCgogICAgIyBGaWx0cmFyIHkgdHJhbnNmb3JtYXIgZGF0b3MKICAgIHRyYW5zZm9ybWFkb3MgPSAoCiAgICAgICAgcm93cwogICAgICAgIHwgJ0ZpbHRyYXIgbWF5b3JlcyBkZSBlZGFkJyA+PiBiZWFtLkZpbHRlcihmaWx0cmFyX21heW9yZXNfZGVfZWRhZCkKICAgICAgICB8ICdUcmFuc2Zvcm1hciBjaXVkYWQnID4+IGJlYW0uTWFwKHRyYW5zZm9ybWFyX2NpdWRhZCkKICAgICkKCiAgICB0cmFuc2Zvcm1hZG9zIHwgJ0VzY3JpYmlyIGEgQmlnUXVlcnknID4+IGJlYW0uaW8uV3JpdGVUb0JpZ1F1ZXJ5KAogICAgICAgICd0dS1wcm95ZWN0by1pZDp0dS1kYXRhc2V0LnR1LXRhYmxhLXJlc3VsdGFkb3MnLAogICAgICAgIHNjaGVtYT0nbm9tYnJlOlNUUklORywgZWRhZDpJTlRFR0VSLCBjaXVkYWQ6U1RSSU5HJywKICAgICAgICB3cml0ZV9kaXNwb3NpdGlvbj1iZWFtLmlvLkJpZ1F1ZXJ5RGlzcG9zaXRpb24uV1JJVEVfVFJVTkNBVEUKICAgICk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions

# Definir las opciones del pipeline
options = PipelineOptions(
    project='tu-proyecto-id',
    region='tu-region',
    runner='DataflowRunner',
    temp_location='gs://tu-bucket/temp',
    staging_location='gs://tu-bucket/staging'
)

# Definir la consulta SQL para leer datos de BigQuery
query = &quot;&quot;&quot;
SELECT
  nombre,
  edad,
  ciudad
FROM
  `tu-proyecto-id.tu-dataset.tu-tabla`
&quot;&quot;&quot;

def filtrar_mayores_de_edad(elemento):
    return elemento['edad'] &gt;= 18

def transformar_ciudad(elemento):
    elemento['ciudad'] = elemento['ciudad'].upper()
    return elemento

# Crear el pipeline
with beam.Pipeline(options=options) as p:
    rows = p | 'Leer de BigQuery' &gt;&gt; beam.io.ReadFromBigQuery(query=query)

    # Filtrar y transformar datos
    transformados = (
        rows
        | 'Filtrar mayores de edad' &gt;&gt; beam.Filter(filtrar_mayores_de_edad)
        | 'Transformar ciudad' &gt;&gt; beam.Map(transformar_ciudad)
    )

    transformados | 'Escribir a BigQuery' &gt;&gt; beam.io.WriteToBigQuery(
        'tu-proyecto-id:tu-dataset.tu-tabla-resultados',
        schema='nombre:STRING, edad:INTEGER, ciudad:STRING',
        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE
    )</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En esta sección, aprendiste cómo utilizar Google Cloud Dataflow para procesar datos de BigQuery. Configuraste un pipeline de Dataflow, leíste datos de BigQuery, realizaste transformaciones y escribiste los resultados de vuelta a BigQuery. Esta integración te permite realizar análisis y transformaciones complejas de datos de manera eficiente y escalable.</p>
</div><h2><p>Próximos Pasos</p>
</h2>
<div class='content'><p>En la siguiente sección, exploraremos cómo automatizar flujos de trabajo en BigQuery utilizando Cloud Functions. Esto te permitirá crear soluciones más dinámicas y automatizadas para tus necesidades de procesamiento de datos.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='08-01-integrating-google-cloud' title="Integración con Servicios de Google Cloud">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='08-03-automating-workflows' title="Automatización de Flujos de Trabajo con Cloud Functions">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Publicidad</h1>
<p>Este espacio está destinado a publicidad.</p>
<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>¡Gracias por colaborar!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
		</div>
	</div>
</div>

<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
