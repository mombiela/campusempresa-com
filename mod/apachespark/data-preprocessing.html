<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Preprocesamiento de Datos en Apache Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/data-preprocessing" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/data-preprocessing" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/data-preprocessing" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png" style="visibility:hiddenxx;"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/apachespark/data-preprocessing" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/data-preprocessing" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='basic-statistics'>&#x25C4;Estadísticas Básicas</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Preprocesamiento de Datos en Apache Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='classification-and-regression'>Clasificación y Regresión &#x25BA;</a>
			</div>
</div>
<div class='content'><p>El preprocesamiento de datos es un paso crucial en la tubería de análisis de datos. Involucra la limpieza, transformación y preparación de datos en bruto para el análisis. En esta sección, cubriremos los conceptos básicos del preprocesamiento de datos usando Apache Spark, progresando desde niveles principiantes hasta avanzados.</p>
</div><h1>Introducción al Preprocesamiento de Datos</h1>
<div class='content'><p>El preprocesamiento de datos involucra varios pasos para asegurar que los datos estén en un formato adecuado para el análisis. Estos pasos incluyen:</p>
<ul>
<li>Limpieza de Datos</li>
<li>Transformación de Datos</li>
<li>Integración de Datos</li>
<li>Reducción de Datos</li>
</ul>
</div><h1>Configuración de Apache Spark</h1>
<div class='content'><p>Antes de sumergirse en el preprocesamiento de datos, asegúrese de tener Apache Spark instalado y configurado. Puede seguir la <a href="https://spark.apache.org/docs/latest/">documentación oficial de Apache Spark</a> para las instrucciones de instalación.</p>
</div><h2>Ejemplo: Inicializando la Sesión de Spark</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIEluaWNpYWxpemFyIHVuYSBzZXNpw7NuIGRlIFNwYXJrCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIgXAogICAgLmFwcE5hbWUoIkRhdGFQcmVwcm9jZXNzaW5nIikgXAogICAgLmdldE9yQ3JlYXRlKCkKCiMgVmVyaWZpY2FyIGxhIHNlc2nDs24gZGUgU3BhcmsKcHJpbnQoc3Bhcmsp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Inicializar una sesi&oacute;n de Spark
spark = SparkSession.builder \
    .appName(&quot;DataPreprocessing&quot;) \
    .getOrCreate()

# Verificar la sesi&oacute;n de Spark
print(spark)</pre></div><div class='content'></div><h1>Limpieza de Datos</h1>
<div class='content'><p>La limpieza de datos involucra el manejo de valores faltantes, la eliminación de duplicados y la corrección de errores en el conjunto de datos.</p>
</div><h2>Manejo de Valores Faltantes</h2>
<div class='content'><ul>
<li><strong>Eliminar valores faltantes</strong>: Eliminar filas con valores faltantes.</li>
<li><strong>Rellenar valores faltantes</strong>: Reemplazar valores faltantes con un valor específico o una medida estadística (media, mediana, etc.).</li>
</ul>
<h4>Ejemplo: Eliminando Valores Faltantes</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDYXJnYXIgZGF0b3MgZGUgbXVlc3RyYQpkYXRhID0gWygiQWxpY2UiLCAzNCwgTm9uZSksICgiQm9iIiwgTm9uZSwgIkhSIiksICgiQ2F0aHkiLCAyOSwgIklUIildCmNvbHVtbnMgPSBbIk5hbWUiLCAiQWdlIiwgIkRlcGFydG1lbnQiXQpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhLCBjb2x1bW5zKQoKIyBFbGltaW5hciBmaWxhcyBjb24gY3VhbHF1aWVyIHZhbG9yIGZhbHRhbnRlCmRmX2NsZWFuZWQgPSBkZi5uYS5kcm9wKCkKCmRmX2NsZWFuZWQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Cargar datos de muestra
data = [(&quot;Alice&quot;, 34, None), (&quot;Bob&quot;, None, &quot;HR&quot;), (&quot;Cathy&quot;, 29, &quot;IT&quot;)]
columns = [&quot;Name&quot;, &quot;Age&quot;, &quot;Department&quot;]
df = spark.createDataFrame(data, columns)

# Eliminar filas con cualquier valor faltante
df_cleaned = df.na.drop()

df_cleaned.show()</pre></div><div class='content'><h4>Ejemplo: Rellenando Valores Faltantes</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBSZWxsZW5hciB2YWxvcmVzIGZhbHRhbnRlcyBjb24gdW4gdmFsb3IgZXNwZWPDrWZpY28KZGZfZmlsbGVkID0gZGYubmEuZmlsbCh7IkFnZSI6IDAsICJEZXBhcnRtZW50IjogIlVua25vd24ifSkKCmRmX2ZpbGxlZC5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Rellenar valores faltantes con un valor espec&iacute;fico
df_filled = df.na.fill({&quot;Age&quot;: 0, &quot;Department&quot;: &quot;Unknown&quot;})

df_filled.show()</pre></div><div class='content'></div><h1>Transformación de Datos</h1>
<div class='content'><p>La transformación de datos involucra convertir datos en un formato adecuado para el análisis. Las transformaciones comunes incluyen normalización, escalado y codificación de variables categóricas.</p>
</div><h2>Normalización y Escalado</h2>
<div class='content'><ul>
<li><strong>Normalización</strong>: Ajusta el rango de los datos.</li>
<li><strong>Escalado</strong>: Ajusta la escala de los datos.</li>
</ul>
<h4>Ejemplo: Escalando Datos</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmZlYXR1cmUgaW1wb3J0IE1pbk1heFNjYWxlcgpmcm9tIHB5c3BhcmsubWwubGluYWxnIGltcG9ydCBWZWN0b3JzCgojIERhdG9zIGRlIG11ZXN0cmEKZGF0YSA9IFsoMCwgVmVjdG9ycy5kZW5zZShbMS4wLCAwLjEsIC0xLjBdKSwpLAogICAgICAgICgxLCBWZWN0b3JzLmRlbnNlKFsyLjAsIDEuMSwgMS4wXSksKSwKICAgICAgICAoMiwgVmVjdG9ycy5kZW5zZShbMy4wLCAxMC4xLCAzLjBdKSwpXQpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhLCBbImlkIiwgImZlYXR1cmVzIl0pCgojIEluaWNpYWxpemFyIE1pbk1heFNjYWxlcgpzY2FsZXIgPSBNaW5NYXhTY2FsZXIoaW5wdXRDb2w9ImZlYXR1cmVzIiwgb3V0cHV0Q29sPSJzY2FsZWRGZWF0dXJlcyIpCgojIEFqdXN0YXIgeSB0cmFuc2Zvcm1hciBsb3MgZGF0b3MKc2NhbGVyTW9kZWwgPSBzY2FsZXIuZml0KGRmKQpzY2FsZWREYXRhID0gc2NhbGVyTW9kZWwudHJhbnNmb3JtKGRmKQoKc2NhbGVkRGF0YS5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.feature import MinMaxScaler
from pyspark.ml.linalg import Vectors

# Datos de muestra
data = [(0, Vectors.dense([1.0, 0.1, -1.0]),),
        (1, Vectors.dense([2.0, 1.1, 1.0]),),
        (2, Vectors.dense([3.0, 10.1, 3.0]),)]
df = spark.createDataFrame(data, [&quot;id&quot;, &quot;features&quot;])

# Inicializar MinMaxScaler
scaler = MinMaxScaler(inputCol=&quot;features&quot;, outputCol=&quot;scaledFeatures&quot;)

# Ajustar y transformar los datos
scalerModel = scaler.fit(df)
scaledData = scalerModel.transform(df)

scaledData.show()</pre></div><div class='content'></div><h2>Codificación de Variables Categóricas</h2>
<div class='content'><ul>
<li><strong>Codificación One-Hot</strong>: Convierte variables categóricas en vectores binarios.</li>
<li><strong>Indexación de Cadenas</strong>: Asigna índices numéricos a variables categóricas.</li>
</ul>
<h4>Ejemplo: Codificación One-Hot</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmZlYXR1cmUgaW1wb3J0IE9uZUhvdEVuY29kZXIsIFN0cmluZ0luZGV4ZXIKCiMgRGF0b3MgZGUgbXVlc3RyYQpkYXRhID0gWygiSFIiLCksICgiSVQiLCksICgiSFIiLCksICgiRmluYW5jZSIsKV0KZGYgPSBzcGFyay5jcmVhdGVEYXRhRnJhbWUoZGF0YSwgWyJEZXBhcnRtZW50Il0pCgojIFN0cmluZ0luZGV4ZXIKaW5kZXhlciA9IFN0cmluZ0luZGV4ZXIoaW5wdXRDb2w9IkRlcGFydG1lbnQiLCBvdXRwdXRDb2w9IkRlcHRJbmRleCIpCmRmX2luZGV4ZWQgPSBpbmRleGVyLmZpdChkZikudHJhbnNmb3JtKGRmKQoKIyBPbmVIb3RFbmNvZGVyCmVuY29kZXIgPSBPbmVIb3RFbmNvZGVyKGlucHV0Q29sPSJEZXB0SW5kZXgiLCBvdXRwdXRDb2w9IkRlcHRWZWMiKQpkZl9lbmNvZGVkID0gZW5jb2Rlci5maXQoZGZfaW5kZXhlZCkudHJhbnNmb3JtKGRmX2luZGV4ZWQpCgpkZl9lbmNvZGVkLnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.feature import OneHotEncoder, StringIndexer

# Datos de muestra
data = [(&quot;HR&quot;,), (&quot;IT&quot;,), (&quot;HR&quot;,), (&quot;Finance&quot;,)]
df = spark.createDataFrame(data, [&quot;Department&quot;])

# StringIndexer
indexer = StringIndexer(inputCol=&quot;Department&quot;, outputCol=&quot;DeptIndex&quot;)
df_indexed = indexer.fit(df).transform(df)

# OneHotEncoder
encoder = OneHotEncoder(inputCol=&quot;DeptIndex&quot;, outputCol=&quot;DeptVec&quot;)
df_encoded = encoder.fit(df_indexed).transform(df_indexed)

df_encoded.show()</pre></div><div class='content'></div><h1>Integración de Datos</h1>
<div class='content'><p>La integración de datos involucra combinar datos de diferentes fuentes en un solo conjunto de datos.</p>
</div><h2>Ejemplo: Uniendo DataFrames</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEYXRvcyBkZSBtdWVzdHJhCmRhdGExID0gWygiQWxpY2UiLCAzNCksICgiQm9iIiwgNDUpXQpkYXRhMiA9IFsoIkFsaWNlIiwgIkhSIiksICgiQm9iIiwgIklUIildCmNvbHVtbnMxID0gWyJOYW1lIiwgIkFnZSJdCmNvbHVtbnMyID0gWyJOYW1lIiwgIkRlcGFydG1lbnQiXQoKZGYxID0gc3BhcmsuY3JlYXRlRGF0YUZyYW1lKGRhdGExLCBjb2x1bW5zMSkKZGYyID0gc3BhcmsuY3JlYXRlRGF0YUZyYW1lKGRhdGEyLCBjb2x1bW5zMikKCiMgVW5pciBEYXRhRnJhbWVzCmRmX2pvaW5lZCA9IGRmMS5qb2luKGRmMiwgb249Ik5hbWUiLCBob3c9ImlubmVyIikKCmRmX2pvaW5lZC5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Datos de muestra
data1 = [(&quot;Alice&quot;, 34), (&quot;Bob&quot;, 45)]
data2 = [(&quot;Alice&quot;, &quot;HR&quot;), (&quot;Bob&quot;, &quot;IT&quot;)]
columns1 = [&quot;Name&quot;, &quot;Age&quot;]
columns2 = [&quot;Name&quot;, &quot;Department&quot;]

df1 = spark.createDataFrame(data1, columns1)
df2 = spark.createDataFrame(data2, columns2)

# Unir DataFrames
df_joined = df1.join(df2, on=&quot;Name&quot;, how=&quot;inner&quot;)

df_joined.show()</pre></div><div class='content'></div><h1>Reducción de Datos</h1>
<div class='content'><p>La reducción de datos involucra reducir el volumen de datos mientras se mantiene su integridad. Las técnicas incluyen muestreo, selección de características y reducción de dimensionalidad.</p>
</div><h2>Ejemplo: Selección de Características</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmZlYXR1cmUgaW1wb3J0IFZlY3RvckFzc2VtYmxlcgpmcm9tIHB5c3BhcmsubWwuc3RhdCBpbXBvcnQgQ29ycmVsYXRpb24KCiMgRGF0b3MgZGUgbXVlc3RyYQpkYXRhID0gWygxLCAwLjEsIC0xLjAsIDMuMCksICgyLCAxLjEsIDEuMCwgMi4wKSwgKDMsIDEwLjEsIDMuMCwgMS4wKV0KY29sdW1ucyA9IFsiaWQiLCAiZmVhdHVyZTEiLCAiZmVhdHVyZTIiLCAiZmVhdHVyZTMiXQpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhLCBjb2x1bW5zKQoKIyBFbnNhbWJsYXIgY2FyYWN0ZXLDrXN0aWNhcyBlbiB1biBzb2xvIHZlY3Rvcgphc3NlbWJsZXIgPSBWZWN0b3JBc3NlbWJsZXIoaW5wdXRDb2xzPVsiZmVhdHVyZTEiLCAiZmVhdHVyZTIiLCAiZmVhdHVyZTMiXSwgb3V0cHV0Q29sPSJmZWF0dXJlcyIpCmRmX3ZlY3RvciA9IGFzc2VtYmxlci50cmFuc2Zvcm0oZGYpCgojIENhbGN1bGFyIG1hdHJpeiBkZSBjb3JyZWxhY2nDs24KY29ycmVsYXRpb25fbWF0cml4ID0gQ29ycmVsYXRpb24uY29ycihkZl92ZWN0b3IsICJmZWF0dXJlcyIpLmhlYWQoKVswXQpwcmludCgiTWF0cml6IGRlIGNvcnJlbGFjacOzbjpcbiIsIGNvcnJlbGF0aW9uX21hdHJpeCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.feature import VectorAssembler
from pyspark.ml.stat import Correlation

# Datos de muestra
data = [(1, 0.1, -1.0, 3.0), (2, 1.1, 1.0, 2.0), (3, 10.1, 3.0, 1.0)]
columns = [&quot;id&quot;, &quot;feature1&quot;, &quot;feature2&quot;, &quot;feature3&quot;]
df = spark.createDataFrame(data, columns)

# Ensamblar caracter&iacute;sticas en un solo vector
assembler = VectorAssembler(inputCols=[&quot;feature1&quot;, &quot;feature2&quot;, &quot;feature3&quot;], outputCol=&quot;features&quot;)
df_vector = assembler.transform(df)

# Calcular matriz de correlaci&oacute;n
correlation_matrix = Correlation.corr(df_vector, &quot;features&quot;).head()[0]
print(&quot;Matriz de correlaci&oacute;n:\n&quot;, correlation_matrix)</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>El preprocesamiento de datos es un paso fundamental en la tubería de análisis de datos. Usando Apache Spark, podemos limpiar, transformar, integrar y reducir datos de manera eficiente a gran escala. Al dominar estas técnicas, puede asegurarse de que sus datos estén listos para el análisis y modelado, lo que lleva a resultados más precisos y confiables.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='basic-statistics'>&#x25C4;Estadísticas Básicas</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Preprocesamiento de Datos en Apache Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='classification-and-regression'>Clasificación y Regresión &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
