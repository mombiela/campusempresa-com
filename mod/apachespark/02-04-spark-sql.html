<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Spark SQL</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/02-04-spark-sql" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/02-04-spark-sql" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/02-04-spark-sql" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>var DEVELOP = window.location.href.indexOf("localhost")!=-1 && true;</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/mod/apachespark/02-04-spark-sql" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/apachespark/02-04-spark-sql" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>
		<!-- <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Contenido del curso
	</a>

			</div>
		</div>
	</div>
</div>
 -->
 
<div class="top-bar container-fluid">
	<div class="container-xxl">
		<nav class="navbar navbar-expand-md p-0">
			<div class="container-fluid">
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				
				<div class="collapse navbar-collapse" id="navbarNav">
					<div class="navbar-nav me-auto">
							<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Contenido del curso
	</a>

					</div>
				</div>			
							</div>
		</nav>
	</div>
</div>				<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='02-03-spark-dataframes' title="DataFrames de Spark">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<h2 style="text-decoration:underline">Spark SQL</h2>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='03-01-loading-saving-data' title="Cargar y Guardar Datos">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1>Introducción a Spark SQL</h1>
<div class='content'><p>Spark SQL es un módulo de Apache Spark que permite trabajar con datos estructurados utilizando el lenguaje SQL. Proporciona una interfaz para ejecutar consultas SQL sobre datos almacenados en archivos, bases de datos y otros formatos de almacenamiento. Spark SQL también permite la integración con herramientas de BI y proporciona una API para trabajar con DataFrames y Datasets.</p>
</div><h2>Objetivos de esta sección:</h2>
<div class='content'><ol>
<li>Comprender qué es Spark SQL y sus beneficios.</li>
<li>Aprender a crear y manipular DataFrames utilizando SQL.</li>
<li>Ejecutar consultas SQL en Spark.</li>
<li>Integrar Spark SQL con otras fuentes de datos.</li>
</ol>
</div><h1><ol>
<li>¿Qué es Spark SQL?</li>
</ol></h1>
<div class='content'><p>Spark SQL es una extensión de Apache Spark que permite el procesamiento de datos estructurados. Ofrece las siguientes características:</p>
<ul>
<li><strong>Interfaz SQL</strong>: Permite ejecutar consultas SQL sobre datos estructurados.</li>
<li><strong>DataFrames y Datasets</strong>: Proporciona estructuras de datos de alto nivel para manipular datos.</li>
<li><strong>Optimización</strong>: Utiliza el optimizador Catalyst para mejorar el rendimiento de las consultas.</li>
<li><strong>Integración</strong>: Se integra fácilmente con otras herramientas y fuentes de datos.</li>
</ul>
</div><h1><ol start="2">
<li>Creación de DataFrames</li>
</ol></h1>
<div class='content'><p>Un DataFrame es una colección distribuida de datos organizados en columnas con nombre. Es similar a una tabla en una base de datos relacional o un DataFrame en R/Python.</p>
</div><h2>Ejemplo de creación de un DataFrame:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIENyZWFyIHVuYSBzZXNpw7NuIGRlIFNwYXJrCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiU3BhcmtTUUxFeGFtcGxlIikuZ2V0T3JDcmVhdGUoKQoKIyBDcmVhciB1biBEYXRhRnJhbWUgYSBwYXJ0aXIgZGUgdW5hIGxpc3RhIGRlIHR1cGxhcwpkYXRhID0gWygiQWxpY2UiLCAzNCksICgiQm9iIiwgNDUpLCAoIkNhdGh5IiwgMjkpXQpjb2x1bW5zID0gWyJOYW1lIiwgIkFnZSJdCgpkZiA9IHNwYXJrLmNyZWF0ZURhdGFGcmFtZShkYXRhLCBjb2x1bW5zKQoKIyBNb3N0cmFyIGVsIERhdGFGcmFtZQpkZi5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Crear una sesi&oacute;n de Spark
spark = SparkSession.builder.appName(&quot;SparkSQLExample&quot;).getOrCreate()

# Crear un DataFrame a partir de una lista de tuplas
data = [(&quot;Alice&quot;, 34), (&quot;Bob&quot;, 45), (&quot;Cathy&quot;, 29)]
columns = [&quot;Name&quot;, &quot;Age&quot;]

df = spark.createDataFrame(data, columns)

# Mostrar el DataFrame
df.show()</pre></div><div class='content'></div><h2>Explicación del código:</h2>
<div class='content'><ol>
<li><strong>Importar SparkSession</strong>: Importamos <code>SparkSession</code> desde <code>pyspark.sql</code>.</li>
<li><strong>Crear una sesión de Spark</strong>: Utilizamos <code>SparkSession.builder</code> para crear una sesión de Spark.</li>
<li><strong>Crear un DataFrame</strong>: Creamos un DataFrame a partir de una lista de tuplas y especificamos los nombres de las columnas.</li>
<li><strong>Mostrar el DataFrame</strong>: Utilizamos el método <code>show()</code> para mostrar el contenido del DataFrame.</li>
</ol>
</div><h1><ol start="3">
<li>Ejecutar Consultas SQL</li>
</ol></h1>
<div class='content'><p>Spark SQL permite ejecutar consultas SQL directamente sobre DataFrames.</p>
</div><h2>Ejemplo de ejecución de una consulta SQL:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBSZWdpc3RyYXIgZWwgRGF0YUZyYW1lIGNvbW8gdW5hIHZpc3RhIHRlbXBvcmFsCmRmLmNyZWF0ZU9yUmVwbGFjZVRlbXBWaWV3KCJwZW9wbGUiKQoKIyBFamVjdXRhciB1bmEgY29uc3VsdGEgU1FMCnJlc3VsdCA9IHNwYXJrLnNxbCgiU0VMRUNUIE5hbWUsIEFnZSBGUk9NIHBlb3BsZSBXSEVSRSBBZ2UgPiAzMCIpCgojIE1vc3RyYXIgZWwgcmVzdWx0YWRvCnJlc3VsdC5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Registrar el DataFrame como una vista temporal
df.createOrReplaceTempView(&quot;people&quot;)

# Ejecutar una consulta SQL
result = spark.sql(&quot;SELECT Name, Age FROM people WHERE Age &gt; 30&quot;)

# Mostrar el resultado
result.show()</pre></div><div class='content'></div><h2>Explicación del código:</h2>
<div class='content'><ol>
<li><strong>Registrar el DataFrame</strong>: Utilizamos <code>createOrReplaceTempView</code> para registrar el DataFrame como una vista temporal.</li>
<li><strong>Ejecutar una consulta SQL</strong>: Utilizamos <code>spark.sql</code> para ejecutar una consulta SQL sobre la vista temporal.</li>
<li><strong>Mostrar el resultado</strong>: Utilizamos el método <code>show()</code> para mostrar el resultado de la consulta.</li>
</ol>
</div><h1><ol start="4">
<li>Integración con Otras Fuentes de Datos</li>
</ol></h1>
<div class='content'><p>Spark SQL puede integrarse con diversas fuentes de datos como archivos CSV, JSON, Parquet, bases de datos JDBC, entre otros.</p>
</div><h2>Ejemplo de lectura de un archivo CSV:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMZWVyIHVuIGFyY2hpdm8gQ1NWCmRmX2NzdiA9IHNwYXJrLnJlYWQuY3N2KCJwYXRoL3RvL2ZpbGUuY3N2IiwgaGVhZGVyPVRydWUsIGluZmVyU2NoZW1hPVRydWUpCgojIE1vc3RyYXIgZWwgRGF0YUZyYW1lCmRmX2Nzdi5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Leer un archivo CSV
df_csv = spark.read.csv(&quot;path/to/file.csv&quot;, header=True, inferSchema=True)

# Mostrar el DataFrame
df_csv.show()</pre></div><div class='content'></div><h2>Explicación del código:</h2>
<div class='content'><ol>
<li><strong>Leer un archivo CSV</strong>: Utilizamos <code>spark.read.csv</code> para leer un archivo CSV. Los parámetros <code>header=True</code> e <code>inferSchema=True</code> indican que el archivo tiene una fila de encabezado y que Spark debe inferir el esquema de los datos.</li>
<li><strong>Mostrar el DataFrame</strong>: Utilizamos el método <code>show()</code> para mostrar el contenido del DataFrame.</li>
</ol>
</div><h1>Ejercicios Prácticos</h1>
<div class='content'></div><h2>Ejercicio 1: Crear y Consultar un DataFrame</h2>
<div class='content'><ol>
<li>
<p>Crea un DataFrame a partir de la siguiente lista de tuplas:</p>
<pre><code class="language-python">data = [(&quot;John&quot;, 28), (&quot;Doe&quot;, 22), (&quot;Jane&quot;, 35), (&quot;Smith&quot;, 40)]
columns = [&quot;Name&quot;, &quot;Age&quot;]
</code></pre>
</li>
<li>
<p>Registra el DataFrame como una vista temporal llamada &quot;people&quot;.</p>
</li>
<li>
<p>Ejecuta una consulta SQL para seleccionar los nombres de las personas cuya edad sea mayor a 30.</p>
</li>
</ol>
</div><h2>Solución:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIENyZWFyIHVuYSBzZXNpw7NuIGRlIFNwYXJrCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiU3BhcmtTUUxFeGVyY2lzZSIpLmdldE9yQ3JlYXRlKCkKCiMgQ3JlYXIgdW4gRGF0YUZyYW1lCmRhdGEgPSBbKCJKb2huIiwgMjgpLCAoIkRvZSIsIDIyKSwgKCJKYW5lIiwgMzUpLCAoIlNtaXRoIiwgNDApXQpjb2x1bW5zID0gWyJOYW1lIiwgIkFnZSJdCmRmID0gc3BhcmsuY3JlYXRlRGF0YUZyYW1lKGRhdGEsIGNvbHVtbnMpCgojIFJlZ2lzdHJhciBlbCBEYXRhRnJhbWUgY29tbyB1bmEgdmlzdGEgdGVtcG9yYWwKZGYuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoInBlb3BsZSIpCgojIEVqZWN1dGFyIHVuYSBjb25zdWx0YSBTUUwKcmVzdWx0ID0gc3Bhcmsuc3FsKCJTRUxFQ1QgTmFtZSBGUk9NIHBlb3BsZSBXSEVSRSBBZ2UgPiAzMCIpCgojIE1vc3RyYXIgZWwgcmVzdWx0YWRvCnJlc3VsdC5zaG93KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Crear una sesi&oacute;n de Spark
spark = SparkSession.builder.appName(&quot;SparkSQLExercise&quot;).getOrCreate()

# Crear un DataFrame
data = [(&quot;John&quot;, 28), (&quot;Doe&quot;, 22), (&quot;Jane&quot;, 35), (&quot;Smith&quot;, 40)]
columns = [&quot;Name&quot;, &quot;Age&quot;]
df = spark.createDataFrame(data, columns)

# Registrar el DataFrame como una vista temporal
df.createOrReplaceTempView(&quot;people&quot;)

# Ejecutar una consulta SQL
result = spark.sql(&quot;SELECT Name FROM people WHERE Age &gt; 30&quot;)

# Mostrar el resultado
result.show()</pre></div><div class='content'></div><h2>Ejercicio 2: Leer y Consultar un Archivo CSV</h2>
<div class='content'><ol>
<li>Descarga un archivo CSV con datos de ejemplo (puedes usar cualquier dataset público).</li>
<li>Lee el archivo CSV en un DataFrame.</li>
<li>Ejecuta una consulta SQL para seleccionar algunas columnas específicas del DataFrame.</li>
</ol>
</div><h2>Solución:</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBMZWVyIHVuIGFyY2hpdm8gQ1NWCmRmX2NzdiA9IHNwYXJrLnJlYWQuY3N2KCJwYXRoL3RvL3lvdXIvZmlsZS5jc3YiLCBoZWFkZXI9VHJ1ZSwgaW5mZXJTY2hlbWE9VHJ1ZSkKCiMgUmVnaXN0cmFyIGVsIERhdGFGcmFtZSBjb21vIHVuYSB2aXN0YSB0ZW1wb3JhbApkZl9jc3YuY3JlYXRlT3JSZXBsYWNlVGVtcFZpZXcoImRhdGEiKQoKIyBFamVjdXRhciB1bmEgY29uc3VsdGEgU1FMCnJlc3VsdCA9IHNwYXJrLnNxbCgiU0VMRUNUIGNvbHVtbjEsIGNvbHVtbjIgRlJPTSBkYXRhIikKCiMgTW9zdHJhciBlbCByZXN1bHRhZG8KcmVzdWx0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Leer un archivo CSV
df_csv = spark.read.csv(&quot;path/to/your/file.csv&quot;, header=True, inferSchema=True)

# Registrar el DataFrame como una vista temporal
df_csv.createOrReplaceTempView(&quot;data&quot;)

# Ejecutar una consulta SQL
result = spark.sql(&quot;SELECT column1, column2 FROM data&quot;)

# Mostrar el resultado
result.show()</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, hemos aprendido los conceptos básicos de Spark SQL, cómo crear y manipular DataFrames utilizando SQL, y cómo ejecutar consultas SQL en Spark. También hemos visto cómo integrar Spark SQL con otras fuentes de datos. Estos conocimientos son fundamentales para trabajar con datos estructurados en Apache Spark y realizar análisis de datos eficientes y escalables.</p>
<p>En el próximo módulo, profundizaremos en el procesamiento de datos con Spark, incluyendo cómo cargar y guardar datos, y realizar operaciones avanzadas con DataFrames y Datasets.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='02-03-spark-dataframes' title="DataFrames de Spark">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='03-01-loading-saving-data' title="Cargar y Guardar Datos">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
	     crossorigin="anonymous"></script>
	<!-- enterprise_campus -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-0611338592562725"
	     data-ad-slot="6914733106"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
	     (adsbygoogle = window.adsbygoogle || []).push({});
	</script>
			
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de Apache Spark</h1>
<h2>Módulo 1: Introducción a Apache Spark</h2>
<ul>
<li><a href="01-01-what-is-apache-spark">¿Qué es Apache Spark?</a></li>
<li><a href="01-02-setting-up-spark-environment">Configuración del Entorno Spark</a></li>
<li><a href="01-03-spark-architecture">Arquitectura de Spark</a></li>
<li><a href="01-04-spark-shell">Shell de Spark</a></li>
</ul>
<h2>Módulo 2: Conceptos Básicos de Spark</h2>
<ul>
<li><a href="02-01-rdds">RDDs (Conjuntos de Datos Distribuidos Resilientes)</a></li>
<li><a href="02-02-transformations-actions">Transformaciones y Acciones</a></li>
<li><a href="02-03-spark-dataframes">DataFrames de Spark</a></li>
<li><a href="02-04-spark-sql">Spark SQL</a></li>
</ul>
<h2>Módulo 3: Procesamiento de Datos con Spark</h2>
<ul>
<li><a href="03-01-loading-saving-data">Cargar y Guardar Datos</a></li>
<li><a href="03-02-dataframe-operations">Operaciones con DataFrames</a></li>
<li><a href="03-03-working-with-datasets">Trabajando con Datasets</a></li>
<li><a href="03-04-handling-missing-data">Manejo de Datos Faltantes</a></li>
</ul>
<h2>Módulo 4: Programación Avanzada en Spark</h2>
<ul>
<li><a href="04-01-spark-streaming">Spark Streaming</a></li>
<li><a href="04-02-structured-streaming">Streaming Estructurado</a></li>
<li><a href="04-03-spark-mllib">Spark MLlib</a></li>
<li><a href="04-04-graphx">GraphX</a></li>
</ul>
<h2>Módulo 5: Ajuste y Optimización del Rendimiento</h2>
<ul>
<li><a href="05-01-understanding-spark-jobs">Entendiendo los Trabajos de Spark</a></li>
<li><a href="05-02-caching-persistence">Caché y Persistencia</a></li>
<li><a href="05-03-memory-management">Gestión de Memoria</a></li>
<li><a href="05-04-optimizing-spark-applications">Optimizando Aplicaciones Spark</a></li>
</ul>
<h2>Módulo 6: Spark en la Nube</h2>
<ul>
<li><a href="06-01-running-spark-aws">Ejecutando Spark en AWS</a></li>
<li><a href="06-02-running-spark-azure">Ejecutando Spark en Azure</a></li>
<li><a href="06-03-running-spark-google-cloud">Ejecutando Spark en Google Cloud</a></li>
<li><a href="06-04-spark-kubernetes">Spark con Kubernetes</a></li>
</ul>
<h2>Módulo 7: Aplicaciones del Mundo Real y Estudios de Caso</h2>
<ul>
<li><a href="07-01-real-time-data-processing">Procesamiento de Datos en Tiempo Real</a></li>
<li><a href="07-02-big-data-analytics">Analítica de Big Data</a></li>
<li><a href="07-03-machine-learning-pipelines">Pipelines de Aprendizaje Automático</a></li>
<li><a href="07-04-case-studies">Estudios de Caso</a></li>
</ul>
<h2>Módulo 8: Proyecto Final</h2>
<ul>
<li><a href="08-01-project-overview">Descripción del Proyecto</a></li>
<li><a href="08-02-project-setup">Configuración del Proyecto</a></li>
<li><a href="08-03-implementation">Implementación</a></li>
<li><a href="08-04-presentation-review">Presentación y Revisión</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
</body>
</html>
