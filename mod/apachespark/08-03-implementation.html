<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Implementación</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/08-03-implementation" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/08-03-implementation" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/08-03-implementation" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>var DEVELOP = window.location.href.indexOf("localhost")!=-1 && true;</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/mod/apachespark/08-03-implementation" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/apachespark/08-03-implementation" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>
		<!-- <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Contenido del curso
	</a>

			</div>
		</div>
	</div>
</div>
 -->
 
<div class="top-bar container-fluid">
	<div class="container-xxl">
		<nav class="navbar navbar-expand-md p-0">
			<div class="container-fluid">
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				
				<div class="collapse navbar-collapse" id="navbarNav">
					<div class="navbar-nav me-auto">
							<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Contenido del curso
	</a>

					</div>
				</div>			
							</div>
		</nav>
	</div>
</div>				<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='08-02-project-setup' title="Configuración del Proyecto">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<h2 style="text-decoration:underline">Implementación</h2>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='08-04-presentation-review' title="Presentación y Revisión">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>En esta sección, vamos a llevar a cabo la implementación del proyecto final utilizando Apache Spark. Este proyecto integrará los conocimientos adquiridos a lo largo del curso y te permitirá aplicar técnicas avanzadas de procesamiento de datos en un entorno realista.</p>
</div><h1>Objetivos del Proyecto</h1>
<div class='content'><ol>
<li><strong>Procesar y analizar un conjunto de datos grande</strong> utilizando Apache Spark.</li>
<li><strong>Aplicar transformaciones y acciones</strong> para limpiar y preparar los datos.</li>
<li><strong>Utilizar Spark SQL y DataFrames</strong> para realizar consultas y análisis.</li>
<li><strong>Implementar un pipeline de aprendizaje automático</strong> utilizando Spark MLlib.</li>
<li><strong>Optimizar el rendimiento</strong> de la aplicación Spark.</li>
<li><strong>Desplegar la aplicación en un entorno de nube</strong> (opcional).</li>
</ol>
</div><h1>Pasos de Implementación</h1>
<div class='content'></div><h2><ol>
<li>Cargar los Datos</li>
</ol></h2>
<div class='content'><p>Primero, necesitamos cargar el conjunto de datos en un DataFrame de Spark. Para este proyecto, utilizaremos un conjunto de datos de ejemplo que contiene información sobre transacciones de ventas.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIENyZWFyIHVuYSBzZXNpw7NuIGRlIFNwYXJrCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIgXAogICAgLmFwcE5hbWUoIlByb3llY3RvIEZpbmFsIGRlIEFwYWNoZSBTcGFyayIpIFwKICAgIC5nZXRPckNyZWF0ZSgpCgojIENhcmdhciBlbCBjb25qdW50byBkZSBkYXRvcwpkYXRhX3BhdGggPSAicGF0aC90by9zYWxlc190cmFuc2FjdGlvbnMuY3N2IgpkZiA9IHNwYXJrLnJlYWQuY3N2KGRhdGFfcGF0aCwgaGVhZGVyPVRydWUsIGluZmVyU2NoZW1hPVRydWUpCgojIE1vc3RyYXIgbGFzIHByaW1lcmFzIGZpbGFzIGRlbCBEYXRhRnJhbWUKZGYuc2hvdyg1KQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Crear una sesi&oacute;n de Spark
spark = SparkSession.builder \
    .appName(&quot;Proyecto Final de Apache Spark&quot;) \
    .getOrCreate()

# Cargar el conjunto de datos
data_path = &quot;path/to/sales_transactions.csv&quot;
df = spark.read.csv(data_path, header=True, inferSchema=True)

# Mostrar las primeras filas del DataFrame
df.show(5)</pre></div><div class='content'></div><h2><ol start="2">
<li>Exploración y Limpieza de Datos</li>
</ol></h2>
<div class='content'><p>Antes de realizar cualquier análisis, es importante explorar y limpiar los datos.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBNb3N0cmFyIGVsIGVzcXVlbWEgZGVsIERhdGFGcmFtZQpkZi5wcmludFNjaGVtYSgpCgojIENvbnRhciBlbCBuw7ptZXJvIGRlIGZpbGFzCm51bV9yb3dzID0gZGYuY291bnQoKQpwcmludChmIkVsIGNvbmp1bnRvIGRlIGRhdG9zIGNvbnRpZW5lIHtudW1fcm93c30gZmlsYXMuIikKCiMgRWxpbWluYXIgZmlsYXMgY29uIGRhdG9zIGZhbHRhbnRlcwpkZl9jbGVhbiA9IGRmLmRyb3BuYSgpCgojIFZlcmlmaWNhciBxdWUgbm8gaGF5IGRhdG9zIGZhbHRhbnRlcwpkZl9jbGVhbi5zZWxlY3QoW2NvdW50KHdoZW4oY29sKGMpLmlzTnVsbCgpLCBjKSkuYWxpYXMoYykgZm9yIGMgaW4gZGZfY2xlYW4uY29sdW1uc10pLnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Mostrar el esquema del DataFrame
df.printSchema()

# Contar el n&uacute;mero de filas
num_rows = df.count()
print(f&quot;El conjunto de datos contiene {num_rows} filas.&quot;)

# Eliminar filas con datos faltantes
df_clean = df.dropna()

# Verificar que no hay datos faltantes
df_clean.select([count(when(col(c).isNull(), c)).alias(c) for c in df_clean.columns]).show()</pre></div><div class='content'></div><h2><ol start="3">
<li>Transformaciones y Acciones</li>
</ol></h2>
<div class='content'><p>Realizaremos algunas transformaciones para preparar los datos para el análisis.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IGNvbCwgc3VtCgojIENhbGN1bGFyIGVsIHRvdGFsIGRlIHZlbnRhcyBwb3IgcHJvZHVjdG8KdG90YWxfc2FsZXNfcGVyX3Byb2R1Y3QgPSBkZl9jbGVhbi5ncm91cEJ5KCJwcm9kdWN0X2lkIikuYWdnKHN1bSgic2FsZXNfYW1vdW50IikuYWxpYXMoInRvdGFsX3NhbGVzIikpCgojIE1vc3RyYXIgbG9zIHJlc3VsdGFkb3MKdG90YWxfc2FsZXNfcGVyX3Byb2R1Y3Quc2hvdyg1KQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql.functions import col, sum

# Calcular el total de ventas por producto
total_sales_per_product = df_clean.groupBy(&quot;product_id&quot;).agg(sum(&quot;sales_amount&quot;).alias(&quot;total_sales&quot;))

# Mostrar los resultados
total_sales_per_product.show(5)</pre></div><div class='content'></div><h2><ol start="4">
<li>Análisis con Spark SQL</li>
</ol></h2>
<div class='content'><p>Utilizaremos Spark SQL para realizar consultas más complejas.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBSZWdpc3RyYXIgZWwgRGF0YUZyYW1lIGNvbW8gdW5hIHZpc3RhIHRlbXBvcmFsCmRmX2NsZWFuLmNyZWF0ZU9yUmVwbGFjZVRlbXBWaWV3KCJzYWxlcyIpCgojIFJlYWxpemFyIHVuYSBjb25zdWx0YSBTUUwKcmVzdWx0ID0gc3Bhcmsuc3FsKCIiIgogICAgU0VMRUNUIHByb2R1Y3RfaWQsIFNVTShzYWxlc19hbW91bnQpIEFTIHRvdGFsX3NhbGVzCiAgICBGUk9NIHNhbGVzCiAgICBHUk9VUCBCWSBwcm9kdWN0X2lkCiAgICBPUkRFUiBCWSB0b3RhbF9zYWxlcyBERVNDCiAgICBMSU1JVCAxMAoiIiIpCgojIE1vc3RyYXIgbG9zIHJlc3VsdGFkb3MKcmVzdWx0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Registrar el DataFrame como una vista temporal
df_clean.createOrReplaceTempView(&quot;sales&quot;)

# Realizar una consulta SQL
result = spark.sql(&quot;&quot;&quot;
    SELECT product_id, SUM(sales_amount) AS total_sales
    FROM sales
    GROUP BY product_id
    ORDER BY total_sales DESC
    LIMIT 10
&quot;&quot;&quot;)

# Mostrar los resultados
result.show()</pre></div><div class='content'></div><h2><ol start="5">
<li>Pipeline de Aprendizaje Automático</li>
</ol></h2>
<div class='content'><p>Implementaremos un pipeline de aprendizaje automático para predecir las ventas futuras.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmZlYXR1cmUgaW1wb3J0IFZlY3RvckFzc2VtYmxlcgpmcm9tIHB5c3BhcmsubWwucmVncmVzc2lvbiBpbXBvcnQgTGluZWFyUmVncmVzc2lvbgoKIyBTZWxlY2Npb25hciBsYXMgY2FyYWN0ZXLDrXN0aWNhcyB5IGxhIHZhcmlhYmxlIG9iamV0aXZvCmFzc2VtYmxlciA9IFZlY3RvckFzc2VtYmxlcihpbnB1dENvbHM9WyJmZWF0dXJlMSIsICJmZWF0dXJlMiJdLCBvdXRwdXRDb2w9ImZlYXR1cmVzIikKZGZfZmVhdHVyZXMgPSBhc3NlbWJsZXIudHJhbnNmb3JtKGRmX2NsZWFuKQoKIyBEaXZpZGlyIGxvcyBkYXRvcyBlbiBjb25qdW50b3MgZGUgZW50cmVuYW1pZW50byB5IHBydWViYQp0cmFpbl9kYXRhLCB0ZXN0X2RhdGEgPSBkZl9mZWF0dXJlcy5yYW5kb21TcGxpdChbMC44LCAwLjJdKQoKIyBDcmVhciB5IGVudHJlbmFyIGVsIG1vZGVsbyBkZSByZWdyZXNpw7NuIGxpbmVhbApsciA9IExpbmVhclJlZ3Jlc3Npb24oZmVhdHVyZXNDb2w9ImZlYXR1cmVzIiwgbGFiZWxDb2w9InNhbGVzX2Ftb3VudCIpCmxyX21vZGVsID0gbHIuZml0KHRyYWluX2RhdGEpCgojIEV2YWx1YXIgZWwgbW9kZWxvCnRlc3RfcmVzdWx0cyA9IGxyX21vZGVsLmV2YWx1YXRlKHRlc3RfZGF0YSkKcHJpbnQoZiJSTVNFOiB7dGVzdF9yZXN1bHRzLnJvb3RNZWFuU3F1YXJlZEVycm9yfSIp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression

# Seleccionar las caracter&iacute;sticas y la variable objetivo
assembler = VectorAssembler(inputCols=[&quot;feature1&quot;, &quot;feature2&quot;], outputCol=&quot;features&quot;)
df_features = assembler.transform(df_clean)

# Dividir los datos en conjuntos de entrenamiento y prueba
train_data, test_data = df_features.randomSplit([0.8, 0.2])

# Crear y entrenar el modelo de regresi&oacute;n lineal
lr = LinearRegression(featuresCol=&quot;features&quot;, labelCol=&quot;sales_amount&quot;)
lr_model = lr.fit(train_data)

# Evaluar el modelo
test_results = lr_model.evaluate(test_data)
print(f&quot;RMSE: {test_results.rootMeanSquaredError}&quot;)</pre></div><div class='content'></div><h2><ol start="6">
<li>Optimización del Rendimiento</li>
</ol></h2>
<div class='content'><p>Aplicaremos técnicas de optimización para mejorar el rendimiento de nuestra aplicación Spark.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBQZXJzaXN0aXIgZWwgRGF0YUZyYW1lIGVuIG1lbW9yaWEKZGZfY2xlYW4uY2FjaGUoKQoKIyBSZWFsaXphciB1bmEgYWNjacOzbiBwYXJhIG1hdGVyaWFsaXphciBlbCBEYXRhRnJhbWUgZW4gbWVtb3JpYQpkZl9jbGVhbi5jb3VudCgpCgojIE9wdGltaXphciBsYXMgY29uc3VsdGFzIFNRTApzcGFyay5jb25mLnNldCgic3Bhcmsuc3FsLnNodWZmbGUucGFydGl0aW9ucyIsICI1MCIp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Persistir el DataFrame en memoria
df_clean.cache()

# Realizar una acci&oacute;n para materializar el DataFrame en memoria
df_clean.count()

# Optimizar las consultas SQL
spark.conf.set(&quot;spark.sql.shuffle.partitions&quot;, &quot;50&quot;)</pre></div><div class='content'></div><h2><ol start="7">
<li>Despliegue en la Nube (Opcional)</li>
</ol></h2>
<div class='content'><p>Finalmente, podemos desplegar nuestra aplicación en un entorno de nube como AWS, Azure o Google Cloud.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBFamVtcGxvIGRlIGNvbWFuZG8gcGFyYSBlamVjdXRhciBsYSBhcGxpY2FjacOzbiBlbiBBV1MgRU1SCnNwYXJrLXN1Ym1pdCAtLW1hc3RlciB5YXJuIC0tZGVwbG95LW1vZGUgY2x1c3RlciAtLWNvbmYgc3BhcmsueWFybi5zdWJtaXQud2FpdEFwcENvbXBsZXRpb249ZmFsc2UgczM6Ly9wYXRoL3RvL3lvdXIvc3BhcmtfYXBwbGljYXRpb24ucHk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Ejemplo de comando para ejecutar la aplicaci&oacute;n en AWS EMR
spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.submit.waitAppCompletion=false s3://path/to/your/spark_application.py</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, hemos implementado un proyecto completo utilizando Apache Spark. Hemos cubierto desde la carga y limpieza de datos hasta la implementación de un pipeline de aprendizaje automático y la optimización del rendimiento. Este proyecto te proporciona una experiencia práctica y te prepara para enfrentar desafíos del mundo real utilizando Apache Spark.</p>
<p>¡Felicidades por completar el proyecto final! Ahora estás listo para aplicar tus habilidades de Apache Spark en proyectos reales y complejos.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='08-02-project-setup' title="Configuración del Proyecto">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='08-04-presentation-review' title="Presentación y Revisión">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
	     crossorigin="anonymous"></script>
	<!-- enterprise_campus -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-0611338592562725"
	     data-ad-slot="6914733106"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
	     (adsbygoogle = window.adsbygoogle || []).push({});
	</script>
			
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de Apache Spark</h1>
<h2>Módulo 1: Introducción a Apache Spark</h2>
<ul>
<li><a href="01-01-what-is-apache-spark">¿Qué es Apache Spark?</a></li>
<li><a href="01-02-setting-up-spark-environment">Configuración del Entorno Spark</a></li>
<li><a href="01-03-spark-architecture">Arquitectura de Spark</a></li>
<li><a href="01-04-spark-shell">Shell de Spark</a></li>
</ul>
<h2>Módulo 2: Conceptos Básicos de Spark</h2>
<ul>
<li><a href="02-01-rdds">RDDs (Conjuntos de Datos Distribuidos Resilientes)</a></li>
<li><a href="02-02-transformations-actions">Transformaciones y Acciones</a></li>
<li><a href="02-03-spark-dataframes">DataFrames de Spark</a></li>
<li><a href="02-04-spark-sql">Spark SQL</a></li>
</ul>
<h2>Módulo 3: Procesamiento de Datos con Spark</h2>
<ul>
<li><a href="03-01-loading-saving-data">Cargar y Guardar Datos</a></li>
<li><a href="03-02-dataframe-operations">Operaciones con DataFrames</a></li>
<li><a href="03-03-working-with-datasets">Trabajando con Datasets</a></li>
<li><a href="03-04-handling-missing-data">Manejo de Datos Faltantes</a></li>
</ul>
<h2>Módulo 4: Programación Avanzada en Spark</h2>
<ul>
<li><a href="04-01-spark-streaming">Spark Streaming</a></li>
<li><a href="04-02-structured-streaming">Streaming Estructurado</a></li>
<li><a href="04-03-spark-mllib">Spark MLlib</a></li>
<li><a href="04-04-graphx">GraphX</a></li>
</ul>
<h2>Módulo 5: Ajuste y Optimización del Rendimiento</h2>
<ul>
<li><a href="05-01-understanding-spark-jobs">Entendiendo los Trabajos de Spark</a></li>
<li><a href="05-02-caching-persistence">Caché y Persistencia</a></li>
<li><a href="05-03-memory-management">Gestión de Memoria</a></li>
<li><a href="05-04-optimizing-spark-applications">Optimizando Aplicaciones Spark</a></li>
</ul>
<h2>Módulo 6: Spark en la Nube</h2>
<ul>
<li><a href="06-01-running-spark-aws">Ejecutando Spark en AWS</a></li>
<li><a href="06-02-running-spark-azure">Ejecutando Spark en Azure</a></li>
<li><a href="06-03-running-spark-google-cloud">Ejecutando Spark en Google Cloud</a></li>
<li><a href="06-04-spark-kubernetes">Spark con Kubernetes</a></li>
</ul>
<h2>Módulo 7: Aplicaciones del Mundo Real y Estudios de Caso</h2>
<ul>
<li><a href="07-01-real-time-data-processing">Procesamiento de Datos en Tiempo Real</a></li>
<li><a href="07-02-big-data-analytics">Analítica de Big Data</a></li>
<li><a href="07-03-machine-learning-pipelines">Pipelines de Aprendizaje Automático</a></li>
<li><a href="07-04-case-studies">Estudios de Caso</a></li>
</ul>
<h2>Módulo 8: Proyecto Final</h2>
<ul>
<li><a href="08-01-project-overview">Descripción del Proyecto</a></li>
<li><a href="08-02-project-setup">Configuración del Proyecto</a></li>
<li><a href="08-03-implementation">Implementación</a></li>
<li><a href="08-04-presentation-review">Presentación y Revisión</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
</body>
</html>
