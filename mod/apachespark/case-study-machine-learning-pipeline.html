<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Estudio de Caso: Pipeline de Aprendizaje Automático</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/case-study-machine-learning-pipeline" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/case-study-machine-learning-pipeline" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/case-study-machine-learning-pipeline" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body  class="test" >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/apachespark/case-study-machine-learning-pipeline" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/case-study-machine-learning-pipeline" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
									<div class="assert">
						<p><b>Atención!</b> Ha habido un error en la generación del curso y puede contener errores de traducción.Estamos trabajando para solucinarlo por lo que se deben usar los contenidos con cuidado.Se puede consultar el contenido correcto en otro idioma en el siguiente enlace:<br>
						<a href="https://enterprisecampus.net/mod/apachespark/case-study-machine-learning-pipeline">https://enterprisecampus.net/mod/apachespark/case-study-machine-learning-pipeline</a></p>
					</div>
								<div class='row navigation'>
	<div class='col-4'>
					<a href='case-study-real-time-data-processing'>&#x25C4;Estudio de Caso: Procesamiento de Datos en Tiempo Real</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Estudio de Caso: Pipeline de Aprendizaje Automático</a>
	</div>
	<div class='col-4 text-end'>
					<a href='case-study-graph-processing'>Estudio de Caso: Procesamiento de Grafos &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción</h1>
<div class='content'><p>En esta sección, exploraremos cómo construir un pipeline de aprendizaje automático usando Apache Spark. Este estudio de caso te guiará a través del proceso desde la ingestión de datos hasta el despliegue del modelo, cubriendo conceptos clave y proporcionando ejemplos prácticos.</p>
</div><h1>Conceptos Clave</h1>
<div class='content'><ul>
<li><strong>Ingestión de Datos</strong>: Cargar datos en Spark.</li>
<li><strong>Preprocesamiento de Datos</strong>: Limpiar y transformar datos.</li>
<li><strong>Ingeniería de Características</strong>: Crear características que mejoren el rendimiento del modelo.</li>
<li><strong>Entrenamiento del Modelo</strong>: Entrenar un modelo de aprendizaje automático.</li>
<li><strong>Evaluación del Modelo</strong>: Evaluar el rendimiento del modelo.</li>
<li><strong>Despliegue del Modelo</strong>: Hacer que el modelo esté disponible para predicciones.</li>
</ul>
</div><h1>Ingestión de Datos</h1>
<div class='content'><p>La ingestión de datos es el primer paso en cualquier pipeline de aprendizaje automático. Apache Spark proporciona varios métodos para cargar datos desde diferentes fuentes.</p>
</div><h2>Ejemplo: Cargar Datos desde un Archivo CSV</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIEluaWNpYWxpemFyIHNlc2nDs24gZGUgU3BhcmsKc3BhcmsgPSBTcGFya1Nlc3Npb24uYnVpbGRlci5hcHBOYW1lKCJNTFBpcGVsaW5lIikuZ2V0T3JDcmVhdGUoKQoKIyBDYXJnYXIgZGF0b3MKZGF0YSA9IHNwYXJrLnJlYWQuY3N2KCJkYXRhL3NhbXBsZV9kYXRhLmNzdiIsIGhlYWRlcj1UcnVlLCBpbmZlclNjaGVtYT1UcnVlKQpkYXRhLnNob3coNSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Inicializar sesi&oacute;n de Spark
spark = SparkSession.builder.appName(&quot;MLPipeline&quot;).getOrCreate()

# Cargar datos
data = spark.read.csv(&quot;data/sample_data.csv&quot;, header=True, inferSchema=True)
data.show(5)</pre></div><div class='content'><p>Explicación:</p>
<ul>
<li>Comenzamos inicializando una sesión de Spark.</li>
<li>Luego cargamos datos desde un archivo CSV usando <code>spark.read.csv</code>.</li>
<li>La opción <code>header=True</code> indica que la primera fila contiene nombres de columnas.</li>
<li>La opción <code>inferSchema=True</code> infiere automáticamente los tipos de datos de las columnas.</li>
</ul>
</div><h1>Preprocesamiento de Datos</h1>
<div class='content'><p>El preprocesamiento de datos implica limpiar y transformar los datos para hacerlos adecuados para el aprendizaje automático.</p>
</div><h2>Ejemplo: Manejo de Valores Faltantes</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBFbGltaW5hciBmaWxhcyBjb24gY3VhbHF1aWVyIHZhbG9yIGZhbHRhbnRlCmNsZWFuZWRfZGF0YSA9IGRhdGEuZHJvcG5hKCkKY2xlYW5lZF9kYXRhLnNob3coNSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Eliminar filas con cualquier valor faltante
cleaned_data = data.dropna()
cleaned_data.show(5)</pre></div><div class='content'><p>Explicación:</p>
<ul>
<li>Usamos el método <code>dropna()</code> para eliminar filas con cualquier valor faltante.</li>
</ul>
</div><h1>Ingeniería de Características</h1>
<div class='content'><p>La ingeniería de características es el proceso de crear nuevas características o transformar las existentes para mejorar el rendimiento del modelo.</p>
</div><h2>Ejemplo: Codificación One-Hot de Variables Categóricas</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmZlYXR1cmUgaW1wb3J0IE9uZUhvdEVuY29kZXIsIFN0cmluZ0luZGV4ZXIKCiMgSW5kZXhhciBjb2x1bW5hIGNhdGVnw7NyaWNhCmluZGV4ZXIgPSBTdHJpbmdJbmRleGVyKGlucHV0Q29sPSJjYXRlZ29yeSIsIG91dHB1dENvbD0iY2F0ZWdvcnlJbmRleCIpCmluZGV4ZWRfZGF0YSA9IGluZGV4ZXIuZml0KGNsZWFuZWRfZGF0YSkudHJhbnNmb3JtKGNsZWFuZWRfZGF0YSkKCiMgQ29kaWZpY2FyIGVuIG9uZS1ob3QgbGEgY29sdW1uYSBpbmRleGFkYQplbmNvZGVyID0gT25lSG90RW5jb2RlcihpbnB1dENvbD0iY2F0ZWdvcnlJbmRleCIsIG91dHB1dENvbD0iY2F0ZWdvcnlWZWMiKQplbmNvZGVkX2RhdGEgPSBlbmNvZGVyLmZpdChpbmRleGVkX2RhdGEpLnRyYW5zZm9ybShpbmRleGVkX2RhdGEpCmVuY29kZWRfZGF0YS5zaG93KDUp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.feature import OneHotEncoder, StringIndexer

# Indexar columna categ&oacute;rica
indexer = StringIndexer(inputCol=&quot;category&quot;, outputCol=&quot;categoryIndex&quot;)
indexed_data = indexer.fit(cleaned_data).transform(cleaned_data)

# Codificar en one-hot la columna indexada
encoder = OneHotEncoder(inputCol=&quot;categoryIndex&quot;, outputCol=&quot;categoryVec&quot;)
encoded_data = encoder.fit(indexed_data).transform(indexed_data)
encoded_data.show(5)</pre></div><div class='content'><p>Explicación:</p>
<ul>
<li>Usamos <code>StringIndexer</code> para convertir valores categóricos en índices numéricos.</li>
<li>Luego usamos <code>OneHotEncoder</code> para convertir estos índices en vectores codificados en one-hot.</li>
</ul>
</div><h1>Entrenamiento del Modelo</h1>
<div class='content'><p>El entrenamiento del modelo implica usar los datos preprocesados para entrenar un modelo de aprendizaje automático.</p>
</div><h2>Ejemplo: Entrenamiento de un Modelo de Regresión Logística</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmNsYXNzaWZpY2F0aW9uIGltcG9ydCBMb2dpc3RpY1JlZ3Jlc3Npb24KZnJvbSBweXNwYXJrLm1sLmZlYXR1cmUgaW1wb3J0IFZlY3RvckFzc2VtYmxlcgoKIyBFbnNhbWJsYXIgY2FyYWN0ZXLDrXN0aWNhcyBlbiB1biBzb2xvIHZlY3Rvcgphc3NlbWJsZXIgPSBWZWN0b3JBc3NlbWJsZXIoaW5wdXRDb2xzPVsiZmVhdHVyZTEiLCAiZmVhdHVyZTIiLCAiY2F0ZWdvcnlWZWMiXSwgb3V0cHV0Q29sPSJmZWF0dXJlcyIpCmFzc2VtYmxlZF9kYXRhID0gYXNzZW1ibGVyLnRyYW5zZm9ybShlbmNvZGVkX2RhdGEpCgojIEluaWNpYWxpemFyIHkgZW50cmVuYXIgZWwgbW9kZWxvIGRlIHJlZ3Jlc2nDs24gbG9nw61zdGljYQpsciA9IExvZ2lzdGljUmVncmVzc2lvbihmZWF0dXJlc0NvbD0iZmVhdHVyZXMiLCBsYWJlbENvbD0ibGFiZWwiKQptb2RlbCA9IGxyLmZpdChhc3NlbWJsZWRfZGF0YSkKCiMgSW1wcmltaXIgY29lZmljaWVudGVzIGRlbCBtb2RlbG8KcHJpbnQoIkNvZWZpY2llbnRlczogIiArIHN0cihtb2RlbC5jb2VmZmljaWVudHMpKQpwcmludCgiSW50ZXJjZXB0bzogIiArIHN0cihtb2RlbC5pbnRlcmNlcHQpKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.classification import LogisticRegression
from pyspark.ml.feature import VectorAssembler

# Ensamblar caracter&iacute;sticas en un solo vector
assembler = VectorAssembler(inputCols=[&quot;feature1&quot;, &quot;feature2&quot;, &quot;categoryVec&quot;], outputCol=&quot;features&quot;)
assembled_data = assembler.transform(encoded_data)

# Inicializar y entrenar el modelo de regresi&oacute;n log&iacute;stica
lr = LogisticRegression(featuresCol=&quot;features&quot;, labelCol=&quot;label&quot;)
model = lr.fit(assembled_data)

# Imprimir coeficientes del modelo
print(&quot;Coeficientes: &quot; + str(model.coefficients))
print(&quot;Intercepto: &quot; + str(model.intercept))</pre></div><div class='content'><p>Explicación:</p>
<ul>
<li>Usamos <code>VectorAssembler</code> para combinar múltiples columnas de características en un solo vector.</li>
<li>Inicializamos un modelo de <code>LogisticRegression</code> y lo entrenamos usando los datos ensamblados.</li>
<li>Imprimimos los coeficientes e intercepto del modelo.</li>
</ul>
</div><h1>Evaluación del Modelo</h1>
<div class='content'><p>La evaluación del modelo implica evaluar el rendimiento del modelo entrenado.</p>
</div><h2>Ejemplo: Evaluación del Rendimiento del Modelo</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLm1sLmV2YWx1YXRpb24gaW1wb3J0IEJpbmFyeUNsYXNzaWZpY2F0aW9uRXZhbHVhdG9yCgojIEhhY2VyIHByZWRpY2Npb25lcwpwcmVkaWN0aW9ucyA9IG1vZGVsLnRyYW5zZm9ybShhc3NlbWJsZWRfZGF0YSkKCiMgRXZhbHVhciBlbCBtb2RlbG8KZXZhbHVhdG9yID0gQmluYXJ5Q2xhc3NpZmljYXRpb25FdmFsdWF0b3IobGFiZWxDb2w9ImxhYmVsIiwgcmF3UHJlZGljdGlvbkNvbD0icmF3UHJlZGljdGlvbiIpCmFjY3VyYWN5ID0gZXZhbHVhdG9yLmV2YWx1YXRlKHByZWRpY3Rpb25zKQpwcmludCgiUHJlY2lzacOzbiBkZWwgTW9kZWxvOiAiICsgc3RyKGFjY3VyYWN5KSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.ml.evaluation import BinaryClassificationEvaluator

# Hacer predicciones
predictions = model.transform(assembled_data)

# Evaluar el modelo
evaluator = BinaryClassificationEvaluator(labelCol=&quot;label&quot;, rawPredictionCol=&quot;rawPrediction&quot;)
accuracy = evaluator.evaluate(predictions)
print(&quot;Precisi&oacute;n del Modelo: &quot; + str(accuracy))</pre></div><div class='content'><p>Explicación:</p>
<ul>
<li>Usamos el modelo entrenado para hacer predicciones sobre los datos.</li>
<li>Usamos <code>BinaryClassificationEvaluator</code> para evaluar la precisión del modelo.</li>
</ul>
</div><h1>Despliegue del Modelo</h1>
<div class='content'><p>El despliegue del modelo implica hacer que el modelo entrenado esté disponible para hacer predicciones sobre nuevos datos.</p>
</div><h2>Ejemplo: Guardar y Cargar el Modelo</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBHdWFyZGFyIGVsIG1vZGVsbwptb2RlbC5zYXZlKCJtb2RlbHMvbG9naXN0aWNfcmVncmVzc2lvbl9tb2RlbCIpCgojIENhcmdhciBlbCBtb2RlbG8KZnJvbSBweXNwYXJrLm1sLmNsYXNzaWZpY2F0aW9uIGltcG9ydCBMb2dpc3RpY1JlZ3Jlc3Npb25Nb2RlbApsb2FkZWRfbW9kZWwgPSBMb2dpc3RpY1JlZ3Jlc3Npb25Nb2RlbC5sb2FkKCJtb2RlbHMvbG9naXN0aWNfcmVncmVzc2lvbl9tb2RlbCIpCgojIFVzYXIgZWwgbW9kZWxvIGNhcmdhZG8gcGFyYSBwcmVkaWNjaW9uZXMKbmV3X3ByZWRpY3Rpb25zID0gbG9hZGVkX21vZGVsLnRyYW5zZm9ybShhc3NlbWJsZWRfZGF0YSkKbmV3X3ByZWRpY3Rpb25zLnNob3coNSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Guardar el modelo
model.save(&quot;models/logistic_regression_model&quot;)

# Cargar el modelo
from pyspark.ml.classification import LogisticRegressionModel
loaded_model = LogisticRegressionModel.load(&quot;models/logistic_regression_model&quot;)

# Usar el modelo cargado para predicciones
new_predictions = loaded_model.transform(assembled_data)
new_predictions.show(5)</pre></div><div class='content'><p>Explicación:</p>
<ul>
<li>Guardamos el modelo entrenado en disco usando el método <code>save</code>.</li>
<li>Cargamos el modelo desde el disco usando <code>LogisticRegressionModel.load</code>.</li>
<li>Usamos el modelo cargado para hacer predicciones sobre los datos.</li>
</ul>
</div><h1>Conclusión</h1>
<div class='content'><p>En este estudio de caso, hemos recorrido el proceso de construir un pipeline de aprendizaje automático usando Apache Spark. Cubrimos la ingestión de datos, preprocesamiento, ingeniería de características, entrenamiento, evaluación y despliegue del modelo. Siguiendo estos pasos, puedes construir pipelines de aprendizaje automático robustos y escalables para diversas aplicaciones.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='case-study-real-time-data-processing'>&#x25C4;Estudio de Caso: Procesamiento de Datos en Tiempo Real</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Estudio de Caso: Pipeline de Aprendizaje Automático</a>
	</div>
	<div class='col-4 text-end'>
					<a href='case-study-graph-processing'>Estudio de Caso: Procesamiento de Grafos &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
