<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Optimizando Aplicaciones Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/05-04-optimizing-spark-applications" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/05-04-optimizing-spark-applications" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/05-04-optimizing-spark-applications" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<a href="https://enterprisecampus.net/mod/apachespark/05-04-optimizing-spark-applications" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/apachespark/05-04-optimizing-spark-applications" class="px-2">CA</a>
<br>
			<cite>Construyendo la sociedad de hoy y del mañana</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
									<a href="./">Contenido del curso</a>
					<span class="sep">|</span>
								<a href="/all/competencias">Competencias técnicas</a>
				<a href="/all/conocimientos">Conocimientos</a>
				<a href="/all/soft_skills">Competencias sociales</a>
			</div>
		</div>
	</div>
</div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-03-memory-management' title="Gestión de Memoria">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Optimizando Aplicaciones Spark</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-01-running-spark-aws' title="Ejecutando Spark en AWS">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>La optimización de aplicaciones en Apache Spark es crucial para mejorar el rendimiento y la eficiencia de los trabajos de procesamiento de datos. En este módulo, aprenderemos diversas técnicas y estrategias para optimizar nuestras aplicaciones Spark.</p>
</div><h1><p>Contenido</p>
</h1>
<div class='content'><ol>
<li><a href="#entendiendo-el-plan-de-ejecución">Entendiendo el Plan de Ejecución</a></li>
<li><a href="#optimización-de-transformaciones">Optimización de Transformaciones</a></li>
<li><a href="#uso-eficiente-de-la-memoria">Uso Eficiente de la Memoria</a></li>
<li><a href="#particionamiento-de-datos">Particionamiento de Datos</a></li>
<li><a href="#configuración-de-parámetros">Configuración de Parámetros</a></li>
<li><a href="#ejercicios-prácticos">Ejercicios Prácticos</a></li>
<li><a href="#conclusión">Conclusión</a></li>
</ol>
</div><h1><p>Entendiendo el Plan de Ejecución</p>
</h1>
<div class='content'></div><h2><p>Plan Lógico y Plan Físico</p>
</h2>
<div class='content'><p>Spark genera dos tipos de planes de ejecución:</p>
<ul>
<li><strong>Plan Lógico</strong>: Describe las operaciones de alto nivel que se realizarán.</li>
<li><strong>Plan Físico</strong>: Detalla cómo se ejecutarán esas operaciones en el clúster.</li>
</ul>
</div><h2><p>Visualización del Plan de Ejecución</p>
</h2>
<div class='content'><p>Podemos visualizar el plan de ejecución utilizando el método <code>explain()</code> en un DataFrame.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIGRmID0gc3BhcmsucmVhZC5qc29uKCJwYXRoL3RvL2pzb24vZmlsZSIpCmRmLmZpbHRlcigkImFnZSIgPiAyMSkuZXhwbGFpbigp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val df = spark.read.json(&quot;path/to/json/file&quot;)
df.filter($&quot;age&quot; &gt; 21).explain()</pre></div><div class='content'><p>Este comando mostrará el plan lógico y físico de la operación.</p>
</div><h1><p>Optimización de Transformaciones</p>
</h1>
<div class='content'></div><h2><p>Transformaciones Narrow y Wide</p>
</h2>
<div class='content'><ul>
<li><strong>Narrow Transformations</strong>: Operaciones que no requieren un shuffle de datos (e.g., <code>map</code>, <code>filter</code>).</li>
<li><strong>Wide Transformations</strong>: Operaciones que requieren un shuffle de datos (e.g., <code>groupBy</code>, <code>join</code>).</li>
</ul>
</div><h2><p>Ejemplo de Transformaciones</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNjLnBhcmFsbGVsaXplKFNlcSgoMSwgMiksICgzLCA0KSwgKDMsIDYpKSkKdmFsIHJlc3VsdCA9IHJkZC5ncm91cEJ5S2V5KCkubWFwVmFsdWVzKF8uc3VtKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = sc.parallelize(Seq((1, 2), (3, 4), (3, 6)))
val result = rdd.groupByKey().mapValues(_.sum)</pre></div><div class='content'><p>En este ejemplo, <code>groupByKey</code> es una transformación wide que puede ser costosa. En su lugar, podemos usar <code>reduceByKey</code> para optimizar:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJlc3VsdCA9IHJkZC5yZWR1Y2VCeUtleShfICsgXyk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val result = rdd.reduceByKey(_ + _)</pre></div><div class='content'></div><h1><p>Uso Eficiente de la Memoria</p>
</h1>
<div class='content'></div><h2><p>Persistencia y Caché</p>
</h2>
<div class='content'><p>Podemos almacenar RDDs en memoria para reutilizarlos sin volver a calcularlos.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNjLnRleHRGaWxlKCJwYXRoL3RvL2ZpbGUiKQpyZGQuY2FjaGUoKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = sc.textFile(&quot;path/to/file&quot;)
rdd.cache()</pre></div><div class='content'></div><h2><p>Niveles de Persistencia</p>
</h2>
<div class='content'><p>Spark ofrece varios niveles de persistencia, como <code>MEMORY_ONLY</code>, <code>MEMORY_AND_DISK</code>, etc.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("cmRkLnBlcnNpc3QoU3RvcmFnZUxldmVsLk1FTU9SWV9BTkRfRElTSyk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>rdd.persist(StorageLevel.MEMORY_AND_DISK)</pre></div><div class='content'></div><h1><p>Particionamiento de Datos</p>
</h1>
<div class='content'></div><h2><p>Reparticionamiento</p>
</h2>
<div class='content'><p>Podemos controlar el número de particiones para optimizar el procesamiento.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNjLnRleHRGaWxlKCJwYXRoL3RvL2ZpbGUiKS5yZXBhcnRpdGlvbigxMCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = sc.textFile(&quot;path/to/file&quot;).repartition(10)</pre></div><div class='content'></div><h2><p>Coalesce</p>
</h2>
<div class='content'><p>Para reducir el número de particiones sin un shuffle completo, usamos <code>coalesce</code>.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNjLnRleHRGaWxlKCJwYXRoL3RvL2ZpbGUiKS5jb2FsZXNjZSg1KQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = sc.textFile(&quot;path/to/file&quot;).coalesce(5)</pre></div><div class='content'></div><h1><p>Configuración de Parámetros</p>
</h1>
<div class='content'></div><h2><p>Parámetros de Configuración</p>
</h2>
<div class='content'><p>Algunos parámetros clave para la optimización incluyen:</p>
<ul>
<li><code>spark.executor.memory</code>: Cantidad de memoria asignada a cada ejecutor.</li>
<li><code>spark.executor.cores</code>: Número de núcleos asignados a cada ejecutor.</li>
<li><code>spark.sql.shuffle.partitions</code>: Número de particiones para operaciones de shuffle.</li>
</ul>
</div><h2><p>Ejemplo de Configuración</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIGNvbmYgPSBuZXcgU3BhcmtDb25mKCkKICAuc2V0QXBwTmFtZSgiT3B0aW1pemVkQXBwIikKICAuc2V0KCJzcGFyay5leGVjdXRvci5tZW1vcnkiLCAiNGciKQogIC5zZXQoInNwYXJrLmV4ZWN1dG9yLmNvcmVzIiwgIjIiKQogIC5zZXQoInNwYXJrLnNxbC5zaHVmZmxlLnBhcnRpdGlvbnMiLCAiNTAiKQoKdmFsIHNjID0gbmV3IFNwYXJrQ29udGV4dChjb25mKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val conf = new SparkConf()
  .setAppName(&quot;OptimizedApp&quot;)
  .set(&quot;spark.executor.memory&quot;, &quot;4g&quot;)
  .set(&quot;spark.executor.cores&quot;, &quot;2&quot;)
  .set(&quot;spark.sql.shuffle.partitions&quot;, &quot;50&quot;)

val sc = new SparkContext(conf)</pre></div><div class='content'></div><h1><p>Ejercicios Prácticos</p>
</h1>
<div class='content'></div><h2><p>Ejercicio 1: Optimización de Transformaciones</p>
</h2>
<div class='content'><p>Dado el siguiente código, optimízalo para mejorar el rendimiento:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNjLnBhcmFsbGVsaXplKFNlcSgoMSwgMiksICgzLCA0KSwgKDMsIDYpKSkKdmFsIHJlc3VsdCA9IHJkZC5ncm91cEJ5S2V5KCkubWFwVmFsdWVzKF8uc3VtKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = sc.parallelize(Seq((1, 2), (3, 4), (3, 6)))
val result = rdd.groupByKey().mapValues(_.sum)</pre></div><div class='content'><p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJlc3VsdCA9IHJkZC5yZWR1Y2VCeUtleShfICsgXyk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val result = rdd.reduceByKey(_ + _)</pre></div><div class='content'></div><h2><p>Ejercicio 2: Uso de Caché</p>
</h2>
<div class='content'><p>Carga un archivo de texto y realiza varias operaciones sobre él. Usa caché para optimizar el rendimiento.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNjLnRleHRGaWxlKCJwYXRoL3RvL2ZpbGUiKQp2YWwgd29yZHMgPSByZGQuZmxhdE1hcChfLnNwbGl0KCIgIikpCnZhbCB3b3JkQ291bnRzID0gd29yZHMubWFwKHdvcmQgPT4gKHdvcmQsIDEpKS5yZWR1Y2VCeUtleShfICsgXykKd29yZENvdW50cy5jb2xsZWN0KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = sc.textFile(&quot;path/to/file&quot;)
val words = rdd.flatMap(_.split(&quot; &quot;))
val wordCounts = words.map(word =&gt; (word, 1)).reduceByKey(_ + _)
wordCounts.collect()</pre></div><div class='content'><p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIHJkZCA9IHNjLnRleHRGaWxlKCJwYXRoL3RvL2ZpbGUiKS5jYWNoZSgpCnZhbCB3b3JkcyA9IHJkZC5mbGF0TWFwKF8uc3BsaXQoIiAiKSkKdmFsIHdvcmRDb3VudHMgPSB3b3Jkcy5tYXAod29yZCA9PiAod29yZCwgMSkpLnJlZHVjZUJ5S2V5KF8gKyBfKQp3b3JkQ291bnRzLmNvbGxlY3QoKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val rdd = sc.textFile(&quot;path/to/file&quot;).cache()
val words = rdd.flatMap(_.split(&quot; &quot;))
val wordCounts = words.map(word =&gt; (word, 1)).reduceByKey(_ + _)
wordCounts.collect()</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En este módulo, hemos aprendido diversas técnicas para optimizar aplicaciones Spark, incluyendo la comprensión del plan de ejecución, la optimización de transformaciones, el uso eficiente de la memoria, el particionamiento de datos y la configuración de parámetros. Estas estrategias son esenciales para mejorar el rendimiento y la eficiencia de nuestras aplicaciones Spark. En el próximo módulo, exploraremos cómo ejecutar Spark en diferentes entornos de nube.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-03-memory-management' title="Gestión de Memoria">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-01-running-spark-aws' title="Ejecutando Spark en AWS">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
