<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Arquitectura de Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/spark-architecture" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/spark-architecture" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/spark-architecture" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/apachespark/spark-architecture" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/spark-architecture" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='installing-and-setting-up-spark'>&#x25C4;Instalación y Configuración de Spark</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Arquitectura de Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='rdds'>RDDs (Conjuntos de Datos Distribuidos Resilientes) &#x25BA;</a>
			</div>
</div>
<div class='content'><p>Apache Spark es un potente motor de procesamiento de código abierto diseñado para el procesamiento y análisis de datos a gran escala. Comprender su arquitectura es crucial para utilizar eficazmente sus capacidades. Este tema cubrirá los componentes y conceptos centrales de la arquitectura de Spark, desde los aspectos básicos hasta los más avanzados.</p>
</div><h1>Componentes Clave de la Arquitectura de Spark</h1>
<div class='content'></div><h2>Programa Driver</h2>
<div class='content'><ul>
<li><strong>Definición</strong>: El programa driver es el proceso de control principal que coordina la ejecución de tareas en el clúster de Spark.</li>
<li><strong>Responsabilidades</strong>:
<ul>
<li>Convierte el código del usuario en un gráfico acíclico dirigido (DAG) de etapas.</li>
<li>Programa tareas en el clúster.</li>
<li>Recoge y muestra los resultados.</li>
</ul>
</li>
</ul>
</div><h2>Gestor de Clúster</h2>
<div class='content'><ul>
<li><strong>Definición</strong>: El gestor de clúster es responsable de gestionar los recursos en todo el clúster.</li>
<li><strong>Tipos</strong>:
<ul>
<li><strong>Standalone</strong>: El gestor de clúster incorporado de Spark.</li>
<li><strong>Apache Mesos</strong>: Un gestor de clúster general que puede gestionar recursos para múltiples frameworks.</li>
<li><strong>Hadoop YARN</strong>: El gestor de recursos para clústeres Hadoop.</li>
<li><strong>Kubernetes</strong>: Un sistema de orquestación de contenedores que también puede gestionar recursos de Spark.</li>
</ul>
</li>
</ul>
</div><h2>Ejecutores</h2>
<div class='content'><ul>
<li><strong>Definición</strong>: Los ejecutores son agentes distribuidos responsables de ejecutar tareas y almacenar datos.</li>
<li><strong>Responsabilidades</strong>:
<ul>
<li>Ejecutar el código asignado por el driver.</li>
<li>Almacenar datos en memoria o en almacenamiento en disco.</li>
<li>Informar el estado y los resultados al driver.</li>
</ul>
</li>
</ul>
</div><h2>Tareas</h2>
<div class='content'><ul>
<li><strong>Definición</strong>: Las tareas son las unidades de trabajo más pequeñas en Spark, representando una sola operación en una partición de datos.</li>
<li><strong>Ejecución</strong>: Las tareas son ejecutadas por los ejecutores.</li>
</ul>
</div><h1>Modelo de Ejecución de Spark</h1>
<div class='content'></div><h2>Trabajos y Etapas</h2>
<div class='content'><ul>
<li><strong>Trabajo</strong>: Un trabajo es desencadenado por una acción (por ejemplo, <code>count()</code>, <code>collect()</code>) y consta de múltiples etapas.</li>
<li><strong>Etapa</strong>: Una etapa es un conjunto de tareas que pueden ejecutarse en paralelo, divididas por límites de shuffle.</li>
</ul>
</div><h2>Gráfico Acíclico Dirigido (DAG)</h2>
<div class='content'><ul>
<li><strong>Definición</strong>: Un DAG es una representación de la secuencia de cálculos realizados sobre los datos.</li>
<li><strong>Importancia</strong>: Ayuda a optimizar el plan de ejecución dividiéndolo en etapas.</li>
</ul>
</div><h2>Ejemplo: Conteo de Palabras Simple</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKCiMgSW5pY2lhbGl6YXIgU3BhcmtDb250ZXh0CnNjID0gU3BhcmtDb250ZXh0KCJsb2NhbCIsICJXb3JkQ291bnQiKQoKIyBMZWVyIGFyY2hpdm8gZGUgZW50cmFkYQp0ZXh0X2ZpbGUgPSBzYy50ZXh0RmlsZSgiaGRmczovL3BhdGgvdG8vaW5wdXQudHh0IikKCiMgUmVhbGl6YXIgY29udGVvIGRlIHBhbGFicmFzCmNvdW50cyA9IHRleHRfZmlsZS5mbGF0TWFwKGxhbWJkYSBsaW5lOiBsaW5lLnNwbGl0KCIgIikpIFwKICAgICAgICAgICAgICAgICAgLm1hcChsYW1iZGEgd29yZDogKHdvcmQsIDEpKSBcCiAgICAgICAgICAgICAgICAgIC5yZWR1Y2VCeUtleShsYW1iZGEgYSwgYjogYSArIGIpCgojIEd1YXJkYXIgZWwgcmVzdWx0YWRvCmNvdW50cy5zYXZlQXNUZXh0RmlsZSgiaGRmczovL3BhdGgvdG8vb3V0cHV0Iik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext

# Inicializar SparkContext
sc = SparkContext(&quot;local&quot;, &quot;WordCount&quot;)

# Leer archivo de entrada
text_file = sc.textFile(&quot;hdfs://path/to/input.txt&quot;)

# Realizar conteo de palabras
counts = text_file.flatMap(lambda line: line.split(&quot; &quot;)) \
                  .map(lambda word: (word, 1)) \
                  .reduceByKey(lambda a, b: a + b)

# Guardar el resultado
counts.saveAsTextFile(&quot;hdfs://path/to/output&quot;)</pre></div><div class='content'><ul>
<li><strong>Explicación</strong>:
<ul>
<li><strong>flatMap</strong>: Divide cada línea en palabras.</li>
<li><strong>map</strong>: Mapea cada palabra a un par (palabra, 1).</li>
<li><strong>reduceByKey</strong>: Agrega los conteos para cada palabra.</li>
<li><strong>saveAsTextFile</strong>: Guarda el resultado en HDFS.</li>
</ul>
</li>
</ul>
</div><h1>Conceptos Avanzados</h1>
<div class='content'></div><h2>Conjuntos de Datos Distribuidos Resilientes (RDDs)</h2>
<div class='content'><ul>
<li><strong>Definición</strong>: Los RDDs son la estructura de datos fundamental de Spark, representando una colección distribuida inmutable de objetos.</li>
<li><strong>Propiedades</strong>:
<ul>
<li><strong>Inmutabilidad</strong>: Una vez creados, los RDDs no pueden ser cambiados.</li>
<li><strong>Tolerancia a Fallos</strong>: Los RDDs pueden ser recomputados en caso de fallos de nodos.</li>
<li><strong>Evaluación Perezosa</strong>: Las transformaciones en RDDs no se ejecutan hasta que se llama a una acción.</li>
</ul>
</li>
</ul>
</div><h2>DataFrames y Datasets</h2>
<div class='content'><ul>
<li><strong>DataFrame</strong>: Una colección distribuida de datos organizada en columnas con nombre, similar a una tabla en una base de datos relacional.</li>
<li><strong>Dataset</strong>: Una colección fuertemente tipada de objetos, proporcionando los beneficios de los RDDs con las optimizaciones de los DataFrames.</li>
</ul>
</div><h2>Spark SQL</h2>
<div class='content'><ul>
<li><strong>Definición</strong>: Spark SQL es un módulo para el procesamiento de datos estructurados, permitiendo la consulta de datos mediante SQL así como la API de DataFrame.</li>
<li><strong>Ejemplo</strong>:</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIEluaWNpYWxpemFyIFNwYXJrU2Vzc2lvbgpzcGFyayA9IFNwYXJrU2Vzc2lvbi5idWlsZGVyLmFwcE5hbWUoIlNwYXJrU1FMRXhhbXBsZSIpLmdldE9yQ3JlYXRlKCkKCiMgQ2FyZ2FyIGRhdG9zIGVuIERhdGFGcmFtZQpkZiA9IHNwYXJrLnJlYWQuanNvbigiaGRmczovL3BhdGgvdG8vaW5wdXQuanNvbiIpCgojIFJlZ2lzdHJhciBEYXRhRnJhbWUgY29tbyB1bmEgdmlzdGEgdGVtcG9yYWwgZGUgU1FMCmRmLmNyZWF0ZU9yUmVwbGFjZVRlbXBWaWV3KCJwZW9wbGUiKQoKIyBFamVjdXRhciBjb25zdWx0YSBTUUwKc3FsREYgPSBzcGFyay5zcWwoIlNFTEVDVCBuYW1lIEZST00gcGVvcGxlIFdIRVJFIGFnZSA+IDIxIikKCiMgTW9zdHJhciBlbCByZXN1bHRhZG8Kc3FsREYuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Inicializar SparkSession
spark = SparkSession.builder.appName(&quot;SparkSQLExample&quot;).getOrCreate()

# Cargar datos en DataFrame
df = spark.read.json(&quot;hdfs://path/to/input.json&quot;)

# Registrar DataFrame como una vista temporal de SQL
df.createOrReplaceTempView(&quot;people&quot;)

# Ejecutar consulta SQL
sqlDF = spark.sql(&quot;SELECT name FROM people WHERE age &gt; 21&quot;)

# Mostrar el resultado
sqlDF.show()</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>Comprender la arquitectura de Spark es esencial para aprovechar todo su potencial en el procesamiento de grandes datos. El programa driver, el gestor de clúster, los ejecutores y las tareas forman los componentes centrales, mientras que el modelo de ejecución DAG asegura una programación y ejecución eficiente de tareas. Conceptos avanzados como RDDs, DataFrames y Spark SQL proporcionan abstracciones poderosas para manejar tareas complejas de procesamiento de datos. Al dominar estos componentes y conceptos, puedes construir aplicaciones de procesamiento de datos robustas y escalables con Apache Spark.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='installing-and-setting-up-spark'>&#x25C4;Instalación y Configuración de Spark</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Arquitectura de Spark</a>
	</div>
	<div class='col-4 text-end'>
					<a href='rdds'>RDDs (Conjuntos de Datos Distribuidos Resilientes) &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
