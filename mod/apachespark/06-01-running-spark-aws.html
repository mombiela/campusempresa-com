<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Ejecutando Spark en AWS</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/06-01-running-spark-aws" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/06-01-running-spark-aws" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/06-01-running-spark-aws" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>var DEVELOP = window.location.href.indexOf("localhost")!=-1 && true;</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/mod/apachespark/06-01-running-spark-aws" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/apachespark/06-01-running-spark-aws" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>
		<!-- <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Contenido del curso
	</a>

			</div>
		</div>
	</div>
</div>
 -->
 
<div class="top-bar container-fluid">
	<div class="container-xxl">
		<nav class="navbar navbar-expand-md p-0">
			<div class="container-fluid">
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				
				<div class="collapse navbar-collapse" id="navbarNav">
					<div class="navbar-nav me-auto">
							<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Contenido del curso
	</a>

					</div>
				</div>			
							</div>
		</nav>
	</div>
</div>				<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-04-optimizing-spark-applications' title="Optimizando Aplicaciones Spark">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<h2 style="text-decoration:underline">Ejecutando Spark en AWS</h2>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-02-running-spark-azure' title="Ejecutando Spark en Azure">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>En este módulo, aprenderás cómo ejecutar Apache Spark en Amazon Web Services (AWS). AWS proporciona una infraestructura escalable y flexible que es ideal para ejecutar aplicaciones de Spark. Utilizaremos Amazon EMR (Elastic MapReduce), un servicio administrado que facilita la ejecución de marcos de procesamiento de big data como Apache Spark.</p>
</div><h1>Contenido</h1>
<div class='content'><ol>
<li><strong>Introducción a Amazon EMR</strong></li>
<li><strong>Configuración del Entorno AWS</strong></li>
<li><strong>Creación de un Cluster EMR</strong></li>
<li><strong>Ejecutando Aplicaciones Spark en EMR</strong></li>
<li><strong>Monitoreo y Gestión del Cluster</strong></li>
<li><strong>Ejercicio Práctico</strong></li>
</ol>
</div><h1><ol>
<li>Introducción a Amazon EMR</li>
</ol></h1>
<div class='content'><p>Amazon EMR es un servicio administrado que facilita el procesamiento de grandes cantidades de datos utilizando herramientas de big data como Apache Spark, Hadoop, y otros. EMR simplifica la configuración, administración y escalado de clústeres de procesamiento de datos.</p>
</div><h2>Ventajas de usar Amazon EMR:</h2>
<div class='content'><ul>
<li><strong>Escalabilidad:</strong> Puedes escalar tu clúster hacia arriba o hacia abajo según sea necesario.</li>
<li><strong>Costo-efectividad:</strong> Paga solo por los recursos que utilizas.</li>
<li><strong>Integración:</strong> Se integra fácilmente con otros servicios de AWS como S3, RDS, DynamoDB, etc.</li>
<li><strong>Administración Simplificada:</strong> AWS se encarga de la administración del clúster, incluyendo la configuración y el mantenimiento.</li>
</ul>
</div><h1><ol start="2">
<li>Configuración del Entorno AWS</li>
</ol></h1>
<div class='content'><p>Antes de crear un clúster EMR, necesitas configurar tu entorno AWS.</p>
</div><h2>Pasos:</h2>
<div class='content'><ol>
<li>
<p><strong>Crear una Cuenta de AWS:</strong></p>
<ul>
<li>Si no tienes una cuenta de AWS, regístrate en <a href="https://aws.amazon.com/">AWS</a>.</li>
</ul>
</li>
<li>
<p><strong>Configurar IAM Roles:</strong></p>
<ul>
<li>Crea roles de IAM (Identity and Access Management) que permitan a EMR acceder a otros servicios de AWS.</li>
<li>Navega a la consola de IAM y crea un nuevo rol con permisos de EMR.</li>
</ul>
</li>
<li>
<p><strong>Configurar AWS CLI:</strong></p>
<ul>
<li>Instala y configura la AWS CLI (Command Line Interface) en tu máquina local.</li>
</ul>
<pre><code class="language-bash">pip install awscli
aws configure
</code></pre>
<ul>
<li>Proporciona tus credenciales de AWS, región y formato de salida preferido.</li>
</ul>
</li>
</ol>
</div><h1><ol start="3">
<li>Creación de un Cluster EMR</li>
</ol></h1>
<div class='content'></div><h2>Pasos:</h2>
<div class='content'><ol>
<li>
<p><strong>Navegar a la Consola de EMR:</strong></p>
<ul>
<li>En la consola de AWS, busca y selecciona &quot;EMR&quot;.</li>
</ul>
</li>
<li>
<p><strong>Crear un Nuevo Cluster:</strong></p>
<ul>
<li>Haz clic en &quot;Create cluster&quot;.</li>
<li>Configura los detalles del clúster:
<ul>
<li><strong>Nombre del Cluster:</strong> Asigna un nombre a tu clúster.</li>
<li><strong>Versión de la Aplicación:</strong> Selecciona la versión de Spark que deseas utilizar.</li>
<li><strong>Instancias:</strong> Configura el tipo y número de instancias (máquinas) que deseas en tu clúster.</li>
<li><strong>Configuración de Red:</strong> Selecciona la VPC y subred donde se ejecutará el clúster.</li>
<li><strong>Permisos:</strong> Asigna los roles de IAM que creaste anteriormente.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Lanzar el Cluster:</strong></p>
<ul>
<li>Revisa la configuración y haz clic en &quot;Create cluster&quot;.</li>
</ul>
</li>
</ol>
</div><h1><ol start="4">
<li>Ejecutando Aplicaciones Spark en EMR</li>
</ol></h1>
<div class='content'><p>Una vez que tu clúster está en funcionamiento, puedes ejecutar aplicaciones Spark en él.</p>
</div><h2>Subir Datos a S3:</h2>
<div class='content'><ul>
<li>Sube tus datos a un bucket de S3 para que Spark pueda acceder a ellos.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("YXdzIHMzIGNwIGxvY2FsLWRhdGEtZmlsZSBzMzovL3lvdXItYnVja2V0LW5hbWUv"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>aws s3 cp local-data-file s3://your-bucket-name/</pre></div><div class='content'></div><h2>Enviar un Trabajo Spark:</h2>
<div class='content'><ul>
<li>Utiliza la consola de EMR o la AWS CLI para enviar trabajos Spark.</li>
</ul>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("YXdzIGVtciBhZGQtc3RlcHMgLS1jbHVzdGVyLWlkIGotWFhYWFhYWFggLS1zdGVwcyBUeXBlPVNwYXJrLE5hbWU9IlNwYXJrIEFwcGxpY2F0aW9uIixBY3Rpb25PbkZhaWx1cmU9Q09OVElOVUUsQXJncz1bLS1kZXBsb3ktbW9kZSxjbHVzdGVyLC0tY2xhc3Msb3JnLmFwYWNoZS5zcGFyay5leGFtcGxlcy5TcGFya1BpLHMzOi8veW91ci1idWNrZXQtbmFtZS95b3VyLXNwYXJrLWFwcGxpY2F0aW9uLmphciwxMF0="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>aws emr add-steps --cluster-id j-XXXXXXXX --steps Type=Spark,Name=&quot;Spark Application&quot;,ActionOnFailure=CONTINUE,Args=[--deploy-mode,cluster,--class,org.apache.spark.examples.SparkPi,s3://your-bucket-name/your-spark-application.jar,10]</pre></div><div class='content'></div><h1><ol start="5">
<li>Monitoreo y Gestión del Cluster</li>
</ol></h1>
<div class='content'></div><h2>Monitoreo:</h2>
<div class='content'><ul>
<li>Utiliza la consola de EMR para monitorear el estado de tu clúster y los trabajos Spark.</li>
<li>AWS CloudWatch proporciona métricas y logs detallados.</li>
</ul>
</div><h2>Gestión:</h2>
<div class='content'><ul>
<li>Puedes escalar tu clúster agregando o eliminando instancias según sea necesario.</li>
<li>Detén o termina el clúster cuando ya no lo necesites para evitar costos adicionales.</li>
</ul>
</div><h1><ol start="6">
<li>Ejercicio Práctico</li>
</ol></h1>
<div class='content'></div><h2>Ejercicio:</h2>
<div class='content'><ol>
<li>
<p><strong>Crear un Clúster EMR:</strong></p>
<ul>
<li>Sigue los pasos anteriores para crear un clúster EMR.</li>
</ul>
</li>
<li>
<p><strong>Subir Datos a S3:</strong></p>
<ul>
<li>Sube un archivo de datos a un bucket de S3.</li>
</ul>
</li>
<li>
<p><strong>Ejecutar una Aplicación Spark:</strong></p>
<ul>
<li>Escribe una aplicación Spark simple que lea datos de S3, realice una transformación y guarde los resultados de nuevo en S3.</li>
<li>Envía el trabajo Spark a tu clúster EMR.</li>
</ul>
</li>
</ol>
</div><h2>Solución:</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIENyZWFyIHVuYSBzZXNpw7NuIGRlIFNwYXJrCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiQVdTIEVNUiBFeGFtcGxlIikuZ2V0T3JDcmVhdGUoKQoKIyBMZWVyIGRhdG9zIGRlIFMzCmRmID0gc3BhcmsucmVhZC5jc3YoInMzOi8veW91ci1idWNrZXQtbmFtZS9pbnB1dC1kYXRhLmNzdiIsIGhlYWRlcj1UcnVlLCBpbmZlclNjaGVtYT1UcnVlKQoKIyBSZWFsaXphciB1bmEgdHJhbnNmb3JtYWNpw7NuCmRmX3RyYW5zZm9ybWVkID0gZGYuZ3JvdXBCeSgiY29sdW1uX25hbWUiKS5jb3VudCgpCgojIEd1YXJkYXIgbG9zIHJlc3VsdGFkb3MgZW4gUzMKZGZfdHJhbnNmb3JtZWQud3JpdGUuY3N2KCJzMzovL3lvdXItYnVja2V0LW5hbWUvb3V0cHV0LWRhdGEuY3N2IikKCiMgRGV0ZW5lciBsYSBzZXNpw7NuIGRlIFNwYXJrCnNwYXJrLnN0b3AoKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Crear una sesi&oacute;n de Spark
spark = SparkSession.builder.appName(&quot;AWS EMR Example&quot;).getOrCreate()

# Leer datos de S3
df = spark.read.csv(&quot;s3://your-bucket-name/input-data.csv&quot;, header=True, inferSchema=True)

# Realizar una transformaci&oacute;n
df_transformed = df.groupBy(&quot;column_name&quot;).count()

# Guardar los resultados en S3
df_transformed.write.csv(&quot;s3://your-bucket-name/output-data.csv&quot;)

# Detener la sesi&oacute;n de Spark
spark.stop()</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En este módulo, aprendiste cómo configurar y ejecutar Apache Spark en AWS utilizando Amazon EMR. Ahora deberías ser capaz de crear un clúster EMR, subir datos a S3, ejecutar aplicaciones Spark y monitorear tu clúster. En el próximo módulo, exploraremos cómo ejecutar Spark en Azure.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-04-optimizing-spark-applications' title="Optimizando Aplicaciones Spark">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-02-running-spark-azure' title="Ejecutando Spark en Azure">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
	     crossorigin="anonymous"></script>
	<!-- enterprise_campus -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-0611338592562725"
	     data-ad-slot="6914733106"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
	     (adsbygoogle = window.adsbygoogle || []).push({});
	</script>
			
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de Apache Spark</h1>
<h2>Módulo 1: Introducción a Apache Spark</h2>
<ul>
<li><a href="01-01-what-is-apache-spark">¿Qué es Apache Spark?</a></li>
<li><a href="01-02-setting-up-spark-environment">Configuración del Entorno Spark</a></li>
<li><a href="01-03-spark-architecture">Arquitectura de Spark</a></li>
<li><a href="01-04-spark-shell">Shell de Spark</a></li>
</ul>
<h2>Módulo 2: Conceptos Básicos de Spark</h2>
<ul>
<li><a href="02-01-rdds">RDDs (Conjuntos de Datos Distribuidos Resilientes)</a></li>
<li><a href="02-02-transformations-actions">Transformaciones y Acciones</a></li>
<li><a href="02-03-spark-dataframes">DataFrames de Spark</a></li>
<li><a href="02-04-spark-sql">Spark SQL</a></li>
</ul>
<h2>Módulo 3: Procesamiento de Datos con Spark</h2>
<ul>
<li><a href="03-01-loading-saving-data">Cargar y Guardar Datos</a></li>
<li><a href="03-02-dataframe-operations">Operaciones con DataFrames</a></li>
<li><a href="03-03-working-with-datasets">Trabajando con Datasets</a></li>
<li><a href="03-04-handling-missing-data">Manejo de Datos Faltantes</a></li>
</ul>
<h2>Módulo 4: Programación Avanzada en Spark</h2>
<ul>
<li><a href="04-01-spark-streaming">Spark Streaming</a></li>
<li><a href="04-02-structured-streaming">Streaming Estructurado</a></li>
<li><a href="04-03-spark-mllib">Spark MLlib</a></li>
<li><a href="04-04-graphx">GraphX</a></li>
</ul>
<h2>Módulo 5: Ajuste y Optimización del Rendimiento</h2>
<ul>
<li><a href="05-01-understanding-spark-jobs">Entendiendo los Trabajos de Spark</a></li>
<li><a href="05-02-caching-persistence">Caché y Persistencia</a></li>
<li><a href="05-03-memory-management">Gestión de Memoria</a></li>
<li><a href="05-04-optimizing-spark-applications">Optimizando Aplicaciones Spark</a></li>
</ul>
<h2>Módulo 6: Spark en la Nube</h2>
<ul>
<li><a href="06-01-running-spark-aws">Ejecutando Spark en AWS</a></li>
<li><a href="06-02-running-spark-azure">Ejecutando Spark en Azure</a></li>
<li><a href="06-03-running-spark-google-cloud">Ejecutando Spark en Google Cloud</a></li>
<li><a href="06-04-spark-kubernetes">Spark con Kubernetes</a></li>
</ul>
<h2>Módulo 7: Aplicaciones del Mundo Real y Estudios de Caso</h2>
<ul>
<li><a href="07-01-real-time-data-processing">Procesamiento de Datos en Tiempo Real</a></li>
<li><a href="07-02-big-data-analytics">Analítica de Big Data</a></li>
<li><a href="07-03-machine-learning-pipelines">Pipelines de Aprendizaje Automático</a></li>
<li><a href="07-04-case-studies">Estudios de Caso</a></li>
</ul>
<h2>Módulo 8: Proyecto Final</h2>
<ul>
<li><a href="08-01-project-overview">Descripción del Proyecto</a></li>
<li><a href="08-02-project-setup">Configuración del Proyecto</a></li>
<li><a href="08-03-implementation">Implementación</a></li>
<li><a href="08-04-presentation-review">Presentación y Revisión</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
</body>
</html>
