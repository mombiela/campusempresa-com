<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spark SQL Avanzado</title>

    <link rel="alternate" href="https://campusempresa.com/mod/apachespark/advanced-spark-sql" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/apachespark/advanced-spark-sql" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/apachespark/advanced-spark-sql" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body  class="test" >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/apachespark/advanced-spark-sql" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/apachespark/advanced-spark-sql" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
									<div class="assert">
						<p><b>Atención!</b> Ha habido un error en la generación del curso y puede contener errores de traducción.Estamos trabajando para solucinarlo por lo que se deben usar los contenidos con cuidado.Se puede consultar el contenido correcto en otro idioma en el siguiente enlace:<br>
						<a href="https://enterprisecampus.net/mod/apachespark/advanced-spark-sql">https://enterprisecampus.net/mod/apachespark/advanced-spark-sql</a></p>
					</div>
								<div class='row navigation'>
	<div class='col-4'>
					<a href='custom-data-sources'>&#x25C4;Fuentes de Datos Personalizadas</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Spark SQL Avanzado</a>
	</div>
	<div class='col-4 text-end'>
					<a href='advanced-streaming-techniques'>Técnicas Avanzadas de Streaming &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción a Spark SQL Avanzado</h1>
<div class='content'><p>En esta sección, profundizaremos en Spark SQL, explorando características avanzadas y optimizaciones que pueden ayudarte a escribir consultas más eficientes y poderosas. Cubriremos temas como funciones de ventana, UDFs (Funciones Definidas por el Usuario) y ajuste de rendimiento.</p>
</div><h1>Funciones de Ventana</h1>
<div class='content'><p>Las funciones de ventana son una característica poderosa en Spark SQL que te permiten realizar cálculos a través de un conjunto de filas de la tabla que están de alguna manera relacionadas con la fila actual.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>Particionamiento</strong>: Divide el conjunto de datos en particiones.</li>
<li><strong>Ordenación</strong>: Define el orden de las filas dentro de cada partición.</li>
<li><strong>Especificación de Marco</strong>: Define el subconjunto de filas a considerar para cada fila.</li>
</ul>
</div><h2>Ejemplo</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLmV4cHJlc3Npb25zLldpbmRvdwppbXBvcnQgb3JnLmFwYWNoZS5zcGFyay5zcWwuZnVuY3Rpb25zLl8KCnZhbCBkZiA9IFNlcSgKICAoMSwgIkEiLCAxMDApLAogICgyLCAiQiIsIDIwMCksCiAgKDMsICJBIiwgMzAwKSwKICAoNCwgIkIiLCA0MDApLAogICg1LCAiQSIsIDUwMCkKKS50b0RGKCJpZCIsICJjYXRlZ29yeSIsICJ2YWx1ZSIpCgp2YWwgd2luZG93U3BlYyA9IFdpbmRvdy5wYXJ0aXRpb25CeSgiY2F0ZWdvcnkiKS5vcmRlckJ5KCJpZCIpCgp2YWwgcmVzdWx0ID0gZGYud2l0aENvbHVtbigicmFuayIsIHJhbmsoKS5vdmVyKHdpbmRvd1NwZWMpKQpyZXN1bHQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.functions._

val df = Seq(
  (1, &quot;A&quot;, 100),
  (2, &quot;B&quot;, 200),
  (3, &quot;A&quot;, 300),
  (4, &quot;B&quot;, 400),
  (5, &quot;A&quot;, 500)
).toDF(&quot;id&quot;, &quot;category&quot;, &quot;value&quot;)

val windowSpec = Window.partitionBy(&quot;category&quot;).orderBy(&quot;id&quot;)

val result = df.withColumn(&quot;rank&quot;, rank().over(windowSpec))
result.show()</pre></div><div class='content'><p>Explicación:</p>
<ul>
<li>Creamos un DataFrame <code>df</code> con las columnas <code>id</code>, <code>category</code> y <code>value</code>.</li>
<li>Definimos una especificación de ventana <code>windowSpec</code> que particiona los datos por <code>category</code> y los ordena por <code>id</code>.</li>
<li>Añadimos una nueva columna <code>rank</code> que calcula el rango de cada fila dentro de su partición.</li>
</ul>
</div><h1>Funciones Definidas por el Usuario (UDFs)</h1>
<div class='content'><p>Las UDFs te permiten definir funciones personalizadas para usar en tus consultas de Spark SQL.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>Definir UDFs</strong>: Crear una función y registrarla como una UDF.</li>
<li><strong>Usar UDFs</strong>: Aplicar la UDF en operaciones de DataFrame.</li>
</ul>
</div><h2>Ejemplo</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLmZ1bmN0aW9ucy51ZGYKCnZhbCB0b1VwcGVyQ2FzZSA9IHVkZigoczogU3RyaW5nKSA9PiBzLnRvVXBwZXJDYXNlKQoKdmFsIGRmID0gU2VxKAogICgxLCAiaGVsbG8iKSwKICAoMiwgIndvcmxkIikKKS50b0RGKCJpZCIsICJ0ZXh0IikKCnZhbCByZXN1bHQgPSBkZi53aXRoQ29sdW1uKCJ1cHBlcl90ZXh0IiwgdG9VcHBlckNhc2UoY29sKCJ0ZXh0IikpKQpyZXN1bHQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.functions.udf

val toUpperCase = udf((s: String) =&gt; s.toUpperCase)

val df = Seq(
  (1, &quot;hello&quot;),
  (2, &quot;world&quot;)
).toDF(&quot;id&quot;, &quot;text&quot;)

val result = df.withColumn(&quot;upper_text&quot;, toUpperCase(col(&quot;text&quot;)))
result.show()</pre></div><div class='content'><p>Explicación:</p>
<ul>
<li>Definimos una UDF <code>toUpperCase</code> que convierte una cadena a mayúsculas.</li>
<li>Creamos un DataFrame <code>df</code> con las columnas <code>id</code> y <code>text</code>.</li>
<li>Añadimos una nueva columna <code>upper_text</code> que aplica la UDF <code>toUpperCase</code> a la columna <code>text</code>.</li>
</ul>
</div><h1>Ajuste de Rendimiento</h1>
<div class='content'><p>Optimizar las consultas de Spark SQL puede mejorar significativamente el rendimiento. Las técnicas clave incluyen usar la API de DataFrame en lugar de RDDs, caché y particionamiento adecuado.</p>
</div><h2>Conceptos Clave</h2>
<div class='content'><ul>
<li><strong>API de DataFrame</strong>: Preferir la API de DataFrame sobre RDDs para una mejor optimización.</li>
<li><strong>Caché</strong>: Cachear resultados intermedios para evitar recomputación.</li>
<li><strong>Particionamiento</strong>: Particionar adecuadamente los datos para balancear la carga entre los nodos.</li>
</ul>
</div><h2>Ejemplo</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIGRmID0gc3BhcmsucmVhZC5wYXJxdWV0KCJoZGZzOi8vcGF0aC90by9kYXRhIikKCi8vIENhY2hlYXIgZWwgRGF0YUZyYW1lCmRmLmNhY2hlKCkKCi8vIFJlYWxpemFyIG9wZXJhY2lvbmVzIGVuIGVsIERhdGFGcmFtZSBjYWNoZWFkbwp2YWwgcmVzdWx0ID0gZGYuZ3JvdXBCeSgiY2F0ZWdvcnkiKS5hZ2coc3VtKCJ2YWx1ZSIpLmFzKCJ0b3RhbF92YWx1ZSIpKQpyZXN1bHQuc2hvdygp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val df = spark.read.parquet(&quot;hdfs://path/to/data&quot;)

// Cachear el DataFrame
df.cache()

// Realizar operaciones en el DataFrame cacheado
val result = df.groupBy(&quot;category&quot;).agg(sum(&quot;value&quot;).as(&quot;total_value&quot;))
result.show()</pre></div><div class='content'><p>Explicación:</p>
<ul>
<li>Leemos un DataFrame <code>df</code> desde un archivo Parquet.</li>
<li>Cacheamos el DataFrame para evitar la recomputación de resultados intermedios.</li>
<li>Realizamos una operación de groupBy en el DataFrame cacheado y calculamos la suma de <code>value</code> para cada <code>category</code>.</li>
</ul>
</div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, exploramos características avanzadas de Spark SQL, incluyendo funciones de ventana, UDFs y técnicas de ajuste de rendimiento. Estas herramientas y técnicas pueden ayudarte a escribir consultas de Spark SQL más eficientes y poderosas, permitiéndote manejar tareas complejas de procesamiento de datos con facilidad. Al dominar estas características avanzadas, puedes mejorar significativamente el rendimiento y la escalabilidad de tus aplicaciones Spark.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='custom-data-sources'>&#x25C4;Fuentes de Datos Personalizadas</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Spark SQL Avanzado</a>
	</div>
	<div class='col-4 text-end'>
					<a href='advanced-streaming-techniques'>Técnicas Avanzadas de Streaming &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
