<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Redes Neuronales Recurrentes (RNN)</title>

    <link rel="alternate" href="https://campusempresa.com/mod/fundamentos_ia/redes-neuronales-recurrentes" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/fundamentos_ia/redes-neuronales-recurrentes" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/fundamentos_ia/redes-neuronales-recurrentes" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body>
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/fundamentos_ia/redes-neuronales-recurrentes" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/fundamentos_ia/redes-neuronales-recurrentes" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content"><div class='row navigation'>
	<div class='col-4'>
					<a href='redes-neuronales-convolucionales'>&#x25C4;Redes Neuronales Convolucionales (CNN)</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Redes Neuronales Recurrentes (RNN)</a>
	</div>
	<div class='col-4 text-end'>
					<a href='logica-difusa'>Lógica Difusa &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción a las Redes Neuronales Recurrentes (RNN)</h1>
<div class='content'><p>Las Redes Neuronales Recurrentes (RNN) son un tipo de red neuronal diseñada para reconocer patrones en secuencias de datos, como texto, series temporales y datos de audio. A diferencia de las redes neuronales tradicionales, las RNN tienen conexiones recurrentes que permiten que la información persista.</p>
<ul>
<li><strong>Secuencias de datos</strong>: Las RNN son especialmente útiles para datos secuenciales donde el orden de los datos es importante.</li>
<li><strong>Memoria</strong>: Las RNN tienen una &quot;memoria&quot; que les permite recordar información sobre los datos anteriores en la secuencia.</li>
<li><strong>Aplicaciones</strong>: Procesamiento de lenguaje natural (NLP), traducción automática, reconocimiento de voz, análisis de series temporales.</li>
</ul>
</div><h1>Arquitectura de una RNN</h1>
<div class='content'><p>Una RNN típica consiste en una capa de entrada, una o más capas recurrentes y una capa de salida.</p>
<ul>
<li><strong>Capa de entrada</strong>: Recibe la secuencia de datos.</li>
<li><strong>Capa recurrente</strong>: Procesa la secuencia de datos, manteniendo una memoria de los estados anteriores.</li>
<li><strong>Capa de salida</strong>: Produce la salida final después de procesar toda la secuencia.</li>
</ul>
</div><h2>Estructura de una RNN</h2>
<div class='content'><p>La estructura básica de una RNN puede representarse como:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("eF90IC0+IGhfdCAtPiB5X3Q="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>x_t -&gt; h_t -&gt; y_t</pre></div><div class='content'><p>Donde:</p>
<ul>
<li><code>x_t</code> es la entrada en el tiempo <code>t</code>.</li>
<li><code>h_t</code> es el estado oculto en el tiempo <code>t</code>.</li>
<li><code>y_t</code> es la salida en el tiempo <code>t</code>.</li>
</ul>
<p>La relación entre estos elementos se puede expresar mediante las siguientes ecuaciones:</p>
<ul>
<li><code>h_t = f(W_hh * h_{t-1} + W_xh * x_t + b_h)</code></li>
<li><code>y_t = g(W_hy * h_t + b_y)</code></li>
</ul>
<p>Aquí, <code>W_hh</code>, <code>W_xh</code>, y <code>W_hy</code> son matrices de pesos, <code>b_h</code> y <code>b_y</code> son sesgos, y <code>f</code> y <code>g</code> son funciones de activación.</p>
</div><h1>Ejemplo de Código: Implementación Básica de una RNN en Python</h1>
<div class='content'><p>A continuación se muestra un ejemplo básico de una RNN utilizando la biblioteca <code>TensorFlow</code> en Python.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBTaW1wbGVSTk4sIERlbnNlCgojIERlZmluaXIgbGEgc2VjdWVuY2lhIGRlIGRhdG9zIGRlIGVudHJhZGEKaW5wdXRfZGF0YSA9IHRmLnJhbmRvbS5ub3JtYWwoWzMyLCAxMCwgOF0pICAjIChiYXRjaF9zaXplLCB0aW1lc3RlcHMsIGlucHV0X2RpbSkKCiMgQ3JlYXIgZWwgbW9kZWxvIFJOTgptb2RlbCA9IFNlcXVlbnRpYWwoKQptb2RlbC5hZGQoU2ltcGxlUk5OKDE2LCBpbnB1dF9zaGFwZT0oMTAsIDgpKSkgICMgMTYgdW5pZGFkZXMgZW4gbGEgY2FwYSBSTk4KbW9kZWwuYWRkKERlbnNlKDEpKSAgIyBDYXBhIGRlIHNhbGlkYQoKIyBDb21waWxhciBlbCBtb2RlbG8KbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdtc2UnKQoKIyBSZXN1bWVuIGRlbCBtb2RlbG8KbW9kZWwuc3VtbWFyeSgp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense

# Definir la secuencia de datos de entrada
input_data = tf.random.normal([32, 10, 8])  # (batch_size, timesteps, input_dim)

# Crear el modelo RNN
model = Sequential()
model.add(SimpleRNN(16, input_shape=(10, 8)))  # 16 unidades en la capa RNN
model.add(Dense(1))  # Capa de salida

# Compilar el modelo
model.compile(optimizer='adam', loss='mse')

# Resumen del modelo
model.summary()</pre></div><div class='content'><p>En este ejemplo:</p>
<ul>
<li><code>input_data</code> es un tensor de datos de entrada con un tamaño de lote de 32, 10 pasos de tiempo y 8 características por paso de tiempo.</li>
<li><code>SimpleRNN</code> es una capa recurrente con 16 unidades.</li>
<li><code>Dense</code> es una capa densa que produce una salida de un solo valor.</li>
</ul>
</div><h1>Ventajas y Desventajas de las RNN</h1>
<h2>Ventajas</h2>
<div class='content'><ul>
<li><strong>Capacidad de manejar secuencias de longitud variable</strong>: Las RNN pueden procesar secuencias de diferentes longitudes.</li>
<li><strong>Memoria de corto plazo</strong>: Las RNN pueden recordar información de los pasos de tiempo anteriores.</li>
</ul>
</div><h2>Desventajas</h2>
<div class='content'><ul>
<li><strong>Problemas de gradiente</strong>: Las RNN pueden sufrir de problemas de desvanecimiento y explosión del gradiente, lo que dificulta el entrenamiento.</li>
<li><strong>Memoria de largo plazo limitada</strong>: Las RNN estándar tienen dificultades para recordar información de pasos de tiempo muy anteriores.</li>
</ul>
</div><h1>Conclusión</h1>
<div class='content'><p>Las Redes Neuronales Recurrentes (RNN) son una herramienta poderosa para el procesamiento de datos secuenciales. Aunque tienen algunas limitaciones, como problemas de gradiente y memoria de largo plazo limitada, son fundamentales en aplicaciones como el procesamiento de lenguaje natural y el análisis de series temporales. Con el avance de técnicas como LSTM y GRU, muchas de estas limitaciones se han mitigado, permitiendo a las RNN manejar secuencias más largas y complejas de manera más efectiva.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='redes-neuronales-convolucionales'>&#x25C4;Redes Neuronales Convolucionales (CNN)</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Redes Neuronales Recurrentes (RNN)</a>
	</div>
	<div class='col-4 text-end'>
					<a href='logica-difusa'>Lógica Difusa &#x25BA;</a>
			</div>
</div>
</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
