<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spark y Computación en Memoria</title>

    <link rel="alternate" href="https://campusempresa.com/mod/arquitecturas_distribuidas/05-02-spark-computacion" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/arquitecturas_distribuidas/05-02-spark-computacio" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/arquitecturas_distribuidas/05-02-spark-computing" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/arquitecturas_distribuidas/05-02-spark-computing" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/arquitecturas_distribuidas/05-02-spark-computacio" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-01-mapreduce-hadoop' title="MapReduce y Hadoop">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Spark y Computación en Memoria</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='05-03-procesamiento-flujos' title="Procesamiento de Flujos de Datos">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción</h1>
<div class='content'><p>Apache Spark es un motor de procesamiento de datos en clústeres que se ha diseñado para ser rápido y general. A diferencia de Hadoop MapReduce, que escribe datos intermedios en disco, Spark realiza la mayor parte de sus operaciones en memoria, lo que lo hace mucho más rápido para ciertas cargas de trabajo.</p>
</div><h2>Objetivos del Módulo</h2>
<div class='content'><ul>
<li>Comprender los conceptos básicos de Apache Spark.</li>
<li>Aprender sobre la arquitectura de Spark.</li>
<li>Explorar las ventajas de la computación en memoria.</li>
<li>Implementar ejemplos prácticos utilizando Spark.</li>
<li>Realizar ejercicios para reforzar los conceptos aprendidos.</li>
</ul>
</div><h1>Conceptos Básicos de Apache Spark</h1>
<div class='content'></div><h2>¿Qué es Apache Spark?</h2>
<div class='content'><p>Apache Spark es un framework de código abierto para el procesamiento de datos a gran escala. Fue desarrollado en el AMPLab de la Universidad de California, Berkeley, y está diseñado para ser rápido y fácil de usar.</p>
</div><h2>Características Principales</h2>
<div class='content'><ul>
<li><strong>Velocidad</strong>: Spark realiza el procesamiento de datos en memoria, lo que lo hace mucho más rápido que Hadoop MapReduce.</li>
<li><strong>Facilidad de Uso</strong>: Spark proporciona APIs en Java, Scala, Python y R, lo que facilita su uso para desarrolladores de diferentes lenguajes.</li>
<li><strong>Generalidad</strong>: Spark puede manejar una variedad de cargas de trabajo, incluyendo procesamiento por lotes, consultas interactivas, análisis en tiempo real y aprendizaje automático.</li>
<li><strong>Compatibilidad con Hadoop</strong>: Spark puede ejecutarse en Hadoop YARN, lo que permite aprovechar las capacidades de almacenamiento y gestión de recursos de Hadoop.</li>
</ul>
</div><h1>Arquitectura de Spark</h1>
<div class='content'></div><h2>Componentes Principales</h2>
<div class='content'><ol>
<li><strong>Driver Program</strong>: El programa principal que define las transformaciones y acciones en los datos.</li>
<li><strong>Cluster Manager</strong>: Responsable de gestionar los recursos del clúster (por ejemplo, YARN, Mesos, o el gestor de clústeres independiente de Spark).</li>
<li><strong>Workers</strong>: Los nodos del clúster que ejecutan las tareas.</li>
<li><strong>Executors</strong>: Procesos que ejecutan las tareas y almacenan los datos en memoria.</li>
<li><strong>Tasks</strong>: Unidades de trabajo que se ejecutan en los ejecutores.</li>
</ol>
</div><h2>Diagrama de Arquitectura</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Ky0tLS0tLS0tLS0tLS0tLS0tKyAgICAgICArLS0tLS0tLS0tLS0tLS0tLS0rCnwgIERyaXZlciBQcm9ncmFtIHwgICAgICAgfCBDbHVzdGVyIE1hbmFnZXIgfAorLS0tLS0tLS0rLS0tLS0tLS0rICAgICAgICstLS0tLS0tLSstLS0tLS0tLSsKICAgICAgICAgfCAgICAgICAgICAgICAgICAgICAgICAgICB8CiAgICAgICAgIHwgICAgICAgICAgICAgICAgICAgICAgICAgfAorLS0tLS0tLS12LS0tLS0tLS0rICAgICAgICstLS0tLS0tLXYtLS0tLS0tLSsKfCAgICAgV29ya2VyICAgICAgfCAgICAgICB8ICAgICBXb3JrZXIgICAgICB8CnwgKy0tLS0tLS0tLS0tLS0rIHwgICAgICAgfCArLS0tLS0tLS0tLS0tLSsgfAp8IHwgICBFeGVjdXRvciAgfCB8ICAgICAgIHwgfCAgIEV4ZWN1dG9yICB8IHwKfCArLS0tLS0tLS0tLS0tLSsgfCAgICAgICB8ICstLS0tLS0tLS0tLS0tKyB8CistLS0tLS0tLS0tLS0tLS0tLSsgICAgICAgKy0tLS0tLS0tLS0tLS0tLS0tKw=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>+-----------------+       +-----------------+
|  Driver Program |       | Cluster Manager |
+--------+--------+       +--------+--------+
         |                         |
         |                         |
+--------v--------+       +--------v--------+
|     Worker      |       |     Worker      |
| +-------------+ |       | +-------------+ |
| |   Executor  | |       | |   Executor  | |
| +-------------+ |       | +-------------+ |
+-----------------+       +-----------------+</pre></div><div class='content'></div><h1>Ventajas de la Computación en Memoria</h1>
<div class='content'></div><h2>Velocidad</h2>
<div class='content'><p>Al mantener los datos en memoria, Spark puede realizar operaciones mucho más rápido que los sistemas que escriben datos intermedios en disco.</p>
</div><h2>Iteraciones Rápidas</h2>
<div class='content'><p>Las aplicaciones de aprendizaje automático y análisis de datos a menudo requieren múltiples iteraciones sobre los mismos datos. La computación en memoria permite que estas iteraciones sean mucho más rápidas.</p>
</div><h2>Tolerancia a Fallos</h2>
<div class='content'><p>Spark utiliza un modelo de datos llamado Resilient Distributed Datasets (RDDs) que permite la recuperación automática de datos en caso de fallos.</p>
</div><h1>Ejemplo Práctico: Contar Palabras con Spark</h1>
<div class='content'></div><h2>Configuración del Entorno</h2>
<div class='content'><p>Para ejecutar Spark en tu máquina local, necesitas instalarlo y configurarlo. Puedes seguir las instrucciones en la <a href="https://spark.apache.org/docs/latest/">documentación oficial de Spark</a>.</p>
</div><h2>Código de Ejemplo</h2>
<div class='content'><p>A continuación se muestra un ejemplo en Python para contar palabras en un archivo de texto utilizando Spark:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQsIFNwYXJrQ29uZgoKIyBDb25maWd1cmFjacOzbiBkZSBTcGFyawpjb25mID0gU3BhcmtDb25mKCkuc2V0QXBwTmFtZSgiV29yZENvdW50Iikuc2V0TWFzdGVyKCJsb2NhbCIpCnNjID0gU3BhcmtDb250ZXh0KGNvbmY9Y29uZikKCiMgTGVlciBlbCBhcmNoaXZvIGRlIHRleHRvCnRleHRfZmlsZSA9IHNjLnRleHRGaWxlKCJoZGZzOi8vcGF0aC90by90ZXh0ZmlsZS50eHQiKQoKIyBDb250YXIgbGFzIHBhbGFicmFzCndvcmRfY291bnRzID0gdGV4dF9maWxlLmZsYXRNYXAobGFtYmRhIGxpbmU6IGxpbmUuc3BsaXQoIiAiKSkgXAogICAgICAgICAgICAgICAgICAgICAgIC5tYXAobGFtYmRhIHdvcmQ6ICh3b3JkLCAxKSkgXAogICAgICAgICAgICAgICAgICAgICAgIC5yZWR1Y2VCeUtleShsYW1iZGEgYSwgYjogYSArIGIpCgojIE1vc3RyYXIgbG9zIHJlc3VsdGFkb3MKZm9yIHdvcmQsIGNvdW50IGluIHdvcmRfY291bnRzLmNvbGxlY3QoKToKICAgIHByaW50KGYie3dvcmR9OiB7Y291bnR9IikKCiMgRGV0ZW5lciBlbCBjb250ZXh0byBkZSBTcGFyawpzYy5zdG9wKCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext, SparkConf

# Configuraci&oacute;n de Spark
conf = SparkConf().setAppName(&quot;WordCount&quot;).setMaster(&quot;local&quot;)
sc = SparkContext(conf=conf)

# Leer el archivo de texto
text_file = sc.textFile(&quot;hdfs://path/to/textfile.txt&quot;)

# Contar las palabras
word_counts = text_file.flatMap(lambda line: line.split(&quot; &quot;)) \
                       .map(lambda word: (word, 1)) \
                       .reduceByKey(lambda a, b: a + b)

# Mostrar los resultados
for word, count in word_counts.collect():
    print(f&quot;{word}: {count}&quot;)

# Detener el contexto de Spark
sc.stop()</pre></div><div class='content'></div><h2>Explicación del Código</h2>
<div class='content'><ol>
<li><strong>Configuración de Spark</strong>: Se crea una configuración de Spark y un contexto de Spark.</li>
<li><strong>Leer el archivo de texto</strong>: Se lee un archivo de texto desde HDFS.</li>
<li><strong>Contar las palabras</strong>:
<ul>
<li><code>flatMap</code>: Divide cada línea en palabras.</li>
<li><code>map</code>: Asigna un valor de 1 a cada palabra.</li>
<li><code>reduceByKey</code>: Suma los valores para cada palabra.</li>
</ul>
</li>
<li><strong>Mostrar los resultados</strong>: Se recogen y muestran los resultados.</li>
<li><strong>Detener el contexto de Spark</strong>: Se detiene el contexto de Spark.</li>
</ol>
</div><h1>Ejercicio Práctico</h1>
<div class='content'></div><h2>Ejercicio 1: Contar Palabras en un Archivo Local</h2>
<div class='content'><p>Modifica el código anterior para contar palabras en un archivo local en lugar de un archivo en HDFS.</p>
</div><h2>Solución</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQsIFNwYXJrQ29uZgoKIyBDb25maWd1cmFjacOzbiBkZSBTcGFyawpjb25mID0gU3BhcmtDb25mKCkuc2V0QXBwTmFtZSgiV29yZENvdW50Iikuc2V0TWFzdGVyKCJsb2NhbCIpCnNjID0gU3BhcmtDb250ZXh0KGNvbmY9Y29uZikKCiMgTGVlciBlbCBhcmNoaXZvIGRlIHRleHRvIGxvY2FsCnRleHRfZmlsZSA9IHNjLnRleHRGaWxlKCJmaWxlOi8vL3BhdGgvdG8vbG9jYWwvdGV4dGZpbGUudHh0IikKCiMgQ29udGFyIGxhcyBwYWxhYnJhcwp3b3JkX2NvdW50cyA9IHRleHRfZmlsZS5mbGF0TWFwKGxhbWJkYSBsaW5lOiBsaW5lLnNwbGl0KCIgIikpIFwKICAgICAgICAgICAgICAgICAgICAgICAubWFwKGxhbWJkYSB3b3JkOiAod29yZCwgMSkpIFwKICAgICAgICAgICAgICAgICAgICAgICAucmVkdWNlQnlLZXkobGFtYmRhIGEsIGI6IGEgKyBiKQoKIyBNb3N0cmFyIGxvcyByZXN1bHRhZG9zCmZvciB3b3JkLCBjb3VudCBpbiB3b3JkX2NvdW50cy5jb2xsZWN0KCk6CiAgICBwcmludChmInt3b3JkfToge2NvdW50fSIpCgojIERldGVuZXIgZWwgY29udGV4dG8gZGUgU3BhcmsKc2Muc3RvcCgp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext, SparkConf

# Configuraci&oacute;n de Spark
conf = SparkConf().setAppName(&quot;WordCount&quot;).setMaster(&quot;local&quot;)
sc = SparkContext(conf=conf)

# Leer el archivo de texto local
text_file = sc.textFile(&quot;file:///path/to/local/textfile.txt&quot;)

# Contar las palabras
word_counts = text_file.flatMap(lambda line: line.split(&quot; &quot;)) \
                       .map(lambda word: (word, 1)) \
                       .reduceByKey(lambda a, b: a + b)

# Mostrar los resultados
for word, count in word_counts.collect():
    print(f&quot;{word}: {count}&quot;)

# Detener el contexto de Spark
sc.stop()</pre></div><div class='content'></div><h2>Ejercicio 2: Filtrar Palabras Comunes</h2>
<div class='content'><p>Modifica el código para filtrar palabras comunes como &quot;el&quot;, &quot;la&quot;, &quot;y&quot;, etc., antes de contar las palabras.</p>
</div><h2>Solución</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQsIFNwYXJrQ29uZgoKIyBDb25maWd1cmFjacOzbiBkZSBTcGFyawpjb25mID0gU3BhcmtDb25mKCkuc2V0QXBwTmFtZSgiV29yZENvdW50Iikuc2V0TWFzdGVyKCJsb2NhbCIpCnNjID0gU3BhcmtDb250ZXh0KGNvbmY9Y29uZikKCiMgTGlzdGEgZGUgcGFsYWJyYXMgY29tdW5lcyBhIGZpbHRyYXIKY29tbW9uX3dvcmRzID0geyJlbCIsICJsYSIsICJ5IiwgImRlIiwgImEiLCAiZW4ifQoKIyBMZWVyIGVsIGFyY2hpdm8gZGUgdGV4dG8gbG9jYWwKdGV4dF9maWxlID0gc2MudGV4dEZpbGUoImZpbGU6Ly8vcGF0aC90by9sb2NhbC90ZXh0ZmlsZS50eHQiKQoKIyBDb250YXIgbGFzIHBhbGFicmFzLCBleGNsdXllbmRvIGxhcyBjb211bmVzCndvcmRfY291bnRzID0gdGV4dF9maWxlLmZsYXRNYXAobGFtYmRhIGxpbmU6IGxpbmUuc3BsaXQoIiAiKSkgXAogICAgICAgICAgICAgICAgICAgICAgIC5maWx0ZXIobGFtYmRhIHdvcmQ6IHdvcmQgbm90IGluIGNvbW1vbl93b3JkcykgXAogICAgICAgICAgICAgICAgICAgICAgIC5tYXAobGFtYmRhIHdvcmQ6ICh3b3JkLCAxKSkgXAogICAgICAgICAgICAgICAgICAgICAgIC5yZWR1Y2VCeUtleShsYW1iZGEgYSwgYjogYSArIGIpCgojIE1vc3RyYXIgbG9zIHJlc3VsdGFkb3MKZm9yIHdvcmQsIGNvdW50IGluIHdvcmRfY291bnRzLmNvbGxlY3QoKToKICAgIHByaW50KGYie3dvcmR9OiB7Y291bnR9IikKCiMgRGV0ZW5lciBlbCBjb250ZXh0byBkZSBTcGFyawpzYy5zdG9wKCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext, SparkConf

# Configuraci&oacute;n de Spark
conf = SparkConf().setAppName(&quot;WordCount&quot;).setMaster(&quot;local&quot;)
sc = SparkContext(conf=conf)

# Lista de palabras comunes a filtrar
common_words = {&quot;el&quot;, &quot;la&quot;, &quot;y&quot;, &quot;de&quot;, &quot;a&quot;, &quot;en&quot;}

# Leer el archivo de texto local
text_file = sc.textFile(&quot;file:///path/to/local/textfile.txt&quot;)

# Contar las palabras, excluyendo las comunes
word_counts = text_file.flatMap(lambda line: line.split(&quot; &quot;)) \
                       .filter(lambda word: word not in common_words) \
                       .map(lambda word: (word, 1)) \
                       .reduceByKey(lambda a, b: a + b)

# Mostrar los resultados
for word, count in word_counts.collect():
    print(f&quot;{word}: {count}&quot;)

# Detener el contexto de Spark
sc.stop()</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En este módulo, hemos explorado Apache Spark y sus ventajas en la computación en memoria. Hemos aprendido sobre la arquitectura de Spark y cómo se diferencia de otros sistemas de procesamiento de datos. Además, hemos implementado ejemplos prácticos para contar palabras en un archivo de texto utilizando Spark.</p>
</div><h2>Resumen</h2>
<div class='content'><ul>
<li><strong>Apache Spark</strong>: Un motor de procesamiento de datos en clústeres rápido y general.</li>
<li><strong>Computación en Memoria</strong>: Permite operaciones mucho más rápidas y eficientes.</li>
<li><strong>Arquitectura de Spark</strong>: Incluye componentes como el Driver Program, Cluster Manager, Workers, Executors y Tasks.</li>
<li><strong>Ejemplos Prácticos</strong>: Contar palabras en archivos de texto utilizando Spark.</li>
</ul>
</div><h2>Próximos Pasos</h2>
<div class='content'><p>En el siguiente módulo, exploraremos el procesamiento de flujos de datos utilizando herramientas como Apache Kafka y Spark Streaming.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-01-mapreduce-hadoop' title="MapReduce y Hadoop">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='05-03-procesamiento-flujos' title="Procesamiento de Flujos de Datos">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
