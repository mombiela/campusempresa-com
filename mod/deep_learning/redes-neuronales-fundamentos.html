<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Redes Neuronales: Fundamentos</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/redes-neuronales-fundamentos" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/redes-neuronales-fundamentos" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/redes-neuronales-fundamentos" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/deep_learning/redes-neuronales-fundamentos" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/deep_learning/redes-neuronales-fundamentos" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-4'>
					<a href='historia-evolucion-deep-learning'>&#x25C4;Historia y Evolución del Deep Learning</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Redes Neuronales: Fundamentos</a>
	</div>
	<div class='col-4 text-end'>
					<a href='aplicaciones-deep-learning'>Aplicaciones del Deep Learning &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción a las Redes Neuronales</h1>
<div class='content'><p>Las redes neuronales son un componente esencial del Deep Learning, inspiradas en la estructura y funcionamiento del cerebro humano. Estas redes están compuestas por unidades básicas llamadas neuronas, que se organizan en capas y se conectan entre sí para procesar y aprender de los datos.</p>
</div><h1>Estructura de una Red Neuronal</h1>
<div class='content'><p>Una red neuronal típica consta de las siguientes capas:</p>
<ul>
<li><strong>Capa de Entrada</strong>: Recibe los datos de entrada.</li>
<li><strong>Capas Ocultas</strong>: Procesan la información recibida de la capa de entrada mediante neuronas interconectadas.</li>
<li><strong>Capa de Salida</strong>: Produce el resultado final de la red.</li>
</ul>
</div><h2>Neurona Artificial</h2>
<div class='content'><p>Cada neurona en una red neuronal realiza una operación matemática simple. La estructura básica de una neurona incluye:</p>
<ul>
<li><strong>Pesos (Weights)</strong>: Coeficientes que ponderan la importancia de cada entrada.</li>
<li><strong>Función de Activación</strong>: Introduce no linealidad en la salida de la neurona.</li>
<li><strong>Bias</strong>: Un término adicional que ayuda a ajustar la salida junto con los pesos.</li>
</ul>
</div><h2>Ejemplo de una Neurona</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIERlZmluaWNpw7NuIGRlIGxhIGZ1bmNpw7NuIGRlIGFjdGl2YWNpw7NuIChzaWdtb2lkZSkKZGVmIHNpZ21vaWQoeCk6CiAgICByZXR1cm4gMSAvICgxICsgbnAuZXhwKC14KSkKCiMgRW50cmFkYXMgeSBwZXNvcwppbnB1dHMgPSBucC5hcnJheShbMC41LCAwLjNdKQp3ZWlnaHRzID0gbnAuYXJyYXkoWzAuNCwgMC43XSkKYmlhcyA9IDAuMQoKIyBDw6FsY3VsbyBkZSBsYSBzYWxpZGEgZGUgbGEgbmV1cm9uYQpvdXRwdXQgPSBzaWdtb2lkKG5wLmRvdChpbnB1dHMsIHdlaWdodHMpICsgYmlhcykKcHJpbnQob3V0cHV0KQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Definici&oacute;n de la funci&oacute;n de activaci&oacute;n (sigmoide)
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Entradas y pesos
inputs = np.array([0.5, 0.3])
weights = np.array([0.4, 0.7])
bias = 0.1

# C&aacute;lculo de la salida de la neurona
output = sigmoid(np.dot(inputs, weights) + bias)
print(output)</pre></div><div class='content'></div><h1>Funciones de Activación</h1>
<div class='content'><p>Las funciones de activación son cruciales para introducir no linealidad en la red, permitiendo que la red aprenda y modele datos complejos. Algunas funciones de activación comunes incluyen:</p>
<ul>
<li><strong>Sigmoide</strong>: <code>σ(x) = 1 / (1 + e^(-x))</code></li>
<li><strong>ReLU (Rectified Linear Unit)</strong>: <code>f(x) = max(0, x)</code></li>
<li><strong>Tanh (Tangente hiperbólica)</strong>: <code>tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))</code></li>
</ul>
</div><h2>Comparación de Funciones de Activación</h2>
<div class='content'><p>| Función de Activación | Fórmula                  | Rango de Salida  | Propiedades                              |
|-----------------------|--------------------------|------------------|------------------------------------------|
| Sigmoide              | \( \sigma(x) = \frac{1}{1 + e^{-x}} \) | (0, 1)           | Suave, derivable, pero puede saturarse.  |
| ReLU                  | \( f(x) = \max(0, x) \)  | [0, ∞)           | Simple, eficiente, pero puede causar &quot;neurona muerta&quot;. |
| Tanh                  | \( \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \) | (-1, 1)         | Suave, derivable, centrada en cero.      |</p>
</div><h1>Proceso de Entrenamiento</h1>
<div class='content'><p>El entrenamiento de una red neuronal implica ajustar los pesos y biases para minimizar el error en las predicciones. Este proceso se realiza mediante:</p>
<ul>
<li><strong>Propagación hacia adelante (Forward Propagation)</strong>: Calcula la salida de la red.</li>
<li><strong>Función de Costo (Cost Function)</strong>: Mide la diferencia entre la salida predicha y la salida real.</li>
<li><strong>Propagación hacia atrás (Backpropagation)</strong>: Ajusta los pesos y biases para reducir el error.</li>
</ul>
</div><h2>Ejemplo de Entrenamiento Simple</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIERhdG9zIGRlIGVudHJhZGEgeSBzYWxpZGEgZXNwZXJhZGEKaW5wdXRzID0gbnAuYXJyYXkoWzAuNSwgMC4zXSkKZXhwZWN0ZWRfb3V0cHV0ID0gMC43CgojIEluaWNpYWxpemFjacOzbiBkZSBwZXNvcyB5IGJpYXMKd2VpZ2h0cyA9IG5wLmFycmF5KFswLjQsIDAuN10pCmJpYXMgPSAwLjEKbGVhcm5pbmdfcmF0ZSA9IDAuMDEKCiMgRGVmaW5pY2nDs24gZGUgbGEgZnVuY2nDs24gZGUgYWN0aXZhY2nDs24geSBzdSBkZXJpdmFkYQpkZWYgc2lnbW9pZCh4KToKICAgIHJldHVybiAxIC8gKDEgKyBucC5leHAoLXgpKQoKZGVmIHNpZ21vaWRfZGVyaXZhdGl2ZSh4KToKICAgIHJldHVybiB4ICogKDEgLSB4KQoKIyBQcm9jZXNvIGRlIGVudHJlbmFtaWVudG8KZm9yIGVwb2NoIGluIHJhbmdlKDEwMDAwKToKICAgICMgUHJvcGFnYWNpw7NuIGhhY2lhIGFkZWxhbnRlCiAgICB3ZWlnaHRlZF9zdW0gPSBucC5kb3QoaW5wdXRzLCB3ZWlnaHRzKSArIGJpYXMKICAgIG91dHB1dCA9IHNpZ21vaWQod2VpZ2h0ZWRfc3VtKQogICAgCiAgICAjIEPDoWxjdWxvIGRlbCBlcnJvcgogICAgZXJyb3IgPSBleHBlY3RlZF9vdXRwdXQgLSBvdXRwdXQKICAgIAogICAgIyBQcm9wYWdhY2nDs24gaGFjaWEgYXRyw6FzCiAgICBhZGp1c3RtZW50cyA9IGVycm9yICogc2lnbW9pZF9kZXJpdmF0aXZlKG91dHB1dCkKICAgIHdlaWdodHMgKz0gbGVhcm5pbmdfcmF0ZSAqIGFkanVzdG1lbnRzICogaW5wdXRzCiAgICBiaWFzICs9IGxlYXJuaW5nX3JhdGUgKiBhZGp1c3RtZW50cwoKcHJpbnQoIlBlc29zIGFqdXN0YWRvczoiLCB3ZWlnaHRzKQpwcmludCgiQmlhcyBhanVzdGFkbzoiLCBiaWFzKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Datos de entrada y salida esperada
inputs = np.array([0.5, 0.3])
expected_output = 0.7

# Inicializaci&oacute;n de pesos y bias
weights = np.array([0.4, 0.7])
bias = 0.1
learning_rate = 0.01

# Definici&oacute;n de la funci&oacute;n de activaci&oacute;n y su derivada
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

# Proceso de entrenamiento
for epoch in range(10000):
    # Propagaci&oacute;n hacia adelante
    weighted_sum = np.dot(inputs, weights) + bias
    output = sigmoid(weighted_sum)
    
    # C&aacute;lculo del error
    error = expected_output - output
    
    # Propagaci&oacute;n hacia atr&aacute;s
    adjustments = error * sigmoid_derivative(output)
    weights += learning_rate * adjustments * inputs
    bias += learning_rate * adjustments

print(&quot;Pesos ajustados:&quot;, weights)
print(&quot;Bias ajustado:&quot;, bias)</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>Las redes neuronales son una herramienta poderosa en el campo del Deep Learning, capaces de aprender y generalizar a partir de datos complejos. Comprender los fundamentos de su estructura, funciones de activación y proceso de entrenamiento es crucial para desarrollar modelos efectivos. En los siguientes temas, profundizaremos en arquitecturas más avanzadas y técnicas de optimización para mejorar el rendimiento de las redes neuronales.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='historia-evolucion-deep-learning'>&#x25C4;Historia y Evolución del Deep Learning</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Redes Neuronales: Fundamentos</a>
	</div>
	<div class='col-4 text-end'>
					<a href='aplicaciones-deep-learning'>Aplicaciones del Deep Learning &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
