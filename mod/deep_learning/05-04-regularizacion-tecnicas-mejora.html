<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Regularización y Técnicas de Mejora</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/05-04-regularizacion-tecnicas-mejora" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/05-04-regularizacion-tecnicas-mejora" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/05-04-regularization-improvement-techniques" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/deep_learning/05-04-regularization-improvement-techniques" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/deep_learning/05-04-regularizacion-tecnicas-mejora" class="px-2">CA</a>
								</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<!-- <a href="/">Home</a>  -->
									<a href="./">Contenido del curso</a>
					<span class="sep">|</span>
								<a href="/all/competencias">Competencias técnicas</a>
				<a href="/all/conocimientos">Conocimientos</a>
				<a href="/all/soft_skills">Competencias sociales</a>
			</div>
		</div>
	</div>
</div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-03-transfer-learning' title="Transfer Learning">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Regularización y Técnicas de Mejora</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-01-introduccion-tensorflow' title="Introducción a TensorFlow">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>En este tema, exploraremos las técnicas de regularización y otras estrategias para mejorar el rendimiento de los modelos de Deep Learning. La regularización es crucial para prevenir el sobreajuste y mejorar la capacidad de generalización de los modelos.</p>
</div><h1><p>Objetivos del Tema</p>
</h1>
<div class='content'><ul>
<li>Comprender qué es la regularización y por qué es importante.</li>
<li>Conocer las técnicas más comunes de regularización.</li>
<li>Aprender otras técnicas de mejora del rendimiento de los modelos.</li>
</ul>
</div><h1><p>¿Qué es la Regularización?</p>
</h1>
<div class='content'><p>La regularización es un conjunto de técnicas utilizadas para reducir el error de generalización de un modelo, es decir, su capacidad para desempeñarse bien en datos no vistos. Esto se logra penalizando la complejidad del modelo para evitar el sobreajuste.</p>
</div><h2><p>Sobreajuste vs Subajuste</p>
</h2>
<div class='content'><ul>
<li><strong>Sobreajuste (Overfitting):</strong> Ocurre cuando un modelo se ajusta demasiado bien a los datos de entrenamiento, capturando ruido y patrones irrelevantes. Esto resulta en un mal desempeño en datos nuevos.</li>
<li><strong>Subajuste (Underfitting):</strong> Ocurre cuando un modelo es demasiado simple para capturar los patrones subyacentes en los datos, resultando en un mal desempeño tanto en los datos de entrenamiento como en los de prueba.</li>
</ul>
</div><h1><p>Técnicas Comunes de Regularización</p>
</h1>
<div class='content'></div><h2><ol>
<li>Regularización L1 y L2</li>
</ol>
</h2>
<div class='content'><h4>Regularización L1 (Lasso)</h4>
<p>La regularización L1 agrega una penalización proporcional a la suma de los valores absolutos de los coeficientes del modelo.</p>
<p><strong>Fórmula:</strong></p>
<p>\[ \text{Loss} = \text{Loss original} + \lambda \sum_{i} |w_i| \]</p>
<h4>Regularización L2 (Ridge)</h4>
<p>La regularización L2 agrega una penalización proporcional a la suma de los cuadrados de los coeficientes del modelo.</p>
<p><strong>Fórmula:</strong></p>
<p>\[ \text{Loss} = \text{Loss original} + \lambda \sum_{i} w_i^2 \]</p>
<h4>Ejemplo en Python</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBEZW5zZQoKIyBDcmVhciB1biBtb2RlbG8gc2VjdWVuY2lhbAptb2RlbCA9IFNlcXVlbnRpYWwoWwogICAgRGVuc2UoNjQsIGFjdGl2YXRpb249J3JlbHUnLCBrZXJuZWxfcmVndWxhcml6ZXI9dGYua2VyYXMucmVndWxhcml6ZXJzLmwyKDAuMDEpLCBpbnB1dF9zaGFwZT0oaW5wdXRfZGltLCkpLAogICAgRGVuc2UoNjQsIGFjdGl2YXRpb249J3JlbHUnLCBrZXJuZWxfcmVndWxhcml6ZXI9dGYua2VyYXMucmVndWxhcml6ZXJzLmwyKDAuMDEpKSwKICAgIERlbnNlKDEsIGFjdGl2YXRpb249J3NpZ21vaWQnKQpdKQoKIyBDb21waWxhciBlbCBtb2RlbG8KbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdiaW5hcnlfY3Jvc3NlbnRyb3B5JywgbWV0cmljcz1bJ2FjY3VyYWN5J10p"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Crear un modelo secuencial
model = Sequential([
    Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(input_dim,)),
    Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    Dense(1, activation='sigmoid')
])

# Compilar el modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])</pre></div><div class='content'></div><h2><ol start="2">
<li>Dropout</li>
</ol>
</h2>
<div class='content'><p>Dropout es una técnica en la que se &quot;apagan&quot; aleatoriamente algunas neuronas durante el entrenamiento para evitar que el modelo dependa demasiado de ciertas neuronas.</p>
<p><strong>Ejemplo en Python:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgRHJvcG91dAoKbW9kZWwgPSBTZXF1ZW50aWFsKFsKICAgIERlbnNlKDY0LCBhY3RpdmF0aW9uPSdyZWx1JywgaW5wdXRfc2hhcGU9KGlucHV0X2RpbSwpKSwKICAgIERyb3BvdXQoMC41KSwKICAgIERlbnNlKDY0LCBhY3RpdmF0aW9uPSdyZWx1JyksCiAgICBEcm9wb3V0KDAuNSksCiAgICBEZW5zZSgxLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykKXSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Dropout

model = Sequential([
    Dense(64, activation='relu', input_shape=(input_dim,)),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])</pre></div><div class='content'></div><h2><ol start="3">
<li>Early Stopping</li>
</ol>
</h2>
<div class='content'><p>Early Stopping detiene el entrenamiento cuando el rendimiento en un conjunto de validación deja de mejorar, evitando así el sobreajuste.</p>
<p><strong>Ejemplo en Python:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmNhbGxiYWNrcyBpbXBvcnQgRWFybHlTdG9wcGluZwoKZWFybHlfc3RvcHBpbmcgPSBFYXJseVN0b3BwaW5nKG1vbml0b3I9J3ZhbF9sb3NzJywgcGF0aWVuY2U9NSkKCm1vZGVsLmZpdChYX3RyYWluLCB5X3RyYWluLCBlcG9jaHM9MTAwLCB2YWxpZGF0aW9uX3NwbGl0PTAuMiwgY2FsbGJhY2tzPVtlYXJseV9zdG9wcGluZ10p"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=5)

model.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping])</pre></div><div class='content'></div><h2><ol start="4">
<li>Data Augmentation</li>
</ol>
</h2>
<div class='content'><p>Data Augmentation genera nuevas muestras de datos a partir de las existentes mediante transformaciones como rotaciones, traslaciones y escalados. Esto ayuda a aumentar la diversidad del conjunto de datos y reduce el sobreajuste.</p>
<p><strong>Ejemplo en Python:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLnByZXByb2Nlc3NpbmcuaW1hZ2UgaW1wb3J0IEltYWdlRGF0YUdlbmVyYXRvcgoKZGF0YWdlbiA9IEltYWdlRGF0YUdlbmVyYXRvcigKICAgIHJvdGF0aW9uX3JhbmdlPTIwLAogICAgd2lkdGhfc2hpZnRfcmFuZ2U9MC4yLAogICAgaGVpZ2h0X3NoaWZ0X3JhbmdlPTAuMiwKICAgIHNoZWFyX3JhbmdlPTAuMiwKICAgIHpvb21fcmFuZ2U9MC4yLAogICAgaG9yaXpvbnRhbF9mbGlwPVRydWUsCiAgICBmaWxsX21vZGU9J25lYXJlc3QnCikKCmRhdGFnZW4uZml0KFhfdHJhaW4p"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

datagen.fit(X_train)</pre></div><div class='content'></div><h1><p>Otras Técnicas de Mejora</p>
</h1>
<div class='content'></div><h2><ol>
<li>Batch Normalization</li>
</ol>
</h2>
<div class='content'><p>Batch Normalization normaliza las activaciones de una capa para cada mini-lote, acelerando el entrenamiento y mejorando la estabilidad del modelo.</p>
<p><strong>Ejemplo en Python:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgQmF0Y2hOb3JtYWxpemF0aW9uCgptb2RlbCA9IFNlcXVlbnRpYWwoWwogICAgRGVuc2UoNjQsIGFjdGl2YXRpb249J3JlbHUnLCBpbnB1dF9zaGFwZT0oaW5wdXRfZGltLCkpLAogICAgQmF0Y2hOb3JtYWxpemF0aW9uKCksCiAgICBEZW5zZSg2NCwgYWN0aXZhdGlvbj0ncmVsdScpLAogICAgQmF0Y2hOb3JtYWxpemF0aW9uKCksCiAgICBEZW5zZSgxLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykKXSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import BatchNormalization

model = Sequential([
    Dense(64, activation='relu', input_shape=(input_dim,)),
    BatchNormalization(),
    Dense(64, activation='relu'),
    BatchNormalization(),
    Dense(1, activation='sigmoid')
])</pre></div><div class='content'></div><h2><ol start="2">
<li>Transfer Learning</li>
</ol>
</h2>
<div class='content'><p>Transfer Learning utiliza un modelo preentrenado en un gran conjunto de datos y lo adapta a una nueva tarea. Esto es especialmente útil cuando se dispone de pocos datos.</p>
<p><strong>Ejemplo en Python:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmFwcGxpY2F0aW9ucyBpbXBvcnQgVkdHMTYKCmJhc2VfbW9kZWwgPSBWR0cxNih3ZWlnaHRzPSdpbWFnZW5ldCcsIGluY2x1ZGVfdG9wPUZhbHNlLCBpbnB1dF9zaGFwZT0oMjI0LCAyMjQsIDMpKQoKbW9kZWwgPSBTZXF1ZW50aWFsKFsKICAgIGJhc2VfbW9kZWwsCiAgICBGbGF0dGVuKCksCiAgICBEZW5zZSgyNTYsIGFjdGl2YXRpb249J3JlbHUnKSwKICAgIERlbnNlKDEsIGFjdGl2YXRpb249J3NpZ21vaWQnKQpdKQoKYmFzZV9tb2RlbC50cmFpbmFibGUgPSBGYWxzZSAgIyBDb25nZWxhciBsYXMgY2FwYXMgZGVsIG1vZGVsbyBiYXNlCgptb2RlbC5jb21waWxlKG9wdGltaXplcj0nYWRhbScsIGxvc3M9J2JpbmFyeV9jcm9zc2VudHJvcHknLCBtZXRyaWNzPVsnYWNjdXJhY3knXSk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.applications import VGG16

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dense(1, activation='sigmoid')
])

base_model.trainable = False  # Congelar las capas del modelo base

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])</pre></div><div class='content'></div><h1><p>Ejercicio Práctico</p>
</h1>
<div class='content'></div><h2><p>Ejercicio: Implementar Regularización L2 y Dropout</p>
</h2>
<div class='content'><ol>
<li>Crea un modelo de red neuronal con dos capas ocultas.</li>
<li>Aplica regularización L2 a las capas ocultas.</li>
<li>Añade capas de Dropout después de cada capa oculta.</li>
<li>Entrena el modelo en un conjunto de datos de tu elección.</li>
</ol>
<p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBEZW5zZSwgRHJvcG91dApmcm9tIHRlbnNvcmZsb3cua2VyYXMucmVndWxhcml6ZXJzIGltcG9ydCBsMgoKIyBDcmVhciBlbCBtb2RlbG8KbW9kZWwgPSBTZXF1ZW50aWFsKFsKICAgIERlbnNlKDY0LCBhY3RpdmF0aW9uPSdyZWx1Jywga2VybmVsX3JlZ3VsYXJpemVyPWwyKDAuMDEpLCBpbnB1dF9zaGFwZT0oaW5wdXRfZGltLCkpLAogICAgRHJvcG91dCgwLjUpLAogICAgRGVuc2UoNjQsIGFjdGl2YXRpb249J3JlbHUnLCBrZXJuZWxfcmVndWxhcml6ZXI9bDIoMC4wMSkpLAogICAgRHJvcG91dCgwLjUpLAogICAgRGVuc2UoMSwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpCl0pCgojIENvbXBpbGFyIGVsIG1vZGVsbwptb2RlbC5jb21waWxlKG9wdGltaXplcj0nYWRhbScsIGxvc3M9J2JpbmFyeV9jcm9zc2VudHJvcHknLCBtZXRyaWNzPVsnYWNjdXJhY3knXSkKCiMgRW50cmVuYXIgZWwgbW9kZWxvCm1vZGVsLmZpdChYX3RyYWluLCB5X3RyYWluLCBlcG9jaHM9NTAsIHZhbGlkYXRpb25fc3BsaXQ9MC4yKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.regularizers import l2

# Crear el modelo
model = Sequential([
    Dense(64, activation='relu', kernel_regularizer=l2(0.01), input_shape=(input_dim,)),
    Dropout(0.5),
    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Compilar el modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenar el modelo
model.fit(X_train, y_train, epochs=50, validation_split=0.2)</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En esta sección, hemos explorado diversas técnicas de regularización y otras estrategias para mejorar el rendimiento de los modelos de Deep Learning. La regularización es esencial para prevenir el sobreajuste y mejorar la capacidad de generalización de los modelos. Además, técnicas como Batch Normalization y Transfer Learning pueden acelerar el entrenamiento y mejorar la precisión del modelo. Con estas herramientas, estarás mejor preparado para construir modelos robustos y eficientes.</p>
<p>En el próximo módulo, profundizaremos en las herramientas y frameworks más utilizados en Deep Learning, como TensorFlow y PyTorch.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-03-transfer-learning' title="Transfer Learning">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-01-introduccion-tensorflow' title="Introducción a TensorFlow">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
