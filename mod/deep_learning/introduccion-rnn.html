<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introducción a las RNN</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/introduccion-rnn" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/introduccion-rnn" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/introduccion-rnn" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/deep_learning/introduccion-rnn" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/deep_learning/introduccion-rnn" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-4'>
					<a href='aplicaciones-cnn-reconocimiento-imagenes'>&#x25C4;Aplicaciones de CNN en Reconocimiento de Imágenes</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Introducción a las RNN</a>
	</div>
	<div class='col-4 text-end'>
					<a href='lstm-gru'>LSTM y GRU &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>¿Qué es una RNN?</h1>
<div class='content'><p>Las Redes Neuronales Recurrentes (RNN, por sus siglas en inglés) son un tipo de red neuronal diseñada para trabajar con datos secuenciales. A diferencia de las redes neuronales tradicionales, las RNN tienen conexiones que forman ciclos, permitiendo que la información persista.</p>
</div><h2>Características principales de las RNN:</h2>
<div class='content'><ul>
<li><strong>Memoria</strong>: Las RNN pueden recordar información de entradas anteriores gracias a sus conexiones recurrentes.</li>
<li><strong>Secuencialidad</strong>: Son ideales para datos secuenciales como series temporales, texto y audio.</li>
<li><strong>Parámetros compartidos</strong>: Utilizan los mismos parámetros (pesos) en cada paso de la secuencia, lo que reduce la complejidad del modelo.</li>
</ul>
</div><h1>Arquitectura de una RNN</h1>
<div class='content'><p>Una RNN típica consta de una capa de entrada, una o más capas recurrentes y una capa de salida. La capa recurrente es la que permite que la red mantenga una &quot;memoria&quot; de las entradas anteriores.</p>
</div><h2>Componentes de una RNN:</h2>
<div class='content'><ul>
<li><strong>Capa de entrada</strong>: Recibe los datos de entrada secuenciales.</li>
<li><strong>Capa recurrente</strong>: Procesa la secuencia de datos y mantiene la memoria de los estados anteriores.</li>
<li><strong>Capa de salida</strong>: Genera la salida final basada en la información procesada.</li>
</ul>
</div><h1>Funcionamiento de una RNN</h1>
<div class='content'><p>En una RNN, cada neurona en la capa recurrente recibe no solo la entrada actual, sino también la salida de la neurona en el paso de tiempo anterior. Esto se puede representar matemáticamente como:</p>
<p>\[ h_t = \sigma(W_{xh}x_t + W_{hh}h_{t-1} + b_h) \]
\[ y_t = \sigma(W_{hy}h_t + b_y) \]</p>
<p>Donde:</p>
<ul>
<li>\( h_t \) es el estado oculto en el tiempo \( t \).</li>
<li>\( x_t \) es la entrada en el tiempo \( t \).</li>
<li>\( W_{xh} \) y \( W_{hh} \) son matrices de pesos.</li>
<li>\( b_h \) y \( b_y \) son sesgos.</li>
<li>\( \sigma \) es una función de activación, como tanh o ReLU.</li>
</ul>
</div><h1>Ejemplo de código: Implementación de una RNN simple en Python usando TensorFlow</h1>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBTaW1wbGVSTk4sIERlbnNlCgojIERlZmluaXIgZWwgbW9kZWxvCm1vZGVsID0gU2VxdWVudGlhbCgpCm1vZGVsLmFkZChTaW1wbGVSTk4oNTAsIGlucHV0X3NoYXBlPSgxMCwgMSkpKSAgIyA1MCB1bmlkYWRlcyByZWN1cnJlbnRlcywgc2VjdWVuY2lhIGRlIGxvbmdpdHVkIDEwCm1vZGVsLmFkZChEZW5zZSgxKSkgICMgQ2FwYSBkZSBzYWxpZGEKCiMgQ29tcGlsYXIgZWwgbW9kZWxvCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nbXNlJykKCiMgUmVzdW1lbiBkZWwgbW9kZWxvCm1vZGVsLnN1bW1hcnkoKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense

# Definir el modelo
model = Sequential()
model.add(SimpleRNN(50, input_shape=(10, 1)))  # 50 unidades recurrentes, secuencia de longitud 10
model.add(Dense(1))  # Capa de salida

# Compilar el modelo
model.compile(optimizer='adam', loss='mse')

# Resumen del modelo
model.summary()</pre></div><div class='content'></div><h2>Explicación del código:</h2>
<div class='content'><ol>
<li><strong>Importación de librerías</strong>: Se importan las librerías necesarias de TensorFlow y Keras.</li>
<li><strong>Definición del modelo</strong>: Se crea un modelo secuencial y se añade una capa recurrente SimpleRNN con 50 unidades y una capa de salida densa.</li>
<li><strong>Compilación del modelo</strong>: Se compila el modelo usando el optimizador 'adam' y la función de pérdida 'mse' (error cuadrático medio).</li>
<li><strong>Resumen del modelo</strong>: Se imprime un resumen del modelo para verificar su estructura.</li>
</ol>
</div><h1>Aplicaciones de las RNN</h1>
<div class='content'><p>Las RNN son ampliamente utilizadas en diversas aplicaciones debido a su capacidad para manejar datos secuenciales:</p>
<ul>
<li><strong>Procesamiento de lenguaje natural (NLP)</strong>: Traducción automática, generación de texto, análisis de sentimientos.</li>
<li><strong>Reconocimiento de voz</strong>: Conversión de voz a texto, asistentes virtuales.</li>
<li><strong>Series temporales</strong>: Predicción de valores futuros en datos financieros, meteorológicos, etc.</li>
</ul>
</div><h1>Limitaciones de las RNN</h1>
<div class='content'><p>A pesar de sus ventajas, las RNN tienen algunas limitaciones:</p>
<ul>
<li><strong>Desvanecimiento del gradiente</strong>: Las RNN pueden tener dificultades para aprender dependencias a largo plazo debido al problema del desvanecimiento del gradiente.</li>
<li><strong>Capacidad de memoria limitada</strong>: Aunque pueden recordar información de pasos anteriores, su capacidad de memoria es limitada.</li>
</ul>
</div><h1>Conclusión</h1>
<div class='content'><p>Las Redes Neuronales Recurrentes son una herramienta poderosa para trabajar con datos secuenciales. Su capacidad para mantener una memoria de entradas anteriores las hace ideales para tareas como el procesamiento de lenguaje natural y el reconocimiento de voz. Sin embargo, también presentan desafíos como el desvanecimiento del gradiente, que deben ser abordados para mejorar su rendimiento.</p>
<p>En las próximas secciones del curso, exploraremos variantes de las RNN, como las LSTM y GRU, que abordan algunas de estas limitaciones y ofrecen mejoras significativas en el manejo de dependencias a largo plazo.</p>
</div><div class='row navigation'>
	<div class='col-4'>
					<a href='aplicaciones-cnn-reconocimiento-imagenes'>&#x25C4;Aplicaciones de CNN en Reconocimiento de Imágenes</a>
			</div>
	<div class='col-4 text-center'>
		<a href="./" class="title">Introducción a las RNN</a>
	</div>
	<div class='col-4 text-end'>
					<a href='lstm-gru'>LSTM y GRU &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
