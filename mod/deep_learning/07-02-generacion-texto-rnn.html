<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Generación de texto con RNN</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/07-02-generacion-texto-rnn" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/07-02-generacion-texto-rnn" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/07-02-text-generation-rnn" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<a href="https://enterprisecampus.net/mod/deep_learning/07-02-text-generation-rnn" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/deep_learning/07-02-generacion-texto-rnn" class="px-2">CA</a>
<br>
			<cite>Construyendo la sociedad de hoy y del mañana</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Lenguajes de Programación</a>
				 					<a href="/categ/frameworks">Frameworks y Librerías</a>
				 					<a href="/categ/tech-tools">Herramientas Técnicas</a>
				 					<a href="/categ/foundations">Fundamentos Teóricos</a>
				 					<a href="/categ/soft-skills">Habilidades Sociales</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-01-clasificacion-imagenes-cnn' title="Clasificación de imágenes con CNN">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Generación de texto con RNN</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-03-deteccion-anomalias-autoencoders' title="Detección de anomalías con Autoencoders">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>En este tema, aprenderemos cómo utilizar Redes Neuronales Recurrentes (RNN) para la generación de texto. Las RNN son especialmente adecuadas para tareas que involucran datos secuenciales, como el procesamiento del lenguaje natural (PLN). Exploraremos los conceptos clave, implementaremos un modelo básico y realizaremos ejercicios prácticos.</p>
</div><h1><p>Conceptos Clave</p>
</h1>
<div class='content'><ol>
<li>
<p><strong>Redes Neuronales Recurrentes (RNN):</strong></p>
<ul>
<li>Las RNN son un tipo de red neuronal diseñada para manejar datos secuenciales.</li>
<li>A diferencia de las redes neuronales tradicionales, las RNN tienen conexiones recurrentes que permiten que la información persista.</li>
</ul>
</li>
<li>
<p><strong>LSTM y GRU:</strong></p>
<ul>
<li>Las Long Short-Term Memory (LSTM) y las Gated Recurrent Units (GRU) son variantes de las RNN que solucionan el problema del desvanecimiento del gradiente.</li>
<li>Estas unidades permiten que la red &quot;recuerde&quot; información durante períodos más largos.</li>
</ul>
</li>
<li>
<p><strong>Generación de Texto:</strong></p>
<ul>
<li>La generación de texto implica predecir la siguiente palabra o carácter en una secuencia basada en el contexto previo.</li>
<li>Se entrena un modelo en un corpus de texto y luego se utiliza para generar nuevas secuencias de texto.</li>
</ul>
</li>
</ol>
</div><h1><p>Implementación de un Modelo Básico de Generación de Texto</p>
</h1>
<div class='content'></div><h2><p>Paso 1: Preparación de Datos</p>
</h2>
<div class='content'><p>Primero, necesitamos un corpus de texto para entrenar nuestro modelo. Utilizaremos un texto simple para este ejemplo.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCB0ZW5zb3JmbG93IGFzIHRmCmZyb20gdGVuc29yZmxvdy5rZXJhcy5tb2RlbHMgaW1wb3J0IFNlcXVlbnRpYWwKZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgRW1iZWRkaW5nLCBMU1RNLCBEZW5zZQoKIyBDb3JwdXMgZGUgZWplbXBsbwpjb3JwdXMgPSAiaG9sYSBtdW5kbyBob2xhIG11bmRvIGhvbGEgbXVuZG8iCgojIENyZWFyIHVuIGRpY2Npb25hcmlvIGRlIGNhcmFjdGVyZXMKY2hhcnMgPSBzb3J0ZWQobGlzdChzZXQoY29ycHVzKSkpCmNoYXJfdG9faW5kZXggPSB7Y2hhcjogaW5kZXggZm9yIGluZGV4LCBjaGFyIGluIGVudW1lcmF0ZShjaGFycyl9CmluZGV4X3RvX2NoYXIgPSB7aW5kZXg6IGNoYXIgZm9yIGluZGV4LCBjaGFyIGluIGVudW1lcmF0ZShjaGFycyl9CgojIENvbnZlcnRpciBlbCBjb3JwdXMgYSB1bmEgc2VjdWVuY2lhIGRlIMOtbmRpY2VzCnNlcXVlbmNlID0gW2NoYXJfdG9faW5kZXhbY2hhcl0gZm9yIGNoYXIgaW4gY29ycHVzXQoKIyBEZWZpbmlyIGVsIHRhbWHDsW8gZGUgbGEgc2VjdWVuY2lhIGRlIGVudHJhZGEgeSBzYWxpZGEKc2VxX2xlbmd0aCA9IDUKWCA9IFtdCnkgPSBbXQoKZm9yIGkgaW4gcmFuZ2UoMCwgbGVuKHNlcXVlbmNlKSAtIHNlcV9sZW5ndGgpOgogICAgWC5hcHBlbmQoc2VxdWVuY2VbaTppICsgc2VxX2xlbmd0aF0pCiAgICB5LmFwcGVuZChzZXF1ZW5jZVtpICsgc2VxX2xlbmd0aF0pCgojIENvbnZlcnRpciBhIGFycmF5cyBudW1weQpYID0gbnAuYXJyYXkoWCkKeSA9IG5wLmFycmF5KHkp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

# Corpus de ejemplo
corpus = &quot;hola mundo hola mundo hola mundo&quot;

# Crear un diccionario de caracteres
chars = sorted(list(set(corpus)))
char_to_index = {char: index for index, char in enumerate(chars)}
index_to_char = {index: char for index, char in enumerate(chars)}

# Convertir el corpus a una secuencia de &iacute;ndices
sequence = [char_to_index[char] for char in corpus]

# Definir el tama&ntilde;o de la secuencia de entrada y salida
seq_length = 5
X = []
y = []

for i in range(0, len(sequence) - seq_length):
    X.append(sequence[i:i + seq_length])
    y.append(sequence[i + seq_length])

# Convertir a arrays numpy
X = np.array(X)
y = np.array(y)</pre></div><div class='content'></div><h2><p>Paso 2: Construcción del Modelo</p>
</h2>
<div class='content'><p>Construimos una RNN simple utilizando LSTM.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBEZWZpbmlyIGVsIHRhbWHDsW8gZGVsIHZvY2FidWxhcmlvIHkgbGEgZGltZW5zacOzbiBkZSBsb3MgZW1iZWRkaW5ncwp2b2NhYl9zaXplID0gbGVuKGNoYXJzKQplbWJlZGRpbmdfZGltID0gNTAKCiMgQ29uc3RydWlyIGVsIG1vZGVsbwptb2RlbCA9IFNlcXVlbnRpYWwoWwogICAgRW1iZWRkaW5nKHZvY2FiX3NpemUsIGVtYmVkZGluZ19kaW0sIGlucHV0X2xlbmd0aD1zZXFfbGVuZ3RoKSwKICAgIExTVE0oMTAwLCByZXR1cm5fc2VxdWVuY2VzPUZhbHNlKSwKICAgIERlbnNlKHZvY2FiX3NpemUsIGFjdGl2YXRpb249J3NvZnRtYXgnKQpdKQoKbW9kZWwuY29tcGlsZShsb3NzPSdzcGFyc2VfY2F0ZWdvcmljYWxfY3Jvc3NlbnRyb3B5Jywgb3B0aW1pemVyPSdhZGFtJykKbW9kZWwuc3VtbWFyeSgp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Definir el tama&ntilde;o del vocabulario y la dimensi&oacute;n de los embeddings
vocab_size = len(chars)
embedding_dim = 50

# Construir el modelo
model = Sequential([
    Embedding(vocab_size, embedding_dim, input_length=seq_length),
    LSTM(100, return_sequences=False),
    Dense(vocab_size, activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')
model.summary()</pre></div><div class='content'></div><h2><p>Paso 3: Entrenamiento del Modelo</p>
</h2>
<div class='content'><p>Entrenamos el modelo con nuestros datos.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBFbnRyZW5hciBlbCBtb2RlbG8KbW9kZWwuZml0KFgsIHksIGVwb2Nocz0xMDAsIHZlcmJvc2U9Mik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Entrenar el modelo
model.fit(X, y, epochs=100, verbose=2)</pre></div><div class='content'></div><h2><p>Paso 4: Generación de Texto</p>
</h2>
<div class='content'><p>Utilizamos el modelo entrenado para generar texto.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGdlbmVyYXRlX3RleHQobW9kZWwsIHN0YXJ0X3N0cmluZywgbnVtX2dlbmVyYXRlKToKICAgIGlucHV0X2V2YWwgPSBbY2hhcl90b19pbmRleFtjaGFyXSBmb3IgY2hhciBpbiBzdGFydF9zdHJpbmddCiAgICBpbnB1dF9ldmFsID0gbnAuYXJyYXkoaW5wdXRfZXZhbCkucmVzaGFwZSgxLCAtMSkKICAgIAogICAgdGV4dF9nZW5lcmF0ZWQgPSBbXQogICAgCiAgICBtb2RlbC5yZXNldF9zdGF0ZXMoKQogICAgZm9yIGkgaW4gcmFuZ2UobnVtX2dlbmVyYXRlKToKICAgICAgICBwcmVkaWN0aW9ucyA9IG1vZGVsLnByZWRpY3QoaW5wdXRfZXZhbCkKICAgICAgICBwcmVkaWN0ZWRfaWQgPSBucC5hcmdtYXgocHJlZGljdGlvbnNbMF0pCiAgICAgICAgCiAgICAgICAgaW5wdXRfZXZhbCA9IG5wLmFwcGVuZChpbnB1dF9ldmFsWzosIDE6XSwgcHJlZGljdGVkX2lkKS5yZXNoYXBlKDEsIC0xKQogICAgICAgIAogICAgICAgIHRleHRfZ2VuZXJhdGVkLmFwcGVuZChpbmRleF90b19jaGFyW3ByZWRpY3RlZF9pZF0pCiAgICAKICAgIHJldHVybiBzdGFydF9zdHJpbmcgKyAnJy5qb2luKHRleHRfZ2VuZXJhdGVkKQoKIyBHZW5lcmFyIHRleHRvCmdlbmVyYXRlZF90ZXh0ID0gZ2VuZXJhdGVfdGV4dChtb2RlbCwgc3RhcnRfc3RyaW5nPSJob2xhICIsIG51bV9nZW5lcmF0ZT0yMCkKcHJpbnQoZ2VuZXJhdGVkX3RleHQp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def generate_text(model, start_string, num_generate):
    input_eval = [char_to_index[char] for char in start_string]
    input_eval = np.array(input_eval).reshape(1, -1)
    
    text_generated = []
    
    model.reset_states()
    for i in range(num_generate):
        predictions = model.predict(input_eval)
        predicted_id = np.argmax(predictions[0])
        
        input_eval = np.append(input_eval[:, 1:], predicted_id).reshape(1, -1)
        
        text_generated.append(index_to_char[predicted_id])
    
    return start_string + ''.join(text_generated)

# Generar texto
generated_text = generate_text(model, start_string=&quot;hola &quot;, num_generate=20)
print(generated_text)</pre></div><div class='content'></div><h1><p>Ejercicios Prácticos</p>
</h1>
<div class='content'></div><h2><p>Ejercicio 1: Ajustar el Corpus</p>
</h2>
<div class='content'><p>Utiliza un corpus de texto más grande y diverso (por ejemplo, un libro completo) para entrenar el modelo. Observa cómo mejora la calidad del texto generado.</p>
</div><h2><p>Ejercicio 2: Experimentar con Hiperparámetros</p>
</h2>
<div class='content'><p>Ajusta los hiperparámetros del modelo, como el tamaño de la secuencia (<code>seq_length</code>), el tamaño de los embeddings (<code>embedding_dim</code>) y el número de unidades LSTM. Observa cómo estos cambios afectan el rendimiento del modelo.</p>
</div><h2><p>Ejercicio 3: Implementar GRU</p>
</h2>
<div class='content'><p>Reemplaza las capas LSTM con GRU y compara los resultados. ¿Hay alguna diferencia en la calidad del texto generado?</p>
</div><h1><p>Soluciones a los Ejercicios</p>
</h1>
<div class='content'></div><h2><p>Solución al Ejercicio 1</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBVdGlsaXphciB1biBjb3JwdXMgbcOhcyBncmFuZGUKd2l0aCBvcGVuKCdwYXRoL3RvL2xhcmdlX2NvcnB1cy50eHQnLCAncicpIGFzIGZpbGU6CiAgICBjb3JwdXMgPSBmaWxlLnJlYWQoKS5sb3dlcigpCgojIFNlZ3VpciBsb3MgbWlzbW9zIHBhc29zIGRlIHByZXBhcmFjacOzbiBkZSBkYXRvcyB5IGVudHJlbmFtaWVudG8KIyAuLi4="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Utilizar un corpus m&aacute;s grande
with open('path/to/large_corpus.txt', 'r') as file:
    corpus = file.read().lower()

# Seguir los mismos pasos de preparaci&oacute;n de datos y entrenamiento
# ...</pre></div><div class='content'></div><h2><p>Solución al Ejercicio 2</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBBanVzdGFyIGhpcGVycGFyw6FtZXRyb3MKc2VxX2xlbmd0aCA9IDEwCmVtYmVkZGluZ19kaW0gPSAxMDAKbHN0bV91bml0cyA9IDIwMAoKbW9kZWwgPSBTZXF1ZW50aWFsKFsKICAgIEVtYmVkZGluZyh2b2NhYl9zaXplLCBlbWJlZGRpbmdfZGltLCBpbnB1dF9sZW5ndGg9c2VxX2xlbmd0aCksCiAgICBMU1RNKGxzdG1fdW5pdHMsIHJldHVybl9zZXF1ZW5jZXM9RmFsc2UpLAogICAgRGVuc2Uodm9jYWJfc2l6ZSwgYWN0aXZhdGlvbj0nc29mdG1heCcpCl0pCgptb2RlbC5jb21waWxlKGxvc3M9J3NwYXJzZV9jYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLCBvcHRpbWl6ZXI9J2FkYW0nKQptb2RlbC5maXQoWCwgeSwgZXBvY2hzPTEwMCwgdmVyYm9zZT0yKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Ajustar hiperpar&aacute;metros
seq_length = 10
embedding_dim = 100
lstm_units = 200

model = Sequential([
    Embedding(vocab_size, embedding_dim, input_length=seq_length),
    LSTM(lstm_units, return_sequences=False),
    Dense(vocab_size, activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')
model.fit(X, y, epochs=100, verbose=2)</pre></div><div class='content'></div><h2><p>Solución al Ejercicio 3</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBSZWVtcGxhemFyIExTVE0gY29uIEdSVQptb2RlbCA9IFNlcXVlbnRpYWwoWwogICAgRW1iZWRkaW5nKHZvY2FiX3NpemUsIGVtYmVkZGluZ19kaW0sIGlucHV0X2xlbmd0aD1zZXFfbGVuZ3RoKSwKICAgIEdSVSgxMDAsIHJldHVybl9zZXF1ZW5jZXM9RmFsc2UpLAogICAgRGVuc2Uodm9jYWJfc2l6ZSwgYWN0aXZhdGlvbj0nc29mdG1heCcpCl0pCgptb2RlbC5jb21waWxlKGxvc3M9J3NwYXJzZV9jYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLCBvcHRpbWl6ZXI9J2FkYW0nKQptb2RlbC5maXQoWCwgeSwgZXBvY2hzPTEwMCwgdmVyYm9zZT0yKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Reemplazar LSTM con GRU
model = Sequential([
    Embedding(vocab_size, embedding_dim, input_length=seq_length),
    GRU(100, return_sequences=False),
    Dense(vocab_size, activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')
model.fit(X, y, epochs=100, verbose=2)</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En esta sección, hemos aprendido cómo utilizar RNN para la generación de texto. Hemos cubierto los conceptos básicos, implementado un modelo simple y realizado ejercicios prácticos para reforzar el aprendizaje. En el siguiente módulo, exploraremos técnicas avanzadas en Deep Learning que pueden mejorar aún más nuestros modelos.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-01-clasificacion-imagenes-cnn' title="Clasificación de imágenes con CNN">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-03-deteccion-anomalias-autoencoders' title="Detección de anomalías con Autoencoders">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
