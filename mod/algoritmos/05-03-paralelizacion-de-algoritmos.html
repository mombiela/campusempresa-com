<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Paralelización de Algoritmos</title>

    <link rel="alternate" href="https://campusempresa.com/mod/algoritmos/05-03-paralelizacion-de-algoritmos" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/algoritmos/05-03-paralelizacion-de-algoritmos" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/algoritmos/05-03-algorithm-parallelization" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/algoritmos/05-03-algorithm-parallelization" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/algoritmos/05-03-paralelizacion-de-algoritmos" class="px-2">CA</a>
								</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<!-- <a href="/">Home</a>  -->
									<a href="./">Contenido del curso</a>
					<span class="sep">|</span>
								<a href="/all/competencias">Competencias técnicas</a>
				<a href="/all/conocimientos">Conocimientos</a>
				<a href="/all/soft_skills">Competencias sociales</a>
			</div>
		</div>
	</div>
</div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-02-uso-eficiente-de-memoria' title="Uso Eficiente de Memoria">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Paralelización de Algoritmos</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-01-ejercicios-complejidad' title="Ejercicios de Complejidad Temporal y Espacial">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>La paralelización de algoritmos es una técnica que permite dividir un problema en subproblemas más pequeños que pueden ser resueltos simultáneamente por múltiples procesadores. Esta técnica es fundamental para aprovechar al máximo el hardware moderno, que a menudo incluye múltiples núcleos de procesamiento.</p>
</div><h1><p>Conceptos Básicos de Paralelización</p>
</h1>
<div class='content'></div><h2><p>¿Qué es la Paralelización?</p>
</h2>
<div class='content'><p>La paralelización es el proceso de dividir una tarea en partes más pequeñas que pueden ser ejecutadas simultáneamente en diferentes unidades de procesamiento. Esto puede reducir significativamente el tiempo de ejecución de un algoritmo.</p>
</div><h2><p>Ventajas de la Paralelización</p>
</h2>
<div class='content'><ul>
<li><strong>Reducción del Tiempo de Ejecución:</strong> Al dividir el trabajo entre múltiples procesadores, se puede completar una tarea más rápidamente.</li>
<li><strong>Escalabilidad:</strong> Los algoritmos paralelos pueden escalar para aprovechar más procesadores a medida que estén disponibles.</li>
<li><strong>Eficiencia:</strong> Mejora el uso de recursos del sistema, especialmente en sistemas con múltiples núcleos.</li>
</ul>
</div><h2><p>Desafíos de la Paralelización</p>
</h2>
<div class='content'><ul>
<li><strong>Sincronización:</strong> Asegurar que los procesos paralelos se coordinen correctamente para evitar condiciones de carrera y otros problemas de concurrencia.</li>
<li><strong>División de Tareas:</strong> No todos los problemas pueden ser fácilmente divididos en subproblemas independientes.</li>
<li><strong>Comunicación:</strong> La sobrecarga de comunicación entre procesadores puede reducir los beneficios de la paralelización.</li>
</ul>
</div><h1><p>Modelos de Paralelización</p>
</h1>
<div class='content'></div><h2><p>Paralelización de Datos</p>
</h2>
<div class='content'><p>En la paralelización de datos, el mismo conjunto de instrucciones se aplica a diferentes partes de los datos. Este modelo es útil para operaciones en grandes conjuntos de datos, como el procesamiento de imágenes o el análisis de datos.</p>
</div><h2><p>Paralelización de Tareas</p>
</h2>
<div class='content'><p>En la paralelización de tareas, diferentes tareas se ejecutan en paralelo. Este modelo es útil cuando las tareas son independientes y pueden ser ejecutadas simultáneamente sin necesidad de comunicación frecuente.</p>
</div><h1><p>Herramientas y Bibliotecas para Paralelización</p>
</h1>
<div class='content'></div><h2><p>OpenMP</p>
</h2>
<div class='content'><p>OpenMP es una API para programación paralela en C, C++ y Fortran. Permite a los desarrolladores escribir programas paralelos de manera sencilla utilizando directivas de compilador.</p>
<h4>Ejemplo de OpenMP en C</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("I2luY2x1ZGUgPG9tcC5oPgojaW5jbHVkZSA8c3RkaW8uaD4KCmludCBtYWluKCkgewogICAgaW50IG50aHJlYWRzLCB0aWQ7CgogICAgI3ByYWdtYSBvbXAgcGFyYWxsZWwgcHJpdmF0ZShudGhyZWFkcywgdGlkKQogICAgewogICAgICAgIHRpZCA9IG9tcF9nZXRfdGhyZWFkX251bSgpOwogICAgICAgIHByaW50ZigiSGVsbG8gV29ybGQgZnJvbSB0aHJlYWQgPSAlZFxuIiwgdGlkKTsKCiAgICAgICAgaWYgKHRpZCA9PSAwKSB7CiAgICAgICAgICAgIG50aHJlYWRzID0gb21wX2dldF9udW1fdGhyZWFkcygpOwogICAgICAgICAgICBwcmludGYoIk51bWJlciBvZiB0aHJlYWRzID0gJWRcbiIsIG50aHJlYWRzKTsKICAgICAgICB9CiAgICB9CiAgICByZXR1cm4gMDsKfQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>#include &lt;omp.h&gt;
#include &lt;stdio.h&gt;

int main() {
    int nthreads, tid;

    #pragma omp parallel private(nthreads, tid)
    {
        tid = omp_get_thread_num();
        printf(&quot;Hello World from thread = %d\n&quot;, tid);

        if (tid == 0) {
            nthreads = omp_get_num_threads();
            printf(&quot;Number of threads = %d\n&quot;, nthreads);
        }
    }
    return 0;
}</pre></div><div class='content'></div><h2><p>MPI (Message Passing Interface)</p>
</h2>
<div class='content'><p>MPI es un estándar para la programación paralela en sistemas distribuidos. Es útil para aplicaciones que requieren comunicación entre diferentes nodos de un clúster.</p>
<h4>Ejemplo de MPI en C</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("I2luY2x1ZGUgPG1waS5oPgojaW5jbHVkZSA8c3RkaW8uaD4KCmludCBtYWluKGludCBhcmdjLCBjaGFyKiogYXJndikgewogICAgTVBJX0luaXQoTlVMTCwgTlVMTCk7CgogICAgaW50IHdvcmxkX3NpemU7CiAgICBNUElfQ29tbV9zaXplKE1QSV9DT01NX1dPUkxELCAmd29ybGRfc2l6ZSk7CgogICAgaW50IHdvcmxkX3Jhbms7CiAgICBNUElfQ29tbV9yYW5rKE1QSV9DT01NX1dPUkxELCAmd29ybGRfcmFuayk7CgogICAgcHJpbnRmKCJIZWxsbyB3b3JsZCBmcm9tIHJhbmsgJWQgb3V0IG9mICVkIHByb2Nlc3NvcnNcbiIsIHdvcmxkX3JhbmssIHdvcmxkX3NpemUpOwoKICAgIE1QSV9GaW5hbGl6ZSgpOwogICAgcmV0dXJuIDA7Cn0="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>#include &lt;mpi.h&gt;
#include &lt;stdio.h&gt;

int main(int argc, char** argv) {
    MPI_Init(NULL, NULL);

    int world_size;
    MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size);

    int world_rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank);

    printf(&quot;Hello world from rank %d out of %d processors\n&quot;, world_rank, world_size);

    MPI_Finalize();
    return 0;
}</pre></div><div class='content'></div><h1><p>Ejercicios Prácticos</p>
</h1>
<div class='content'></div><h2><p>Ejercicio 1: Paralelización de un Bucle</p>
</h2>
<div class='content'><p><strong>Descripción:</strong> Paraleliza el siguiente bucle utilizando OpenMP.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("I2luY2x1ZGUgPHN0ZGlvLmg+CgppbnQgbWFpbigpIHsKICAgIGludCBpOwogICAgaW50IHN1bSA9IDA7CiAgICBpbnQgbiA9IDEwMDsKCiAgICBmb3IgKGkgPSAwOyBpIDwgbjsgaSsrKSB7CiAgICAgICAgc3VtICs9IGk7CiAgICB9CgogICAgcHJpbnRmKCJTdW0gPSAlZFxuIiwgc3VtKTsKICAgIHJldHVybiAwOwp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>#include &lt;stdio.h&gt;

int main() {
    int i;
    int sum = 0;
    int n = 100;

    for (i = 0; i &lt; n; i++) {
        sum += i;
    }

    printf(&quot;Sum = %d\n&quot;, sum);
    return 0;
}</pre></div><div class='content'><p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("I2luY2x1ZGUgPG9tcC5oPgojaW5jbHVkZSA8c3RkaW8uaD4KCmludCBtYWluKCkgewogICAgaW50IGk7CiAgICBpbnQgc3VtID0gMDsKICAgIGludCBuID0gMTAwOwoKICAgICNwcmFnbWEgb21wIHBhcmFsbGVsIGZvciByZWR1Y3Rpb24oKzpzdW0pCiAgICBmb3IgKGkgPSAwOyBpIDwgbjsgaSsrKSB7CiAgICAgICAgc3VtICs9IGk7CiAgICB9CgogICAgcHJpbnRmKCJTdW0gPSAlZFxuIiwgc3VtKTsKICAgIHJldHVybiAwOwp9"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>#include &lt;omp.h&gt;
#include &lt;stdio.h&gt;

int main() {
    int i;
    int sum = 0;
    int n = 100;

    #pragma omp parallel for reduction(+:sum)
    for (i = 0; i &lt; n; i++) {
        sum += i;
    }

    printf(&quot;Sum = %d\n&quot;, sum);
    return 0;
}</pre></div><div class='content'></div><h2><p>Ejercicio 2: Comunicación entre Procesos</p>
</h2>
<div class='content'><p><strong>Descripción:</strong> Implementa un programa en MPI que envíe un mensaje desde el proceso 0 al proceso 1.</p>
<p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("I2luY2x1ZGUgPG1waS5oPgojaW5jbHVkZSA8c3RkaW8uaD4KCmludCBtYWluKGludCBhcmdjLCBjaGFyKiogYXJndikgewogICAgTVBJX0luaXQoTlVMTCwgTlVMTCk7CgogICAgaW50IHdvcmxkX3Jhbms7CiAgICBNUElfQ29tbV9yYW5rKE1QSV9DT01NX1dPUkxELCAmd29ybGRfcmFuayk7CgogICAgaWYgKHdvcmxkX3JhbmsgPT0gMCkgewogICAgICAgIGludCBudW1iZXIgPSA0MjsKICAgICAgICBNUElfU2VuZCgmbnVtYmVyLCAxLCBNUElfSU5ULCAxLCAwLCBNUElfQ09NTV9XT1JMRCk7CiAgICB9IGVsc2UgaWYgKHdvcmxkX3JhbmsgPT0gMSkgewogICAgICAgIGludCBudW1iZXI7CiAgICAgICAgTVBJX1JlY3YoJm51bWJlciwgMSwgTVBJX0lOVCwgMCwgMCwgTVBJX0NPTU1fV09STEQsIE1QSV9TVEFUVVNfSUdOT1JFKTsKICAgICAgICBwcmludGYoIlByb2Nlc3MgMSByZWNlaXZlZCBudW1iZXIgJWQgZnJvbSBwcm9jZXNzIDBcbiIsIG51bWJlcik7CiAgICB9CgogICAgTVBJX0ZpbmFsaXplKCk7CiAgICByZXR1cm4gMDsKfQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>#include &lt;mpi.h&gt;
#include &lt;stdio.h&gt;

int main(int argc, char** argv) {
    MPI_Init(NULL, NULL);

    int world_rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank);

    if (world_rank == 0) {
        int number = 42;
        MPI_Send(&amp;number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
    } else if (world_rank == 1) {
        int number;
        MPI_Recv(&amp;number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        printf(&quot;Process 1 received number %d from process 0\n&quot;, number);
    }

    MPI_Finalize();
    return 0;
}</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>La paralelización de algoritmos es una técnica poderosa para mejorar el rendimiento de las aplicaciones. Al dividir las tareas en subproblemas más pequeños y ejecutarlos simultáneamente, se puede reducir significativamente el tiempo de ejecución. Sin embargo, es importante tener en cuenta los desafíos de la sincronización y la comunicación entre procesos. Utilizando herramientas como OpenMP y MPI, los desarrolladores pueden escribir programas paralelos de manera más eficiente y efectiva.</p>
<p>En el siguiente módulo, exploraremos ejercicios prácticos que consolidarán los conceptos aprendidos en este curso.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-02-uso-eficiente-de-memoria' title="Uso Eficiente de Memoria">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-01-ejercicios-complejidad' title="Ejercicios de Complejidad Temporal y Espacial">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
