<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aprendizaje No Supervisado</title>

    <link rel="alternate" href="https://campusempresa.com/mod/r/07-04-unsupervised-learning" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/r/07-04-unsupervised-learning" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/r/07-04-unsupervised-learning" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<a href="https://enterprisecampus.net/mod/r/07-04-unsupervised-learning" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/r/07-04-unsupervised-learning" class="px-2">CA</a>
<br>
			<cite>Construyendo la sociedad de hoy y del mañana</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
									<a href="./">Contenido del curso</a>
					<span class="sep">|</span>
								<a href="/all/competencias">Competencias técnicas</a>
				<a href="/all/conocimientos">Conocimientos</a>
				<a href="/all/soft_skills">Competencias sociales</a>
			</div>
		</div>
	</div>
</div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-03-supervised-learning' title="Aprendizaje Supervisado">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Aprendizaje No Supervisado</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-05-model-evaluation-tuning' title="Evaluación y Ajuste de Modelos">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>El aprendizaje no supervisado es una rama del aprendizaje automático que se utiliza para encontrar patrones y estructuras ocultas en datos sin etiquetas. A diferencia del aprendizaje supervisado, donde los datos de entrenamiento están etiquetados, en el aprendizaje no supervisado, el algoritmo intenta aprender las estructuras inherentes de los datos sin ninguna guía externa.</p>
</div><h1><p>Objetivos del Módulo</p>
</h1>
<div class='content'><ul>
<li>Comprender los conceptos básicos del aprendizaje no supervisado.</li>
<li>Aprender sobre los algoritmos más comunes de aprendizaje no supervisado.</li>
<li>Implementar algoritmos de clustering y reducción de dimensionalidad en R.</li>
<li>Evaluar y visualizar los resultados de los algoritmos de aprendizaje no supervisado.</li>
</ul>
</div><h1><p>Contenido</p>
</h1>
<div class='content'><ol>
<li>Introducción al Aprendizaje No Supervisado</li>
<li>Clustering
<ul>
<li>K-means</li>
<li>Clustering Jerárquico</li>
</ul>
</li>
<li>Reducción de Dimensionalidad
<ul>
<li>Análisis de Componentes Principales (PCA)</li>
<li>t-SNE</li>
</ul>
</li>
<li>Evaluación de Modelos No Supervisados</li>
<li>Ejercicios Prácticos</li>
</ol>
</div><h1><ol>
<li>Introducción al Aprendizaje No Supervisado</li>
</ol>
</h1>
<div class='content'><p>El aprendizaje no supervisado se utiliza principalmente para:</p>
<ul>
<li><strong>Clustering</strong>: Agrupar datos en clusters o grupos basados en similitudes.</li>
<li><strong>Reducción de Dimensionalidad</strong>: Reducir el número de variables en un dataset mientras se preserva la mayor cantidad de información posible.</li>
</ul>
</div><h1><ol start="2">
<li>Clustering</li>
</ol>
</h1>
<div class='content'></div><h2><p>K-means</p>
</h2>
<div class='content'><p>El algoritmo K-means es uno de los métodos de clustering más populares. Su objetivo es dividir un conjunto de datos en K clusters, donde cada punto de datos pertenece al cluster con la media más cercana.</p>
<h4>Pasos del Algoritmo K-means:</h4>
<ol>
<li>Seleccionar K puntos aleatorios como centroides iniciales.</li>
<li>Asignar cada punto de datos al centroide más cercano.</li>
<li>Recalcular los centroides como la media de los puntos asignados a cada cluster.</li>
<li>Repetir los pasos 2 y 3 hasta que los centroides no cambien significativamente.</li>
</ol>
<h4>Ejemplo en R:</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDYXJnYXIgbGlicmVyw61hcyBuZWNlc2FyaWFzCmxpYnJhcnkoZ2dwbG90MikKbGlicmFyeShjbHVzdGVyKQoKIyBHZW5lcmFyIGRhdG9zIGRlIGVqZW1wbG8Kc2V0LnNlZWQoMTIzKQpkYXRhIDwtIGRhdGEuZnJhbWUoeCA9IHJub3JtKDEwMCksIHkgPSBybm9ybSgxMDApKQoKIyBBcGxpY2FyIEstbWVhbnMgY29uIDMgY2x1c3RlcnMKa21lYW5zX3Jlc3VsdCA8LSBrbWVhbnMoZGF0YSwgY2VudGVycyA9IDMpCgojIEHDsWFkaXIgbG9zIGNsdXN0ZXJzIGFsIGRhdGFmcmFtZSBvcmlnaW5hbApkYXRhJGNsdXN0ZXIgPC0gYXMuZmFjdG9yKGttZWFuc19yZXN1bHQkY2x1c3RlcikKCiMgVmlzdWFsaXphciBsb3MgY2x1c3RlcnMKZ2dwbG90KGRhdGEsIGFlcyh4ID0geCwgeSA9IHksIGNvbG9yID0gY2x1c3RlcikpICsKICBnZW9tX3BvaW50KCkgKwogIGxhYnModGl0bGUgPSAiSy1tZWFucyBDbHVzdGVyaW5nIiwgeCA9ICJYIiwgeSA9ICJZIik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Cargar librer&iacute;as necesarias
library(ggplot2)
library(cluster)

# Generar datos de ejemplo
set.seed(123)
data &lt;- data.frame(x = rnorm(100), y = rnorm(100))

# Aplicar K-means con 3 clusters
kmeans_result &lt;- kmeans(data, centers = 3)

# A&ntilde;adir los clusters al dataframe original
data$cluster &lt;- as.factor(kmeans_result$cluster)

# Visualizar los clusters
ggplot(data, aes(x = x, y = y, color = cluster)) +
  geom_point() +
  labs(title = &quot;K-means Clustering&quot;, x = &quot;X&quot;, y = &quot;Y&quot;)</pre></div><div class='content'></div><h2><p>Clustering Jerárquico</p>
</h2>
<div class='content'><p>El clustering jerárquico crea una jerarquía de clusters que puede representarse mediante un dendrograma. Existen dos enfoques principales:</p>
<ul>
<li><strong>Aglomerativo</strong>: Comienza con cada punto como un cluster individual y fusiona los clusters más cercanos hasta que todos los puntos estén en un solo cluster.</li>
<li><strong>Divisivo</strong>: Comienza con todos los puntos en un solo cluster y divide los clusters hasta que cada punto esté en su propio cluster.</li>
</ul>
<h4>Ejemplo en R:</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBHZW5lcmFyIGRhdG9zIGRlIGVqZW1wbG8Kc2V0LnNlZWQoMTIzKQpkYXRhIDwtIGRhdGEuZnJhbWUoeCA9IHJub3JtKDEwMCksIHkgPSBybm9ybSgxMDApKQoKIyBDYWxjdWxhciBsYSBtYXRyaXogZGUgZGlzdGFuY2lhcwpkaXN0X21hdHJpeCA8LSBkaXN0KGRhdGEpCgojIEFwbGljYXIgY2x1c3RlcmluZyBqZXLDoXJxdWljbyBhZ2xvbWVyYXRpdm8KaGNsdXN0X3Jlc3VsdCA8LSBoY2x1c3QoZGlzdF9tYXRyaXgsIG1ldGhvZCA9ICJjb21wbGV0ZSIpCgojIFZpc3VhbGl6YXIgZWwgZGVuZHJvZ3JhbWEKcGxvdChoY2x1c3RfcmVzdWx0LCBsYWJlbHMgPSBGQUxTRSwgbWFpbiA9ICJEZW5kcm9ncmFtYSBkZSBDbHVzdGVyaW5nIEplcsOhcnF1aWNvIik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Generar datos de ejemplo
set.seed(123)
data &lt;- data.frame(x = rnorm(100), y = rnorm(100))

# Calcular la matriz de distancias
dist_matrix &lt;- dist(data)

# Aplicar clustering jer&aacute;rquico aglomerativo
hclust_result &lt;- hclust(dist_matrix, method = &quot;complete&quot;)

# Visualizar el dendrograma
plot(hclust_result, labels = FALSE, main = &quot;Dendrograma de Clustering Jer&aacute;rquico&quot;)</pre></div><div class='content'></div><h1><ol start="3">
<li>Reducción de Dimensionalidad</li>
</ol>
</h1>
<div class='content'></div><h2><p>Análisis de Componentes Principales (PCA)</p>
</h2>
<div class='content'><p>El PCA es una técnica de reducción de dimensionalidad que transforma un conjunto de variables posiblemente correlacionadas en un conjunto de variables no correlacionadas llamadas componentes principales.</p>
<h4>Ejemplo en R:</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDYXJnYXIgbGlicmVyw61hIG5lY2VzYXJpYQpsaWJyYXJ5KGdncGxvdDIpCgojIEdlbmVyYXIgZGF0b3MgZGUgZWplbXBsbwpzZXQuc2VlZCgxMjMpCmRhdGEgPC0gZGF0YS5mcmFtZSh4ID0gcm5vcm0oMTAwKSwgeSA9IHJub3JtKDEwMCksIHogPSBybm9ybSgxMDApKQoKIyBBcGxpY2FyIFBDQQpwY2FfcmVzdWx0IDwtIHByY29tcChkYXRhLCBzY2FsZS4gPSBUUlVFKQoKIyBWaXN1YWxpemFyIGxvcyByZXN1bHRhZG9zCmJpcGxvdChwY2FfcmVzdWx0LCBtYWluID0gIkJpcGxvdCBkZSBQQ0EiKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Cargar librer&iacute;a necesaria
library(ggplot2)

# Generar datos de ejemplo
set.seed(123)
data &lt;- data.frame(x = rnorm(100), y = rnorm(100), z = rnorm(100))

# Aplicar PCA
pca_result &lt;- prcomp(data, scale. = TRUE)

# Visualizar los resultados
biplot(pca_result, main = &quot;Biplot de PCA&quot;)</pre></div><div class='content'></div><h2><p>t-SNE</p>
</h2>
<div class='content'><p>El t-SNE (t-Distributed Stochastic Neighbor Embedding) es una técnica de reducción de dimensionalidad que se utiliza principalmente para la visualización de datos de alta dimensión en un espacio de menor dimensión (2D o 3D).</p>
<h4>Ejemplo en R:</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDYXJnYXIgbGlicmVyw61hIG5lY2VzYXJpYQpsaWJyYXJ5KFJ0c25lKQoKIyBHZW5lcmFyIGRhdG9zIGRlIGVqZW1wbG8Kc2V0LnNlZWQoMTIzKQpkYXRhIDwtIGRhdGEuZnJhbWUoeCA9IHJub3JtKDEwMCksIHkgPSBybm9ybSgxMDApLCB6ID0gcm5vcm0oMTAwKSkKCiMgQXBsaWNhciB0LVNORQp0c25lX3Jlc3VsdCA8LSBSdHNuZShkYXRhLCBkaW1zID0gMiwgcGVycGxleGl0eSA9IDMwKQoKIyBDb252ZXJ0aXIgbG9zIHJlc3VsdGFkb3MgYSB1biBkYXRhZnJhbWUKdHNuZV9kYXRhIDwtIGRhdGEuZnJhbWUodHNuZV9yZXN1bHQkWSkKY29sbmFtZXModHNuZV9kYXRhKSA8LSBjKCJEaW0xIiwgIkRpbTIiKQoKIyBWaXN1YWxpemFyIGxvcyByZXN1bHRhZG9zCmdncGxvdCh0c25lX2RhdGEsIGFlcyh4ID0gRGltMSwgeSA9IERpbTIpKSArCiAgZ2VvbV9wb2ludCgpICsKICBsYWJzKHRpdGxlID0gInQtU05FIiwgeCA9ICJEaW1lbnNpw7NuIDEiLCB5ID0gIkRpbWVuc2nDs24gMiIp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Cargar librer&iacute;a necesaria
library(Rtsne)

# Generar datos de ejemplo
set.seed(123)
data &lt;- data.frame(x = rnorm(100), y = rnorm(100), z = rnorm(100))

# Aplicar t-SNE
tsne_result &lt;- Rtsne(data, dims = 2, perplexity = 30)

# Convertir los resultados a un dataframe
tsne_data &lt;- data.frame(tsne_result$Y)
colnames(tsne_data) &lt;- c(&quot;Dim1&quot;, &quot;Dim2&quot;)

# Visualizar los resultados
ggplot(tsne_data, aes(x = Dim1, y = Dim2)) +
  geom_point() +
  labs(title = &quot;t-SNE&quot;, x = &quot;Dimensi&oacute;n 1&quot;, y = &quot;Dimensi&oacute;n 2&quot;)</pre></div><div class='content'></div><h1><ol start="4">
<li>Evaluación de Modelos No Supervisados</li>
</ol>
</h1>
<div class='content'><p>Evaluar modelos no supervisados puede ser más desafiante que los supervisados debido a la falta de etiquetas. Algunas técnicas comunes incluyen:</p>
<ul>
<li><strong>Elbow Method</strong>: Utilizado para determinar el número óptimo de clusters en K-means.</li>
<li><strong>Silhouette Score</strong>: Mide qué tan similar es un punto a su propio cluster en comparación con otros clusters.</li>
</ul>
<h4>Ejemplo del Método del Codo en R:</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBHZW5lcmFyIGRhdG9zIGRlIGVqZW1wbG8Kc2V0LnNlZWQoMTIzKQpkYXRhIDwtIGRhdGEuZnJhbWUoeCA9IHJub3JtKDEwMCksIHkgPSBybm9ybSgxMDApKQoKIyBDYWxjdWxhciBlbCB0b3RhbCBkZSB3aXRoaW4tY2x1c3RlciBzdW0gb2Ygc3F1YXJlcyAoV1NTKSBwYXJhIGRpZmVyZW50ZXMgdmFsb3JlcyBkZSBLCndzcyA8LSBzYXBwbHkoMToxMCwgZnVuY3Rpb24oaykgewogIGttZWFucyhkYXRhLCBjZW50ZXJzID0gaykkdG90LndpdGhpbnNzCn0pCgojIFZpc3VhbGl6YXIgZWwgbcOpdG9kbyBkZWwgY29kbwpwbG90KDE6MTAsIHdzcywgdHlwZSA9ICJiIiwgcGNoID0gMTksIGZyYW1lID0gRkFMU0UsCiAgICAgeGxhYiA9ICJOw7ptZXJvIGRlIENsdXN0ZXJzIEsiLAogICAgIHlsYWIgPSAiU3VtYSBkZSBDdWFkcmFkb3MgRGVudHJvIGRlbCBDbHVzdGVyIChXU1MpIiwKICAgICBtYWluID0gIk3DqXRvZG8gZGVsIENvZG8gcGFyYSBEZXRlcm1pbmFyIGVsIE7Dum1lcm8gw5NwdGltbyBkZSBDbHVzdGVycyIp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Generar datos de ejemplo
set.seed(123)
data &lt;- data.frame(x = rnorm(100), y = rnorm(100))

# Calcular el total de within-cluster sum of squares (WSS) para diferentes valores de K
wss &lt;- sapply(1:10, function(k) {
  kmeans(data, centers = k)$tot.withinss
})

# Visualizar el m&eacute;todo del codo
plot(1:10, wss, type = &quot;b&quot;, pch = 19, frame = FALSE,
     xlab = &quot;N&uacute;mero de Clusters K&quot;,
     ylab = &quot;Suma de Cuadrados Dentro del Cluster (WSS)&quot;,
     main = &quot;M&eacute;todo del Codo para Determinar el N&uacute;mero &Oacute;ptimo de Clusters&quot;)</pre></div><div class='content'></div><h1><ol start="5">
<li>Ejercicios Prácticos</li>
</ol>
</h1>
<div class='content'></div><h2><p>Ejercicio 1: Aplicar K-means a un Dataset Real</p>
</h2>
<div class='content'><p><strong>Instrucciones:</strong></p>
<ol>
<li>Cargar el dataset <code>iris</code> disponible en R.</li>
<li>Aplicar K-means con 3 clusters.</li>
<li>Visualizar los clusters resultantes.</li>
</ol>
<p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDYXJnYXIgZWwgZGF0YXNldCBpcmlzCmRhdGEoaXJpcykKaXJpc19kYXRhIDwtIGlyaXNbLCAtNV0KCiMgQXBsaWNhciBLLW1lYW5zIGNvbiAzIGNsdXN0ZXJzCmttZWFuc19yZXN1bHQgPC0ga21lYW5zKGlyaXNfZGF0YSwgY2VudGVycyA9IDMpCgojIEHDsWFkaXIgbG9zIGNsdXN0ZXJzIGFsIGRhdGFmcmFtZSBvcmlnaW5hbAppcmlzJGNsdXN0ZXIgPC0gYXMuZmFjdG9yKGttZWFuc19yZXN1bHQkY2x1c3RlcikKCiMgVmlzdWFsaXphciBsb3MgY2x1c3RlcnMKZ2dwbG90KGlyaXMsIGFlcyh4ID0gU2VwYWwuTGVuZ3RoLCB5ID0gU2VwYWwuV2lkdGgsIGNvbG9yID0gY2x1c3RlcikpICsKICBnZW9tX3BvaW50KCkgKwogIGxhYnModGl0bGUgPSAiSy1tZWFucyBDbHVzdGVyaW5nIGVuIGVsIERhdGFzZXQgSXJpcyIsIHggPSAiTG9uZ2l0dWQgZGVsIFPDqXBhbG8iLCB5ID0gIkFuY2hvIGRlbCBTw6lwYWxvIik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Cargar el dataset iris
data(iris)
iris_data &lt;- iris[, -5]

# Aplicar K-means con 3 clusters
kmeans_result &lt;- kmeans(iris_data, centers = 3)

# A&ntilde;adir los clusters al dataframe original
iris$cluster &lt;- as.factor(kmeans_result$cluster)

# Visualizar los clusters
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = cluster)) +
  geom_point() +
  labs(title = &quot;K-means Clustering en el Dataset Iris&quot;, x = &quot;Longitud del S&eacute;palo&quot;, y = &quot;Ancho del S&eacute;palo&quot;)</pre></div><div class='content'></div><h2><p>Ejercicio 2: Aplicar PCA a un Dataset Real</p>
</h2>
<div class='content'><p><strong>Instrucciones:</strong></p>
<ol>
<li>Cargar el dataset <code>mtcars</code> disponible en R.</li>
<li>Aplicar PCA.</li>
<li>Visualizar los resultados.</li>
</ol>
<p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBDYXJnYXIgZWwgZGF0YXNldCBtdGNhcnMKZGF0YShtdGNhcnMpCgojIEFwbGljYXIgUENBCnBjYV9yZXN1bHQgPC0gcHJjb21wKG10Y2Fycywgc2NhbGUuID0gVFJVRSkKCiMgVmlzdWFsaXphciBsb3MgcmVzdWx0YWRvcwpiaXBsb3QocGNhX3Jlc3VsdCwgbWFpbiA9ICJCaXBsb3QgZGUgUENBIGVuIGVsIERhdGFzZXQgbXRjYXJzIik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Cargar el dataset mtcars
data(mtcars)

# Aplicar PCA
pca_result &lt;- prcomp(mtcars, scale. = TRUE)

# Visualizar los resultados
biplot(pca_result, main = &quot;Biplot de PCA en el Dataset mtcars&quot;)</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En esta sección, hemos explorado los conceptos y técnicas fundamentales del aprendizaje no supervisado, incluyendo el clustering y la reducción de dimensionalidad. Hemos aprendido a implementar y evaluar estos algoritmos en R, y hemos practicado con ejemplos y ejercicios prácticos. Con estos conocimientos, estamos preparados para abordar problemas más complejos y aplicar técnicas de aprendizaje no supervisado a datasets reales.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='07-03-supervised-learning' title="Aprendizaje Supervisado">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='07-05-model-evaluation-tuning' title="Evaluación y Ajuste de Modelos">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
