<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Apache Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/procesamiento_datos_masivos/03-02-apache-spark" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/procesamiento_datos_masivos/03-02-apache-spark" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/procesamiento_datos_masivos/03-02-apache-spark" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
				<a href="https://enterprisecampus.net/mod/procesamiento_datos_masivos/03-02-apache-spark" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/procesamiento_datos_masivos/03-02-apache-spark" class="px-2">CA</a>
<br>
			<cite>Construyendo la sociedad de hoy y del mañana</cite>
		</div>
	</div>
</div>
<div id="subheader" class="container-xxl">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				 					<a href="/categ/languages">Lenguajes de Programación</a>
				 					<a href="/categ/frameworks">Frameworks y Librerías</a>
				 					<a href="/categ/tech-tools">Herramientas Técnicas</a>
				 					<a href="/categ/foundations">Fundamentos Teóricos</a>
				 					<a href="/categ/soft-skills">Habilidades Sociales</a>
							</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='03-01-mapreduce' title="MapReduce">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Apache Spark</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='03-03-procesamiento-tiempo-real' title="Procesamiento en Tiempo Real">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'><p>Apache Spark es una plataforma de procesamiento de datos masivos que permite realizar análisis de datos a gran escala de manera rápida y eficiente. Spark es conocido por su velocidad, facilidad de uso y su capacidad para manejar tanto procesamiento en batch como en tiempo real.</p>
</div><h1><p>Conceptos Básicos de Apache Spark</p>
</h1>
<div class='content'></div><h2><p>¿Qué es Apache Spark?</p>
</h2>
<div class='content'><p>Apache Spark es un motor de análisis unificado para el procesamiento de datos a gran escala. Fue desarrollado en la Universidad de California, Berkeley, y es un proyecto de código abierto bajo la Fundación Apache.</p>
</div><h2><p>Características Principales</p>
</h2>
<div class='content'><ol>
<li><strong>Velocidad</strong>: Spark puede ejecutar programas hasta 100 veces más rápido que Hadoop MapReduce en memoria y 10 veces más rápido en disco.</li>
<li><strong>Facilidad de Uso</strong>: Spark soporta APIs en Java, Scala, Python y R, lo que facilita su uso para desarrolladores con diferentes habilidades.</li>
<li><strong>Procesamiento Unificado</strong>: Spark puede manejar tanto procesamiento en batch como en tiempo real, así como consultas interactivas y aprendizaje automático.</li>
<li><strong>Compatibilidad con Hadoop</strong>: Spark puede integrarse con Hadoop, utilizando HDFS como sistema de almacenamiento y YARN como gestor de recursos.</li>
</ol>
</div><h2><p>Componentes de Apache Spark</p>
</h2>
<div class='content'><ol>
<li><strong>Spark Core</strong>: El motor de ejecución central que proporciona APIs para tareas básicas como el manejo de datos y la programación de tareas.</li>
<li><strong>Spark SQL</strong>: Un módulo para trabajar con datos estructurados utilizando SQL.</li>
<li><strong>Spark Streaming</strong>: Permite el procesamiento de flujos de datos en tiempo real.</li>
<li><strong>MLlib</strong>: Una biblioteca de aprendizaje automático escalable.</li>
<li><strong>GraphX</strong>: Un módulo para el procesamiento de gráficos y análisis de grafos.</li>
</ol>
</div><h1><p>Instalación de Apache Spark</p>
</h1>
<div class='content'></div><h2><p>Requisitos Previos</p>
</h2>
<div class='content'><ul>
<li><strong>Java</strong>: Spark requiere Java 8 o superior.</li>
<li><strong>Scala</strong>: Aunque no es obligatorio, Scala es el lenguaje en el que Spark está escrito y puede ser útil para ciertos desarrollos.</li>
<li><strong>Hadoop</strong>: Opcional, si se desea integrar Spark con Hadoop.</li>
</ul>
</div><h2><p>Pasos de Instalación</p>
</h2>
<div class='content'><ol>
<li><strong>Descargar Spark</strong>:
<pre><code class="language-bash">wget https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz
</code></pre>
</li>
<li><strong>Descomprimir el archivo</strong>:
<pre><code class="language-bash">tar -xvzf spark-3.1.2-bin-hadoop3.2.tgz
</code></pre>
</li>
<li><strong>Configurar las variables de entorno</strong>:
<pre><code class="language-bash">export SPARK_HOME=/path/to/spark-3.1.2-bin-hadoop3.2
export PATH=$PATH:$SPARK_HOME/bin
</code></pre>
</li>
</ol>
</div><h1><p>Ejemplo Práctico: Contar Palabras con Spark</p>
</h1>
<div class='content'></div><h2><p>Código en Python (PySpark)</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQsIFNwYXJrQ29uZgoKIyBDb25maWd1cmFjacOzbiBkZSBTcGFyawpjb25mID0gU3BhcmtDb25mKCkuc2V0QXBwTmFtZSgiV29yZENvdW50Iikuc2V0TWFzdGVyKCJsb2NhbCIpCnNjID0gU3BhcmtDb250ZXh0KGNvbmY9Y29uZikKCiMgTGVlciBlbCBhcmNoaXZvIGRlIHRleHRvCnRleHRfZmlsZSA9IHNjLnRleHRGaWxlKCJoZGZzOi8vcGF0aC90by90ZXh0ZmlsZS50eHQiKQoKIyBDb250YXIgbGFzIHBhbGFicmFzCmNvdW50cyA9IHRleHRfZmlsZS5mbGF0TWFwKGxhbWJkYSBsaW5lOiBsaW5lLnNwbGl0KCIgIikpIFwKICAgICAgICAgICAgICAgICAgLm1hcChsYW1iZGEgd29yZDogKHdvcmQsIDEpKSBcCiAgICAgICAgICAgICAgICAgIC5yZWR1Y2VCeUtleShsYW1iZGEgYSwgYjogYSArIGIpCgojIEd1YXJkYXIgZWwgcmVzdWx0YWRvCmNvdW50cy5zYXZlQXNUZXh0RmlsZSgiaGRmczovL3BhdGgvdG8vb3V0cHV0Iik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext, SparkConf

# Configuraci&oacute;n de Spark
conf = SparkConf().setAppName(&quot;WordCount&quot;).setMaster(&quot;local&quot;)
sc = SparkContext(conf=conf)

# Leer el archivo de texto
text_file = sc.textFile(&quot;hdfs://path/to/textfile.txt&quot;)

# Contar las palabras
counts = text_file.flatMap(lambda line: line.split(&quot; &quot;)) \
                  .map(lambda word: (word, 1)) \
                  .reduceByKey(lambda a, b: a + b)

# Guardar el resultado
counts.saveAsTextFile(&quot;hdfs://path/to/output&quot;)</pre></div><div class='content'></div><h2><p>Explicación del Código</p>
</h2>
<div class='content'><ol>
<li><strong>Configuración de Spark</strong>: Se crea una configuración de Spark y un contexto de Spark.</li>
<li><strong>Leer el archivo de texto</strong>: Se lee un archivo de texto desde HDFS.</li>
<li><strong>Contar las palabras</strong>:
<ul>
<li><code>flatMap</code>: Divide cada línea en palabras.</li>
<li><code>map</code>: Asigna un valor de 1 a cada palabra.</li>
<li><code>reduceByKey</code>: Suma los valores para cada palabra.</li>
</ul>
</li>
<li><strong>Guardar el resultado</strong>: Se guarda el resultado en HDFS.</li>
</ol>
</div><h1><p>Ejercicios Prácticos</p>
</h1>
<div class='content'></div><h2><p>Ejercicio 1: Contar Palabras en un Archivo Local</p>
</h2>
<div class='content'><p>Modifica el ejemplo anterior para contar las palabras en un archivo local en lugar de HDFS.</p>
</div><h2><p>Ejercicio 2: Filtrar Palabras Comunes</p>
</h2>
<div class='content'><p>Modifica el ejemplo para filtrar palabras comunes como &quot;el&quot;, &quot;la&quot;, &quot;y&quot;, etc., antes de contar las palabras.</p>
</div><h2><p>Ejercicio 3: Procesamiento en Tiempo Real</p>
</h2>
<div class='content'><p>Utiliza Spark Streaming para contar palabras en un flujo de datos en tiempo real desde un socket.</p>
<h4>Soluciones</h4>
<p><strong>Ejercicio 1:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dGV4dF9maWxlID0gc2MudGV4dEZpbGUoImZpbGU6Ly8vcGF0aC90by9sb2NhbGZpbGUudHh0Iik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>text_file = sc.textFile(&quot;file:///path/to/localfile.txt&quot;)</pre></div><div class='content'><p><strong>Ejercicio 2:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y29tbW9uX3dvcmRzID0geyJlbCIsICJsYSIsICJ5IiwgImRlIiwgImEifQpjb3VudHMgPSB0ZXh0X2ZpbGUuZmxhdE1hcChsYW1iZGEgbGluZTogbGluZS5zcGxpdCgiICIpKSBcCiAgICAgICAgICAgICAgICAgIC5maWx0ZXIobGFtYmRhIHdvcmQ6IHdvcmQgbm90IGluIGNvbW1vbl93b3JkcykgXAogICAgICAgICAgICAgICAgICAubWFwKGxhbWJkYSB3b3JkOiAod29yZCwgMSkpIFwKICAgICAgICAgICAgICAgICAgLnJlZHVjZUJ5S2V5KGxhbWJkYSBhLCBiOiBhICsgYik="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>common_words = {&quot;el&quot;, &quot;la&quot;, &quot;y&quot;, &quot;de&quot;, &quot;a&quot;}
counts = text_file.flatMap(lambda line: line.split(&quot; &quot;)) \
                  .filter(lambda word: word not in common_words) \
                  .map(lambda word: (word, 1)) \
                  .reduceByKey(lambda a, b: a + b)</pre></div><div class='content'><p><strong>Ejercicio 3:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnN0cmVhbWluZyBpbXBvcnQgU3RyZWFtaW5nQ29udGV4dAoKc3NjID0gU3RyZWFtaW5nQ29udGV4dChzYywgMSkKbGluZXMgPSBzc2Muc29ja2V0VGV4dFN0cmVhbSgibG9jYWxob3N0IiwgOTk5OSkKY291bnRzID0gbGluZXMuZmxhdE1hcChsYW1iZGEgbGluZTogbGluZS5zcGxpdCgiICIpKSBcCiAgICAgICAgICAgICAgLm1hcChsYW1iZGEgd29yZDogKHdvcmQsIDEpKSBcCiAgICAgICAgICAgICAgLnJlZHVjZUJ5S2V5KGxhbWJkYSBhLCBiOiBhICsgYikKY291bnRzLnBwcmludCgpCnNzYy5zdGFydCgpCnNzYy5hd2FpdFRlcm1pbmF0aW9uKCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.streaming import StreamingContext

ssc = StreamingContext(sc, 1)
lines = ssc.socketTextStream(&quot;localhost&quot;, 9999)
counts = lines.flatMap(lambda line: line.split(&quot; &quot;)) \
              .map(lambda word: (word, 1)) \
              .reduceByKey(lambda a, b: a + b)
counts.pprint()
ssc.start()
ssc.awaitTermination()</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En esta sección, hemos explorado Apache Spark, una herramienta poderosa para el procesamiento de datos masivos. Hemos cubierto sus características principales, componentes, y cómo instalarlo. Además, hemos visto un ejemplo práctico y ejercicios para reforzar los conceptos aprendidos. Con Apache Spark, puedes manejar grandes volúmenes de datos de manera eficiente y realizar análisis complejos en tiempo real.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='03-01-mapreduce' title="MapReduce">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='03-03-procesamiento-tiempo-real' title="Procesamiento en Tiempo Real">
				<span class="d-none d-md-inline">Siguiente &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
