<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Caso de Estudio 1: Análisis de Logs</title>

    <link rel="alternate" href="https://campusempresa.com/mod/procesamiento_datos_masivos/07-01-caso-estudio-logs" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/procesamiento_datos_masivos/07-01-cas-estudi-logs" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/procesamiento_datos_masivos/07-01-case-study-logs" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/procesamiento_datos_masivos/07-01-case-study-logs" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/procesamiento_datos_masivos/07-01-cas-estudi-logs" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='06-03-visualizacion-datos' title="Visualización de Datos">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Caso de Estudio 1: Análisis de Logs</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='07-02-caso-estudio-recomendaciones' title="Caso de Estudio 2: Recomendaciones en Tiempo Real">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1><p>Introducción</p>
</h1>
<div class='content'><p>En este caso de estudio, exploraremos cómo se puede utilizar el procesamiento de datos masivos para analizar logs de servidores. Los logs son registros detallados de eventos que ocurren en un sistema, y su análisis puede proporcionar información valiosa sobre el rendimiento del sistema, la detección de anomalías y la seguridad.</p>
</div><h1><p>Objetivos del Caso de Estudio</p>
</h1>
<div class='content'><ol>
<li><strong>Comprender la importancia del análisis de logs.</strong></li>
<li><strong>Aprender a procesar y analizar grandes volúmenes de logs utilizando herramientas y técnicas de procesamiento de datos masivos.</strong></li>
<li><strong>Implementar un flujo de trabajo para la ingesta, almacenamiento y análisis de logs.</strong></li>
</ol>
</div><h1><p>Pasos del Caso de Estudio</p>
</h1>
<div class='content'><ol>
<li><strong>Ingesta de Logs</strong></li>
<li><strong>Almacenamiento de Logs</strong></li>
<li><strong>Procesamiento de Logs</strong></li>
<li><strong>Análisis y Visualización</strong></li>
</ol>
</div><h2><ol>
<li>Ingesta de Logs</li>
</ol>
</h2>
<div class='content'><p>La ingesta de logs es el primer paso en el análisis de logs. Implica la recopilación de logs de diversas fuentes y su preparación para el almacenamiento y procesamiento.</p>
<h4>Herramientas Comunes para la Ingesta de Logs</h4>
<ul>
<li><strong>Fluentd:</strong> Un colector de datos de código abierto que unifica la recopilación y el consumo de datos.</li>
<li><strong>Logstash:</strong> Una herramienta de ingesta de datos que puede recopilar, transformar y enviar datos a un destino específico.</li>
</ul>
<h4>Ejemplo de Configuración de Fluentd</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("PHNvdXJjZT4KICBAdHlwZSB0YWlsCiAgcGF0aCAvdmFyL2xvZy9uZ2lueC9hY2Nlc3MubG9nCiAgcG9zX2ZpbGUgL3Zhci9sb2cvdGQtYWdlbnQvbmdpbngtYWNjZXNzLmxvZy5wb3MKICB0YWcgbmdpbnguYWNjZXNzCiAgPHBhcnNlPgogICAgQHR5cGUgbmdpbngKICA8L3BhcnNlPgo8L3NvdXJjZT4KCjxtYXRjaCBuZ2lueC5hY2Nlc3M+CiAgQHR5cGUgZm9yd2FyZAogIDxzZXJ2ZXI+CiAgICBob3N0IDE5Mi4xNjguMS4xCiAgICBwb3J0IDI0MjI0CiAgPC9zZXJ2ZXI+CjwvbWF0Y2g+"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>&lt;source&gt;
  @type tail
  path /var/log/nginx/access.log
  pos_file /var/log/td-agent/nginx-access.log.pos
  tag nginx.access
  &lt;parse&gt;
    @type nginx
  &lt;/parse&gt;
&lt;/source&gt;

&lt;match nginx.access&gt;
  @type forward
  &lt;server&gt;
    host 192.168.1.1
    port 24224
  &lt;/server&gt;
&lt;/match&gt;</pre></div><div class='content'><p><strong>Explicación:</strong></p>
<ul>
<li><strong><source>:</strong> Define la fuente de los logs. En este caso, estamos leyendo logs de acceso de Nginx.</li>
<li><strong>path:</strong> Ruta al archivo de logs.</li>
<li><strong>pos_file:</strong> Archivo de posición para rastrear la lectura de logs.</li>
<li><strong>tag:</strong> Etiqueta para identificar los logs.</li>
<li><strong><parse>:</strong> Define el formato de los logs.</li>
<li><strong><match>:</strong> Define el destino de los logs. En este caso, se envían a un servidor remoto.</li>
</ul>
</div><h2><ol start="2">
<li>Almacenamiento de Logs</li>
</ol>
</h2>
<div class='content'><p>Una vez que los logs se han ingerido, deben almacenarse de manera eficiente para permitir un acceso rápido y análisis posterior.</p>
<h4>Tecnologías de Almacenamiento Comunes</h4>
<ul>
<li><strong>Elasticsearch:</strong> Un motor de búsqueda y análisis distribuido.</li>
<li><strong>HDFS (Hadoop Distributed File System):</strong> Un sistema de archivos distribuido diseñado para grandes volúmenes de datos.</li>
</ul>
<h4>Ejemplo de Configuración de Elasticsearch</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("UFVUIC9sb2dzCnsKICAibWFwcGluZ3MiOiB7CiAgICAicHJvcGVydGllcyI6IHsKICAgICAgInRpbWVzdGFtcCI6IHsgInR5cGUiOiAiZGF0ZSIgfSwKICAgICAgIm1lc3NhZ2UiOiB7ICJ0eXBlIjogInRleHQiIH0sCiAgICAgICJob3N0IjogeyAidHlwZSI6ICJrZXl3b3JkIiB9LAogICAgICAicGF0aCI6IHsgInR5cGUiOiAia2V5d29yZCIgfQogICAgfQogIH0KfQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>PUT /logs
{
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;timestamp&quot;: { &quot;type&quot;: &quot;date&quot; },
      &quot;message&quot;: { &quot;type&quot;: &quot;text&quot; },
      &quot;host&quot;: { &quot;type&quot;: &quot;keyword&quot; },
      &quot;path&quot;: { &quot;type&quot;: &quot;keyword&quot; }
    }
  }
}</pre></div><div class='content'><p><strong>Explicación:</strong></p>
<ul>
<li><strong>PUT /logs:</strong> Crea un índice llamado &quot;logs&quot;.</li>
<li><strong>mappings:</strong> Define la estructura de los documentos en el índice.</li>
<li><strong>properties:</strong> Define los campos y sus tipos.</li>
</ul>
</div><h2><ol start="3">
<li>Procesamiento de Logs</li>
</ol>
</h2>
<div class='content'><p>El procesamiento de logs implica transformar y analizar los datos para extraer información útil.</p>
<h4>Herramientas Comunes para el Procesamiento</h4>
<ul>
<li><strong>Apache Spark:</strong> Un motor de procesamiento de datos masivos.</li>
<li><strong>Hadoop MapReduce:</strong> Un modelo de programación para el procesamiento de grandes volúmenes de datos.</li>
</ul>
<h4>Ejemplo de Procesamiento con Apache Spark</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIENyZWFyIHVuYSBzZXNpw7NuIGRlIFNwYXJrCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiTG9nQW5hbHlzaXMiKS5nZXRPckNyZWF0ZSgpCgojIExlZXIgbG9zIGxvZ3MgZGVzZGUgSERGUwpsb2dzX2RmID0gc3BhcmsucmVhZC5qc29uKCJoZGZzOi8vL2xvZ3MvbmdpbngvYWNjZXNzLmxvZyIpCgojIEZpbHRyYXIgbG9ncyBkZSBlcnJvcmVzCmVycm9yX2xvZ3NfZGYgPSBsb2dzX2RmLmZpbHRlcihsb2dzX2RmWyJzdGF0dXMiXSA+PSA0MDApCgojIENvbnRhciBlbCBuw7ptZXJvIGRlIGVycm9yZXMgcG9yIGhvc3QKZXJyb3JfY291bnRfYnlfaG9zdCA9IGVycm9yX2xvZ3NfZGYuZ3JvdXBCeSgiaG9zdCIpLmNvdW50KCkKCiMgTW9zdHJhciBsb3MgcmVzdWx0YWRvcwplcnJvcl9jb3VudF9ieV9ob3N0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Crear una sesi&oacute;n de Spark
spark = SparkSession.builder.appName(&quot;LogAnalysis&quot;).getOrCreate()

# Leer los logs desde HDFS
logs_df = spark.read.json(&quot;hdfs:///logs/nginx/access.log&quot;)

# Filtrar logs de errores
error_logs_df = logs_df.filter(logs_df[&quot;status&quot;] &gt;= 400)

# Contar el n&uacute;mero de errores por host
error_count_by_host = error_logs_df.groupBy(&quot;host&quot;).count()

# Mostrar los resultados
error_count_by_host.show()</pre></div><div class='content'><p><strong>Explicación:</strong></p>
<ul>
<li><strong>SparkSession:</strong> Punto de entrada para usar Spark.</li>
<li><strong>read.json:</strong> Lee los logs en formato JSON desde HDFS.</li>
<li><strong>filter:</strong> Filtra los logs con un estado HTTP mayor o igual a 400.</li>
<li><strong>groupBy:</strong> Agrupa los logs por host.</li>
<li><strong>count:</strong> Cuenta el número de errores por host.</li>
<li><strong>show:</strong> Muestra los resultados.</li>
</ul>
</div><h2><ol start="4">
<li>Análisis y Visualización</li>
</ol>
</h2>
<div class='content'><p>El análisis y la visualización de logs permiten identificar patrones y tendencias, así como detectar anomalías.</p>
<h4>Herramientas Comunes para la Visualización</h4>
<ul>
<li><strong>Kibana:</strong> Una herramienta de visualización para Elasticsearch.</li>
<li><strong>Grafana:</strong> Una plataforma de análisis y monitoreo.</li>
</ul>
<h4>Ejemplo de Visualización con Kibana</h4>
<ol>
<li>
<p><strong>Crear un índice en Kibana:</strong></p>
<ul>
<li>Navega a &quot;Management&quot; &gt; &quot;Index Patterns&quot;.</li>
<li>Crea un nuevo patrón de índice para los logs.</li>
</ul>
</li>
<li>
<p><strong>Crear una visualización:</strong></p>
<ul>
<li>Navega a &quot;Visualize&quot; &gt; &quot;Create visualization&quot;.</li>
<li>Selecciona el tipo de visualización (por ejemplo, gráfico de barras).</li>
<li>Configura la visualización para mostrar el número de errores por host.</li>
</ul>
</li>
</ol>
</div><h1><p>Ejercicio Práctico</p>
</h1>
<div class='content'></div><h2><p>Ejercicio 1: Configuración de Fluentd para Ingesta de Logs</p>
</h2>
<div class='content'><p><strong>Objetivo:</strong> Configurar Fluentd para ingerir logs de un servidor web y enviarlos a Elasticsearch.</p>
<p><strong>Pasos:</strong></p>
<ol>
<li>Instala Fluentd en tu servidor.</li>
<li>Configura Fluentd para leer logs de acceso de Nginx.</li>
<li>Configura Fluentd para enviar los logs a Elasticsearch.</li>
</ol>
<p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("PHNvdXJjZT4KICBAdHlwZSB0YWlsCiAgcGF0aCAvdmFyL2xvZy9uZ2lueC9hY2Nlc3MubG9nCiAgcG9zX2ZpbGUgL3Zhci9sb2cvdGQtYWdlbnQvbmdpbngtYWNjZXNzLmxvZy5wb3MKICB0YWcgbmdpbnguYWNjZXNzCiAgPHBhcnNlPgogICAgQHR5cGUgbmdpbngKICA8L3BhcnNlPgo8L3NvdXJjZT4KCjxtYXRjaCBuZ2lueC5hY2Nlc3M+CiAgQHR5cGUgZWxhc3RpY3NlYXJjaAogIGhvc3QgbG9jYWxob3N0CiAgcG9ydCA5MjAwCiAgbG9nc3Rhc2hfZm9ybWF0IHRydWUKICBpbmRleF9uYW1lIG5naW54LWxvZ3MKPC9tYXRjaD4="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>&lt;source&gt;
  @type tail
  path /var/log/nginx/access.log
  pos_file /var/log/td-agent/nginx-access.log.pos
  tag nginx.access
  &lt;parse&gt;
    @type nginx
  &lt;/parse&gt;
&lt;/source&gt;

&lt;match nginx.access&gt;
  @type elasticsearch
  host localhost
  port 9200
  logstash_format true
  index_name nginx-logs
&lt;/match&gt;</pre></div><div class='content'></div><h2><p>Ejercicio 2: Análisis de Logs con Apache Spark</p>
</h2>
<div class='content'><p><strong>Objetivo:</strong> Utilizar Apache Spark para analizar logs y contar el número de errores por host.</p>
<p><strong>Pasos:</strong></p>
<ol>
<li>Configura un clúster de Spark.</li>
<li>Carga los logs desde HDFS.</li>
<li>Filtra los logs de errores.</li>
<li>Cuenta el número de errores por host.</li>
<li>Muestra los resultados.</li>
</ol>
<p><strong>Solución:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrLnNxbCBpbXBvcnQgU3BhcmtTZXNzaW9uCgojIENyZWFyIHVuYSBzZXNpw7NuIGRlIFNwYXJrCnNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiTG9nQW5hbHlzaXMiKS5nZXRPckNyZWF0ZSgpCgojIExlZXIgbG9zIGxvZ3MgZGVzZGUgSERGUwpsb2dzX2RmID0gc3BhcmsucmVhZC5qc29uKCJoZGZzOi8vL2xvZ3MvbmdpbngvYWNjZXNzLmxvZyIpCgojIEZpbHRyYXIgbG9ncyBkZSBlcnJvcmVzCmVycm9yX2xvZ3NfZGYgPSBsb2dzX2RmLmZpbHRlcihsb2dzX2RmWyJzdGF0dXMiXSA+PSA0MDApCgojIENvbnRhciBlbCBuw7ptZXJvIGRlIGVycm9yZXMgcG9yIGhvc3QKZXJyb3JfY291bnRfYnlfaG9zdCA9IGVycm9yX2xvZ3NfZGYuZ3JvdXBCeSgiaG9zdCIpLmNvdW50KCkKCiMgTW9zdHJhciBsb3MgcmVzdWx0YWRvcwplcnJvcl9jb3VudF9ieV9ob3N0LnNob3coKQ=="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark.sql import SparkSession

# Crear una sesi&oacute;n de Spark
spark = SparkSession.builder.appName(&quot;LogAnalysis&quot;).getOrCreate()

# Leer los logs desde HDFS
logs_df = spark.read.json(&quot;hdfs:///logs/nginx/access.log&quot;)

# Filtrar logs de errores
error_logs_df = logs_df.filter(logs_df[&quot;status&quot;] &gt;= 400)

# Contar el n&uacute;mero de errores por host
error_count_by_host = error_logs_df.groupBy(&quot;host&quot;).count()

# Mostrar los resultados
error_count_by_host.show()</pre></div><div class='content'></div><h1><p>Conclusión</p>
</h1>
<div class='content'><p>En este caso de estudio, hemos aprendido cómo utilizar herramientas y técnicas de procesamiento de datos masivos para analizar logs de servidores. Hemos cubierto la ingesta, almacenamiento, procesamiento y visualización de logs, proporcionando una comprensión integral del flujo de trabajo de análisis de logs. Este conocimiento es fundamental para gestionar y optimizar sistemas a gran escala, detectar anomalías y mejorar la seguridad.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='06-03-visualizacion-datos' title="Visualización de Datos">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='07-02-caso-estudio-recomendaciones' title="Caso de Estudio 2: Recomendaciones en Tiempo Real">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
