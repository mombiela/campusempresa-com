<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    <title>Arquitecturas Avanzadas de CNN</title>

    <link rel="alternate" href="https://campusempresa.com/mod/tensorflow/05-04-advanced-cnn-architectures" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/tensorflow/05-04-advanced-cnn-architectures" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/tensorflow/05-04-advanced-cnn-architectures" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.ea63f62b9e.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "es";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "tensorflow";
  		var TEMA_NAME = "5-4";
  		var TYPE = "mod";
  		var PATH = "mod/tensorflow/05-04-advanced-cnn-architectures";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.86da6c742a.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/mod/tensorflow/05-04-advanced-cnn-architectures" class="px-2">EN</a></b>
	|
	<b class="px-2">ES</b>
	|
	<a href="https://campusempresa.cat/mod/tensorflow/05-04-advanced-cnn-architectures" class="px-2">CA</a>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Todo el conocimiento a tu alcance</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my_modules" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Mis cursos</b></i>
</a>
<a href="/end_modules" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalizados             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="tensorflow">
		<a  href="#" class="text-secondary d-none" data-read-mod="tensorflow" data-read-unit="5-4" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar como leído
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="tensorflow" data-unread-unit="5-4" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar como no leído
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contenido del curso
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-03-pooling-layers' title="Capas de Pooling" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-03-pooling-layers' title="Capas de Pooling" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h2 style="text-decoration:underline">Arquitecturas Avanzadas de CNN</h2>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='06-01-introduction-to-rnns' title="Introducción a RNNs" class="py-2 px-3 btn btn-primary"
				data-read-mod="tensorflow" data-read-unit="5-4">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='06-01-introduction-to-rnns' title="Introducción a RNNs" class="py-2 px-3 btn btn-primary" 
				data-read-mod="tensorflow" data-read-unit="5-4">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>En este módulo, exploraremos algunas de las arquitecturas más avanzadas y populares de Redes Neuronales Convolucionales (CNNs). Estas arquitecturas han demostrado ser extremadamente efectivas en una variedad de tareas de visión por computadora y han ganado múltiples competiciones en el campo. Aprenderemos sobre las siguientes arquitecturas:</p>
<ol>
<li><strong>AlexNet</strong></li>
<li><strong>VGGNet</strong></li>
<li><strong>Inception</strong></li>
<li><strong>ResNet</strong></li>
</ol>
</div><h1><ol>
<li>AlexNet</li>
</ol></h1>
<div class='content'></div><h2>Descripción</h2>
<div class='content'><p>AlexNet fue una de las primeras arquitecturas de CNN en demostrar un rendimiento superior en la competencia ImageNet en 2012. Introdujo varias innovaciones clave, como el uso de ReLU en lugar de funciones de activación sigmoide y el uso de dropout para reducir el sobreajuste.</p>
</div><h2>Arquitectura</h2>
<div class='content'><ul>
<li><strong>Capas Convolucionales</strong>: 5</li>
<li><strong>Capas Fully Connected</strong>: 3</li>
<li><strong>Funciones de Activación</strong>: ReLU</li>
<li><strong>Dropout</strong>: Sí</li>
<li><strong>Normalización Local de Respuesta (LRN)</strong>: Sí</li>
</ul>
</div><h2>Implementación en TensorFlow</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzIGltcG9ydCBsYXllcnMsIG1vZGVscwoKZGVmIGNyZWF0ZV9hbGV4bmV0KCk6CiAgICBtb2RlbCA9IG1vZGVscy5TZXF1ZW50aWFsKCkKICAgIG1vZGVsLmFkZChsYXllcnMuQ29udjJEKDk2LCAoMTEsIDExKSwgc3RyaWRlcz00LCBhY3RpdmF0aW9uPSdyZWx1JywgaW5wdXRfc2hhcGU9KDIyNywgMjI3LCAzKSkpCiAgICBtb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMywgMyksIHN0cmlkZXM9MikpCiAgICBtb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgyNTYsICg1LCA1KSwgcGFkZGluZz0nc2FtZScsIGFjdGl2YXRpb249J3JlbHUnKSkKICAgIG1vZGVsLmFkZChsYXllcnMuTWF4UG9vbGluZzJEKCgzLCAzKSwgc3RyaWRlcz0yKSkKICAgIG1vZGVsLmFkZChsYXllcnMuQ29udjJEKDM4NCwgKDMsIDMpLCBwYWRkaW5nPSdzYW1lJywgYWN0aXZhdGlvbj0ncmVsdScpKQogICAgbW9kZWwuYWRkKGxheWVycy5Db252MkQoMzg0LCAoMywgMyksIHBhZGRpbmc9J3NhbWUnLCBhY3RpdmF0aW9uPSdyZWx1JykpCiAgICBtb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgyNTYsICgzLCAzKSwgcGFkZGluZz0nc2FtZScsIGFjdGl2YXRpb249J3JlbHUnKSkKICAgIG1vZGVsLmFkZChsYXllcnMuTWF4UG9vbGluZzJEKCgzLCAzKSwgc3RyaWRlcz0yKSkKICAgIG1vZGVsLmFkZChsYXllcnMuRmxhdHRlbigpKQogICAgbW9kZWwuYWRkKGxheWVycy5EZW5zZSg0MDk2LCBhY3RpdmF0aW9uPSdyZWx1JykpCiAgICBtb2RlbC5hZGQobGF5ZXJzLkRyb3BvdXQoMC41KSkKICAgIG1vZGVsLmFkZChsYXllcnMuRGVuc2UoNDA5NiwgYWN0aXZhdGlvbj0ncmVsdScpKQogICAgbW9kZWwuYWRkKGxheWVycy5Ecm9wb3V0KDAuNSkpCiAgICBtb2RlbC5hZGQobGF5ZXJzLkRlbnNlKDEwMDAsIGFjdGl2YXRpb249J3NvZnRtYXgnKSkKICAgIHJldHVybiBtb2RlbAoKYWxleG5ldCA9IGNyZWF0ZV9hbGV4bmV0KCkKYWxleG5ldC5zdW1tYXJ5KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import layers, models

def create_alexnet():
    model = models.Sequential()
    model.add(layers.Conv2D(96, (11, 11), strides=4, activation='relu', input_shape=(227, 227, 3)))
    model.add(layers.MaxPooling2D((3, 3), strides=2))
    model.add(layers.Conv2D(256, (5, 5), padding='same', activation='relu'))
    model.add(layers.MaxPooling2D((3, 3), strides=2))
    model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))
    model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))
    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
    model.add(layers.MaxPooling2D((3, 3), strides=2))
    model.add(layers.Flatten())
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(1000, activation='softmax'))
    return model

alexnet = create_alexnet()
alexnet.summary()</pre></div><div class='content'></div><h1><ol start="2">
<li>VGGNet</li>
</ol></h1>
<div class='content'></div><h2>Descripción</h2>
<div class='content'><p>VGGNet, desarrollado por el Visual Geometry Group de la Universidad de Oxford, se destacó en la competencia ImageNet 2014. Su principal contribución fue demostrar que la profundidad de la red es un factor crítico para el rendimiento.</p>
</div><h2>Arquitectura</h2>
<div class='content'><ul>
<li><strong>Capas Convolucionales</strong>: 16-19</li>
<li><strong>Capas Fully Connected</strong>: 3</li>
<li><strong>Funciones de Activación</strong>: ReLU</li>
<li><strong>Tamaño de Filtro</strong>: 3x3</li>
</ul>
</div><h2>Implementación en TensorFlow</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGNyZWF0ZV92Z2cxNigpOgogICAgbW9kZWwgPSBtb2RlbHMuU2VxdWVudGlhbCgpCiAgICBtb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg2NCwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JywgcGFkZGluZz0nc2FtZScsIGlucHV0X3NoYXBlPSgyMjQsIDIyNCwgMykpKQogICAgbW9kZWwuYWRkKGxheWVycy5Db252MkQoNjQsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScsIHBhZGRpbmc9J3NhbWUnKSkKICAgIG1vZGVsLmFkZChsYXllcnMuTWF4UG9vbGluZzJEKCgyLCAyKSkpCiAgICAKICAgIG1vZGVsLmFkZChsYXllcnMuQ29udjJEKDEyOCwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JywgcGFkZGluZz0nc2FtZScpKQogICAgbW9kZWwuYWRkKGxheWVycy5Db252MkQoMTI4LCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnLCBwYWRkaW5nPSdzYW1lJykpCiAgICBtb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQogICAgCiAgICBtb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCgyNTYsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScsIHBhZGRpbmc9J3NhbWUnKSkKICAgIG1vZGVsLmFkZChsYXllcnMuQ29udjJEKDI1NiwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JywgcGFkZGluZz0nc2FtZScpKQogICAgbW9kZWwuYWRkKGxheWVycy5Db252MkQoMjU2LCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnLCBwYWRkaW5nPSdzYW1lJykpCiAgICBtb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQogICAgCiAgICBtb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg1MTIsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScsIHBhZGRpbmc9J3NhbWUnKSkKICAgIG1vZGVsLmFkZChsYXllcnMuQ29udjJEKDUxMiwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JywgcGFkZGluZz0nc2FtZScpKQogICAgbW9kZWwuYWRkKGxheWVycy5Db252MkQoNTEyLCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnLCBwYWRkaW5nPSdzYW1lJykpCiAgICBtb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQogICAgCiAgICBtb2RlbC5hZGQobGF5ZXJzLkNvbnYyRCg1MTIsICgzLCAzKSwgYWN0aXZhdGlvbj0ncmVsdScsIHBhZGRpbmc9J3NhbWUnKSkKICAgIG1vZGVsLmFkZChsYXllcnMuQ29udjJEKDUxMiwgKDMsIDMpLCBhY3RpdmF0aW9uPSdyZWx1JywgcGFkZGluZz0nc2FtZScpKQogICAgbW9kZWwuYWRkKGxheWVycy5Db252MkQoNTEyLCAoMywgMyksIGFjdGl2YXRpb249J3JlbHUnLCBwYWRkaW5nPSdzYW1lJykpCiAgICBtb2RlbC5hZGQobGF5ZXJzLk1heFBvb2xpbmcyRCgoMiwgMikpKQogICAgCiAgICBtb2RlbC5hZGQobGF5ZXJzLkZsYXR0ZW4oKSkKICAgIG1vZGVsLmFkZChsYXllcnMuRGVuc2UoNDA5NiwgYWN0aXZhdGlvbj0ncmVsdScpKQogICAgbW9kZWwuYWRkKGxheWVycy5EZW5zZSg0MDk2LCBhY3RpdmF0aW9uPSdyZWx1JykpCiAgICBtb2RlbC5hZGQobGF5ZXJzLkRlbnNlKDEwMDAsIGFjdGl2YXRpb249J3NvZnRtYXgnKSkKICAgIHJldHVybiBtb2RlbAoKdmdnMTYgPSBjcmVhdGVfdmdnMTYoKQp2Z2cxNi5zdW1tYXJ5KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def create_vgg16():
    model = models.Sequential()
    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    
    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    
    model.add(layers.Flatten())
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dense(1000, activation='softmax'))
    return model

vgg16 = create_vgg16()
vgg16.summary()</pre></div><div class='content'></div><h1><ol start="3">
<li>Inception</li>
</ol></h1>
<div class='content'></div><h2>Descripción</h2>
<div class='content'><p>La arquitectura Inception, también conocida como GoogLeNet, fue introducida por Google en 2014. Su principal innovación es el uso de módulos Inception, que permiten a la red elegir entre múltiples tamaños de filtro en cada capa.</p>
</div><h2>Arquitectura</h2>
<div class='content'><ul>
<li><strong>Módulos Inception</strong>: Sí</li>
<li><strong>Capas Convolucionales</strong>: Varias</li>
<li><strong>Capas Fully Connected</strong>: 1</li>
<li><strong>Funciones de Activación</strong>: ReLU</li>
</ul>
</div><h2>Implementación en TensorFlow</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def inception_module(x, filters):
    f1, f3_r, f3, f5_r, f5, pool_proj = filters
    
    conv1 = layers.Conv2D(f1, (1, 1), padding='same', activation='relu')(x)
    
    conv3 = layers.Conv2D(f3_r, (1, 1), padding='same', activation='relu')(x)
    conv3 = layers.Conv2D(f3, (3, 3), padding='same', activation='relu')(conv3)
    
    conv5 = layers.Conv2D(f5_r, (1, 1), padding='same', activation='relu')(x)
    conv5 = layers.Conv2D(f5, (5, 5), padding='same', activation='relu')(conv5)
    
    pool = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)
    pool = layers.Conv2D(pool_proj, (1, 1), padding='same', activation='relu')(pool)
    
    return layers.concatenate([conv1, conv3, conv5, pool], axis=-1)

def create_inception():
    input_layer = layers.Input(shape=(224, 224, 3))
    x = layers.Conv2D(64, (7, 7), strides=2, padding='same', activation='relu')(input_layer)
    x = layers.MaxPooling2D((3, 3), strides=2, padding='same')(x)
    x = layers.Conv2D(192, (3, 3), padding='same', activation='relu')(x)
    x = layers.MaxPooling2D((3, 3), strides=2, padding='same')(x)
    
    x = inception_module(x, [64, 96, 128, 16, 32, 32])
    x = inception_module(x, [128, 128, 192, 32, 96, 64])
    x = layers.MaxPooling2D((3, 3), strides=2, padding='same')(x)
    
    x = inception_module(x, [192, 96, 208, 16, 48, 64])
    x = inception_module(x, [160, 112, 224, 24, 64, 64])
    x = inception_module(x, [128, 128, 256, 24, 64, 64])
    x = inception_module(x, [112, 144, 288, 32, 64, 64])
    x = inception_module(x, [256, 160, 320, 32, 128, 128])
    x = layers.MaxPooling2D((3, 3), strides=2, padding='same')(x)
    
    x = inception_module(x, [256, 160, 320, 32, 128, 128])
    x = inception_module(x, [384, 192, 384, 48, 128, 128])
    
    x = layers.GlobalAveragePooling2D()(x)
    output_layer = layers.Dense(1000, activation='softmax')(x)
    
    model = models.Model(input_layer, output_layer)
    return model

inception = create_inception()
inception.summary()</pre></div><div class='content'></div><h1><ol start="4">
<li>ResNet</li>
</ol></h1>
<div class='content'></div><h2>Descripción</h2>
<div class='content'><p>ResNet, o Redes Residuales, fue introducida por Microsoft en 2015 y ganó la competencia ImageNet. Su principal innovación es el uso de conexiones residuales, que permiten entrenar redes mucho más profundas sin problemas de degradación.</p>
</div><h2>Arquitectura</h2>
<div class='content'><ul>
<li><strong>Bloques Residuales</strong>: Sí</li>
<li><strong>Capas Convolucionales</strong>: Varias</li>
<li><strong>Capas Fully Connected</strong>: 1</li>
<li><strong>Funciones de Activación</strong>: ReLU</li>
</ul>
</div><h2>Implementación en TensorFlow</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIHJlc2lkdWFsX2Jsb2NrKHgsIGZpbHRlcnMsIGtlcm5lbF9zaXplPTMsIHN0cmlkZT0xLCBjb252X3Nob3J0Y3V0PVRydWUpOgogICAgaWYgY29udl9zaG9ydGN1dDoKICAgICAgICBzaG9ydGN1dCA9IGxheWVycy5Db252MkQoNCAqIGZpbHRlcnMsIDEsIHN0cmlkZXM9c3RyaWRlKSh4KQogICAgICAgIHNob3J0Y3V0ID0gbGF5ZXJzLkJhdGNoTm9ybWFsaXphdGlvbigpKHNob3J0Y3V0KQogICAgZWxzZToKICAgICAgICBzaG9ydGN1dCA9IHgKCiAgICB4ID0gbGF5ZXJzLkNvbnYyRChmaWx0ZXJzLCAxLCBzdHJpZGVzPXN0cmlkZSkoeCkKICAgIHggPSBsYXllcnMuQmF0Y2hOb3JtYWxpemF0aW9uKCkoeCkKICAgIHggPSBsYXllcnMuQWN0aXZhdGlvbigncmVsdScpKHgpCgogICAgeCA9IGxheWVycy5Db252MkQoZmlsdGVycywga2VybmVsX3NpemUsIHBhZGRpbmc9J3NhbWUnKSh4KQogICAgeCA9IGxheWVycy5CYXRjaE5vcm1hbGl6YXRpb24oKSh4KQogICAgeCA9IGxheWVycy5BY3RpdmF0aW9uKCdyZWx1JykoeCkKCiAgICB4ID0gbGF5ZXJzLkNvbnYyRCg0ICogZmlsdGVycywgMSkoeCkKICAgIHggPSBsYXllcnMuQmF0Y2hOb3JtYWxpemF0aW9uKCkoeCkKCiAgICB4ID0gbGF5ZXJzLmFkZChbc2hvcnRjdXQsIHhdKQogICAgeCA9IGxheWVycy5BY3RpdmF0aW9uKCdyZWx1JykoeCkKICAgIHJldHVybiB4CgpkZWYgY3JlYXRlX3Jlc25ldDUwKCk6CiAgICBpbnB1dF9sYXllciA9IGxheWVycy5JbnB1dChzaGFwZT0oMjI0LCAyMjQsIDMpKQogICAgeCA9IGxheWVycy5Db252MkQoNjQsIDcsIHN0cmlkZXM9MiwgcGFkZGluZz0nc2FtZScpKGlucHV0X2xheWVyKQogICAgeCA9IGxheWVycy5CYXRjaE5vcm1hbGl6YXRpb24oKSh4KQogICAgeCA9IGxheWVycy5BY3RpdmF0aW9uKCdyZWx1JykoeCkKICAgIHggPSBsYXllcnMuTWF4UG9vbGluZzJEKDMsIHN0cmlkZXM9MiwgcGFkZGluZz0nc2FtZScpKHgpCgogICAgeCA9IHJlc2lkdWFsX2Jsb2NrKHgsIDY0LCBjb252X3Nob3J0Y3V0PUZhbHNlKQogICAgeCA9IHJlc2lkdWFsX2Jsb2NrKHgsIDY0KQogICAgeCA9IHJlc2lkdWFsX2Jsb2NrKHgsIDY0KQoKICAgIHggPSByZXNpZHVhbF9ibG9jayh4LCAxMjgsIHN0cmlkZT0yKQogICAgeCA9IHJlc2lkdWFsX2Jsb2NrKHgsIDEyOCkKICAgIHggPSByZXNpZHVhbF9ibG9jayh4LCAxMjgpCiAgICB4ID0gcmVzaWR1YWxfYmxvY2soeCwgMTI4KQoKICAgIHggPSByZXNpZHVhbF9ibG9jayh4LCAyNTYsIHN0cmlkZT0yKQogICAgeCA9IHJlc2lkdWFsX2Jsb2NrKHgsIDI1NikKICAgIHggPSByZXNpZHVhbF9ibG9jayh4LCAyNTYpCiAgICB4ID0gcmVzaWR1YWxfYmxvY2soeCwgMjU2KQogICAgeCA9IHJlc2lkdWFsX2Jsb2NrKHgsIDI1NikKICAgIHggPSByZXNpZHVhbF9ibG9jayh4LCAyNTYpCgogICAgeCA9IHJlc2lkdWFsX2Jsb2NrKHgsIDUxMiwgc3RyaWRlPTIpCiAgICB4ID0gcmVzaWR1YWxfYmxvY2soeCwgNTEyKQogICAgeCA9IHJlc2lkdWFsX2Jsb2NrKHgsIDUxMikKCiAgICB4ID0gbGF5ZXJzLkdsb2JhbEF2ZXJhZ2VQb29saW5nMkQoKSh4KQogICAgb3V0cHV0X2xheWVyID0gbGF5ZXJzLkRlbnNlKDEwMDAsIGFjdGl2YXRpb249J3NvZnRtYXgnKSh4KQoKICAgIG1vZGVsID0gbW9kZWxzLk1vZGVsKGlucHV0X2xheWVyLCBvdXRwdXRfbGF5ZXIpCiAgICByZXR1cm4gbW9kZWwKCnJlc25ldDUwID0gY3JlYXRlX3Jlc25ldDUwKCkKcmVzbmV0NTAuc3VtbWFyeSgp"))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True):
    if conv_shortcut:
        shortcut = layers.Conv2D(4 * filters, 1, strides=stride)(x)
        shortcut = layers.BatchNormalization()(shortcut)
    else:
        shortcut = x

    x = layers.Conv2D(filters, 1, strides=stride)(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)

    x = layers.Conv2D(filters, kernel_size, padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)

    x = layers.Conv2D(4 * filters, 1)(x)
    x = layers.BatchNormalization()(x)

    x = layers.add([shortcut, x])
    x = layers.Activation('relu')(x)
    return x

def create_resnet50():
    input_layer = layers.Input(shape=(224, 224, 3))
    x = layers.Conv2D(64, 7, strides=2, padding='same')(input_layer)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)

    x = residual_block(x, 64, conv_shortcut=False)
    x = residual_block(x, 64)
    x = residual_block(x, 64)

    x = residual_block(x, 128, stride=2)
    x = residual_block(x, 128)
    x = residual_block(x, 128)
    x = residual_block(x, 128)

    x = residual_block(x, 256, stride=2)
    x = residual_block(x, 256)
    x = residual_block(x, 256)
    x = residual_block(x, 256)
    x = residual_block(x, 256)
    x = residual_block(x, 256)

    x = residual_block(x, 512, stride=2)
    x = residual_block(x, 512)
    x = residual_block(x, 512)

    x = layers.GlobalAveragePooling2D()(x)
    output_layer = layers.Dense(1000, activation='softmax')(x)

    model = models.Model(input_layer, output_layer)
    return model

resnet50 = create_resnet50()
resnet50.summary()</pre></div><div class='content'></div><h1>Conclusión</h1>
<div class='content'><p>En esta sección, hemos explorado algunas de las arquitecturas más avanzadas de CNN, incluyendo AlexNet, VGGNet, Inception y ResNet. Cada una de estas arquitecturas ha contribuido significativamente al campo de la visión por computadora y ha introducido innovaciones clave que han mejorado el rendimiento de las redes neuronales. En el próximo módulo, profundizaremos en las Redes Neuronales Recurrentes (RNNs) y sus aplicaciones.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-03-pooling-layers' title="Capas de Pooling" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-03-pooling-layers' title="Capas de Pooling" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='06-01-introduction-to-rnns' title="Introducción a RNNs" class="py-2 px-3 btn btn-primary"
				data-read-mod="tensorflow" data-read-unit="5-4">
				Siguiente &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='06-01-introduction-to-rnns' title="Introducción a RNNs" class="py-2 px-3 btn btn-primary" 
				data-read-mod="tensorflow" data-read-unit="5-4">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curso de TensorFlow</h1>
<h2>Módulo 1: Introducción a TensorFlow</h2>
<ul>
<li><a href="01-01-what-is-tensorflow">¿Qué es TensorFlow?</a></li>
<li><a href="01-02-setting-up-tensorflow">Configuración de TensorFlow</a></li>
<li><a href="01-03-basic-tensorflow-concepts">Conceptos Básicos de TensorFlow</a></li>
<li><a href="01-04-tensorflow-hello-world">Hola Mundo en TensorFlow</a></li>
</ul>
<h2>Módulo 2: Fundamentos de TensorFlow</h2>
<ul>
<li><a href="02-01-tensors-and-operations">Tensores y Operaciones</a></li>
<li><a href="02-02-variables-and-constants">Variables y Constantes</a></li>
<li><a href="02-03-tensorflow-graphs">Grafos de TensorFlow</a></li>
<li><a href="02-04-eager-execution">Ejecución Eager</a></li>
</ul>
<h2>Módulo 3: Manejo de Datos en TensorFlow</h2>
<ul>
<li><a href="03-01-loading-data">Cargando Datos</a></li>
<li><a href="03-02-data-pipelines-with-tf-data">Pipelines de Datos con tf.data</a></li>
<li><a href="03-03-data-augmentation">Aumento de Datos</a></li>
<li><a href="03-04-working-with-datasets">Trabajando con Conjuntos de Datos</a></li>
</ul>
<h2>Módulo 4: Construcción de Redes Neuronales</h2>
<ul>
<li><a href="04-01-introduction-to-neural-networks">Introducción a Redes Neuronales</a></li>
<li><a href="04-02-creating-a-simple-neural-network">Creando una Red Neuronal Simple</a></li>
<li><a href="04-03-activation-functions">Funciones de Activación</a></li>
<li><a href="04-04-loss-functions-and-optimizers">Funciones de Pérdida y Optimizadores</a></li>
</ul>
<h2>Módulo 5: Redes Neuronales Convolucionales (CNNs)</h2>
<ul>
<li><a href="05-01-introduction-to-cnns">Introducción a CNNs</a></li>
<li><a href="05-02-building-a-cnn">Construyendo una CNN</a></li>
<li><a href="05-03-pooling-layers">Capas de Pooling</a></li>
<li><a href="05-04-advanced-cnn-architectures">Arquitecturas Avanzadas de CNN</a></li>
</ul>
<h2>Módulo 6: Redes Neuronales Recurrentes (RNNs)</h2>
<ul>
<li><a href="06-01-introduction-to-rnns">Introducción a RNNs</a></li>
<li><a href="06-02-building-an-rnn">Construyendo una RNN</a></li>
<li><a href="06-03-long-short-term-memory">Memoria a Largo Plazo (LSTM)</a></li>
<li><a href="06-04-gated-recurrent-units">Unidades Recurrentes Gated (GRUs)</a></li>
</ul>
<h2>Módulo 7: Técnicas Avanzadas de TensorFlow</h2>
<ul>
<li><a href="07-01-custom-layers-and-models">Capas y Modelos Personalizados</a></li>
<li><a href="07-02-tensorflow-hub">TensorFlow Hub</a></li>
<li><a href="07-03-transfer-learning">Aprendizaje por Transferencia</a></li>
<li><a href="07-04-hyperparameter-tuning">Ajuste de Hiperparámetros</a></li>
</ul>
<h2>Módulo 8: TensorFlow para Producción</h2>
<ul>
<li><a href="08-01-model-saving-and-loading">Guardado y Carga de Modelos</a></li>
<li><a href="08-02-tensorflow-serving">TensorFlow Serving</a></li>
<li><a href="08-03-deploying-models">Despliegue de Modelos</a></li>
<li><a href="08-04-monitoring-and-maintenance">Monitoreo y Mantenimiento</a></li>
</ul>
<h2>Módulo 9: TensorFlow Extendido (TFX)</h2>
<ul>
<li><a href="09-01-introduction-to-tfx">Introducción a TFX</a></li>
<li><a href="09-02-data-validation">Validación de Datos</a></li>
<li><a href="09-03-transforming-data">Transformación de Datos</a></li>
<li><a href="09-04-model-analysis">Análisis de Modelos</a></li>
</ul>
<h2>Módulo 10: Temas Especiales</h2>
<ul>
<li><a href="10-01-tensorflow-lite">TensorFlow Lite</a></li>
<li><a href="10-02-tensorflow-js">TensorFlow.js</a></li>
<li><a href="10-03-tensorflow-federated">TensorFlow Federated</a></li>
<li><a href="10-04-tensorflow-quantum">TensorFlow Quantum</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Proyecto</a> | 
<a href="/about">Sobre nosotros</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donaciones</a> | 
<a href="/licence">Licencia</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Usamos cookies para mejorar tu experiencia de uso y ofrecer contenidos adaptados a tus intereses.
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuario no autenticado</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<p id="loginModalEmail"></p>
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
