<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Apache Spark</title>

    <link rel="alternate" href="https://campusempresa.com/mod/big_data/03-02-apache-spark" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/big_data/03-02-apache-spark" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/big_data/03-02-apache-spark" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 px-0 py-2 py-md-0 text-end">
			<h2 id="main_title"><cite>Construyendo la sociedad de hoy y del mañana</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 px-0 py-2 py-md-0 m-0 text-end">
										<a href="https://enterprisecampus.net/mod/big_data/03-02-apache-spark" class="px-2">EN</a></b>
				|
				<b class="px-2">ES</b>
				|
				<a href="https://campusempresa.cat/mod/big_data/03-02-apache-spark" class="px-2">CA</a>
								</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Proyecto</a>
				<a href="/about">Sobre nosotros</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donaciones</a>
				<a href="/licence">Licencia</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='03-01-mapreduce-hadoop' title="MapReduce y Hadoop">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Apache Spark</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='03-03-procesamiento-tiempo-real' title="Procesamiento en Tiempo Real">Siguiente &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducción a Apache Spark</h1>
<div class='content'><p>Apache Spark es una plataforma de procesamiento de datos en clústeres de código abierto diseñada para ser rápida y de propósito general. Spark proporciona una interfaz para la programación de clústeres completos con paralelismo implícito y tolerancia a fallos.</p>
</div><h2>Características Clave de Apache Spark</h2>
<div class='content'><ol>
<li><strong>Velocidad</strong>: Spark puede ejecutar aplicaciones hasta 100 veces más rápido en memoria y 10 veces más rápido en disco que Hadoop MapReduce.</li>
<li><strong>Facilidad de Uso</strong>: Spark tiene APIs fáciles de usar para Scala, Java, Python y R.</li>
<li><strong>Generalidad</strong>: Spark combina SQL, streaming, y análisis complejos en una sola plataforma.</li>
<li><strong>Compatibilidad con Hadoop</strong>: Spark puede ejecutarse en Hadoop, Mesos, Kubernetes, en la nube o de forma independiente.</li>
</ol>
</div><h2>Componentes de Apache Spark</h2>
<div class='content'><ol>
<li><strong>Spark Core</strong>: El motor de procesamiento subyacente responsable de la programación, optimización y ejecución de tareas.</li>
<li><strong>Spark SQL</strong>: Un módulo para trabajar con datos estructurados utilizando SQL.</li>
<li><strong>Spark Streaming</strong>: Permite el procesamiento de flujos de datos en tiempo real.</li>
<li><strong>MLlib (Machine Learning Library)</strong>: Una biblioteca de aprendizaje automático escalable.</li>
<li><strong>GraphX</strong>: Una API para gráficos y cálculos paralelos de gráficos.</li>
</ol>
</div><h1>Instalación de Apache Spark</h1>
<div class='content'></div><h2>Requisitos Previos</h2>
<div class='content'><ul>
<li><strong>Java</strong>: Spark requiere Java 8 o superior.</li>
<li><strong>Scala</strong>: Aunque no es obligatorio, Scala es el lenguaje nativo de Spark.</li>
<li><strong>Python</strong>: Para usar PySpark, la API de Python para Spark.</li>
</ul>
</div><h2>Pasos de Instalación</h2>
<div class='content'><ol>
<li>
<p><strong>Descargar Apache Spark</strong>:</p>
<pre><code class="language-bash">wget https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz
</code></pre>
</li>
<li>
<p><strong>Extraer el archivo descargado</strong>:</p>
<pre><code class="language-bash">tar -xvzf spark-3.1.2-bin-hadoop2.7.tgz
</code></pre>
</li>
<li>
<p><strong>Configurar las variables de entorno</strong>:</p>
<pre><code class="language-bash">export SPARK_HOME=~/spark-3.1.2-bin-hadoop2.7
export PATH=$PATH:$SPARK_HOME/bin
</code></pre>
</li>
<li>
<p><strong>Verificar la instalación</strong>:</p>
<pre><code class="language-bash">spark-shell
</code></pre>
</li>
</ol>
</div><h1>Programación con Apache Spark</h1>
<div class='content'></div><h2>RDD (Resilient Distributed Datasets)</h2>
<div class='content'><p>Los RDD son la abstracción principal de Spark, representando una colección inmutable de objetos que se pueden dividir en particiones y procesar en paralelo.</p>
<h4>Creación de un RDD</h4>
<ol>
<li>
<p><strong>Desde una colección</strong>:</p>
<pre><code class="language-python">from pyspark import SparkContext
sc = SparkContext(&quot;local&quot;, &quot;Simple App&quot;)
data = [1, 2, 3, 4, 5]
rdd = sc.parallelize(data)
</code></pre>
</li>
<li>
<p><strong>Desde un archivo</strong>:</p>
<pre><code class="language-python">rdd = sc.textFile(&quot;path/to/file.txt&quot;)
</code></pre>
</li>
</ol>
<h4>Operaciones en RDD</h4>
<ol>
<li>
<p><strong>Transformaciones</strong>: Crean un nuevo RDD a partir de uno existente.</p>
<ul>
<li><code>map()</code>: Aplica una función a cada elemento del RDD.
<pre><code class="language-python">rdd2 = rdd.map(lambda x: x * 2)
</code></pre>
</li>
<li><code>filter()</code>: Filtra los elementos del RDD según una función.
<pre><code class="language-python">rdd3 = rdd.filter(lambda x: x % 2 == 0)
</code></pre>
</li>
</ul>
</li>
<li>
<p><strong>Acciones</strong>: Devuelven un valor al controlador después de ejecutar una computación en el RDD.</p>
<ul>
<li><code>collect()</code>: Devuelve todos los elementos del RDD.
<pre><code class="language-python">result = rdd.collect()
</code></pre>
</li>
<li><code>count()</code>: Devuelve el número de elementos en el RDD.
<pre><code class="language-python">count = rdd.count()
</code></pre>
</li>
</ul>
</li>
</ol>
</div><h2>DataFrames y Spark SQL</h2>
<div class='content'><p>Los DataFrames son una abstracción de datos estructurados distribuidos, similar a una tabla en una base de datos relacional.</p>
<h4>Creación de un DataFrame</h4>
<ol>
<li>
<p><strong>Desde un RDD</strong>:</p>
<pre><code class="language-python">from pyspark.sql import SparkSession
spark = SparkSession.builder.appName(&quot;example&quot;).getOrCreate()
df = spark.createDataFrame(rdd, schema=[&quot;value&quot;])
</code></pre>
</li>
<li>
<p><strong>Desde un archivo CSV</strong>:</p>
<pre><code class="language-python">df = spark.read.csv(&quot;path/to/file.csv&quot;, header=True, inferSchema=True)
</code></pre>
</li>
</ol>
<h4>Operaciones en DataFrames</h4>
<ol>
<li>
<p><strong>Selección de columnas</strong>:</p>
<pre><code class="language-python">df.select(&quot;column_name&quot;).show()
</code></pre>
</li>
<li>
<p><strong>Filtrado de filas</strong>:</p>
<pre><code class="language-python">df.filter(df[&quot;column_name&quot;] &gt; 10).show()
</code></pre>
</li>
<li>
<p><strong>Agrupación y agregación</strong>:</p>
<pre><code class="language-python">df.groupBy(&quot;column_name&quot;).count().show()
</code></pre>
</li>
</ol>
</div><h2>Ejercicio Práctico</h2>
<div class='content'><h4>Objetivo</h4>
<p>Procesar un archivo de texto para contar la frecuencia de cada palabra.</p>
<h4>Código</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSBweXNwYXJrIGltcG9ydCBTcGFya0NvbnRleHQKZnJvbSBvcGVyYXRvciBpbXBvcnQgYWRkCgojIEluaWNpYWxpemFyIFNwYXJrQ29udGV4dApzYyA9IFNwYXJrQ29udGV4dCgibG9jYWwiLCAiV29yZCBDb3VudCIpCgojIExlZXIgZWwgYXJjaGl2byBkZSB0ZXh0bwp0ZXh0X2ZpbGUgPSBzYy50ZXh0RmlsZSgicGF0aC90by90ZXh0ZmlsZS50eHQiKQoKIyBDb250YXIgbGEgZnJlY3VlbmNpYSBkZSBjYWRhIHBhbGFicmEKY291bnRzID0gKHRleHRfZmlsZS5mbGF0TWFwKGxhbWJkYSBsaW5lOiBsaW5lLnNwbGl0KCIgIikpCiAgICAgICAgICAgICAgICAgICAgLm1hcChsYW1iZGEgd29yZDogKHdvcmQsIDEpKQogICAgICAgICAgICAgICAgICAgIC5yZWR1Y2VCeUtleShhZGQpKQoKIyBNb3N0cmFyIGxvcyByZXN1bHRhZG9zCmNvdW50cy5jb2xsZWN0KCk="))));alert("¡Copiado!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from pyspark import SparkContext
from operator import add

# Inicializar SparkContext
sc = SparkContext(&quot;local&quot;, &quot;Word Count&quot;)

# Leer el archivo de texto
text_file = sc.textFile(&quot;path/to/textfile.txt&quot;)

# Contar la frecuencia de cada palabra
counts = (text_file.flatMap(lambda line: line.split(&quot; &quot;))
                    .map(lambda word: (word, 1))
                    .reduceByKey(add))

# Mostrar los resultados
counts.collect()</pre></div><div class='content'><h4>Explicación</h4>
<ol>
<li><strong>Leer el archivo de texto</strong>: <code>sc.textFile(&quot;path/to/textfile.txt&quot;)</code> carga el archivo como un RDD.</li>
<li><strong>Dividir las líneas en palabras</strong>: <code>flatMap(lambda line: line.split(&quot; &quot;))</code> divide cada línea en palabras.</li>
<li><strong>Mapear cada palabra a un par (palabra, 1)</strong>: <code>map(lambda word: (word, 1))</code> crea pares clave-valor.</li>
<li><strong>Reducir por clave para contar las palabras</strong>: <code>reduceByKey(add)</code> suma los valores para cada clave.</li>
<li><strong>Recoger y mostrar los resultados</strong>: <code>counts.collect()</code> devuelve los resultados al controlador.</li>
</ol>
</div><h2>Resumen</h2>
<div class='content'><p>En esta sección, hemos cubierto los conceptos básicos de Apache Spark, incluyendo sus componentes clave, la instalación, y la programación con RDDs y DataFrames. También hemos proporcionado un ejercicio práctico para contar la frecuencia de palabras en un archivo de texto. Con estos conocimientos, estás preparado para explorar más a fondo el procesamiento de Big Data con Apache Spark.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='03-01-mapreduce-hadoop' title="MapReduce y Hadoop">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='03-03-procesamiento-tiempo-real' title="Procesamiento en Tiempo Real">Siguiente &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicidad</h1>
			<p>Este espacio está destinado a publicidad.</p>
			<p>Si quieres ser patrocinador, contáctanos para incluir enlaces en esta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>¡Gracias por colaborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Todos los derechos reservados</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Aceptar</a>
    <a href="/cookies">Mas información</a>
</div>	

	</div>    
</body>
</html>
